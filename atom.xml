<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Palette</title>
  <icon>https://www.gravatar.com/avatar/f6d0550c9229791f51dcfd63ef1e86d9</icon>
  <subtitle>个人博客</subtitle>
  <link href="https://palette-k.github.io/atom.xml" rel="self"/>
  
  <link href="https://palette-k.github.io/"/>
  <updated>2025-10-17T07:20:47.362Z</updated>
  <id>https://palette-k.github.io/</id>
  
  <author>
    <name>Palette</name>
    <email>1148432487@qq.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>RocketMQ消息模型提升AI通信效率</title>
    <link href="https://palette-k.github.io/2025/10/17/RocketMQ%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8D%87AI%E9%80%9A%E4%BF%A1%E6%95%88%E7%8E%87/"/>
    <id>https://palette-k.github.io/2025/10/17/RocketMQ%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B%E6%8F%90%E5%8D%87AI%E9%80%9A%E4%BF%A1%E6%95%88%E7%8E%87/</id>
    <published>2025-10-17T06:49:26.000Z</published>
    <updated>2025-10-17T07:20:47.362Z</updated>
    
    <content type="html"><![CDATA[<h1 id="传统消息队列在-AI-场景的局限性"><a href="#传统消息队列在-AI-场景的局限性" class="headerlink" title="传统消息队列在 AI 场景的局限性"></a>传统消息队列在 AI 场景的局限性</h1><p>在传统互联网应用中，消息队列广泛用于服务解耦、异步通信和削峰填谷等场景。它通过异步化的事件驱动方式，提升系统可扩展性与稳定性。典型场景如订单处理、日志收集、通知推送等。传统消息队列(如 Apache RocketMO、Kafka)强调高并发写入、顺序消费和基本负载均衡，已形成成熟的技术范式。</p><p>然而，随着生成式 AI 的兴起，AI 应用呈现出截然不同的业务特征：推理耗时长达分钟级、上下文数据高达上百 MB、多轮对话需长期维护状态、多 Agent 协同依赖复杂异步编排，且严重依赖昂贵的 GPU 资源。</p><p>在此背景下，传统消息队列暴露出明显局限:无法高效支持百万级长会话隔离、缺乏对大消息的优化传输、难以实现消费速度的精细控制，更不具备优先级调度与资源导向的智能负载均衡能力。简单的异步模型已无法一步满足 AI 场景下对稳定性、成本控制与任务优先级的严苛要求。</p><p>因此在A1云原生架构下的消息队列必须具备以下特点:</p><ul><li>支持长会话与大消息体的消息中枢。</li><li>实现削峰填谷、定速消费的智能调度能力。</li><li>提供优先级、权重控制的分级事件驱动机制。</li><li>构建高可靠、可恢复的 Agent 编排引擎。</li></ul><h1 id="消息模型提升-AI-通信效率"><a href="#消息模型提升-AI-通信效率" class="headerlink" title="消息模型提升 AI 通信效率"></a>消息模型提升 AI 通信效率</h1><p>AI 应用的交互通常具有长耗时、多轮次和高算力成本的特点。当依赖 SSE或 WebSocket 等长连接时，一旦连接中断(如网关重启、超时或网络波动)，不仅会话上下文可能丢失，已执行的 AI 任务也会被迫中断，导致昂贵的计算资源被浪费。因此，构建一个可靠的会话管理机制，确保在长时间对话中上下文的连续性与完整性，减少因重连或重试带来的资源消耗，同时降低应用逻辑的复杂性，成为该场景下的关键技术挑战。</p><p>针对这一挑战，RocketMQ 提出了一种创新的轻量化架构——其核心理念是:为每个会话或问题动态创建一个独立的轻量级主题(Lite-Topic)。以客户端与 AI 服务建立会话为例，系统自动创建一个以 SessionID 命名的专属队列(如 chatbot&#x2F;{sessionlD}或 chatbot&#x2F;{questionlD})，所有会话历史、上下文和中间结果均以消息形式在该主题中有序流转。通过将每个会话隔离在独立的消息通道中，不仅实现了上下文的持久化与顺序保障，也彻底解耦了会话生命周期与长连接状态，为构建高可靠、可恢复的 AI对话系统提供了底层支撑。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/59cd8768bd0c61cf64434db7c725f7fc76f54606.png" alt="image-20251017145753452"></p><p>这一创新架构的实现，依托于 RocketMQ为 AI场景深度优化的四大核心能力:</p><ul><li>百万级 Lite-Topic 支持：单集群可管理百万级轻量主题，为每个会话独立分配 Topic，实现高并发下的会话隔离，性能无损。</li><li>全自动轻量管理：Lite-Topic 按需动态创建，连接断开后自动回收，彻底杜绝资源泄漏，运维零干预。</li><li>大消息体传输能力：支持数十 MB乃至更大消息，轻松承载长 Prompt、图像、文档等 AIGC典型数据负载。</li><li>严格顺序消息保障：在单队列内保证消息有序，确保LLM 流式输出的token 顺序不乱，支撑连贯流畅的交互体验。</li></ul><p>从业务模型上来看，轻量级消息模型包括了轻量级发送、轻量级订阅以及全新的消费分发策略。</p><ul><li>轻量级发送：<ul><li>基于百万队列的方案，本质上是一个个 Queue。</li><li>从全局上来看，一个轻量级Topic不会存在于每一个 Broker 上，在分配和发送时像顺序 Topic 的发送一样要做 Queue 的 Hash。</li><li>Queue 的消息是某个 Broker专属的，一个轻量级 Topic的发送在只会到一台Broker，而不是轮询发送。</li></ul></li><li>轻量级订阅：<ul><li>消费组 Group 的概念被弱化。</li><li>订阅关系、消费进度管理粒度更细，以 clientID 维度维护。</li><li>新增互斥(Exclusive)消费模式。</li><li>TTL到期后自动删除订阅关系。</li></ul></li><li>消费分发策略:<ul><li>客户端发起读请求不再指定 Topic，而是 Broker 根据 client ID 识别订阅关系，并返回多<br>个 Topic 的多条消息。</li><li>引入类似 Epoll 机制的 Topic ready set，在 POP 请求处理时直接访问就绪的topic。</li><li>当订阅上线、新消息发送、消息 ACK(Acknowledgement，确认)后仍有消息、order Lock 释放时往 topic ready set 进行 add 操作。</li></ul></li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/9238993062bd3d2a348b275946671d24cd423fec.png" alt="image-20251017150418687"></p><p>轻量化消息模型突破了传统消息队列订阅关系单一、隔离粒度粗、管理复杂等局限，通过精细化的资源隔离机制，实现了海量 Lite-Topic 的高效生命周期管理与低延迟消息投递。该模型为 AI 场景下的会话管理、上下文持久化以及多 Agent 间的异步协同，提供了高可靠、易扩展的全新架构解决方案。</p><p><strong>应用案例：阿里巴巴安全团队“安全小蜜”智能助手</strong></p><p>阿里巴巴安全团队推出的“安全小蜜”智能助手，在应对大规模并发会话时，曾面临会话上下文丢失、任务中断导致资源浪费等挑战。</p><p>通过引入 RocketMQ 的 Lite-Topic 能力重构会话保持机制，“安全小蜜”成功实现了会话状态的自动持久化与快速恢复。这不仅能够在多轮对话中，对用户的安全问题进行快速、精准的理解和响应，还大幅简化了工程实现复杂度，有效降低了因任务中断引发的资源浪费，整体提升了用户体验与业务处理效率。</p><p>目前，阿里云多个产品线的 AI 答疑机器人也已采用该方案完成升级，进一步验证了该架构在多样化 AI 场景下的通用性与有效性。</p><h1 id="基于消息驱动的智能化资源调度"><a href="#基于消息驱动的智能化资源调度" class="headerlink" title="基于消息驱动的智能化资源调度"></a>基于消息驱动的智能化资源调度</h1><p>大模型服务普遍面临两大核心资源调度难题：</p><ul><li>负载不匹配：前端请求常突发波动，而后端算力资源有限且稳定，直接对接易引发服务过载或利用率不足，难以实现稳定服务与资源效率的平衡。</li><li>资源分配无差别：在流量被平滑后，仍需解决关键问题——如何优先保障高价值任务(如 VIP 请求、核心业务)的资源获取，以最大化算力的服务价值。</li></ul><p>RocketMQ 不仅实现了流量的平滑缓冲，更通过优先级与配额机制，赋予系统智能调度与资源优化的能力，推动消息系统从被动队列向主动控制中枢演进。开发者无需自研复杂调度中间件，即可实现对 AI流量的精细化管控。其核心能力包括：</p><ul><li>天然削峰填谷，保护 AI算力：消息队列作为“流量水库”，可缓存突发请求，使后端 AI 服务按自身处理能力自适应消费，实现负载均衡，避免因瞬时高峰导致服务崩溃或资源闲置。</li><li>定速消费，精准控制算力使用：支持为消费者组(ConsumerGroup)设置消费配额(quota)，实现稳定速率消费。开发者可精确设定每秒调用次数，在保障模型服务稳定的前提下，最大化GPU 利用率与系统吞吐。</li><li>优先级调度，实现智能资源分配：在资源竞争场景下，支持多维度调度策略：<ul><li>抢占式优先级:将 VIP 请求、关键任务标记为高优先级消息，确保其优先被消费，保障核心业务响应质量。</li><li>权重动态分配：在多租户共享算力池场景中，可根据业务重要性或执行状态动态调整消息优先级，平衡吞吐效率与资源公平性，防止个别租户“资源饥饿”</li></ul></li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/23cee64298e54dc078f149e31622d323d4851ef0.png" alt="image-20251017150939670"></p><p>通过 RocketMQ 的综合调度能力，可以高效稳定的实现资源管理。用户将请求统一写入RocketMQ突发流量被暂存为“待处理会话”。AI 推理服务按自身处理能力设置定速平滑消费，避免雪崩或空转，保障服务稳定性。当有更高优先级的用户消息进入时会被标记，系统优先调度处理，确保高价值客户获得毫秒级响应体验。而当多个业务线共享算力池时，根据 SLA和执行状态动态调整消息优先级，保障核心业务的同时，避免低优先级租户长期得不到资源。</p><p><strong>应用案例：阿里云大模型服务平台百炼、通义灵码</strong></p><p>阿里云大模型服务平台百炼的网关系统通过引入 RocketMQ 实现了对请求流量的削峰填谷，有效将前端不规则的访问压力转化为平稳、可控的后端算力调度。同时，借助 RocketMQ 的消息优先级功能，根据用户的请求流量设置合理的优先级，避免了大流量用户请求导致小流量用户分配不到算力资源，显著提升了资源利用率和服务公平性。</p><p>通义灵码通过 RocketMQ 将其 codebase RAG 架构从原有的同步流程升级为异步流程，实现代码向量化与流量削峰填谷，保障了系统全链路的稳定性。</p><h1 id="异步通信枢纽：AI-工作流"><a href="#异步通信枢纽：AI-工作流" class="headerlink" title="异步通信枢纽：AI 工作流"></a>异步通信枢纽：AI 工作流</h1><p>Google 提出的 A2A 协议推荐采用异步通信机制来解决 AI 任务长耗时带来的同步阻塞问题。其核心机制是将一次请求 - 响应（Request-Reply）调用，解耦为一个初始请求和一个异步通知（pushNotificationConfig）。在各类 Agentic AI 平台的工作流中，每个节点执行完任务后都需要向下游节点通知执行结果，而异步通信正是支撑这种复杂协作的关键。</p><p>由于 AI 任务普遍运行时间长，工作流场景同样需要解决“同步调用导致级联阻塞”的问题。无论是 Agent 之间的外部通信，还是工作流内部的任务流转，都面临一个共同挑战：如何优雅地处理长耗时任务，避免系统阻塞？核心解决方案是采用统一的架构模式——<strong>将长耗时、有状态的交互，转化为由无状态、事件驱动的可靠异步通知机制来连接</strong>。</p><p>前文提到，Apache RocketMQ 全新推出的 <strong>Lite-Topic 机制</strong>，凭借其轻量化、自动化的动态管理能力，可高效实现 Request-Reply 模式的异步通信。核心流程如下：</p><ul><li><p><strong>动态创建回复通道</strong>：当 Agent A 向 Agent B 发起请求时（如 message&#x2F;send），无需同步等待响应。而是在请求中嵌入唯一的动态回复地址，例如 a2a-topic&#x2F;{taskID}。同时，Agent A 订阅该地址，RocketMQ 会在首次连接时自动创建这个轻量化的 Sub-Topic，相当于为本次任务开辟了一个专属的异步通信通道。</p></li><li><p><strong>异步投递执行结果</strong>：Agent B 按照自己的节奏处理任务。在任务完成后，它将结果封装为消息，直接发布到请求中指定的回复地址 a2a-topic&#x2F;{taskID}。</p></li><li><p><strong>自动回收通信资源</strong>：当 Agent A 成功接收并处理完结果后，会断开与该 Lite-Topic 的连接。RocketMQ 的智能资源管理机制会检测到该 Topic 已无消费者，并在设定的 TTL（Time-To-Live）后自动清理该 Topic 资源。整个过程完全自动化，无需人工干预，杜绝了资源泄露的风险。</p></li></ul><p>RocketMQ 的 Lite-Topic 方案优势在于其系统性的设计：<strong>百万级 Lite-Topic 的海量并发能力，结合按需创建、用后即焚的零开销资源管理</strong>，从根本上解决了大规模 Agent 协作场景下的扩展性与易用性问题。同时，顺序消息保障机制确保了流式或多步任务的逻辑正确，而内置的<strong>持久化与高可用机制</strong>则保障了异步通信的最终一致性与可靠性。这些能力共同为 A2A 场景构建了一个真正健壮、高效且可扩展的异步通信基础设施。</p><p><strong>应用案例：阿里 AI 实验室</strong></p><p>阿里 AI 实验室在其多 AI Agent 工作流中，基于 RocketMQ 构建了一套高效、可靠的 Agent 编排体系。工作流中的每个节点均采用事件驱动架构，实现可靠、持久化的通信。借助 Lite-Topic 机制，还能实现 Agent 之间的节点级通信，从而实现任务流程的精细化编排。</p><p>在多 Agent 协同执行 AI 任务的过程中，即使遇到 Agent 发布重启、调用超时等情况导致完整任务链中断，也能通过持久化事件流的可靠重试，继续推进中断的 AI 任务，既有效避免了资源浪费，又显著提升了用户体验。</p><h1 id="架构解析：RocketMQ-for-AI-的关键技术升级"><a href="#架构解析：RocketMQ-for-AI-的关键技术升级" class="headerlink" title="架构解析：RocketMQ for AI 的关键技术升级"></a>架构解析：RocketMQ for AI 的关键技术升级</h1><p>为实现前文所述的创新模型，Apache RocketMQ 需具备在单个集群中高效管理百万级 Lite-Topic 的能力，但原有架构在支持该能力时面临两大核心挑战：在存储层面，原先基于文件的索引和元数据管理机制已难以支撑如此量级的 Topic；在消息分发投递过程中，当单个消费者订阅大量的 Lite-Topic 时，旧有的长轮询通知机制在延迟和并发性能上也显得捉襟见肘。</p><p>因此，要实现海量 Lite-Topic 的高效管理，必须攻克以下两个关键技术难题：</p><ul><li>百万级 Lite-Topic 的元数据存储与索引结构的技术方案；</li><li>面向海量 Lite-Topic 订阅场景的高效消息分发与投递机制。</li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/f9247af8b5b6a4f4011102dab3e7b3356475f421.png" alt="image-20251017152009567"></p><p>百万级 Lite-Topic 的数量级跃升，意味着索引和元数据无法沿用之前的模型。若为每个主题维护一个或者多个基于物理文件的索引结构，将带来巨大的系统开销和运维负担。</p><p>为此，Apache RocketMQ 基于其 LMQ 存储引擎 和 KV Store 能力，重新设计了元数据管理和索引存储：</p><ul><li><p><strong>统一存储、多路分发</strong>：所有消息在底层的 CommitLog 文件中仅存储一份，但通过多路分发机制，可以为不同的 Lite-Topic 生成各自的消费索引（ConsumerQueue，简称 CQ）。</p></li><li><p><strong>索引存储引擎升级</strong>：摒弃了传统的文件型 CQ 结构，替换为高性能的 KV 存储引擎 RocksDB。通过将队列索引信息和消息物理偏移量（Physical Offset）作为键值对存储，充分发挥 RocksDB 在顺序写入方面的高性能优势，从而实现对百万级队列的高效管理。</p></li></ul><p>在 Lite-Topic 存储模型的基础上，RocketMQ 进一步对消息分发与投递机制进行优化，针对单个消费者订阅上万个 Lite-Topic 的场景，重新设计了一套创新的事件驱动拉取（Event-Driven Pull）机制，如图 3 所示：</p><ul><li><p><strong>订阅关系（Subscription Set）管理</strong>：Broker 负责管理消费者订阅关系 Subscription 的 Lite-Topic Set，并支持增量更新，从而能够实时、主动地感知消息与订阅的匹配状态。</p></li><li><p><strong>事件驱动与就绪集（Ready Set）维护</strong>：每当有新消息写入，Broker 会立即根据其维护的 Subscription Set 进行匹配，并将符合条件的消息（或其索引）添加到为消费者维护的 Ready Set 中。</p></li><li><p><strong>高效 Poll Ready Set</strong>：消费者只需对 Ready Set 发起 poll 请求，即可从 Ready Set 中获取所有匹配的消息。这种方式允许 Broker 将来自不同主题、不同流量的消息进行合并与攒批，在一次响应中高效地返回给消费者，显著降低了网络交互频率，从而提升整体性能。</p></li></ul><p>通过在存储层与分发机制的创新升级，Apache RocketMQ 有效解决了 Lite-Topic 模型的关键挑战：在存储层面，<strong>采用高性能的 RocksDB 替代传统文件索引</strong>，实现了对百万级元数据的高效管理；在消息分发层面，通过<strong>创新的“事件驱动拉取”模型</strong>，由 Broker 主动维护订阅集与就绪集，将消费者的海量轮询转变为对聚合消息的单次高效拉取，确保了在海量订阅场景下的低延迟与高吞吐。</p>]]></content>
    
    
    <summary type="html">Apache RocketMQ 顺应AIGC浪潮，针对长时会话、稀缺算力调度及AI Agent协作等挑战，推出专为AI时代打造的消息引擎。</summary>
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/categories/RocketMQ/"/>
    
    <category term="AI" scheme="https://palette-k.github.io/categories/RocketMQ/AI/"/>
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
    <category term="AI" scheme="https://palette-k.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>APISIX的使用</title>
    <link href="https://palette-k.github.io/2025/10/17/APISIX%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
    <id>https://palette-k.github.io/2025/10/17/APISIX%E7%9A%84%E4%BD%BF%E7%94%A8/</id>
    <published>2025-10-17T02:20:26.000Z</published>
    <updated>2025-10-17T02:34:56.137Z</updated>
    
    <content type="html"><![CDATA[<h1 id="APISIX的主要概念"><a href="#APISIX的主要概念" class="headerlink" title="APISIX的主要概念"></a>APISIX的主要概念</h1><p>Apache APISIX是一个动态、实时、高性能的API网关，提供丰富的流量管理特性，例如负载均衡、动态路由、灰度发布、服务熔断、身份认证等。支持多种环境部署，并提供大量插件实现不同业务场景需求，且支持编写自定义插件，提供dashboard供用户通过页面管理apisix。</p><p>APISIX网关的数据面和控制面分离，和传统网关相比，它具有负载均衡、动态上游、灰度发布、服务熔断、身份认证、可观测性等丰富的流量管理功能，并且它的动态路由和插件热加载非常适合管理微服务;</p><p>APISIX有完整的生态系统，能支持多种协议（http,tcp,udp,mqtt,grpc，…），丰富的插件（身份认证，安全，流控，监控，日志,…);</p><p>1.我们为何选择它？<br>1).开源社区活跃，国内参与度高;<br>2).高可用集群，功能强大，成熟的生态圈;<br>3).丰富的插件，支持热加载，可随时插拔，修改;<br>4).最主要的是我司的业务场景90%以上都能满足;</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ab8ee41b3eab2c58df2208d2d99e4e63ca864db9.png" alt="image-20251017102338089"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/bf95adb26f089f9ce9bfda47c3abbe2a733d757f.png" alt="image-20251017102346088"></p><blockquote><p>我们是如何部署的?</p></blockquote><p>1.外置etcd集群存储apisix元数据，保证数据不丢失和高可用;<br>2.通过k8s-configmap管理dashboard+apisix的config配置;<br>3.在k8s集群内部部署多个apisix服务，保证服务高可用;<br>4.修改apisix相关组件日志输出，所有日志采集到腾讯日志云，本地不存储日志;</p><p>我们是如何使用它？<br>1.将k8s ingress ，nginx ，springgateway 合并，在ingress中采用通配二级域名使所有请求转发到apisix服务上</p><p><img src="https://i0.hdslb.com/bfs/openplatform/165dd0abd8f268a99609e32696c728b59dceebdd.png" alt="image-20251017103018816"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/0a70bd108378619a7d7be61ba6466fa9608b40e4.png" alt="image-20251017103033344"></p><p>2.通过apisix-dashboard配置路由规则，替代所有nginx代理功能，并处理L7层流量，使所有流量先经过网关再转发到对应微服务;</p><p>3.所有上层SaaS服务根据k8s-service-name+k8s-service-port进行转发，支持k8s容器服务发现;</p><p>4.开发ext-plugin插件，开辟内部PaaS服务网关，对所有PaaS服务统一入口，统一鉴权，统一流控;</p><p>5.创建统一的前端service（web）和后端service（java），通过配置服务的kafka插件把所有访问数据推送到kafka上，开发对应服务对topic上数据进行消费，统计各系统API PV，UV;</p><p>6.灰度发布，通过不同的请求头标识，配置不同路由规则实现，服务灰度发布和流量切换;</p><p><img src="https://i0.hdslb.com/bfs/openplatform/231cbb8f399c04965fa63d3582fcf4b6f5de6a42.png" alt="image-20251017103133488"></p><p>4.总结<br>作为cloud-native gateway 后续我们会整合所有L7层流量治理，定制个性化插件，打造云原生网关，提供更可靠，成本低，更高效的企业级网关系统;</p><h1 id="APISIX-组件"><a href="#APISIX-组件" class="headerlink" title="APISIX 组件"></a>APISIX 组件</h1><h2 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h2><p>Service 也称为服务，是某类 API 的抽象（也可以理解为一组 Route 的抽象）。它通常与上游服务抽象是一一对应的，Route 与 Service 之间，通常是 N:1 的关系。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/6150517ccf2f76990f26f98a5571bb2d0ebec89d.png" alt="image-20251017102437562"></p><h2 id="上游"><a href="#上游" class="headerlink" title="上游"></a>上游</h2><p>Upstream 也称为上游，上游是对虚拟主机的抽象，即应用层服务或节点的抽象。</p><p>上游的作用是按照配置规则对服务节点进行负载均衡，它的地址信息可以直接配置到路由或服务上。当多个路由或服务引用同一个上游时，可以通过创建上游对象，在路由或服务中使用上游的 ID 方式引用上游，减轻维护压力。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/823b28fdf1bd7d4686ce327c811fa30aa54a12d4.png" alt="image-20251017102448080"></p><h2 id="路由"><a href="#路由" class="headerlink" title="路由"></a>路由</h2><p>Route 也称为路由，是 APISIX 中最基础和最核心的资源对象。</p><p>APISIX 可以通过路由定义规则来匹配客户端请求，根据匹配结果加载并执行相应的插件，最后把请求转发给到指定的上游服务。路由中主要包含三部分内容：匹配规则、插件配置和上游信息。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/dfc426ae570f01798382e2bc0440519be9273dcd.png" alt="image-20251017102513022"></p><h3 id="路由基本使用"><a href="#路由基本使用" class="headerlink" title="路由基本使用"></a>路由基本使用</h3><p>示例：<a href="https://paas.jrit.top/paas/test/v1/service/queryElectronicReceipt%E8%BD%AC%E5%8F%91%E5%88%B0">https://paas.jrit.top/paas/test/v1/service/queryElectronicReceipt转发到</a></p><p>k8s服务jr-paas-pay-service-svc，端口10808，&#x2F;jr-paas-pay&#x2F;pay&#x2F;v1&#x2F;service&#x2F;queryElectronicReceipt</p><p>请求头：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">x-paas-app-key:com.junrunrenli.rpa</span></span><br><span class="line"></span><br><span class="line"><span class="string">X-HMAC-PAY-TYPE:PAY_TYPE_BANK</span></span><br><span class="line"></span><br><span class="line"><span class="string">X-HMAC-ACCESS-KEY:com.junrunrenli.rpa</span></span><br><span class="line"></span><br><span class="line"><span class="string">x-paas-app-tenant:default</span></span><br></pre></td></tr></table></figure><p>参数：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;yurref&quot;</span><span class="punctuation">:</span> <span class="string">&quot;20240514173301&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;bankType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;receiptType&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="创建服务"><a href="#创建服务" class="headerlink" title="创建服务"></a>创建服务</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/f6d1134e85d767553f1a6d446c21e72f5e429a1b.png" alt="image-20251017102622714"></p><h2 id="创建上游"><a href="#创建上游" class="headerlink" title="创建上游"></a>创建上游</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/07d8e7b02534cbd823d09fe9599f7649827487ca.png" alt="image-20251017102630481"></p><h2 id="创建路由"><a href="#创建路由" class="headerlink" title="创建路由"></a>创建路由</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/ca9b4d1ee1d69e3f53c8e1dc4928af068f28effa.png" alt="image-20251017102637407"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/2956683f3d6b29753716ee8edf7ed040ba2ae0d1.png" alt="image-20251017102641524"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/4922c0d0d965ac4699262a42004c1479b4740508.png" alt="image-20251017102647327"></p><h2 id="hmac-auth验签"><a href="#hmac-auth验签" class="headerlink" title="hmac-auth验签"></a>hmac-auth验签</h2><p>生成密钥，并推给APISIX</p><p><img src="https://i0.hdslb.com/bfs/openplatform/7838a503f1b1f5869b0cd71485f61fd1303d12c7.png" alt="image-20251017102656278"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/1125fe6b19eb1e81fcecf43528c9062d4987c792.png" alt="image-20251017102701195"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/91374587ed0289e118e1d38a15e2fe514baa2743.png" alt="image-20251017102750768"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;APISIX的主要概念&quot;&gt;&lt;a href=&quot;#APISIX的主要概念&quot; class=&quot;headerlink&quot; title=&quot;APISIX的主要概念&quot;&gt;&lt;/a&gt;APISIX的主要概念&lt;/h1&gt;&lt;p&gt;Apache APISIX是一个动态、实时、高性能的API网关，提供</summary>
      
    
    
    
    <category term="安全" scheme="https://palette-k.github.io/categories/%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="APISIX" scheme="https://palette-k.github.io/tags/APISIX/"/>
    
  </entry>
  
  <entry>
    <title>MAT案例整理</title>
    <link href="https://palette-k.github.io/2025/09/24/MAT%E6%A1%88%E4%BE%8B%E6%95%B4%E7%90%86/"/>
    <id>https://palette-k.github.io/2025/09/24/MAT%E6%A1%88%E4%BE%8B%E6%95%B4%E7%90%86/</id>
    <published>2025-09-24T07:42:27.000Z</published>
    <updated>2025-10-13T03:26:45.980Z</updated>
    
    <content type="html"><![CDATA[<h1 id="开启Dump文件自动转储"><a href="#开启Dump文件自动转储" class="headerlink" title="开启Dump文件自动转储"></a>开启Dump文件自动转储</h1><p>一般来说，线上运行的系统都会加上下面的 JVM 参数，以便如果线上出现 OOM 问题的时候，自动将事故现场保留下来。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"> 当程序出现OutofMemory时，将会在相应的目录下生成一份dump文件，如果不指定选项HeapDumpPath则在当前目录下生成dump文件</span></span><br><span class="line">-XX:+HeapDumpOnOutOfMemoryError -XX:ErrorFile=/logs/oom_dump/xxx.log -XX:HeapDumpPath=/logs/oom_dump/xxx.hprof</span><br></pre></td></tr></table></figure><p>但是有某种情况下，pod会被k8s的某种保护机制下自动kill掉，那么dump文件没办法保存下来。此时也可以联系运维给这个服务加上EFS （Amazon 文件系统）等待下次出现能抓住这个问题。</p><p>EFS 是 <strong>Amazon 提供的完全托管的弹性网络文件系统</strong>，主要用于在 AWS 上运行的多台 EC2 实例之间 <strong>共享存储</strong>。它可以实现多个容器等实例同时挂载同一个 EFS 文件系统。</p><p>如果程序出现 OOM 之后，就是有代码存在内存泄漏的风险，这个时候即使能对外提供服务，其实也是有风险的，可能造成更多的请求有问题，所以该参数非常有必要，可以让 K8S 快速的再拉起来一个实例。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-XX:+ExitOnOutOfMemoryError</span><br></pre></td></tr></table></figure><p>也有比较原始的方式获取到dump文件，通过 <code>jmap</code> 工具生成可以生成任意Java进程的dump文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">先找到PID</span></span><br><span class="line">ps -ef | grep java</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">jmap 转存快照</span></span><br><span class="line">jmap -dump:format=b,file=/opt/dump/test.dump &#123;PID&#125;</span><br></pre></td></tr></table></figure><p>无法在生产环境上使用<code>jstack</code>、<code>jmap</code>等命令直接查错的原因：</p><ol><li><strong>需要和 JVM 进程交互</strong></li></ol><ul><li><ul><li>jstack、jmap 等工具会通过 <strong>Attach API</strong> 去连接目标 Java 进程。</li></ul></li><li><ul><li>连接过程中 JVM 可能会有短暂停顿，尤其是在生成 <strong>堆转储（heap dump）</strong> 时，会触发 <strong>STW（Stop-The-World）</strong>。</li></ul></li></ul><ol><li><strong>堆转储会消耗大量资源</strong></li></ol><ul><li><ul><li>jmap -dump 会把整个堆内存写到磁盘，如果堆是几十 GB，磁盘 IO 和 CPU 会瞬间飙升。</li></ul></li><li><ul><li>在高并发的生产环境里，这可能导致应用延迟飙升，甚至直接 OOM &#x2F; 崩溃。</li></ul></li></ul><ol><li><strong>阻塞风险</strong></li></ol><ul><li><ul><li>某些 JVM bug 或特定版本下，jstack、jmap 执行时可能卡住，甚至把目标进程挂死。</li></ul></li><li><ul><li>这在大规模线上系统中是 <strong>不可接受的风险</strong>。</li></ul></li></ul><p>而使用-XX:+HeapDumpOnOutOfMemoryError这个参数，只在 JVM 已经抛出 OutOfMemoryError、进程无法继续正常工作时才触发 dump。HeapDumpOnOutOfMemoryError 的触发时刻，进程已经 <strong>内存耗尽，服务功能基本不可用</strong>，此时再做 dump 不会额外带来业务中断风险，反而能保留关键现场用于问题分析。</p><p>从安全性维度上讲，运维不会允许研发随时在生产上执行 jmap，因为这是“人为操作”，风险可控但不可预测。而使用JVM 参数 -XX:+HeapDumpOnOutOfMemoryError 是 <strong>只读配置</strong>，行为固定、无人工干预，且只在最坏情况下触发，<strong>可控且可预期</strong>。</p><h1 id="MAT工具参数调整"><a href="#MAT工具参数调整" class="headerlink" title="MAT工具参数调整"></a>MAT工具参数调整</h1><h2 id="MAT需要JDK11才能运行"><a href="#MAT需要JDK11才能运行" class="headerlink" title="MAT需要JDK11才能运行"></a>MAT需要JDK11才能运行</h2><p>解决办法是，打开MAT的安装目录，有一个配置文件MemoryAnalyzer.ini。打开这个文件，在文件中指定JDK版本即可。新增两行配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-vm D:/jdkPath/bin/javaw.exe</span><br></pre></td></tr></table></figure><p>在使用jvisualvm分析大的dump文件时，堆查器使用的内存不足</p><p>修改JAVA_HOME&#x2F;lib&#x2F;visualvm&#x2F;etc&#x2F;visualvm.conf文件中 visualvm_default_options&#x3D;”-J-client -J-Xms24 -J-Xmx256m”，然后重启jvisualVM即可</p><h2 id="MAT修改内存空间"><a href="#MAT修改内存空间" class="headerlink" title="MAT修改内存空间"></a>MAT修改内存空间</h2><p>分析堆转储文件需要消耗很多的堆空间，为了保证分析的效率和性能，在有条件的情况下，建议分配给 MAT 尽可能多的内存资源。两种方式分配内存资源给 MAT：<br>1）修改启动参数 MemoryAnalyzer.exe -vmargs -Xmx4g<br>2）编辑文件 MemoryAnalyzer.ini 添加 -vmargs – Xmx4g</p><h1 id="案例一：查询条件未做限制全表扫描"><a href="#案例一：查询条件未做限制全表扫描" class="headerlink" title="案例一：查询条件未做限制全表扫描"></a>案例一：查询条件未做限制全表扫描</h1><h2 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h2><p>线上某个服务有接口非常慢，通过监控链路查看发现，中间的 GAP 时间非常大，实际接口并没有消耗很多时间，并且在那段时间里有很多这样的请求。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/693a19a64dd945e8bbd4baee1ee76e15~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="null"></p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>先从监控链路分析了一波，发现请求是已经打到服务上了，处理之前不知道为什么等了 3s，猜测是不是机器当时负载太大了，通过 QPS 监控查看发现，在接口慢的时候 CPU 突然增高，同时也频繁的 GC ，并且时间很长，但是请求量并不大，并且这台机器很快就因为 Heap满了而被下掉了。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b7de13c219964feb9f2d00cad9e0552f~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="null"></p><p>dump 出来的文件足有 4.8G，话不多说祭出 jvisualvm 进行分析，分析工具都被这个dump文件给搞挂了也报了个<code>java.lang.OutOfMemoryError: Java heap space</code>，加载成功之后就给出了导致OOM的线程。</p><p>找到<code>class</code>按照大小排序，占用最多的是一个 byte 数组，有 1.07G，char 数组也有1.03G，byte 数组都是数字，直接查看 char 数组吧，点进去查看具体内容，果然是那条count语句，一条 SQL 1.03G 难以想象。。。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2b4d6894ebf045d9bdd175e9a1fb880e~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="null"></p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f0be4c3f444c4d8e8e92c29a940cb9a9~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp" alt="null"></p><p>这个<code>userId</code>的数据完全是外部传过来的，并没有做什么操作，从监控上看，这个入参有 64M，马上联系对应系统排查为啥会传这么多用户过来查询，经过一番排查确认他们有个<code>bug</code>，会把所有用户都发过来查询。。。到此问题排查清楚。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>对方系统控制传入<code>userId</code>的数量，我们自己的系统也对<code>userId</code>做一个限制，问题排查过程比较困难，修改方案总是那么的简单。</p><p>对于 SQL 语句，如果监测到没有<code>where</code>条件的全表查询应该默认增加一个合适的<code>limit</code>作为限制，防止这种问题拖垮整个系统。</p><h1 id="案例二：文件删除导致内存泄漏"><a href="#案例二：文件删除导致内存泄漏" class="headerlink" title="案例二：文件删除导致内存泄漏"></a>案例二：文件删除导致内存泄漏</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>今天下午，正酣畅淋漓的搬砖，突然运维同事在群里通知，核心服务某个节点内存异常，服务假死。神经一下子紧张起来，赶紧跑到运维那边观察现象。</p><p>观察的结果是服务内存溢出，该服务是核心服务，分配了5G内存。运维在转存快照后，立刻重启服务后正常。在接下来的一段时间里，另一台服务节点也发生了同样的情况。</p><h2 id="分析过程"><a href="#分析过程" class="headerlink" title="分析过程"></a>分析过程</h2><p>进入到<code>Dominator Tree</code>视图, 列出当前存活的对象的内存大小，这看起来像是我需要关注的重点。然后查了下这个类 <code>java.io.DeleteOnExitHook</code> 与 内存泄露的相关问题。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/639dc7ba1a0e7a00d97eb65737e5a58e19056ef1.png" alt="img"></p><p>在删除文件使用 <code>File.deleteOnExit()</code> 方法时，并不是立刻删除文件，而是将该文件路径维护在类DeleteOnExit的一个LinkedHashSet中，最后在JVM关闭的时候，才会去删除这里面的文件，这个方法不能用于长时间运行的服务。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>问题定位于<code>File.deleteOnExit()</code>方法的调用，导致内存泄漏。调用该方法只会将需要删除文件的路径，维护在类<code>DeleteOnExit</code>的一个LinkedHashSet中，在JVM关闭时，才会去真正执行删除文件操作。这样导致<code>DeleteOnExitHook</code>这个对象越来越大，最终内存溢出。</p><p><code>File.delete()</code>与 <code>File.deleteOnExit()</code> 的区别：<br>当调用delete()方法时，直接删除文件，不管该文件是否存在，一经调用立即执行<br>当调用deleteOnExit()方法时，只是相当于对deleteOnExit()作一个声明，当程序运行结束，JVM终止时才真正调用deleteOnExit()方法实现删除操作。</p><p>我写了下面这个测试方法，对比 <code>delete()</code>和<code>deleteOnExit()</code>的区别，现象会比较明显。使用<code>deleteOnExit</code>时是在文件全部创建，JVM关闭的时候，才一个个删除文件，<code>delete</code>会立刻删除文件。(所以这个方法的使用场景是怎样的，我就不太清楚了)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">loopTest</span><span class="params">()</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">root</span> <span class="operator">=</span> <span class="string">&quot;D:\\C_Temp\\files\\&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">File</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(root);</span><br><span class="line">    <span class="keyword">if</span> (!path.exists()) &#123;</span><br><span class="line">        path.mkdirs();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; <span class="number">40000</span>) &#123;</span><br><span class="line">        <span class="type">File</span> <span class="variable">file</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">File</span>(path, <span class="string">&quot;Hello-&quot;</span> + i + <span class="string">&quot;.txt&quot;</span>);</span><br><span class="line">        file.createNewFile();</span><br><span class="line">        file.delete();</span><br><span class="line"><span class="comment">//            file.deleteOnExit();</span></span><br><span class="line">        i++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="案例三：JVM启动参数有误"><a href="#案例三：JVM启动参数有误" class="headerlink" title="案例三：JVM启动参数有误"></a>案例三：JVM启动参数有误</h1><h2 id="事故背景"><a href="#事故背景" class="headerlink" title="事故背景"></a>事故背景</h2><p>2023年3月10日14时19分，C公司开发人员向A公司开发人员反映某开放接口从2023年3月10日14时许开始无法访问和使用。该系统为某基础数据接口服务，基于 HTTP 协议进行通信。按照惯例，首先排查网络是否异常，经运维人员检查，证明网络连通性没有问题。A公司开发组于2023年3月10日14时30分通知运维人员重启应用服务，期间短暂恢复正常。但是，很快，十分钟后，电话再次响起，告知服务又出现异常，无法访问。为了避免影响进一步扩大，A公司决定将程序<strong>紧急回滚至上一稳定版本</strong>。回滚后，系统业务功能恢复正常。短暂松一口气后，开始排查问题。</p><h2 id="事故分析"><a href="#事故分析" class="headerlink" title="事故分析"></a>事故分析</h2><p>根据前面的故障现象，初步猜测是内存问题。堆转储文件出来后，用*MAT(Memory Analyzer Tool)*工具打开转储文件，原以为会发现某个类型对象占用大量的内存，结果出乎意料，Histogram（直方图）中显示活跃对象居然只有100多M！尝试 Calculate Precise Retained Size（计算精确大小），计算结果与前面相差不大。检查 Outgoing References （追踪引用对象）和 Incoming References（追踪被引用对象）也未见明显异常，令人头大。</p><p>日志已经明确提示我们<code>java.lang.OutOfMemoryError: Java heap space</code>，首先肯定这是一个堆内存空间引起的问题，可能的原因有：</p><ul><li><p>内存加载数据量过大例如不受行数限制的数据库查询语句，或者不限制字节数的文件读取等，事故系统显然没有这些情况；</p></li><li><p>内存泄漏（资源未关闭&#x2F;无法回收）当系统存在大量未关闭的 IO 资源，或者错误使用<code>ThreadLocal</code>等场景时也会发生<code>OOM</code>，经排查，也不存在这种情况；</p></li><li><p>系统内存不足系统内存不足以支撑当前业务场景所需要的内存，过小的机器内存或者不合理的<em>JVM</em>内存参数。</p></li></ul><p>如果排除所有合理选项，最不合理那个会不会就是答案呢？遂开始检查机器的内存，根据运维的说法，机器内存为16GB，<code>top</code>命令查看<code>java</code>进程占用内存约为7.8GB，看起来似乎没毛病。</p><p>但是随后另一个同事注意到了一个事情，最后一次系统升级的时候，改动过应用启停脚本，对比旧版本的脚本，发现差异部分就是内存参数：</p><p>旧版本原为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xms8g -Xmx8g -Xmn3g</span><br></pre></td></tr></table></figure><p>新版本改为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xms8g -Xmx8g -Xmn8g</span><br></pre></td></tr></table></figure><h2 id="事故原因"><a href="#事故原因" class="headerlink" title="事故原因"></a>事故原因</h2><p><strong>-Xms</strong>：初始堆大小，通常和 -Xmx 设置一样大，避免堆在运行中动态扩容，减少 GC 和内存分配的开销。</p><p><strong>-Xmx</strong>：最大堆大小，和物理机&#x2F;容器内存要匹配，不能随意大于系统可用内存</p><p><strong>-Xmn</strong>：年轻代大小，年轻代太大，意味着老年代空间变小，Full GC 更容易触发；但太小的话 Minor GC 会频繁发生。</p><p>为什么<code>-Xmn</code>参数设置成与<code>-Xmx</code>参数一样的大小会导致<code>OOM</code>呢？该项目使用的<em>JDK</em>版本为1.8，看看<em>JDK 8</em>的内存模型：</p><p><img src="https://img2023.cnblogs.com/blog/1925794/202304/1925794-20230407022218419-543043266.png" alt="null"></p><p>不难发现，<code>Heap Space Size = Young Space Size + Old Space Size</code>，而<code>-Xmn</code>参数控制的正是 Young 区的大小，当堆区被 Young Gen 完全挤占，又有对象想要升代到 Old Gen 时，发现 Old 区空间不足，于是触发 Full GC，触发 Full GC 以后呢，通常又会面临两种情况：</p><ul><li><p>Young 区又刚好腾出来一点空间，对象又不用放到 Old 区里面了，皆大欢喜</p></li><li><p>Young 区空间还是不够，对象还是得放到 Old 区，Old 区空间不够，卒，喜提<code>OOM</code></p></li><li><p>诶，就是奔着 Old 区去的，管你 Young 不 Young，Old 区空间不够，卒，喜提<code>OOM</code></p></li></ul><p>这个就解释了为什么系统刚刚启动时，会有一个短时间正常工作的现象，随后，当某段程序触发 Old Gen 升代时，就会发生随机的<code>OOM</code>错误。那么什么时候对象会进入老年代呢？这里也很有意思，不妨结合日志里面出现<code>OOM</code>的地方，对号入座：</p><ul><li><p>经历足够多次数 GC 依然存活的对象</p></li><li><p>申请一个大对象（比如超过 Eden 区一半大小）</p></li><li><p>GC 后 Eden 区对象大小超过 S 区之和</p></li><li><p>Eden 区 + S0 区 GC 后，S1 区放不下</p></li></ul><p>换言之，正常情况下，<code>-Xmn</code>参数总是应当小于<code>-Xmx</code>参数，否则就会触发<code>OOM</code>错误。触发 GC 的前后，Old 区几乎都没有空间，仅有的一点点还是<em>JDK</em>强行分配的（在启动<em>JVM</em>时强制覆写了我们的<code>-Xmn</code>参数）</p><h2 id="事故复盘"><a href="#事故复盘" class="headerlink" title="事故复盘"></a>事故复盘</h2><p>这是一场典型的”人祸“，来源于某个同事的”调优“，比起追究责任，更重要的是带给我们的启发：</p><ul><li><p>即使是应用启停脚本，也应该作为程序的一部分，纳入测试验证流程和上线检查清单，禁止随意变更；</p></li><li><p>很多时候，默认的就是最好的，矫枉则常常过正。</p></li></ul><h2 id="事故影响"><a href="#事故影响" class="headerlink" title="事故影响"></a>事故影响</h2><p>造成C公司关键业务停摆半小时，生产系统紧急回滚一次。A公司相关负责人连夜编写事故报告一份。</p><h1 id="案例四：YGC耗时过长"><a href="#案例四：YGC耗时过长" class="headerlink" title="案例四：YGC耗时过长"></a>案例四：YGC耗时过长</h1><h2 id="事故背景-1"><a href="#事故背景-1" class="headerlink" title="事故背景"></a>事故背景</h2><p>今年4月份，我们的广告服务在新版本上线后，收到了大量的服务超时告警，通过下面的监控图可以看到：超时量突然大面积增加，1分钟内甚至达到了上千次接口超时。下面详细介绍下该问题的排查过程。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/5423da7c0b241096b32b7b20bfe0bd9372217824.png" alt="image-20251009151826385"></p><h2 id="事故分析-1"><a href="#事故分析-1" class="headerlink" title="事故分析"></a>事故分析</h2><h3 id="检查监控"><a href="#检查监控" class="headerlink" title="检查监控"></a>检查监控</h3><p>收到告警后，我们第一时间查看了监控系统，立马发现了YoungGC耗时过长的异常。我们的程序大概在21点50左右上线，通过下图可以看出：在上线之前，YGC基本几十毫秒内完成，而上线后YGC耗时明显变长，最长甚至达到了3秒多。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0dd60a1953718b85aca5fa43fb62cb5d3d3c64a5.png" alt="image-20251009151840777"></p><p>由于YGC期间程序会Stop The World，而我们上游系统设置的服务超时时间都在几百毫秒，因此推断：是因为YGC耗时过长引发了服务大面积超时。<br>按照GC问题的常规排查流程，我们立刻摘掉了一个节点，然后通过以下命令dump了堆内存文件用来保留现场。<br>jmap -dump:format&#x3D;b,file&#x3D;heap pid<br>最后对线上服务做了回滚处理，回滚后服务立马恢复了正常，接下来就是长达1天的问题排查和修复过程。</p><h3 id="确认JVM配置"><a href="#确认JVM配置" class="headerlink" title="确认JVM配置"></a>确认JVM配置</h3><p>用下面的命令，我们再次检查了JVM的参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep &quot;applicationName=adsearch&quot;</span><br><span class="line">-Xms4g -Xmx4g -Xmn2g -Xss1024K </span><br><span class="line">-XX:ParallelGCThreads=5 </span><br><span class="line">-XX:+UseConcMarkSweepGC </span><br><span class="line">-XX:+UseParNewGC </span><br><span class="line">-XX:+UseCMSCompactAtFullCollection </span><br><span class="line">-XX:CMSInitiatingOccupancyFraction=80</span><br></pre></td></tr></table></figure><p>可以看到堆内存为4G，新生代和老年代均为2G，新生代采用ParNew收集器。<br>再通过命令 <strong>jmap -heap pid</strong> 查到：新生代的Eden区为1.6G，S0和S1区均为0.2G。<br>本次上线并未修改JVM相关的任何参数，同时我们服务的请求量基本和往常持平。因此猜测：此问题大概率和上线的代码相关。</p><h3 id="检查代码"><a href="#检查代码" class="headerlink" title="检查代码"></a>检查代码</h3><p>再回到YGC的原理来思考这个问题，一次YGC的过程主要包括以下两个步骤：</p><p>1、从GC Root扫描对象，对存活对象进行标注<br>2、将存活对象复制到S1区或者晋升到Old区</p><p>根据下面的监控图可以看出：正常情况下，Survivor区的使用率一直维持在很低的水平（大概30M左右），但是上线后，Survivor区的使用率开始波动，最多的时候快占满0.2G了。而且，YGC耗时和Survivor区的使用率基本成正相关。因此，我们推测：应该是长生命周期的对象越来越多，导致标注和复制过程的耗时增加。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/687ecf4776dda049497eaf723cebc9eefec4b215.png" alt="image-20251009151910165"></p><p>再回到服务的整体表现：上游流量并没有出现明显变化，正常情况下，核心接口的响应时间也基本在200ms以内，YGC的频率大概每8秒进行1次。</p><p>很显然，对于局部变量来说，在每次YGC后就能够马上被回收了。那为什么还会有如此多的对象在YGC后存活下来呢？</p><p>我们进一步将怀疑对象锁定在：程序的全局变量或者类静态变量上。但是diff了本次上线的代码，我们并未发现代码中有引入此类变量。</p><h3 id="对dump的堆内存文件进行分析"><a href="#对dump的堆内存文件进行分析" class="headerlink" title="对dump的堆内存文件进行分析"></a>对dump的堆内存文件进行分析</h3><p>代码排查没有进展后，我们开始从堆内存文件中寻找线索，使用MAT工具导入了第1步dump出来的堆文件后，然后通过Dominator Tree视图查看到了当前堆中的所有大对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/43a137057fc71d67df1e4a638d0ab82cd30136e3.png" alt="image-20251009151921350"></p><p>立马发现NewOldMappingService这个类所占的空间很大，通过代码定位到：这个类位于第三方的client包中，由我们公司的商品团队提供，用于实现新旧类目转换（最近商品团队在对类目体系进行改造，为了兼容旧业务，需要进行新旧类目映射）。</p><p>进一步查看代码，发现这个类中存在大量的静态HashMap，用于缓存新旧类目转换时需要用到的各种数据，以减少RPC调用，提高转换性能。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c6cd37b626eb699c56d7e52c5a79c0559250ee1e.png" alt="image-20251009151932001"></p><p>原本以为，非常接近问题的真相了，但是深入排查发现：这个类的所有静态变量全部在类加载时就初始化完数据了，虽然会占到100多M的内存，但是之后基本不会再新增数据。并且，这个类早在3月份就上线使用了，client包的版本也一直没变过。</p><p>经过上面种种分析，这个类的静态HashMap会一直存活，经过多轮YGC后，最终晋升到老年代中，它不应该是YGC持续耗时过长的原因。因此，我们暂时排除了这个可疑点。</p><h3 id="分析YGC处理Reference的耗时"><a href="#分析YGC处理Reference的耗时" class="headerlink" title="分析YGC处理Reference的耗时"></a>分析YGC处理Reference的耗时</h3><p>团队对于YGC问题的排查经验很少，不知道再往下该如何分析了。基本扫光了网上可查到的所有案例，发现原因集中在这两类上：</p><p>1、对存活对象标注时间过长：比如重载了Object类的Finalize方法，导致标注Final Reference耗时过长；或者String.intern方法使用不当，导致YGC扫描StringTable时间过长。<br>2、长周期对象积累过多：比如本地缓存使用不当，积累了太多存活对象；或者锁竞争严重导致线程阻塞，局部变量的生命周期变长。</p><p>针对第1类问题，可以通过以下参数显示GC处理Reference的耗时-XX:+PrintReferenceGC。添加此参数后，可以看到不同类型的 reference 处理耗时都很短，因此又排除了此项因素。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9ecf81f51d2ab44de2776ea56de9fae4d0f4db2c.png" alt="image-20251009151943216"></p><h3 id="再回到长周期对象进行分析"><a href="#再回到长周期对象进行分析" class="headerlink" title="再回到长周期对象进行分析"></a>再回到长周期对象进行分析</h3><p>再往后，我们添加了各种GC参数试图寻找线索都没有结果，似乎要黔驴技穷，没有思路了。综合监控和种种分析来看：应该只有长周期对象才会引发我们这个问题。<br>折腾了好几个小时，最终峰回路转，一个小伙伴重新从MAT堆内存中找到了第二个怀疑点。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2be25637c40c5b2fbab1bd51249092bb63991778.png" alt="image-20251009152000836"></p><p>从上面的截图可以看到：大对象中排在第3位的ConfigService类进入了我们的视野，该类的一个ArrayList变量中竟然包含了270W个对象，而且大部分都是相同的元素。<br>ConfigService这个类在第三方Apollo的包中，不过源代码被公司架构部进行了二次改造，通过代码可以看出：<strong>问题出在了第11行，每次调用getConfig方法时都会往List中添加元素，并且未做去重处理</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/5ca57283ab1e5257efdaf64438737c6c0f863074.png" alt="image-20251009152011394"></p><p>我们的广告服务在apollo中存储了大量的广告策略配置，而且大部分请求都会调用ConfigService的getConfig方法来获取配置，因此会不断地往静态变量namespaces中添加新对象，从而引发此问题。</p><p>至此，整个问题终于水落石出了。这个BUG是因为架构部在对apollo client包进行定制化开发时不小心引入的，很显然没有经过仔细测试，并且刚好在我们上线前一天发布到了中央仓库中，而公司基础组件库的版本是通过super-pom方式统一维护的，业务无感知。</p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><p>为了快速验证YGC耗时过长是因为此问题导致的，我们在一台服务器上直接用旧版本的apollo client 包进行了替换，然后重启了服务，观察了将近20分钟，YGC恢复正常。<br>最后，我们通知架构部修复BUG，重新发布了super-pom，彻底解决了这个问题。<br>通过上面这个案例，可以看到YGC问题其实比较难排查。相比FGC或者OOM，YGC的日志很简单，只知道新生代内存的变化和耗时，同时dump出来的堆内存必须要仔细排查才行。</p><p>另外，如果不清楚YGC的流程，排查起来会更加困难。这里，我对YGC相关的知识点再做下梳理，方便大家更全面的理解YGC。</p><h2 id="YGC的相关知识点总结"><a href="#YGC的相关知识点总结" class="headerlink" title="YGC的相关知识点总结"></a>YGC的相关知识点总结</h2><h3 id="5个问题重新认识新生代"><a href="#5个问题重新认识新生代" class="headerlink" title="5个问题重新认识新生代"></a>5个问题重新认识新生代</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/0646869f14e1952bcb7886e95fca3833227e7098.png" alt="image-20251009152021669"></p><p>YGC 在新生代中进行，首先要清楚新生代的堆结构划分。新生代分为Eden区和两个Survivor区，其中Eden:from:to &#x3D; 8:1:1 (比例可以通过参数 –XX:SurvivorRatio 来设定 )，这是最基本的认识。</p><p><strong>为什么会有新生代？</strong></p><p>如果不分代，所有对象全部在一个区域，每次GC都需要对全堆进行扫描，存在效率问题。分代后，可分别控制回收频率，并采用不同的回收算法，确保GC性能全局最优。</p><p><strong>为什么新生代会采用复制算法？</strong></p><p>新生代的对象朝生夕死，大约90%的新建对象可以被很快回收，复制算法成本低，同时还能保证空间没有碎片。虽然标记整理算法也可以保证没有碎片，但是由于新生代要清理的对象数量很大，将存活的对象整理到待清理对象之前，需要大量的移动操作，时间复杂度比复制算法高。</p><p><strong>为什么新生代需要两个Survivor区？</strong></p><p>为了节省空间考虑，如果采用传统的复制算法，只有一个Survivor区，则Survivor区大小需要等于Eden区大小，此时空间消耗是8 * 2，而两块Survivor可以保持新对象始终在Eden区创建，存活对象在Survivor之间转移即可，空间消耗是8+1+1，明显后者的空间利用率更高。</p><p><strong>新生代的实际可用空间是多少？</strong></p><p>YGC后，总有一块Survivor区是空闲的，因此新生代的可用内存空间是90%。在YGC的log中或者通过 jmap -heap pid 命令查看新生代的空间时，如果发现capacity只有90%，不要觉得奇怪。</p><p><strong>Eden区是如何加速内存分配的？</strong></p><p>HotSpot虚拟机使用了两种技术来加快内存分配。分别是bump-the-pointer和TLAB（Thread Local Allocation Buffers）。</p><p>由于Eden区是连续的，因此bump-the-pointer在对象创建时，只需要检查最后一个对象后面是否有足够的内存即可，从而加快内存分配速度。</p><p>TLAB技术是对于多线程而言的，基于 CAS 的独享线程（Mutator Threads）可以优先将对象分配在 Eden 中的一块内存，因为是 Java 线程独享的内存区没有锁竞争，所以分配速度更快，每个 TLAB 都是一个线程独享的。</p><h3 id="新生代的4种回收器"><a href="#新生代的4种回收器" class="headerlink" title="新生代的4种回收器"></a>新生代的4种回收器</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/74c0af883d201ea5c29522a83964f1b8f87c4ac9.png" alt="image-20251009152033492"></p><p>SerialGC（串行回收器），最古老的一种，单线程执行，适合单CPU场景。</p><p>ParNew（并行回收器），将串行回收器多线程化，适合多CPU场景，需要搭配老年代CMS回收器一起使用。</p><p>ParallelGC（并行回收器），和ParNew不同点在于它关注吞吐量，可设置期望的停顿时间，它在工作时会自动调整堆大小和其他参数。</p><p>G1（Garage-First回收器），JDK 9及以后版本的默认回收器，兼顾新生代和老年代，将堆拆成一系列Region，不要求内存块连续，新生代仍然是并行收集。</p><p>上述回收器均采用复制算法，都是独占式的，执行期间都会Stop The World.</p><h3 id="YGC的触发时机"><a href="#YGC的触发时机" class="headerlink" title="YGC的触发时机"></a>YGC的触发时机</h3><p>当Eden区空间不足时，就会触发YGC。结合新生代对象的内存分配看下详细过程：</p><p>1、新对象会先尝试在栈上分配，如果不行则尝试在TLAB分配，否则再看是否满足大对象条件要在老年代分配，最后才考虑在Eden区申请空间。</p><p>2、如果Eden区没有合适的空间，则触发YGC。</p><p>3、YGC时，对Eden区和From Survivor区的存活对象进行处理，如果满足动态年龄判断的条件或者To Survivor区空间不够则直接进入老年代，如果老年代空间也不够了，则会发生promotion failed，触发老年代的回收。否则将存活对象复制到To Survivor区。</p><p>4、此时Eden区和From Survivor区的剩余对象均为垃圾对象，可直接抹掉回收。</p><p>此外，老年代如果采用的是CMS回收器，为了减少CMS Remark阶段的耗时，也有可能会触发一次YGC，这里不作展开。</p><h3 id="YGC的执行过程"><a href="#YGC的执行过程" class="headerlink" title="YGC的执行过程"></a>YGC的执行过程</h3><p>YGC采用的复制算法，主要分成以下两个步骤：</p><p>1、查找GC Roots，将其引用的对象拷贝到S1区<br>2、递归遍历第1步的对象，拷贝其引用的对象到S1区或者晋升到Old区</p><p>上述整个过程都是需要暂停业务线程的（STW），不过ParNew等新生代回收器可以多线程并行执行，提高处理效率。<br>YGC通过可达性分析算法，从GC Root（可达对象的起点）开始向下搜索，标记出当前存活的对象，那么剩下未被标记的对象就是需要回收的对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c8f660c88c58d76eb43d82946901eca39951e029.png" alt="image-20251009152043568"></p><p>可作为YGC时GC Root的对象包括以下几种：</p><p>1、虚拟机栈中引用的对象<br>2、方法区中静态属性、常量引用的对象<br>3、本地方法栈中引用的对象<br>4、被Synchronized锁持有的对象<br>5、记录当前被加载类的SystemDictionary<br>6、记录字符串常量引用的StringTable<br>7、存在跨代引用的对象<br>8、和GC Root处于同一CardTable的对象</p><p>其中1-3是大家容易想到的，而4-8很容易被忽视，却极有可能是分析YGC问题时的线索入口。</p><p>另外需要注意的是，针对下图中跨代引用的情况，老年代的对象A也必须作为GC Root的一部分，但是如果每次YGC时都去扫描老年代，肯定存在效率问题。在HotSpot JVM，引入卡表（Card Table）来对跨代引用的标记进行加速。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c9c2eca238cf6ee5b0136ccbbf7a44463d701a57.png" alt="image-20251009152100016"></p><p>Card Table，简单理解是一种空间换时间的思路，因为存在跨代引用的对象大概占比不到1%，因此可将堆空间划分成大小为512字节的卡页，如果卡页中有一个对象存在跨代引用，则可以用1个字节来标识该卡页是dirty状态，卡页状态进一步通过写屏障技术进行维护。</p><p>遍历完GC Roots后，便能够找出第一批存活的对象，然后将其拷贝到S1区。接下来，就是一个递归查找和拷贝存活对象的过程。</p><p>S1区为了方便维护内存区域，引入了两个指针变量：_saved_mark_word和_top，其中_saved_mark_word表示当前遍历对象的位置，_top表示当前可分配内存的位置，很显然，_saved_mark_word到_top之间的对象都是已拷贝但未扫描的对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/fda76ace4388f57324a1cbdad9646a62cbddb096.png" alt="image-20251009152108967"></p><p>贝到S1区，_top也会往前移动，直到_saved_mark_word追上_top，说明S1区所有对象都已经遍历完成。</p><p>有一个细节点需要注意的是：拷贝对象的目标空间不一定是S1区，也可能是老年代。如果一个对象的年龄（经历的YGC次数）满足动态年龄判定条件便直接晋升到老年代中。对象的年龄保存在Java对象头的mark word数据结构中（如果大家对Java并发锁熟悉，肯定了解这个数据结构，不熟悉的建议查阅资料了解下，这里不做展开）。</p><h2 id="最后的话"><a href="#最后的话" class="headerlink" title="最后的话"></a>最后的话</h2><p>这篇文章通过线上案例分析并结合原理讲解，详细介绍了YGC的相关知识。从YGC实战角度出发，再简单总结一下：<br>1、首先要清楚YGC的执行原理，比如年轻代的堆内存结构、Eden区的内存分配机制、GC Roots扫描、对象拷贝过程等。<br>2、YGC的核心步骤是标注和复制，绝部分YGC问题都集中在这两步，因此可以结合YGC日志和堆内存变化情况逐一排查，同时dump的堆内存文件需要仔细分析。</p><h1 id="案例五：动态对象年龄判定机制引起STW"><a href="#案例五：动态对象年龄判定机制引起STW" class="headerlink" title="案例五：动态对象年龄判定机制引起STW"></a>案例五：动态对象年龄判定机制引起STW</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>公司某规则引擎系统，在每次发版启动会手动预热，预热完成当流量切进来之后会偶发的出现一次长达1-2秒的Young GC（流量并不大，并且LB下的每个节点都会出现该情况）</p><p>在这次长暂停之后，每一次的年轻代GC暂停时间又都恢复在20-100ms以内</p><p>2秒虽然看起来不算长吧，但规则引擎每次执行也才几毫秒，这谁能忍？而且这玩意一旦超时，出单可能也跟着超时失败！</p><h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><p>在分析该系统GC日志后发现，2s暂停发生在Young GC阶段，而且每次发生长暂停的Young GC都会伴随着新生代对象的晋升(Promotion)</p><p><strong>启动后第一次年轻代GC日志</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2023-04-23T16:28:31.108</span><span class="string">+0800:</span> [<span class="string">GC2023-04-23T16:28:31.108+0800:</span> [<span class="string">ParNew2023-04-23T16:28:31.229+0800:</span> [<span class="string">SoftReference</span>, <span class="number">0</span> <span class="string">refs</span>, <span class="number">0.0000950</span> <span class="string">secs</span>]<span class="number">2023-04-23T16:28:31.229</span><span class="string">+0800:</span> [<span class="string">WeakReference</span>, <span class="number">1156 </span><span class="string">refs</span>, <span class="number">0.0001040</span> <span class="string">secs</span>]<span class="number">2023-04-23T16:28:31.229</span><span class="string">+0800:</span> [<span class="string">FinalReference</span>, <span class="number">10410</span> <span class="string">refs</span>, <span class="number">0.0103720</span> <span class="string">secs</span>]<span class="number">2023-04-23T16:28:31.240</span><span class="string">+0800:</span> [<span class="string">PhantomReference</span>, <span class="number">286</span> <span class="string">refs</span>, <span class="number">2</span> <span class="string">refs</span>, <span class="number">0.0129420</span> <span class="string">secs</span>]<span class="number">2023-04-23T16:28:31.253</span><span class="string">+0800:</span> [<span class="string">JNI</span> <span class="string">Weak</span> <span class="string">Reference</span>, <span class="number">0.0000000</span> <span class="string">secs</span>]</span><br><span class="line"><span class="string">Desired</span> <span class="string">survivor</span> <span class="string">size</span> <span class="number">214728704</span> <span class="string">bytes</span>, <span class="string">new</span> <span class="string">threshold</span> <span class="number">1</span> <span class="string">(max</span> <span class="number">15</span><span class="string">)</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   1:</span>  <span class="number">315529928</span> <span class="string">bytes</span>,  <span class="number">315529928</span> <span class="string">total</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   2:</span>   <span class="number">40956656</span> <span class="string">bytes</span>,  <span class="number">356486584</span> <span class="string">total</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   3:</span>    <span class="number">8408040</span> <span class="string">bytes</span>,  <span class="number">364894624</span> <span class="string">total</span></span><br><span class="line"><span class="string">:</span> <span class="string">3544342K-&gt;374555K(3774912K)</span>, <span class="number">0.1444710</span> <span class="string">secs</span>] <span class="string">3544342K-&gt;374555K(10066368K)</span>, <span class="number">0.1446290</span> <span class="string">secs</span>] [<span class="attr">Times:</span> <span class="string">user=1.46</span> <span class="string">sys=0.09</span>, <span class="string">real=0.15</span> <span class="string">secs</span>] </span><br></pre></td></tr></table></figure><p><strong>长暂停年轻代GC日志</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2023-04-23T17:18:28.514</span><span class="string">+0800:</span> [<span class="string">GC2023-04-23T17:18:28.514+0800:</span> [<span class="string">ParNew2023-04-23T17:18:29.975+0800:</span> [<span class="string">SoftReference</span>, <span class="number">0</span> <span class="string">refs</span>, <span class="number">0.0000660</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:18:29.975</span><span class="string">+0800:</span> [<span class="string">WeakReference</span>, <span class="number">1224 </span><span class="string">refs</span>, <span class="number">0.0001400</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:18:29.975</span><span class="string">+0800:</span> [<span class="string">FinalReference</span>, <span class="number">8898 </span><span class="string">refs</span>, <span class="number">0.0149670</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:18:29.990</span><span class="string">+0800:</span> [<span class="string">PhantomReference</span>, <span class="number">600</span> <span class="string">refs</span>, <span class="number">1</span> <span class="string">refs</span>, <span class="number">0.0344300</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:18:30.025</span><span class="string">+0800:</span> [<span class="string">JNI</span> <span class="string">Weak</span> <span class="string">Reference</span>, <span class="number">0.0000210</span> <span class="string">secs</span>]</span><br><span class="line"><span class="string">Desired</span> <span class="string">survivor</span> <span class="string">size</span> <span class="number">214728704</span> <span class="string">bytes</span>, <span class="string">new</span> <span class="string">threshold</span> <span class="number">15</span> <span class="string">(max</span> <span class="number">15</span><span class="string">)</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   1:</span>   <span class="number">79203576</span> <span class="string">bytes</span>,   <span class="number">79203576</span> <span class="string">total</span></span><br><span class="line"><span class="string">:</span> <span class="string">3730075K-&gt;304371K(3774912K)</span>, <span class="number">1.5114000</span> <span class="string">secs</span>] <span class="string">3730075K-&gt;676858K(10066368K)</span>, <span class="number">1.5114870</span> <span class="string">secs</span>] [<span class="attr">Times:</span> <span class="string">user=6.32</span> <span class="string">sys=0.58</span>, <span class="string">real=1.51</span> <span class="string">secs</span>] </span><br></pre></td></tr></table></figure><p><strong>从这个长暂停的GC日志来看，是发生了晋升的，在Young GC后，有363M+的对象晋升到了老年代，这个晋升操作因该就是耗时原因（ps: 检查过safepoint原因，不存在异常）</strong></p><p>由于日志参数中没有配置<code>-XX:+PrintHeapAtGC</code>参数，这里是手动计算的晋升大小：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">年轻代年轻变化</span> <span class="bullet">-</span> <span class="string">全堆容量变化</span> <span class="string">=</span> <span class="string">晋升大小</span></span><br><span class="line"><span class="string">(304371K</span> <span class="bullet">-</span> <span class="string">3730075K)</span> <span class="bullet">-</span> <span class="string">(676858K</span> <span class="bullet">-</span> <span class="string">3730075K)</span> <span class="string">=</span> <span class="string">372487K(363M)</span></span><br></pre></td></tr></table></figure><p><strong>下一次年轻代GC日志</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2023-04-23T17:23:39.749</span><span class="string">+0800:</span> [<span class="string">GC2023-04-23T17:23:39.749+0800:</span> [<span class="string">ParNew2023-04-23T17:23:39.774+0800:</span> [<span class="string">SoftReference</span>, <span class="number">0</span> <span class="string">refs</span>, <span class="number">0.0000500</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:23:39.774</span><span class="string">+0800:</span> [<span class="string">WeakReference</span>, <span class="number">3165 </span><span class="string">refs</span>, <span class="number">0.0002720</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:23:39.774</span><span class="string">+0800:</span> [<span class="string">FinalReference</span>, <span class="number">3520 </span><span class="string">refs</span>, <span class="number">0.0021520</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:23:39.776</span><span class="string">+0800:</span> [<span class="string">PhantomReference</span>, <span class="number">150</span> <span class="string">refs</span>, <span class="number">1</span> <span class="string">refs</span>, <span class="number">0.0051910</span> <span class="string">secs</span>]<span class="number">2023-04-23T17:23:39.782</span><span class="string">+0800:</span> [<span class="string">JNI</span> <span class="string">Weak</span> <span class="string">Reference</span>, <span class="number">0.0000100</span> <span class="string">secs</span>]</span><br><span class="line"><span class="string">Desired</span> <span class="string">survivor</span> <span class="string">size</span> <span class="number">214728704</span> <span class="string">bytes</span>, <span class="string">new</span> <span class="string">threshold</span> <span class="number">15</span> <span class="string">(max</span> <span class="number">15</span><span class="string">)</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   1:</span>   <span class="number">17076040</span> <span class="string">bytes</span>,   <span class="number">17076040</span> <span class="string">total</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   2:</span>   <span class="number">40832336</span> <span class="string">bytes</span>,   <span class="number">57908376</span> <span class="string">total</span></span><br><span class="line"><span class="string">:</span> <span class="string">3659891K-&gt;90428K(3774912K)</span>, <span class="number">0.0321300</span> <span class="string">secs</span>] <span class="string">4032378K-&gt;462914K(10066368K)</span>, <span class="number">0.0322210</span> <span class="string">secs</span>] [<span class="attr">Times:</span> <span class="string">user=0.30</span> <span class="string">sys=0.00</span>, <span class="string">real=0.03</span> <span class="string">secs</span>] </span><br></pre></td></tr></table></figure><p>乍一看好像没什么问题，仔细想想还是发现了不对劲，为什么程序刚启动第二次gc就发生了晋升？</p><p>推测这里应该是动态年龄判定导致的，GC中晋升年龄阈值并不是固定的15，而是jvm每次gc后动态计算的</p><h3 id="年轻代晋升机制"><a href="#年轻代晋升机制" class="headerlink" title="年轻代晋升机制"></a>年轻代晋升机制</h3><p>为了能更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄</p><p>《深入理解Java虚拟机》一书中提到，对象晋升年龄的阈值是动态判定的。</p><p>不过经查阅其他资料和验证后，发现此处和《深入理解Java虚拟机》解释的有些出入</p><p><strong>其实就是按年龄给对象分组，取total（累加值，小于等与当前年龄的对象总大小）最大的年龄分组，如果该分组的total大于survivor的一半，就将晋升年龄阈值更新为该分组的年龄</strong></p><p><strong>注意：不是是超过survivor一半就晋升，超过survivor一半只会重新设置晋升阈值（threshold），在下一次GC才会使用该新阈值</strong></p><p>从上面第一次的GC日志也可以证明这个结论，在这次GC中全堆的内存变化和年轻代内存变化是相等的，所以并没有发生对象的晋升</p><p>就像上面的日志中，第一次GC只是将threshold设置为1，因为此时survivor一半为214728704 bytes，而年龄为1的对象总和有315529928 bytes，超过了Desired survivor size，所以在本次GC后将threshold设置为年龄为1的对象年龄1</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">这里更新了对象晋升年龄阈值为1</span></span><br><span class="line"><span class="string">Desired</span> <span class="string">survivor</span> <span class="string">size</span> <span class="number">214728704</span> <span class="string">bytes,</span> <span class="string">new</span> <span class="string">threshold</span> <span class="number">1</span> <span class="string">(max</span> <span class="number">15</span><span class="string">)</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   1:</span>  <span class="number">315529928</span> <span class="string">bytes,</span>  <span class="number">315529928</span> <span class="string">total</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   2:</span>   <span class="number">40956656</span> <span class="string">bytes,</span>  <span class="number">356486584</span> <span class="string">total</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">age   3:</span>    <span class="number">8408040</span> <span class="string">bytes,</span>  <span class="number">364894624</span> <span class="string">total</span></span><br></pre></td></tr></table></figure><p>这里顺便解释下这个年龄分布的输出内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="attr">age   1:</span>  <span class="number">315529928</span> <span class="string">bytes,</span>  <span class="number">315529928</span> <span class="string">total</span> </span><br></pre></td></tr></table></figure><p><code>- age 1</code>表示年龄为1的对象分组，<code>315529928 bytes</code>表示年龄为1的对象占用内存大小</p><p><code>315529928 total</code>这个是一个累加值，表示小于等于当前分组年龄的对象总大小。先把对象按年龄分组，age 1的分组total为age 1总大小（前面的xxx bytes），age 2的分组total为<code>age 1 + age 2</code>总大小，age n的分组total为<code>age 1 + age 2 + ... +age n</code>的总大小，累加规则如下图所示</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2d4920d4bcfd40bb9b11289af232c2b1~tplv-k3u1fbpfcp-jj-mark:1512:0:0:0:q75.avis#?w=1916&h=632&s=75385&e=png&b=fdfdfd" alt="null"></p><p>当total最大的分组的total值超过了survivor&#x2F;2时，就会更新晋升阈值</p><p>在第二次年轻代GC“长暂停年轻代GC日志”中，由于新的晋升年龄阈值为1，所以那些经历了一次GC并存活并且现在仍然可达（reachable）的对象们就会发生晋升了</p><p><strong>由于此次GC发生了363M的对象晋升，所以导致了长暂停</strong></p><h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>JVM中这个“动态对象年龄判定”真的合理吗？</p><p>个人认为机制是好的，可以更好的适应不同程序的内存状况，但不是任何场景都适合，比如在本文中这个刚启动不就GC的场景下就会有问题</p><p>因为在程序刚启动时，大多数对象年龄都是0或者1，很容易出现年龄为1的大量存活对象；在这个“动态对象年龄判定”机制下，就会导致新的晋升阈值被设置为1，导致这些不该晋升的对象发生了晋升</p><p>比如程序在初始化，正在加载各种资源时发生了Young GC，加载逻辑还在执行中，很多新建的对象年龄在这次GC时还是可达的（reachable）</p><p>经历了这次GC后，这些对象年龄更新为1，但是由于“动态对象年龄判定”机制的影响，晋升年龄阈值更新为了“最大的对象年龄分组”的年龄，也就是这批刚经历了一次GC的对象们</p><p>在这次GC之后不久，资源初始化完成了，涉及的相关对象有很可能不可达了，但是由于刚才晋升年龄阈值被更新为了1，在下一次正常的Young GC这批年龄为1的对象会直接发生晋升，提前或者说错误的发生了晋升</p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>经查阅文档、资料，发现“动态年龄判定”这个机制并不能禁用，所以如果想解决这个问题，只有靠“绕过”这个计算规则了</p><p>动态年龄的判定，是根据Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半来判定的，那么根据这个机制解决也很简单</p><p>由于我们足够了解自己的系统，清楚的知道加载资源所需的大概内存，完全可以设定一个大于这些暂时可达的对象总和的数值来作为survivor的容量</p><p><strong>比如上面的日志中，第一次GC后年龄为1的对象有315529928 Bytes(300M)，Desired survivor size为（survivor size &#x2F;2）214728704 bytes(204M)，那么survivor就可以设置为600M以上。</strong></p><p><strong>不过为了稳妥，还是将survivor调到800M，这样desired survivor size就是400M左右，在第一次Young GC后，就不会因年龄为1的对象总和超过了desired survivor size而导致晋升年龄阈值的更新了，从而也就不会有提前&#x2F;错误晋升而导致的GC长暂停问题</strong></p><p>survivor不可以直接指定大小，不过可以通过-XX:SurvivorRatio这种调节比例的方式来调节survivor大小</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:SurvivorRatio=8</span></span><br></pre></td></tr></table></figure><p>表示两个Survivor和Edgen区的比，8表示两个Survivor:Eden&#x3D;2:8，即一个Survivor占新生代的1&#x2F;10。</p><p>好了，现在直接通过比例，强行给 Survivor 调大</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">-XX:SurvivorRatio=3</span></span><br></pre></td></tr></table></figure><p>调整之后，Survivor 总占比为 40%，大小为 1717829632 Bytes，单个 S0&#x2F;S1的一半也有 10% - 429457408 Bytes，远超 age&#x3D;1 的分组总大小 315529928 Bytes。</p><p>这样一来， Young GC 后复制到 Survivor 的对象（最大年龄分组）占总比例的大小就不会到 50% 了，也就不会把 MaxTenuringThreshold 更新为 1 ，自然就解决了这个“乱晋升”的问题</p><p>改完收工，再次发版手动预热后，再也没有切量后长暂停的问题了，Young GC稳定在 30-100ms，成功解决！</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;开启Dump文件自动转储&quot;&gt;&lt;a href=&quot;#开启Dump文件自动转储&quot; class=&quot;headerlink&quot; title=&quot;开启Dump文件自动转储&quot;&gt;&lt;/a&gt;开启Dump文件自动转储&lt;/h1&gt;&lt;p&gt;一般来说，线上运行的系统都会加上下面的 JVM 参数，以便如</summary>
      
    
    
    
    <category term="JVM" scheme="https://palette-k.github.io/categories/JVM/"/>
    
    
    <category term="JVM" scheme="https://palette-k.github.io/tags/JVM/"/>
    
    <category term="MAT" scheme="https://palette-k.github.io/tags/MAT/"/>
    
  </entry>
  
  <entry>
    <title>玩转AI应用</title>
    <link href="https://palette-k.github.io/2025/09/22/%E7%8E%A9%E8%BD%ACAI%E5%BA%94%E7%94%A8/"/>
    <id>https://palette-k.github.io/2025/09/22/%E7%8E%A9%E8%BD%ACAI%E5%BA%94%E7%94%A8/</id>
    <published>2025-09-22T03:42:27.000Z</published>
    <updated>2025-10-17T09:54:20.229Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大模型"><a href="#大模型" class="headerlink" title="大模型"></a>大模型</h1><p>以下是一些常用大模型的特性以及区别：</p><table><thead><tr><th>厂商&#x2F;系列</th><th>代表模型</th><th>核心特点</th><th>典型应用场景</th><th>开源&#x2F;闭源</th><th>大致成本</th></tr></thead><tbody><tr><td><strong>OpenAI</strong></td><td>GPT-3.5</td><td>成本（计算／资源）较低；能做一般写作、代码辅助、总结、翻译等任务；</td><td>对话式任务，对一般任务（写作、聊天、翻译、简单问题）非常合适</td><td>闭源</td><td>输入$0.5&#x2F;百万tokens，输出$1.5&#x2F;百万tokens</td></tr><tr><td></td><td>GPT-4o &#x2F; GPT-4.1-series</td><td>通用性强，多模态（文本、图像、音频），生态整合好，引入更大的上下文支持</td><td>内容创作、复杂推理、代码生成、多模态分析</td><td>闭源</td><td>GPT-4.1 API: 输入$2&#x2F;百万tokens, 输出$8&#x2F;百万tokens</td></tr><tr><td></td><td>GPT-5</td><td><strong>上下文长度</strong>：API 上输入 + 输出合起来可以 ~400K tokens 或更多，更好地处理非常长对话、文档、或混合任务（例如图像＋文本长内容）；<strong>逻辑推理</strong>：在推理深度、多步逻辑、工具调用／agent 工作流中是目前顶尖版本；被设计为“知道什么时候 fast 回答、什么时候 think 更久”的。<strong>多模态感知能力</strong>：多模态能力更成熟；不仅处理图像 + 文本，也能够把这些模态的信息整合进工具调用、推理等任务中。<strong>工具使用</strong>：GPT-5 在 Agent &#x2F;复杂任务自动化 &#x2F;工具链调用 &#x2F;长流程任务中被设计为更可靠的支持者。</td><td>企业／团队使用／复杂 agent &#x2F; 多工具调用流程</td><td>闭源</td><td>GPT-5 是最新旗舰，默认模型；Plus／Pro／Enterprise 等订阅得到不同等级访问；API 用户也可以调用多个变体；有“thinking 模式”等可选设定以匹配任务需求。</td></tr><tr><td><strong>Anthropic</strong></td><td>Claude 3.5 (Sonnet)</td><td>在多数普通任务／生成任务／基础编程任务中表现稳定。能较好处理图像 + 文本，写作、摘要、对话类任务表现不错。支持的上下文窗口已经很大（在 Claude 平台／Bedrock 等为 200,000 tokens 的默认窗口）对文档 &#x2F;对话历史处理不错。</td><td>简单写作／对话／摘要／内容生成，不需要特别复杂的逻辑链／大量上下文</td><td>闭源</td><td>输入$3&#x2F;百万tokens, 输出$15&#x2F;百万tokens</td></tr><tr><td></td><td>Claude 3.7 (Sonnet)</td><td><strong>安全稳健</strong>，<strong>超长上下文</strong>（200K tokens），<strong>混合推理模式</strong>（快思慢想），代码能力强。对复杂推理任务、中间解释 (“step-by-step thinking”) 更强；对指令的遵守 (“follow instructions”) 在多数情况下提升；写作／创造性任务中语境构建更丰富。</td><td>企业级应用、长文档处理、安全敏感型任务</td><td>闭源</td><td>输入$3&#x2F;百万tokens, 输出$15&#x2F;百万tokens</td></tr><tr><td></td><td>Claude 4</td><td>在 agent 工作流 &#x2F;自动化任务中表现更强；在复杂编码任务、长链推理任务（需要多个步骤／需要处理大量上下文／计划任务等）中优势明显。Sonnet 4 最新版本（及 Opus 4）支持 <strong>1,000,000 tokens（即百万 token）</strong> 的上下文窗口（至少 Sonnet 4 有 preview &#x2F;扩展支持）。</td><td>高复杂／长期项目／大型代码库／需要工具调用／代理操作／大型文件 &#x2F; 上下文／精准度高／安全性要求高</td><td>闭源</td><td>输入$3&#x2F;百万tokens, 输出$15&#x2F;百万tokens</td></tr><tr><td><strong>DeepSeek (开源)</strong></td><td>DeepSeek-R1 (系列)</td><td><strong>逻辑推理专家</strong>，专为数学证明、代码生成、金融分析等复杂任务优化。它基于强化学习（RL）训练，能展示“思维链”（Chain-of-Thought），让推理过程更透明。</td><td><strong>科研与数学</strong>（解数学题、公式推导）、<strong>金融分析</strong>（生成复杂SQL查询、策略优化）、<strong>算法开发</strong>（优化代码逻辑、调试）、<strong>教育辅助</strong>（分步讲解解题思路）</td><td>部分开源</td><td>较小模型可本地免费部署；671B通过API调用</td></tr><tr><td></td><td>DeepSeek-V3 (系列)</td><td><strong>全能型选手</strong>，擅长<a href="https://cloud.tencent.com/product/nlp?from=20067&from_column=20067">自然语言处理</a>（NLP）任务，如文本生成、多语言翻译、智能客服等。计算效率极高，适合大规模应用。</td><td><strong>内容创作</strong>（写文章、报告、广告文案）、<strong>智能客服</strong>（快速响应、多轮对话）、<strong>多语言翻译</strong>（支持高质量中英互译）、<strong>代码辅助</strong>（补全、注释生成）</td><td>闭源</td><td>API成本低（输入$0.14&#x2F;百万tokens），适合企业大规模部署。</td></tr></tbody></table><blockquote><p>小模型与大模型的区别在哪？为什么现在AI大模型这么流行？</p></blockquote><p>小模型／专门模型：通常训练／设计是为某一类任务或某一个业务场景（比如推荐系统、CTR预测、分类、标签预测）。当任务变了或者场景变复杂，这些模型可能性能下降严重。而且小模型往往依赖有限特征（用户行为、特定历史、有限长度的输入／窗口），不能处理非常长对话／非常多上下文，而且依赖于监督学习和既定规则，边界清晰，职责单一，不会改变系统的核心架构。</p><p>大模型（LLMs）：LLMs 可以处理大上下文、对话历史、复杂提示（prompt）／prompt engineering，可以做推理链、中间思考、解释性输出。甚至可以去做RAG（外部知识库检索增强）、MCP（连接外部工具使用），形成可扩展的 Agent 体系。</p><h1 id="RAG"><a href="#RAG" class="headerlink" title="RAG"></a>RAG</h1><p>RAG<strong>（Retrieval Augmented Generation，检索增强生成）</strong>, 其核心在于将 LLMs 与外部知识库（如维基百科或企业内部文档）连接，使得模型在生成响应前，能够先从这些知识库中检索并使用最相关的信息。这项使开发者能够在无需为每个特定任务重新训练或微调大模型的情况下，通过连接外部知识库和文档，为模型注入额外的非参数化知识，从而显著提升其在专业领域的能力和回答精度。</p><p>RAG 系统的搭建与运维，需依托于一套复杂的检索机制，该机制依赖向量搜索及嵌入技术，以确保 LLM 能够高效获取最为契合的信息资源。</p><p>RAG是一种将信息检索与生成模型相结合的混合架构。首先，检索器从外部知识库或文档集中获取与用户查询相关的内容片段；然后，生成器基于这些检索到的内容生成自然语言输出，确保生成的内容既信息丰富，又具备高度的相关性和准确性。</p><p>一张图看下RAG的基础原理：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/3c53071211311c4f98dabdf7faac64f1f86e7dcb.png"></p><h2 id="RAG-标准技术流程"><a href="#RAG-标准技术流程" class="headerlink" title="RAG 标准技术流程"></a>RAG 标准技术流程</h2><p>首先看下这张来自于极客时间实战专栏：RAG 快速开发实战中的分享：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/175ece8ae90127050ad7c5c523bb508406af5e48.png" alt="image-20250922135345984"></p><p>RAG 标准流程由索引（Indexing）、检索（Retriever）和生成（Generation）三个核心阶段组成。</p><p><strong>索引阶段</strong>，通过处理多种来源多种格式的文档提取其中文本，将其切分为标准长度的文本块（chunk），并进行嵌入向量化（embedding），向量存储在向量数据库（vector database）中。</p><p><strong>检索阶段</strong>，用户输入的查询（query）被转化为向量表示，通过相似度匹配从向量数据库中检索出最相关的文本块</p><p><strong>最后生成阶段</strong>，检索到的相关文本与原始查询共同构成提示词（Prompt），输入大语言模型（LLM），生成精确且具备上下文关联的回答。通过这一流程，RAG实现了检索与生成的有机结合，显著提升了 LLM 在领域任务中的准确性和实时性。</p><p>再来看看向量的概念和语义搜索。</p><p>比如说你有两个水果，我们可以把2个水果通过不同的维度计算出来一个向量的值，形成一个向量的数组，例如：</p><p>苹果：[红色: 0.92, 甜度: 0.83, 圆形: 0.78]</p><p>草莓：[红色: 0.85, 甜度: 0.75, 圆形: 0.62]</p><p>虽然苹果和草莓是不同的水果，但它们的向量很接近。这表明它们有相似的特性，比如颜色和甜度。但如果你把“老虎”表示成向量，则和苹果的向量就不接近。通过比较向量的“距离”，计算机能快速判断哪些事物是相关的。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2b30a18a157ba09bd690bb4f47bab1c9fc6f38b1.png" alt="image-20250922135546319"></p><p>理解了向量后，我们也许要知道在RAG中，一个重要的搜索方法就是基于向量的语义相似性搜索：</p><p>语义检索是通过向量距离，计算用户问题与知识库内容的距离，从而得出“相似度”，当然这并不是语文上的相似度，而是数学上的。</p><h2 id="RAG-优化手段"><a href="#RAG-优化手段" class="headerlink" title="RAG 优化手段"></a>RAG 优化手段</h2><h3 id="知识采集"><a href="#知识采集" class="headerlink" title="知识采集"></a>知识采集</h3><p>RAG的使用有一个关键起点，就是知识库的搭建。而知识库搭建又涉及到一个最原始最通用的方式：数据导入。在企业实际场景中，数据导入的形式五花八门，远不止网页内容。我们需要将各种<strong>结构化数据</strong>和<strong>非结构化数据</strong>导入到 AI 的知识库中，才能为后续问答系统提供高质量的“知识地基”。</p><blockquote><p>什么是结构化数据与非结构化数据？</p></blockquote><p><strong>非结构化数据</strong>：指那些没有固定格式、不可按行列直接组织的数据，例如：</p><ul><li><p>PDF、Word、PPT 等文档</p></li><li><p>云文档</p></li><li><p>图片</p></li><li><p>网页内容等</p></li></ul><p><strong>结构化数据</strong>：指按预定义结构组织的数据，通常以行和列构成，例如：</p><ul><li>数据库中的表格数据</li></ul><p>因此，企业在构建 AI 系统时，还需要掌握从不同来源导入数据的能力，包括文本、表格、图片、网页等内容，为 RAG 系统提供多样、真实的数据支撑。</p><p>一个PDF转Markdown的软件：MinerU，这个软件已经在很多公司的生产环境使用。</p><p>企业中除了数据库的知识数据外，还有大量的企业对外的产品文档、帮助手册，而这些文件也需要存储到AI的知识库中。MinurU能够非常较大程度的解析各种PDF文件为Markdown格式，同时识别里面的各种元素。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ffa3692c081c4ab33add66320b2aede0e5f1c79e.png" alt="image-20250922140535592"></p><h3 id="内容分块"><a href="#内容分块" class="headerlink" title="内容分块"></a>内容分块</h3><p>在 RAG 系统中，文档是需要分割成文本块再进行向量嵌入的。分块太大，可能包含太多不相关的信息，从而降低了检索的准确性。相反，分块太小可能会丢失必要的上下文信息，导致生成的回应缺乏连贯性或深度。</p><p>分块方式的选择：</p><ul><li><strong>固定大小的分块</strong>：直接设定块中的字数，并选择块之间是否重复内容。通常我们会保持块之间的一些重叠，以确保语义上下文不会在块之间丢失。</li><li><strong>内容分块</strong>：根据文档具体内容分块，例如根据标点符号（如句号）分割。或者直接使用更高级的NLTK或者spaCy库提供的句子分割功能。</li><li><strong>递归分块</strong>：在大多数情况下推荐的方法。其通过重复地应用分块规则来递归地分解文本。例如在langchain中会先通过段落换行符（<code>\n\n</code>）进行分割。然后检查这些块地大小。如果大小不超过一定阈值，则该块被保留。对于大小超过标准的块，使用单换行符（<code>\n</code>）再次分割。以此类推，不断根据块更新更小的分块规则（如空格、句号）。这种方法可以灵活地调整块的大小。例如，对于文本中的密集信息部分，可能需要更细的分割来捕捉细节；而对于信息较少的部分，则可以使用更大的块。而它的挑战在于，需要制定精细的规则来决定何时和如何分割文本。</li><li><strong>从小到大分块</strong>：更直接的解决方案是把同一文档进行从大到小所有尺寸的分割，然后把不同大小的分块全部存进向量数据库，并保存每个分块的上下级关系，进行递归搜索。但是可想而知，我们需要存储大量重复内容，这种方案的缺点就是需要更大的储存空间。</li><li><strong>特殊结构分块</strong>：针对特定结构化内容的专门分割器。这些分割器特别设计来处理这些类型的文档，以确保正确保留和理解其结构。langchain提供的特殊分割器包括：Markdown文件，Latex文件，以及各种主流代码语言分割器。</li></ul><blockquote><p>上述方法中无一例外最终都需要设定一个参数——块的大小，那么我们应该如何选择呢？</p></blockquote><p>首先不同的嵌入模型有其最佳输入大小。比如openai和text-embedding-ada-002模型在256或512大小的块上效果更好。其次，文档的类型和用户查询的长度及复杂性也是决定分块大小的重要因素。处理长篇文章或书籍时，较大分块有助于保留更多的上下文和主题连贯性；而对于社交媒体帖子，较小的分块更适合捕捉每个帖子的精确语义。实际场景中，可能需要不断实验调整，在一些测试中，128大小的分块往往是最佳选择，在无从下手时，可以从这个大小作为起点进行测试。</p><h3 id="嵌入模型"><a href="#嵌入模型" class="headerlink" title="嵌入模型"></a>嵌入模型</h3><p>嵌入模型可以帮我们把文本转换成向量，显然不同的嵌入模型带来的效果也不尽相同。比如Word2Vec模型有一些局限性，其生成的词向量是静态的。一旦模型训练完成，每个词的向量就是固定不变的，但如果存在一词多义的情况，可能就会导致问题。相比之下，引入自注意力机制的模型，比如BERT，能够根据上下文动态地调整词义，使得同一个词在不同语境下有不同的向量表示。</p><p>在这种情况下，我们推荐参考Hugging Face推出的嵌入模型排行榜MTEB（<a href="https://huggingface.co/spaces/mteb/leaderboard">huggingface.co</a>），同时要注意并非所有的嵌入模型都支持中文，因此在选择时应查阅模型说明。</p><h3 id="重排模型"><a href="#重排模型" class="headerlink" title="重排模型"></a>重排模型</h3><p>重排模型通过对初始检索结果进行更深入的相关性评估排序，确保最终展示给用户的结果更加符合其查询意图。这一过程通常由深度学习模型实现，如Cohere模型。这些模型会考虑更多的特征，比如查询意图、词汇的多重语义、用户的历史行为和上下文信息等。</p><p>在实践中，使用RAG构建系统时都应考虑重排方法，以评估其是否能够提高系统性能。</p><h3 id="指代消解"><a href="#指代消解" class="headerlink" title="指代消解"></a>指代消解</h3><blockquote><p><strong>什么是指代消解？</strong></p></blockquote><p>简单来说，<strong>指代消解</strong>就是让机器学会理解“它”“他”“这里”这种模糊代词到底指的是什么。在我们日常的对话中，代词就像个调皮的小孩，躲在句子里不肯说出“我是谁”，而机器如果不能正确理解这些代词，就很容易答非所问。</p><p>尤其是在 RAG（Retrieval Augmented Generation）系统中，能否精准“还原”代词背后的真实含义，直接影响到知识的检索效果和准确率。</p><p>在RAG系统中，信息的准确检索和生成依赖于对上下文的深刻理解。如果系统不能正确解析指代关系，就会出现信息混淆，降低召回率和准确性。例如，在检索知识库时，错误地理解“它”可能导致系统返回与用户真正意图不匹配的答案。因此，指代消解有助于：</p><ol><li>提升信息检索的精确度</li><li>增强生成回答的逻辑连贯性</li><li>改善用户体验</li></ol><p>指代消解在处理含有复杂指代关系的文本时尤为关键。常见应用场景包括：</p><ol><li>自然语言问答系统</li><li>对话机器人</li><li>机器翻译</li><li>信息抽取与文本摘要</li></ol><p>当文本中出现多次代词指向同一对象或者含糊不清的指代时，指代消解的作用就显得格外重要。</p><p>指代消解的实现通常涉及以下几个步骤：</p><ol><li><strong>候选实体识别</strong>：梳理用户可能常见的问题，并识别出文本中所有可能的指代对象。</li><li><strong>特征提取</strong>：利用上下文历史聊天记录信息、语义关系等提取有助于判断指代关系的特征。</li><li><strong>模型判定</strong>：基于AI大模型，根据当前用户问题和历史聊天记录，从而确定最佳的指代关系。</li><li><strong>后处理与评估</strong>：持续的对返回结果结果进行优化和校正，确保整体准确性。</li></ol><h3 id="查询重写"><a href="#查询重写" class="headerlink" title="查询重写"></a>查询重写</h3><blockquote><p><strong>什么是查询重写？</strong></p></blockquote><p><strong>查询重写</strong>（Query Rewriting），是将用户原始的提问，转换为一个更能表达其真实意图的查询方式。它的目标是重新表述问题，以更高的匹配度找到相关文档。</p><p>这个能力在面对模糊、歧义或用户表达方式与知识库中的文档术语不一致的情况下，尤其重要。比如用户问：“它开放吗？”如果能自动重写为“长城这个景点现在开放吗，可以去参观吗？”那么检索结果的范围和语义就丰富了，返回的结果显然就更准确了。</p><blockquote><p><strong>为什么需要查询重写</strong></p></blockquote><p>• 用户的提问通常比较口语化，直接用问题检索效果不佳</p><p>• 减少查询和文档之间的语义差异</p><p>• 多轮对话中的检索，需要指代消解</p><p>查询重写策略：</p><ul><li><strong>子问题查询</strong>，生成相关子问题，补充query的细节：利用LLM的分析能力，识别出需要解答哪些子问题才能全面回答主问题。将这些子问题同时发送到检索系统（如向量数据库或搜索引擎）中，寻找与每个子问题最相关的文档片段。将检索到的所有与子问题相关的信息提供给LLM，指令它基于这些证据进行梳理、整合，最终生成一个连贯、全面的答案。</li><li><strong>假设文档（HyDE）</strong>：向LLM发送指令，如“请生成一个能回答以下问题的段落：[用户查询]”。LLM会输出一段虚构但合理的文本。将这个生成的“假设文档”转换为向量（Embedding），然后在向量数据库中进行相似度搜索。找到与“假设文档”最相似的真实文档片段，并将其作为最终检索结果返回给用户或用于后续的答案生成。</li><li><strong>回溯提示（STEP-BACK Prompting）</strong>：引导LLM基于原始问题，提出一个关于基本概念、通用原则或更广泛背景的问题。先检索并获取这个回溯问题的答案。将检索到的通用知识与原始的具体问题相结合，进行演绎推理，最终得出答案。</li><li><strong>查询扩展</strong>，伪相关反馈提供领域知识补充：使用用户的原始查询进行初步检索，得到一组初始文档。从排名前K的文档中，通过算法（如TF-IDF, BM25, 或Embedding）提取出与原始查询最相关且信息量最大的术语。将原始查询与提取出的新术语组合在一起，形成一个新的、更丰富的查询。使用扩展后的新查询进行最终检索，得到更准确、更全面的结果。</li></ul><h1 id="MCP"><a href="#MCP" class="headerlink" title="MCP"></a>MCP</h1><p>模型上下文协议（MCP）是一种 开放协议，用于实现 LLM 应用 与 外部数据源和工具 之间的无缝集成。无论你是在构建 AI 驱动的 IDE，优化 聊天界面，还是创建自定义 AI 工作流，MCP 提供了一种 标准化方式，让 LLM 能够访问所需的上下文信息。</p><p>MCP（ModelContext Protocol）就像是AI世界的USB-C接口，统一了各种工具的连接方式，也就是说通过这个“扩展坞”，AI就可以轻松地与世界上的各种工具协作，变得更聪明、更高效。有了这个，在企业开发中就会通过MCP更容易地接入业务系统，从而实现通过自然语言来操作业务系统。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/67912d55b60e090cd2e644f06d906393e84b6f33.png" alt="image-20250922144712395"></p><p>目前已经有非常多的MCP Server可以让大家使用，网址如下：</p><ul><li><p>Smithery：<a href="https://smithery.ai/">https://smithery.ai/</a></p></li><li><p>MCP导航：<a href="https://mcp.so/">https://mcp.so/</a></p></li><li><p>阿里云百炼：<a href="https://bailian.console.aliyun.com/?tab=mcp">https://bailian.console.aliyun.com/?tab=mcp</a></p></li><li><p>MCP官方服务器合集：<a href="https://github.com/modelcontextprotocol/servers">https://github.com/modelcontextprotocol/servers</a></p></li><li><p>MCP Github热门导航：<a href="https://github.com/punkpeye/awesome-mcp-servers">https://github.com/punkpeye/awesome-mcp-servers</a></p></li></ul><p>MCP刚发布的时候不温不火，直到今年Agent大爆发才被广泛关注。而在今年2月，Cursor正式宣布加入MCP功能支持，一举将MCP推到了全体开发人员面前。从本质上来说，MCP是一种技术协议，一种智能体Agent开发过程中共同约定的一种规范。这就好比秦始皇的“<strong>书同文、车同轨</strong>”，在统一的规范下，大家的<strong>协作效率就能大幅提高</strong>，最终<strong>提升智能体Agent的开发效率</strong>。</p><p>总的来说，MCP解决的最大痛点，就是Agent开发中调用外部工具的技术门槛过高的问题。</p><h2 id="MCP工作原理"><a href="#MCP工作原理" class="headerlink" title="MCP工作原理"></a>MCP工作原理</h2><p>下面这张图展示了MCP的工作原理：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1de07bb9f1590e01cf839d5a5619b6c880f0eaab.png" alt="image-20250922145126975"></p><h3 id="MCP通信数据结构"><a href="#MCP通信数据结构" class="headerlink" title="MCP通信数据结构"></a>MCP通信数据结构</h3><p>在MCP开发过程中，我们会涉及到客户端的开发、服务端的开发，在使用中，客户端AI程序必须通过MCP客服端与MCP服务端进行数据通信，而在通信过程中，通常我们会约定一个说话的格式，这个说话的格式通常称为：协议。</p><p>MCP的通信过程中，采用的协议是JSON-RPC，JSON-RPC 就是一个在MCP业务场景中的“说话的格式”。</p><p>MCP 强制使用 JSON-RPC 2.0，通过这种标准的约定格式，完成业务流程的通信。这种协议简单轻量，消息格式简单。基于 JSON，几乎所有编程语言都支持。它传输层无关：可在 HTTP、WebSocket、TCP 等多种传输协议上使用。</p><p>比如一个JSON-RPC的请求结构如下所示：</p><p>请求体：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;subtract&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="number">42</span><span class="punctuation">,</span> <span class="number">23</span><span class="punctuation">]</span><span class="punctuation">,</span> <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>返回体：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span><span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;result&quot;</span><span class="punctuation">:</span> <span class="number">19</span><span class="punctuation">,</span> <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>针对请求体的结构说明如下：</p><p>jsonrpc : 必须为 “2.0”。</p><p>method: 调用的方法名（字符串）。</p><p>params: 参数（可省略），支持对象（命名参数）或数组（位置参数）。</p><p>id: 请求标识符。</p><p>请求体这种东西就像你给外卖小哥发消息：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;method&quot;</span><span class="punctuation">:</span> <span class="string">&quot;buy&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;params&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;item&quot;</span><span class="punctuation">:</span> <span class="string">&quot;coffee&quot;</span><span class="punctuation">,</span> <span class="attr">&quot;count&quot;</span><span class="punctuation">:</span> <span class="number">2</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>method：我要干啥，比如“buy”。</p><p>params：我要的细节，比如“2杯咖啡”。</p><p>id：这是我给这单起的编号，方便等下对上结果。</p><p>然后再响应阶段：外卖小哥给你回消息：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;result&quot;</span><span class="punctuation">:</span> <span class="string">&quot;ok&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>这时候你就能根据 id 知道：哦，这是我刚才点的咖啡的结果。</p><p>要是出错了，对方会这么回：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;jsonrpc&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;error&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span> <span class="attr">&quot;code&quot;</span><span class="punctuation">:</span> <span class="number">-32601</span><span class="punctuation">,</span> <span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Method not found&quot;</span> <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">&quot;id&quot;</span><span class="punctuation">:</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>意思就是“你点的这个菜菜单里没有”。</p><h2 id="MCP通信协议"><a href="#MCP通信协议" class="headerlink" title="MCP通信协议"></a>MCP通信协议</h2><p><strong>MCP 协议基于 SSE 的完整生命周期</strong>：从“握手建联”，到“初始化确认”，再到“发工具清单、调用工具”，中间还有“心跳保活”，最后“优雅断开”。</p><p>1️⃣ 连接建立</p><ol><li>客户端：我先 GET &#x2F;sse，想开个 SSE 通道。</li><li>服务端：好，给你一个 SSE 管道（Emitter），还顺手建了个会话（Session）。</li><li>双方：通道打通啦，可以传消息了。</li></ol><p>2️⃣ 会话初始化</p><ol><li>客户端：我发个初始化请求（InitializeRequest），告诉你我是谁、怎么工作。</li><li>服务端：收到！找到对应的会话，回你一个 InitializeResponse。</li><li>双方：好，身份确认，咱们对接上了。</li></ol><p>3️⃣ ToolList请求（工具清单）</p><ol><li>客户端：你有哪些工具能用？我来调用。</li><li>服务端：等下，我调调工具管理器，整理出工具清单。</li><li>服务端推送：这是工具列表，拿去用吧。</li></ol><p>4️⃣ 连接维持（心跳）</p><ol><li>客户端：ping~ 还活着吗？</li><li>服务端：pong~ 我在呢，同时更新一下心跳时间。</li><li>双方：OK，确认连接不中断。</li></ol><p>5️⃣ 工具调用</p><ol><li>客户端：我现在要用某个工具（POST tools&#x2F;call），给你参数。</li><li>服务端：收到，我去找对应的工具处理器执行一下。</li><li>服务端：执行完了，把结果推给你（SSE）。</li><li>双方：一次完整的调用结束。</li></ol><p>6️⃣ 连接关闭</p><ol><li>客户端：事情办完了，我要断开啦。</li><li>服务端：好，那我把你的会话和 SSE 管道都清掉。</li><li>双方：优雅收尾，拜拜。</li></ol><h1 id="AI编排设计模式分享"><a href="#AI编排设计模式分享" class="headerlink" title="AI编排设计模式分享"></a>AI编排设计模式分享</h1><h2 id="设计模式之一：链式工作流"><a href="#设计模式之一：链式工作流" class="headerlink" title="设计模式之一：链式工作流"></a>设计模式之一：链式工作流</h2><p>这个模式就像工厂流水线——把复杂任务拆成一个个小工序，前一道工序的结果自动传给下一道。技术实现上用了”责任链”设计模式，支持随时增加新的处理环节。</p><p>使用场景：</p><p>这个实现展示了几个关键原则：</p><ol><li>需要分步骤完成的复杂任务（比如先查天气再规划行程最后生成攻略）</li><li>宁愿多花点时间也要保证准确率（像重要文件的多级审批）</li><li>后一步依赖前一步的结果（就像做菜必须按洗菜→切菜→炒菜的顺序）</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/a2383d98c3c4c765d007a2180ae97444e7a75057.png" alt="image-20250922153332913"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/d163ec16eb01561d2002ea8b470e196c771df6e9.png" alt="image-20251017142639069"></p><p>使用 SequentialAgent 将 writer_agent、reviewer_agent 依次串联起来。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0487cd0b8901c94ceb892ca661163718f80dd55b.png" alt="image-20251017142651357"></p><h2 id="设计模式之二：并行化工作流"><a href="#设计模式之二：并行化工作流" class="headerlink" title="设计模式之二：并行化工作流"></a>设计模式之二：并行化工作流</h2><p>这个模式就像开了多个窗口同时干活——让多个大模型同时处理任务，最后把结果汇总起来。主要有两种方式：</p><ol><li><strong>分片处理</strong>：把大任务拆成小任务，分给不同的大模型同时处理（类似分工作业）</li><li><strong>投票机制</strong>：让多个大模型同时处理同一个任务，最后投票选出最佳结果（像开会讨论）</li></ol><p>使用场景：</p><p>并行化工作流模式展示了对多个大语言模型操作的高效并发处理。这种模式对于需要并行执行大语言模型调用并自动聚合输出的场景特别有用。</p><ol><li>要处理一堆相似但互不干扰的任务（比如同时分析多个用户群体的数据）</li><li>需要多个任务独立运行（像工厂里的流水线作业）</li><li>任务能快速拆解且可以并行执行（比如同时生成多个产品描述）</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/a812fd2c6ec53a5b0a88c7979a109eba35abaec3.png" alt="image-20250922153404486"></p><p>开发一个智能搜索助手的智能体，它包含 ResearchAgent1(擅长AI Agent)、ResearchAgent2(擅长 Microsercies)两个搜索智能体，分别擅长特定领域搜索。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/26122847424090d4b1533d3745585d2211a7ee83.png" alt="image-20251017142224196"></p><p>使用 ParallelAgent 工作流将两个子 Agent 关联起来： </p><p><img src="https://i0.hdslb.com/bfs/openplatform/47fd9fedb228c1842233f0ae4a7aa713c36b2384.png" alt="image-20251017142236243"></p><p>两个并行子 Agent 的输出需要进行合并汇总，因此定义一个 MergerAgent，最后通过 SequentialAgent 将 ResearchAgent 和 MergerAgent 串联到一起。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/39a00fc699a3eb6be137314c27d00c29060f2022.png" alt="image-20251017142520742"></p><h2 id="设计模式之三：路由工作流"><a href="#设计模式之三：路由工作流" class="headerlink" title="设计模式之三：路由工作流"></a>设计模式之三：路由工作流</h2><p>路由模式实现了智能任务分配，能够针对不同类型的输入进行专门处理，这种模式专为复杂任务设计，不同类型的输入由专门的流程处理会更好。</p><p>这个模式就像智能分诊台——能自动识别问题类型，转给最专业的处理流程。技术实现上相当于给大模型装了个智能路由器，不同的问题自动走专用通道。</p><p>使用场景：</p><p>它使用大语言模型分析输入内容，并将其路由到最合适的专门提示或处理程序。</p><ol><li>要处理五花八门的问题类型（比如客服系统同时接咨询、投诉、技术问题）</li><li>不同问题需要不同专家处理（像医院分内科&#x2F;外科&#x2F;急诊）</li><li>需要精准分类输入内容（像快递自动分拣系统）</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/21d64ac100bdd9a4b0736c57a1afe00cf6e6de58.png" alt="image-20250922153437157"></p><p>可以使用  LlmRountingAgent 实现路由控制，它会根据 RoutingAgent 的职责、所有可用子 Agent的能力、当前用户的请求，来使用 LLM 智能决策下一个流程节点。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f17192518ac42942babaff5c4fe916aed50534ca.png" alt="image-20251017141813129"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/d1508d670668b26c6efd301741326bb0d0543d30.png" alt="image-20251017141827696"></p><h2 id="设计模式之四：协调者-执行者"><a href="#设计模式之四：协调者-执行者" class="headerlink" title="设计模式之四：协调者-执行者"></a>设计模式之四：协调者-执行者</h2><p>这个模式就像电影拍摄现场——导演（协调者）负责分镜头，各工种（执行者）专注自己的专业领域。技术实现上采用”中央指挥部+特种部队”的架构，既保持灵活又确保可控。</p><p>使用场景：</p><p>当你的任务像建造摩天大楼需要多方协作时：</p><ol><li>任务复杂到无法提前拆解（像应对突发事件的应急小组）</li><li>需要不同专业视角（像建筑设计需要结构&#x2F;水电&#x2F;装修多方配合）</li><li>解决方案需要动态调整（像军事行动中的实时战术变化）</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/a90bee98019fc81e130757642f432fb4a2daa1ea.png" alt="image-20250922153500040"></p><h2 id="设计模式之五：生成者-评估者"><a href="#设计模式之五：生成者-评估者" class="headerlink" title="设计模式之五：生成者-评估者"></a>设计模式之五：生成者-评估者</h2><p>这个模式就像作家与编辑的协作——写手（生成者）负责创作初稿，编辑（评估者）逐字推敲提出修改意见。技术实现上采用”创作-反馈”循环机制，直到作品达到出版标准。</p><ol><li><strong>生成者大语言模型</strong>：生成初始响应并根据反馈进行改进。</li><li><strong>评估者大语言模型</strong>：分析响应并提供详细的改进反馈。</li></ol><p>使用场景</p><p>评估者 - 优化者模式适用于需要多轮迭代以提高质量的任务。</p><ol><li>有明确的品质标准（像学术论文需要同行评审）</li><li>迭代改进能显著提升价值（像广告文案的AB测试）</li><li>追求完美输出（像电影剧本的多次修订）</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/789dc061f610565f1baf1e40bc652196ed359a3e.png" alt="image-20250922153802595"></p><p>这种模式我觉得和反思模式应该是同一个。反思（Reflection），是一种重要的AIAgent工作范式。</p><p>反思模式对于那些<strong>一次执行难以成功</strong>的任务特别有用。具体来说，AI首先针对任务生成一个初始输出，然后对这个输出进行审视，检查其准确性、完整性和逻辑性，识别出潜在的问题和改进空间。</p><p>这种模式的核心在于赋予AI自我评估和自我修正的能力。它不再是一个简单的输出生成器，而是一个能够不断学习、进步的智能体。通过反思，AI可以从自己的错误中吸取教训，积累经验，逐步提升解决问题的能力。</p><p>反思模式的应用：第一个模型处理完成后，第2个模型进行评审，然后让第1个模型处理节点在进行反思性的处理。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0ae05b10520ce3c039fe815767e4a5775b24ef69.png" alt="image-20250922155732340"></p><p>LoopAgent 可在循环中执行其子代理。它在指定的迭代次数内重复运行一系列代理，或者知道满足终止条件。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/cabb997d10dfd8a0dd27b8332f9997e18a57c814.png" alt="image-20251017142053602"></p><h2 id="设计模式之六：工具使用模式"><a href="#设计模式之六：工具使用模式" class="headerlink" title="设计模式之六：工具使用模式"></a>设计模式之六：工具使用模式</h2><p>模型可调用外部 API 或工具获取信息或执行操作，适用于实时数据查询、智能控制等。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/823494fc956bc51d7e84042c76d72e10ab993481.png" alt="image-20250922153915900"></p><p>在AI会话节点中集成了MCP工具服务，也算是这种模式的应用了。</p><h1 id="上下文管理与记忆系统"><a href="#上下文管理与记忆系统" class="headerlink" title="上下文管理与记忆系统"></a>上下文管理与记忆系统</h1><h2 id="运行时上下文处理的四大策略"><a href="#运行时上下文处理的四大策略" class="headerlink" title="运行时上下文处理的四大策略"></a>运行时上下文处理的四大策略</h2><p>根据上下文工程的研究与实践，智能体在运行时的上下文处理策略可归纳为四大类：写入(Write)、选择(Select)、压缩(Compress)和隔离(lsolate)。</p><h3 id="写入：将信息保存到外部记忆"><a href="#写入：将信息保存到外部记忆" class="headerlink" title="写入：将信息保存到外部记忆"></a>写入：将信息保存到外部记忆</h3><p>该策略指将信息保存到上下文窗口之外，以便未来使用，这是构建记忆系统的基础。</p><ul><li>暂存区(Scratchpads)：它特指 LLM 在生成下一步行动前，被引导输出的中间推理过程(即“思想链”，Chain ofThought)。这些思考步骤被记录下来，并与任务的观察结果一同作为下一轮推理的输入，从而形成一个连贯的思考与行动循环。</li><li>记忆(Memories)：帮助智能体跨越多个会话记住信息的持久化存储，如通过反思(Reflexion)模型在每次执行后生成的自我总结和经验。</li></ul><h3 id="选择：将相关信息拉入上下文"><a href="#选择：将相关信息拉入上下文" class="headerlink" title="选择：将相关信息拉入上下文"></a>选择：将相关信息拉入上下文</h3><p>该策略指在需要时，精准地将最相关的信息从外部拉入当前的上下文窗口。</p><ul><li>记忆检索：智能体根据当前任务，从长期记忆库中选择最相关的记忆。这通常利用向量检索<br>(用于语义相关性)和&#x2F;或知识图谱(用于实体关系)来实现。</li><li>工具选择：当智能体需要使用工具时，通过 RAG技术，根据当前任务的语义描述，从众多可用工具中选择最匹配的几个，将其 API描述放入上下文，供智能体决策调用。</li></ul><h3 id="压缩：为上下文瘦身"><a href="#压缩：为上下文瘦身" class="headerlink" title="压缩：为上下文瘦身"></a>压缩：为上下文瘦身</h3><p>该策略指在保留核心信息的前提下，减少上下文中的token数量。</p><ul><li>上下文摘要：使用 LLM 对冗长的对话历史或工具调用返回的密集信息进行总结，生成一个简短的摘要。</li><li>上下文修剪：通过过滤或修剪上下文，移除旧的或不重要的信息，例如只保留最近N轮的对话历史。</li></ul><h3 id="隔离：拆分与保护上下文"><a href="#隔离：拆分与保护上下文" class="headerlink" title="隔离：拆分与保护上下文"></a>隔离：拆分与保护上下文</h3><p>该策略指将上下文进行拆分，以帮助智能体更好地执行任务。</p><ul><li>多智能体系统：将复杂任务拆分给多个子智能体，每个智能体拥有独立的、更小的上下文窗口，专注于自己的子任务。</li><li>状态对象：通过定义结构化的模式(如 Pydantic模型)，在每个回合中只将指定的关键字段暴露给 LLM，而其他信息则保持隔离，避免干扰。</li></ul><h2 id="构建智能体的多级记忆系统"><a href="#构建智能体的多级记忆系统" class="headerlink" title="构建智能体的多级记忆系统"></a>构建智能体的多级记忆系统</h2><p>上述运行时策略的有效执行，依赖于一个设计精良的多级记忆系统。这个系统通常分为短期记忆和长期记忆两个层面，共同构成了智能体的认知基础。</p><h3 id="短期记忆-管理当前对话"><a href="#短期记忆-管理当前对话" class="headerlink" title="短期记忆:管理当前对话"></a>短期记忆:管理当前对话</h3><p>短期记忆管理着当前任务会话的完整上下文，它不仅包括对话历史，还应涵盖最近的工具调用结果、当前的执行计划和中间结论等。</p><ul><li>管理策略：<ul><li>滑动窗口：维护一个固定大小的窗口，只保留最近N轮的对话。</li><li>关键信息保留：识别并优先保留对话中的关键信息，如用户的明确指令、重要的实体等</li><li>定期清理:定期清理无关或冗余的对话内容。</li></ul></li></ul><h3 id="长期记忆：沉淀持久化知识"><a href="#长期记忆：沉淀持久化知识" class="headerlink" title="长期记忆：沉淀持久化知识"></a>长期记忆：沉淀持久化知识</h3><p>长期记忆存储跨越多个对话的持久化知识库，如用户偏好、过去项目的摘要、需要长期记住的事实等，是实现个性化和长期连贯性的关键。</p><ul><li>构建策略：<ul><li>定期提取:定期从短期记忆中提取关键信息，并合成为长期记忆。</li><li>高效检索:使用向量嵌入和向量数据库实现高效的语义检索。</li><li>版本管理:实现记忆的版本控制和更新机制，确保记忆的准确性。</li></ul></li></ul><h3 id="记忆转换时机"><a href="#记忆转换时机" class="headerlink" title="记忆转换时机"></a>记忆转换时机</h3><p>确定何时将短期记忆转化为长期记忆，是一个关键的决策点。常见的时机包括:</p><ul><li>对话自然结束时：提取关键信息保存为长期记忆。</li><li>识别到重要特征时：当系统识别到重要的用户偏好或个人信息时，主动进行保存。</li><li>定期摘要：定期(如每5轮对话)对短期记忆进行总结并存入长期记忆。</li></ul><p>对于 Agent 而言，上下文管理与记忆系统并非两个独立的组件，而是其认知核心的一体两面。运行时上下文管理是战术层面的操作，它决定了智能体在此时此刻如何最高效地利用其工作记忆;而多级记忆系统则是战略层面的支撑，它为智能体提供了历史感和个性化的基础。</p><p>通过将这两者有机结合，上下文工程使得智能体能够摆脱无状态的束缚，成为真正能够处理复杂任务、提供个性化服务的智能伙伴。这是 AI应用从能用走向可靠和好用的关键一步。</p>]]></content>
    
    
    <summary type="html">AI基本概念及新玩法</summary>
    
    
    
    <category term="AI" scheme="https://palette-k.github.io/categories/AI/"/>
    
    
    <category term="AI" scheme="https://palette-k.github.io/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>如何设计一个秒杀系统</title>
    <link href="https://palette-k.github.io/2025/09/12/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    <id>https://palette-k.github.io/2025/09/12/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</id>
    <published>2025-09-12T03:42:27.000Z</published>
    <updated>2025-10-13T08:39:29.494Z</updated>
    
    <content type="html"><![CDATA[<h1 id="不同场景下的不同架构案例"><a href="#不同场景下的不同架构案例" class="headerlink" title="不同场景下的不同架构案例"></a>不同场景下的不同架构案例</h1><p>如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。</p><p>但随着请求量的加大（比如从1w&#x2F;s到了10w&#x2F;s的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：</p><ol><li>把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；</li><li>在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；</li><li>将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；</li><li>增加秒杀答题，防止有秒杀器抢单。</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/5d227f416eecc2b7d5d67fc81dadaef7c026170f.png" alt="image-20250912114800915"></p><p>然而这个架构仍然支持不了超过100w&#x2F;s的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级，比如：</p><ol><li>对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；</li><li>在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。</li><li>增加系统限流保护，防止最坏情况发生。</li></ol><p>我们对页面进行了进一步的静态化，秒杀过程中不需要刷新整个页面，而只需要向服务端请求很少的动态数据。而且，最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2b3360a22d998a4d3fc49221fb41aa34da2f7626.png" alt="image-20250912114836701"></p><h1 id="动静分离方案"><a href="#动静分离方案" class="headerlink" title="动静分离方案"></a>动静分离方案</h1><h2 id="何为动静数据"><a href="#何为动静数据" class="headerlink" title="何为动静数据"></a>何为动静数据</h2><p>简单来说，<strong>“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和URL、浏览者、时间、地域相关，以及是否含有Cookie等私密数据</strong>。比如说：</p><ol><li>很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据，但是它是个动态页面。</li><li>我们如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。</li></ol><p>那么，怎样对静态数据做缓存呢？我在这里总结了几个重点。</p><p><strong>第一，你应该把静态数据缓存到离用户最近的地方</strong>。静态数据就是那些相对不会变化的数据，因此我们可以把它们缓存起来。缓存到哪里呢？常见的就三种，用户浏览器里、CDN上或者在服务端的Cache中。你应该根据情况，把它们尽量缓存到离用户最近的地方。</p><p><strong>第二，静态化改造就是要直接缓存HTTP连接</strong>。相较于普通的数据缓存而言，你肯定还听过系统的静态化改造。静态化改造是直接缓存HTTP连接而不是仅仅缓存数据，如下图所示，Web代理服务器根据请求URL，直接取出对应的HTTP响应头和响应体然后直接返回，这个响应过程简单得连HTTP协议都不用重新组装，甚至连HTTP请求头也不需要解析。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d6b55cefca40b52b2b7b753c5138fbde48a805bc.png" alt="image-20250912115240035"></p><p>第三，让谁来缓存静态数据也很重要。不同语言写的Cache软件处理缓存数据的效率也各不相同。以Java为例，因为Java系统本身也有其弱点（比如不擅长处理大量连接请求，每个连接消耗的内存较多，Servlet容器解析HTTP协议较慢），所以你可以不在Java层做缓存，而是直接在Web服务器层上做，这样你就可以屏蔽Java语言层面的一些弱点；而相比起来，Web服务器（如Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。</p><h2 id="如何做动静分离的改造"><a href="#如何做动静分离的改造" class="headerlink" title="如何做动静分离的改造"></a>如何做动静分离的改造</h2><p>下面，我以典型的商品详情系统为例来详细介绍。这里，你可以先打开京东或者淘宝的商品详情页，看看这个页面里都有哪些动静数据。我们从以下5个方面来分离出动态内容。</p><ol><li><strong>URL唯一化</strong>。商品详情系统天然地就可以做到URL唯一化，比如每个商品都由ID来标识，那么<a href="http://item.xxx.com/item.htm?id=xxxx%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA%E5%94%AF%E4%B8%80%E7%9A%84URL%E6%A0%87%E8%AF%86%E3%80%82%E4%B8%BA%E5%95%A5%E8%A6%81URL%E5%94%AF%E4%B8%80%E5%91%A2%EF%BC%9F%E5%89%8D%E9%9D%A2%E8%AF%B4%E4%BA%86%E6%88%91%E4%BB%AC%E6%98%AF%E8%A6%81%E7%BC%93%E5%AD%98%E6%95%B4%E4%B8%AAHTTP%E8%BF%9E%E6%8E%A5%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BB%A5%E4%BB%80%E4%B9%88%E4%BD%9C%E4%B8%BAKey%E5%91%A2%EF%BC%9F%E5%B0%B1%E4%BB%A5URL%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98%E7%9A%84Key%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BB%A5id=xxx%E8%BF%99%E4%B8%AA%E6%A0%BC%E5%BC%8F%E8%BF%9B%E8%A1%8C%E5%8C%BA%E5%88%86%E3%80%82">http://item.xxx.com/item.htm?id=xxxx就可以作为唯一的URL标识。为啥要URL唯一呢？前面说了我们是要缓存整个HTTP连接，那么以什么作为Key呢？就以URL作为缓存的Key，例如以id=xxx这个格式进行区分。</a></li><li><strong>分离浏览者相关的因素</strong>。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。</li><li><strong>分离时间因素</strong>。服务端输出的时间也通过动态请求获取。</li><li><strong>异步化地域因素</strong>。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。</li><li><strong>去掉Cookie</strong>。服务端输出的页面包含的Cookie可以通过代码软件来删除，如Web服务器Varnish可以通过unset req.http.cookie 命令去掉Cookie。注意，这里说的去掉Cookie并不是用户端收到的页面就不含Cookie了，而是说，在缓存的静态数据中不含有Cookie。</li></ol><p>分离出动态内容之后，如何组织这些内容页就变得非常关键了。这里我要提醒你一点，因为这其中很多动态内容都会被页面中的其他模块用到，如判断该用户是否已登录、用户ID是否匹配等，所以这个时候我们应该将这些信息JSON化（用JSON格式组织这些数据），以方便前端获取。</p><p>前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和CSI（Client Side Include）方案。</p><ol><li><strong>ESI方案（或者SSI）</strong>：即在Web代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。</li><li><strong>CSI方案</strong>。即单独发起一个异步JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。</li></ol><h2 id="动静分离的几种架构方案"><a href="#动静分离的几种架构方案" class="headerlink" title="动静分离的几种架构方案"></a>动静分离的几种架构方案</h2><p>前面我们通过改造把静态数据和动态数据做了分离，那么如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户呢？</p><p>这就涉及对用户请求路径进行合理的架构了。根据架构上的复杂度，有3种方案可选：</p><ol><li>实体机单机部署；</li><li>统一Cache层；</li><li>上CDN。</li></ol><h3 id="方案1：实体机单机部署"><a href="#方案1：实体机单机部署" class="headerlink" title="方案1：实体机单机部署"></a>方案1：实体机单机部署</h3><p>这种方案是将虚拟机改为实体机，以增大Cache的容量，并且采用了一致性Hash分组的方式来提升命中率。这里将Cache分成若干组，是希望能达到命中率和访问热点的平衡。Hash分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致Cache被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/986972ae2092227affa74c5b03bbcf3ca3f6db57.png" alt="image-20250912115638023"></p><p>实体机单机部署有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少Gzip压缩；</li><li>减少Cache失效压力，因为采用定时失效方式，例如只缓存3秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的Java应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了CPU的浪费，因为单个的Java进程很难用完整个实体机的CPU。</p><p>另外就是，一个实体机上部署了Java应用又作为Cache来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把Cache层单独抽出来公用比较合理，如下面的方案2所示。</p><h3 id="方案2：统一Cache层"><a href="#方案2：统一Cache层" class="headerlink" title="方案2：统一Cache层"></a>方案2：统一Cache层</h3><p>所谓统一Cache层，就是将单机的Cache统一分离出来，形成一个单独的Cache集群。统一Cache层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e8594ffc6609e96746a9cc8c8eef50a4ac0c22cc.png" alt="image-20250912115702515"></p><p>将Cache层单独拿出来统一管理可以减少运维成本，同时也方便接入其他静态化系统。此外，它还有一些优点。</p><ol><li>单独一个Cache层，可以减少多个应用接入时使用Cache的成本。这样接入的应用只要维护自己的Java系统就好，不需要单独维护Cache，而只关心如何使用即可。</li><li>统一Cache的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案虽然维护上更方便了，但是也带来了其他一些问题，比如缓存更加集中，导致：</p><ol><li>Cache层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对Cache做Hash分组，即一组Cache缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><blockquote><p>一个商品数据存储在多个Cache实例中，如何保证数据一致性呢？</p></blockquote><p>这个专栏中提的Hash分组都是基于Nginx+Varnish实现的，Nginx把请求的URL中的商品ID进行Hash并路由到一个upstream中，这个upstream挂载一个Varnish分组（如下图所示）。这样，一个相同的商品就可以随机访问一个分组的任意一台Varnish机器了。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/743f34318cce13b91dcdeb6c671a1325e8f07ed2.png" alt="image-20250912162900348"></p><p>有Cache的地方就必然存在失效问题。为啥要失效？因为要保证数据的一致性。所以要用到Cache必然会问如何保证Cache和DB的数据一致性，如果Cache有分组的话，还要保证一个分组中多个实例之间数据的一致性，就像保证MySQL的主从一致一样。</p><p>其实，失效有主动失效和被动失效两种方式。</p><ul><li>被动失效，主要处理如模板变更和一些对时效性不太敏感数据的失效，采用设置一定时间长度（如只缓存3秒钟）这种自动失效的方式。当然，你也要开发一个后台管理界面，以便能够在紧急情况下手工失效某些Cache。</li><li>主动失效，一般有Cache失效中心监控数据库表变化发送失效请求、系统发布也需要清空Cache数据等几种场景。其中失效中心承担了主要的失效功能，这个失效中心的逻辑图如下：</li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/8b53486d63156810d687cbe61fcc36941c34793d.png" alt="image-20250912163041092"></p><p>失效中心会监控关键数据表的变更（有个中间件来解析MySQL的binglog，然后发现有Insert、Update、Delete等操作时，会把变更前的数据以及要变更的数据转成一个消息发送给订阅方），通过这种方式来发送失效请求给Cache，从而清除Cache数据。如果Cache数据放在CDN上，那么也可以采用类似的方式来设计级联的失效结构，采用主动发请求给Cache软件失效的方式，如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/3607b38a11073d67a13333ea184a8ed537b481c2.png" alt="image-20250912163117755"></p><p>这种失效有失效中心将失效请求发送给每个CDN节点上的Console机，然后Console机来发送失效请求给每台Cache机器。</p><h3 id="方案3：上CDN"><a href="#方案3：上CDN" class="headerlink" title="方案3：上CDN"></a>方案3：上CDN</h3><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将Cache进一步前移到CDN上，因为CDN离用户最近，效果会更好。</p><p>但是要想这么做，有以下几个问题需要解决。</p><ol><li><strong>失效问题</strong>。前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证CDN可以在秒级时间内，让分布在全国各地的Cache同时失效，这对CDN的失效系统要求很高。</li><li><strong>命中率问题</strong>。Cache最重要的一个衡量指标就是“高命中率”，不然Cache的存在就失去了意义。同样，如果将数据全部放到全国的CDN上，必然导致Cache分散，而Cache分散又会导致访问请求命中同一个Cache的可能性降低，那么命中率就成为一个问题。</li><li><strong>发布更新问题</strong>。如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</li></ol><p>从前面的分析来看，将商品详情系统放到全国的所有CDN节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区；</li><li>离主站相对较远；</li><li>节点到主站间的网络比较好，而且稳定；</li><li>节点容量比较大，不会占用其他CDN太多的资源。</li></ol><p>最后，还有一点也很重要，那就是：节点不要太多。</p><p>基于上面几个因素，选择CDN的二级Cache比较合适，因为二级Cache数量偏少，容量也更大，让用户的请求先回源的CDN的二级Cache中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/871f14b3e51d04c89e03e5af239796b4e6237def.png" alt="image-20250912115722599"></p><p>使用CDN的二级Cache作为缓存，可以达到和当前服务端静态化Cache类似的命中率，因为节点数不多，Cache不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种CDN化方案。</p><p>除此之外，CDN化部署方案还有以下几个特点：</p><ol><li>把整个页面缓存在用户浏览器中；</li><li>如果强制刷新整个页面，也会请求CDN；</li><li>实际有效请求，只是用户对“刷新抢宝”按钮的点击。</li></ol><p>这样就把90%的静态数据缓存在了用户端或者CDN上，当真正秒杀时，用户只需要点击特殊的“刷新抢宝”按钮，而不需要刷新整个页面。这样一来，系统只是向服务端请求很少的有效数据，而不需要重复请求大量的静态数据。</p><p>秒杀的动态数据和普通详情页面的动态数据相比更少，性能也提升了3倍以上。所以“抢宝”这种设计思路，让我们不用刷新页面就能够很好地请求到服务端最新的动态数据。</p><h1 id="二八原则：有针对性地处理好系统的“热点数据”"><a href="#二八原则：有针对性地处理好系统的“热点数据”" class="headerlink" title="二八原则：有针对性地处理好系统的“热点数据”"></a>二八原则：有针对性地处理好系统的“热点数据”</h1><h2 id="发现热点数据"><a href="#发现热点数据" class="headerlink" title="发现热点数据"></a>发现热点数据</h2><h3 id="发现静态热点数据"><a href="#发现静态热点数据" class="headerlink" title="发现静态热点数据"></a>发现静态热点数据</h3><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出TOP N的商品，我们可以认为这些TOP N的商品就是热点商品。</p><h3 id="发现动态热点数据"><a href="#发现动态热点数据" class="headerlink" title="发现动态热点数据"></a>发现动态热点数据</h3><p>我们可以通过卖家报名或者大数据预测这些手段来提前预测静态热点数据，但这其中有一个痛点，就是实时性较差，如果我们的系统能在秒级内自动发现热点商品那就完美了。</p><p>能够动态地实时发现热点不仅对秒杀商品，对其他热卖商品也同样有价值，所以我们需要想办法实现热点的动态发现功能。</p><p>这里我给出一个动态热点发现系统的具体实现。</p><ol><li>构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点Key，如Nginx、缓存、RPC服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上Nginx模块统计的热点URL。</li><li>将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。</li></ol><p>这里我给出了一个图，其中用户访问商品时经过的路径有很多，我们主要是依赖前面的导购页面（包括首页、搜索页面、商品详情、购物车等）提前识别哪些商品的访问量高，通过这些系统中的中间件来收集热点数据，并记录到日志中。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/83dcc8c0d1a9284b05c9d5fa8b63e4f61a7b3ce0.png" alt="image-20250912120422769"></p><h2 id="处理热点数据"><a href="#处理热点数据" class="headerlink" title="处理热点数据"></a>处理热点数据</h2><p><strong>处理热点数据通常有几种思路：一是优化，二是限制，三是隔离</strong>。</p><p>先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用LRU淘汰算法替换。</p><p>再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的ID做一致性Hash，然后根据Hash做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。</p><p>最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的99%，隔离出来后也更方便对这1%的请求做针对性的优化。</p><p>具体到“秒杀”业务，我们可以在以下几个层次实现隔离。</p><ol><li><strong>业务隔离</strong>。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。</li><li><strong>系统隔离</strong>。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。</li><li><strong>数据隔离</strong>。秒杀所调用的数据大部分都是热点数据，比如会启用单独的Cache集群或者MySQL数据库来放热点数据，目的也是不想0.01%的数据有机会影响99.99%数据。</li></ol><p>当然了，实现隔离有很多种办法。比如，你可以按照用户来区分，给不同的用户分配不同的Cookie，在接入层，路由到不同的服务接口中；再比如，你还可以在接入层针对URL中的不同Path来设置限流策略。服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。</p><h1 id="流量削峰这事应该怎么做？"><a href="#流量削峰这事应该怎么做？" class="headerlink" title="流量削峰这事应该怎么做？"></a>流量削峰这事应该怎么做？</h1><h2 id="排队"><a href="#排队" class="headerlink" title="排队"></a>排队</h2><p>要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。</p><p>但是，如果流量峰值持续一段时间达到了消息队列的处理上限，例如本机的消息积压达到了存储空间的上限，消息队列同样也会被压垮，这样虽然保护了下游的系统，但是和直接把请求丢弃也没多大的区别。就像遇到洪水爆发时，即使是有水库恐怕也无济于事。</p><p>除了消息队列，类似的排队方式还有很多，例如：</p><ol><li>利用线程池加锁等待也是一种常用的排队方式；</li><li>先进先出、先进后出等常用的内存排队算法的实现方式；</li><li>把请求序列化到文件中，然后再顺序地读文件（例如基于MySQL binlog的同步机制）来恢复请求等方式。</li></ol><h2 id="答题"><a href="#答题" class="headerlink" title="答题"></a>答题</h2><p>最早期的秒杀只是纯粹地刷新页面和点击购买按钮，它是后来才增加了答题功能的。那么，为什么要增加答题功能呢？</p><p>这主要是为了增加购买的复杂度，从而达到两个目的。</p><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。2011年秒杀非常火的时候，秒杀器也比较猖獗，因而没有达到全民参与和营销的目的，所以系统增加了答题来限制秒杀器。增加答题后，下单的时间基本控制在2s后，秒杀器的下单比例也大大下降。</p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的1s之内延长到2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。</p><p>这里，我重点说一下秒杀答题的设计思路。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/013b09c6b0eae6269ad0742ee7059ea59a172628.png" alt="image-20250912155807956"></p><p>如上图所示，整个秒杀答题的逻辑主要分为3部分。</p><ol><li><strong>题库生成模块</strong>，这个部分主要就是生成一个个问题和答案，其实题目和答案本身并不需要很复杂，重要的是能够防止由机器来算出结果，即防止秒杀器来答题。</li><li><strong>题库的推送模块</strong>，用于在秒杀答题前，把题目提前推送给详情系统和交易系统。题库的推送主要是为了保证每次用户请求的题目是唯一的，目的也是防止答题作弊。</li><li><strong>题目的图片生成模块</strong>，用于把题目生成为图片格式，并且在图片里增加一些干扰因素。这也同样是为防止机器直接来答题，它要求只有人才能理解题目本身的含义。这里还要注意一点，由于答题时网络比较拥挤，我们应该把题目的图片提前推送到CDN上并且要进行预热，不然的话当用户真正请求题目时，图片可能加载比较慢，从而影响答题的体验。</li></ol><p>其实真正答题的逻辑比较简单，很好理解：当用户提交的答案和题目对应的答案做比较，如果通过了就继续进行下一步的下单逻辑，否则就失败。我们可以把问题和答案用下面这样的key来进行MD5加密：</p><ul><li>问题key：userId+itemId+question_Id+time+PK</li><li>答案key：userId+itemId+answer+PK</li></ul><p>验证的逻辑如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a984a6e0a560de3994f6c6448eeb307ee697840c.png" alt="image-20250912155917942"></p><p>注意，这里面的验证逻辑，除了验证问题的答案以外，还包括用户本身身份的验证，例如是否已经登录、用户的Cookie是否完整、用户是否重复频繁提交等。</p><p>除了做正确性验证，我们还可以对提交答案的时间做些限制，例如从开始答题到接受答案要超过1s，因为小于1s是人为操作的可能性很小，这样也能防止机器答题的情况。</p><h2 id="分层过滤"><a href="#分层过滤" class="headerlink" title="分层过滤"></a>分层过滤</h2><p>前面介绍的排队和答题要么是少发请求，要么对发出来的请求进行缓冲，而针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c7aa7c6890ffec67c74f2acea3924f7b06230cc7.png" alt="image-20250912160024914"></p><p>假如请求分别经过CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者CDN上获取，这一层可以拦截大部分数据的读取；</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走Cache，过滤一些无效的请求；</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少；</li><li>最后在数据层完成数据的强一致性校验。</li></ul><p>这样就像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了。</p><p><strong>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求</strong>。而要达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则是：</p><ol><li>将动态请求的读数据缓存（Cache）在Web端，过滤掉无效的数据读；</li><li>对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题；</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求；</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉；</li><li>对写数据进行强一致性校验，只保留最后有效的数据。</li></ol><h1 id="影响性能的因素有哪些？"><a href="#影响性能的因素有哪些？" class="headerlink" title="影响性能的因素有哪些？"></a>影响性能的因素有哪些？</h1><h2 id="影响性能的因素"><a href="#影响性能的因素" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h2><p>我们讨论的主要是系统服务端性能，一般用QPS（Query Per Second，每秒请求数）来衡量，还有一个影响和QPS也息息相关，那就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时。</p><p><strong>首先，我们先来看看响应时间和QPS有啥关系</strong>。</p><p>对于大部分的Web系统而言，响应时间一般都是由CPU执行时间和线程等待时间（比如RPC、IO等待、Sleep、Wait等）组成，即服务器在处理一个请求时，一部分是CPU本身在做运算，还有一部分是在各种等待。</p><p>理解了服务器处理请求的逻辑，估计你会说为什么我们不去减少这种等待时间。很遗憾，根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系，这点在很多代理服务器（Proxy）上可以做验证。</p><p>如果代理服务器本身没有CPU消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的QPS的影响。</p><p>其实，真正对性能有影响的是CPU的执行时间。这也很好理解，因为CPU的执行真正消耗了服务器的资源。经过实际的测试，如果减少CPU一半的执行时间，就可以增加一倍的QPS。</p><p>也就是说，我们应该致力于减少CPU的执行时间。</p><p><strong>其次，我们再来看看线程数对QPS的影响</strong>。</p><p>单看“总QPS”的计算公式，你会觉得线程数越多QPS也就会越高，但这会一直正确吗？显然不是，线程数不是越多越好，因为线程本身也消耗资源，也受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程也都会耗费一定内存。</p><p>那么，设置什么样的线程数最合理呢？其实<strong>很多多线程的场景都有一个默认配置，即“线程数 &#x3D; 2 * CPU核数 + 1”</strong>。除去这个配置，还有一个根据最佳实践得出来的公式：</p><blockquote><p>线程数 &#x3D; [(线程等待时间 + 线程CPU时间) &#x2F; 线程CPU时间] × CPU数量</p></blockquote><p>当然，最好的办法是通过性能测试来发现最佳的线程数。</p><p>换句话说，要提升性能我们就要减少CPU的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能。</p><h2 id="如何发现瓶颈"><a href="#如何发现瓶颈" class="headerlink" title="如何发现瓶颈"></a>如何发现瓶颈</h2><p>那么，如何发现CPU的瓶颈呢？其实有很多CPU诊断工具可以发现CPU的消耗，最常用的就是JProfiler和Yourkit这两个工具，它们可以列出整个请求中每个函数的CPU执行时间，可以发现哪个函数消耗的CPU时间最多，以便你有针对性地做优化。</p><p>当然还有一些办法也可以近似地统计CPU的耗时，例如通过jstack定时地打印调用栈，如果某些函数调用频繁或者耗时较多，那么那些函数就会多次出现在系统调用栈里，这样相当于采样的方式也能够发现耗时较多的函数。</p><h2 id="如何优化系统"><a href="#如何优化系统" class="headerlink" title="如何优化系统"></a>如何优化系统</h2><h3 id="减少编码"><a href="#减少编码" class="headerlink" title="减少编码"></a>减少编码</h3><p>Java的编码运行比较慢，这是Java的一大硬伤。在很多场景下，只要涉及字符串的操作（如输入输出操作、I&#x2F;O操作）都比较耗CPU资源，不管它是磁盘I&#x2F;O还是网络I&#x2F;O，因为都需要将字符转换成字节，而这个转换必须编码。</p><p>那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用resp.getOutputStream()函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用OutputStream()函数写，就可以减少静态数据的编码转换。</p><p>我在《深入分析Java Web技术内幕》一书中介绍的“Velocity优化实践”一章的内容，就是基于把静态的字符串提前编码成字节并缓存，然后直接输出字节内容到页面，从而大大减少编码的性能消耗的，网页输出的性能比没有提前进行字符到字节转换时提升了30%左右。</p><h3 id="减少序列化"><a href="#减少序列化" class="headerlink" title="减少序列化"></a>减少序列化</h3><p>序列化大部分是在RPC中发生的，因此避免或者减少RPC就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的RPC也可以减少序列化的消耗。</p><p>所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个Tomcat容器中，且不能走本机的Socket，这样才能避免序列化的产生</p><h3 id="Java极致优化"><a href="#Java极致优化" class="headerlink" title="Java极致优化"></a>Java极致优化</h3><p>Java和通用的Web服务器（如Nginx或Apache服务器）相比，在处理大并发的HTTP请求时要弱一点，所以一般我们都会对大流量的Web系统做静态化改造，让大部分请求和数据直接在Nginx服务器或者Web代理服务器（如Varnish、Squid等）上直接返回（这样可以减少数据的序列化与反序列化），而Java层只需处理少量数据的动态请求。针对这些请求，我们可以使用以下手段进行优化：</p><ul><li>直接使用Servlet处理请求。避免使用传统的MVC框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省1ms时间（具体取决于你对MVC框架的依赖程度）。</li><li>直接输出流数据。使用resp.getOutputStream()而不是resp.getWriter()函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用JSON而不是模板引擎（一般都是解释执行）来输出页面。</li></ul><h3 id="并发读优化"><a href="#并发读优化" class="headerlink" title="并发读优化"></a>并发读优化</h3><ul><li>像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；</li><li>像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。</li></ul><p>你可能还会有疑问：像库存这种频繁更新的数据，一旦数据不一致，会不会导致超卖？</p><p>这就要用到前面介绍的读数据的分层校验原则了，读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。</p><h1 id="秒杀系统“减库存”设计的核心逻辑"><a href="#秒杀系统“减库存”设计的核心逻辑" class="headerlink" title="秒杀系统“减库存”设计的核心逻辑"></a>秒杀系统“减库存”设计的核心逻辑</h1><p>如果要设计一套秒杀系统，那我想你的老板肯定会先对你说：千万不要超卖，这是大前提。</p><p>我们平常购物都是这样，看到喜欢的商品然后下单，但并不是每个下单请求你都最后付款了。你说系统是用户下单了就算这个商品卖出去了，还是等到用户真正付款了才算卖出了呢？这的确是个问题！</p><p>我们可以先根据减库存是发生在下单阶段还是付款阶段，把减库存做一下划分。</p><h2 id="减库存有哪几种方式"><a href="#减库存有哪几种方式" class="headerlink" title="减库存有哪几种方式"></a>减库存有哪几种方式</h2><p>总结来说，减库存操作一般有如下几个方式：</p><ul><li><strong>下单减库存</strong>，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。</li><li><strong>付款减库存</strong>，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</li><li><strong>预扣库存</strong>，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如10分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</li></ul><h2 id="减库存可能存在的问题"><a href="#减库存可能存在的问题" class="headerlink" title="减库存可能存在的问题"></a>减库存可能存在的问题</h2><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><p>“付款减库存”又会导致另外一个问题：库存超卖。假如有100件商品，就可能出现300人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为10分钟，但是恶意买家完全可以在10分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买3件），以及对重复下单不付款的操作进行次数限制等。</p><p>针对“库存超卖”这种情况，在10分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h2 id="大型秒杀中如何减库存？"><a href="#大型秒杀中如何减库存？" class="headerlink" title="大型秒杀中如何减库存？"></a>大型秒杀中如何减库存？</h2><p>目前来看，业务系统中最常见的就是预扣库存方案，像你在买机票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？</p><p>由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行SQL语句来报错；再有一种就是使用CASE WHEN判断语句，例如这样的SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> item <span class="keyword">SET</span> inventory <span class="operator">=</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> inventory <span class="operator">&gt;=</span> xxx <span class="keyword">THEN</span> inventory<span class="operator">-</span>xxx <span class="keyword">ELSE</span> inventory <span class="keyword">END</span></span><br></pre></td></tr></table></figure><h2 id="秒杀减库存的极致优化"><a href="#秒杀减库存的极致优化" class="headerlink" title="秒杀减库存的极致优化"></a>秒杀减库存的极致优化</h2><p>由于MySQL存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争InnoDB行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致0.01%的商品影响99.99%的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ul><li><strong>应用层做排队</strong>。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</li><li><strong>数据库层做排队</strong>。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种MySQL的InnoDB层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。</li></ul><p>你可能有疑问了，排队和锁竞争不都是要等待吗，有啥区别？</p><p>如果熟悉MySQL的话，你会知道InnoDB内部的死锁检测，以及MySQL Server和InnoDB的切换会比较消耗性能，淘宝的MySQL核心团队还做了很多其他方面的优化，如COMMIT_ON_SUCCESS和ROLLBACK_ON_FAIL的补丁程序，配合在SQL里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条SQL后，直接根据TARGET_AFFECT_ROW的结果进行提交或回滚，可以减少网络等待时间（平均约0.7ms）。据我所知，目前阿里MySQL团队已经将包含这些补丁程序的MySQL开源。</p><p>另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的lastmodifytime字段的）更新会非常频繁，在某些场景下这些多条SQL是可以合并的，一定时间内只要执行最后一条SQL就行了，以便减少对数据库的更新操作。</p><blockquote><p> 如果异步的请求失败了，怎么办？</p></blockquote><p>对秒杀来说，我觉得如果失败了直接丢弃就好了，最坏的结果就是这个人没有抢到而已。但是你非要纠结的话，就要做异步消息的持久化以及重试机制了，要保证异步请求的最终正确处理一般都要借助消息系统，即消息的最终可达，例如阿里的消息中间件是能承诺只要客户端消息发送成功，那么消息系统一定会保证消息最终被送到目的地，即消息不会丢。因为客户端只要成功发送一条消息，下游消费方就一定会消费这条消息，所以也就不存在消息发送失败的问题了。</p><h1 id="准备Plan-B：如何设计兜底方案"><a href="#准备Plan-B：如何设计兜底方案" class="headerlink" title="准备Plan B：如何设计兜底方案"></a>准备Plan B：如何设计兜底方案</h1><h2 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h2><p>所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。</p><p>降级方案可以这样设计：当秒杀流量达到5w&#x2F;s时，把成交记录的获取从展示20条降级到只展示5条。“从20改到5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。</p><p>这里，我给出开关系统的示意图。它分为两部分，一部分是开关控制台，它保存了开关的具体配置信息，以及具体执行开关所对应的机器列表；另一部分是执行下发开关数据的Agent，主要任务就是保证开关被正确执行，即使系统重启后也会生效。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1b7fe21e0720519aff27e1b7c9621e6d482473cb.png" alt="image-20250912161948237"></p><p>执行降级无疑是在系统性能和用户体验之间选择了前者，降级后肯定会影响一部分用户的体验，例如在双11零点时，如果优惠券系统扛不住，可能会临时降级商品详情的优惠信息展示，把有限的系统资源用在保障交易系统正确展示优惠信息上，即保障用户真正下单时的价格是正确的。所以降级的核心目标是牺牲次要的功能和用户体验来保证核心业务流程的稳定，是一个不得已而为之的举措。</p><h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><p>如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。</p><p>这里，我同样给出了限流系统的示意图。总体来说，限流既可以是在客户端限流，也可以是在服务端限流。此外，限流的实现方式既要支持URL以及方法级别的限流，也要支持基于QPS和线程的限流。</p><p>首先，我以内部的系统调用为例，来分别说下客户端限流和服务端限流的优缺点。</p><ul><li><strong>客户端限流</strong>，好处可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗。缺点就是当客户端比较分散时，没法设置合理的限流阈值：如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制；而如果设的太大，则起不到限制的作用。</li><li><strong>服务端限流</strong>，好处是可以根据服务端的性能设置合理的阈值，而缺点就是被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源。</li></ul><p>在限流的实现手段上来讲，基于QPS和线程数的限流应用最多，最大QPS很容易通过压测提前获取，例如我们的系统最高支持1w QPS时，可以设置8000来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。</p><p>限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能fast fail（快速失败）而拖垮系统。</p><h2 id="拒绝服务"><a href="#拒绝服务" class="headerlink" title="拒绝服务"></a>拒绝服务</h2><p>如果限流还不能解决问题，最后一招就是直接拒绝服务了。</p><p>当系统负载达到一定阈值时，例如CPU使用率达到90%或者系统load值达到2*CPU核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：</p><blockquote><p>在最前端的Nginx上设置过载保护，当机器负载达到某个值时直接拒绝HTTP请求并返回503错误码，在Java层同样也可以设计过载保护。</p></blockquote><p>拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。</p>]]></content>
    
    
    <summary type="html">关于秒杀场景设计思路拓展</summary>
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/categories/%E5%9C%BA%E6%99%AF/"/>
    
    
    <category term="场景" scheme="https://palette-k.github.io/tags/%E5%9C%BA%E6%99%AF/"/>
    
  </entry>
  
  <entry>
    <title>Java并发编程实战</title>
    <link href="https://palette-k.github.io/2025/09/08/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/"/>
    <id>https://palette-k.github.io/2025/09/08/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/</id>
    <published>2025-09-08T06:28:27.000Z</published>
    <updated>2025-10-13T03:27:44.954Z</updated>
    
    <content type="html"><![CDATA[<h1 id="可见性、原子性和有序性问题：并发编程Bug的源头"><a href="#可见性、原子性和有序性问题：并发编程Bug的源头" class="headerlink" title="可见性、原子性和有序性问题：并发编程Bug的源头"></a>可见性、原子性和有序性问题：并发编程Bug的源头</h1><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>在单核时代，所有的线程都是在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/525e6b4dc17e61d2cb4da7e6f5f4c67ba68a3153.png" alt="image-20250908170705273"></p><p>一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为<strong>可见性</strong>。</p><p>多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/39d83dc297f154950222d9a7551da57d130d8abb.png" alt="image-20250908170740063"></p><p>每执行一次add10K()方法，都会循环10000次count+&#x3D;1操作。在calc()方法中我们创建了两个线程，每个线程调用一次add10K()方法，循环10000次count+&#x3D;1操作如果改为循环1亿次，你会发现效果更明显，最终count的值接近1亿，而不是2亿。如果循环10000次，count的值接近20000，原因是两个线程不是同时启动的，有一个时差。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/abc22292dd8bfc85443ce291a89178383ce64afe.png" alt="image-20250908170851695"></p><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>操作系统允许某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个50毫秒称为“<strong>时间片</strong>”。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9226bbf245fc08ebbd74c48bcfed9ef9be99e6a6.png" alt="image-20250908170951720"></p><p>在一个时间片内，如果一个进程进行一个IO操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让CPU的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得CPU的使用权了。</p><p>务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条CPU指令完成，例如上面代码中的<code>count += 1</code>，至少需要三条CPU指令。</p><ul><li>指令1：首先，需要把变量count从内存加载到CPU的寄存器；</li><li>指令2：之后，在寄存器中执行+1操作；</li><li>指令3：最后，将结果写入内存（缓存机制导致可能写入的是CPU缓存而不是内存）。</li></ul><p>操作系统做任务切换，可以发生在任何一条<strong>CPU指令</strong>执行完，是的，是CPU指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设count&#x3D;0，如果线程A在指令1执行完后做线程切换，线程A和线程B按照下图的序列执行，那么我们会发现两个线程都执行了count+&#x3D;1的操作，但是得到的结果不是我们期望的2，而是1。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c702606869213089b3670d92e946f27e86248407.png" alt="image-20250908171038462"></p><h2 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h2><p>在Java领域一个经典的案例就是利用双重检查创建单例对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">  <span class="keyword">static</span> Singleton instance;</span><br><span class="line">  <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">synchronized</span>(Singleton.class) &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>)</span><br><span class="line">          instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设有两个线程A、B同时调用getInstance()方法，他们会同时发现 <code>instance == null</code> ，于是同时对Singleton.class加锁，此时JVM保证只有一个线程能够加锁成功（假设是线程A），另外一个线程则会处于等待状态（假设是线程B）；线程A会创建一个Singleton实例，之后释放锁，锁释放后，线程B被唤醒，线程B再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程B检查 <code>instance == null</code> 时会发现，已经创建过Singleton实例了，所以线程B不会再创建一个Singleton实例。</p><p>这看上去一切都很完美，无懈可击，但实际上这个getInstance()方法并不完美。问题出在哪里呢？出在new操作上，我们以为的new操作应该是：</p><ol><li>分配一块内存M；</li><li>在内存M上初始化Singleton对象；</li><li>然后M的地址赋值给instance变量。</li></ol><p>但是实际上优化后的执行路径却是这样的：</p><ol><li>分配一块内存M；</li><li>将M的地址赋值给instance变量；</li><li>最后在内存M上初始化Singleton对象。</li></ol><p>优化后会导致什么问题呢？我们假设线程A先执行getInstance()方法，当执行完指令2时恰好发生了线程切换，切换到了线程B上；如果此时线程B也执行getInstance()方法，那么线程B在执行第一个判断时会发现 <code>instance != null</code> ，所以直接返回instance，而此时的instance是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1df032b69cd1d24f984ed4966f34c1f78e2a7439.png" alt="image-20250908171208513"></p><h1 id="Java内存模型：看Java如何解决可见性和有序性问题"><a href="#Java内存模型：看Java如何解决可见性和有序性问题" class="headerlink" title="Java内存模型：看Java如何解决可见性和有序性问题"></a>Java内存模型：看Java如何解决可见性和有序性问题</h1><h2 id="什么是Java内存模型？"><a href="#什么是Java内存模型？" class="headerlink" title="什么是Java内存模型？"></a>什么是Java内存模型？</h2><p>Java 内存模型（JMM）是一组规范和规则，它定义了在多线程环境下，Java 程序中的变量（包括实例字段、静态字段和构成数组对象的元素）如何被写入内存以及如何从内存中读取。它的核心目标是解决在并发编程中由于可见性、原子性和有序性问题而导致的线程不安全问题</p><p>JMM 从逻辑上划分了这两种内存：</p><ul><li><strong>主内存</strong>：所有共享变量都存储在主内存中。它是所有线程共享的区域。</li><li><strong>工作内存</strong>：每个线程都有自己的工作内存，其中保存了该线程使用到的变量的<strong>主内存副本</strong>。线程对所有变量的操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。</li></ul><p><strong>交互流程</strong>：</p><ol><li>线程要读取一个共享变量时，会先从主内存<strong>复制</strong>一份到自己的工作内存。</li><li>然后线程就在自己的工作内存中操作这个副本。</li><li>操作完成后，在某个时间点再将工作内存中的副本<strong>刷新</strong>回主内存。</li></ol><h2 id="Happens-Before-规则"><a href="#Happens-Before-规则" class="headerlink" title="Happens-Before 规则"></a>Happens-Before 规则</h2><p>真正要表达的是：<strong>前面一个操作的结果对后续操作是可见的</strong>。</p><h3 id="程序的顺序性规则"><a href="#程序的顺序性规则" class="headerlink" title="程序的顺序性规则"></a>程序的顺序性规则</h3><p>这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。这还是比较容易理解的，比如刚才那段示例代码，按照程序的顺序，第6行代码 “x &#x3D; 42;” Happens-Before 于第7行代码 “v &#x3D; true;”，这就是规则1的内容，也比较符合单线程里面的思维：程序前面对某个变量的修改一定是对后续操作可见的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VolatileExample</span> &#123;</span><br><span class="line">  <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">boolean</span> <span class="variable">v</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writer</span><span class="params">()</span> &#123;</span><br><span class="line">    x = <span class="number">42</span>;</span><br><span class="line">    v = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reader</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (v == <span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="comment">// 这里x会是多少呢？</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="volatile变量规则"><a href="#volatile变量规则" class="headerlink" title="volatile变量规则"></a>volatile变量规则</h3><p>这条规则是指对一个volatile变量的写操作， Happens-Before 于后续对这个volatile变量的读操作。</p><h3 id="传递性"><a href="#传递性" class="headerlink" title="传递性"></a>传递性</h3><p>这条规则是指如果A Happens-Before B，且B Happens-Before C，那么A Happens-Before C。</p><p>我们将规则3的传递性应用到我们的例子中，会发生什么呢？可以看下面这幅图：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2e84c7e0cd776461314d31731e24eaed02283e6e.png" alt="image-20250908171850247"></p><p>示例代码中的传递性规则</p><p>从图中，我们可以看到：</p><ol><li>“x&#x3D;42” Happens-Before 写变量 “v&#x3D;true” ，这是规则1的内容；</li><li>写变量“v&#x3D;true” Happens-Before 读变量 “v&#x3D;true”，这是规则2的内容 。</li></ol><p>如果线程B读到了“v&#x3D;true”，那么线程A设置的“x&#x3D;42”对线程B是可见的。也就是说，线程B能看到 “x &#x3D;&#x3D; 42”</p><h3 id="管程中锁的规则"><a href="#管程中锁的规则" class="headerlink" title="管程中锁的规则"></a>管程中锁的规则</h3><p>这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。</p><p><strong>管程</strong>是一种通用的同步原语，在Java中指的就是synchronized，synchronized是Java里对管程的实现。</p><p>管程中的锁在Java里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123; <span class="comment">//此处自动加锁</span></span><br><span class="line">  <span class="comment">// x是共享变量,初始值=10</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">this</span>.x &lt; <span class="number">12</span>) &#123;</span><br><span class="line">    <span class="built_in">this</span>.x = <span class="number">12</span>; </span><br><span class="line">  &#125;  </span><br><span class="line">&#125; <span class="comment">//此处自动解锁</span></span><br></pre></td></tr></table></figure><p>假设x的初始值是10，线程A执行完代码块后x的值会变成12（执行完自动释放锁），线程B进入代码块时，能够看到线程A对x的写操作，也就是线程B能够看到x&#x3D;&#x3D;12。</p><h3 id="线程-start-规则"><a href="#线程-start-规则" class="headerlink" title="线程 start() 规则"></a>线程 start() 规则</h3><p>主线程A启动子线程B后，子线程B能够看到主线程在启动子线程B前的操作。</p><p>如果线程A调用线程B的 start() 方法（即在线程A中启动线程B），那么该start()操作 Happens-Before 于线程B中的任意操作。具体可参考下面示例代码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">B</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 主线程调用B.start()之前</span></span><br><span class="line">  <span class="comment">// 所有对共享变量的修改，此处皆可见</span></span><br><span class="line">  <span class="comment">// 此例中，var==77</span></span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 此处对共享变量var修改</span></span><br><span class="line"><span class="keyword">var</span> = <span class="number">77</span>;</span><br><span class="line"><span class="comment">// 主线程启动子线程</span></span><br><span class="line">B.start();</span><br></pre></td></tr></table></figure><h3 id="线程-join-规则"><a href="#线程-join-规则" class="headerlink" title="线程 join() 规则"></a>线程 join() 规则</h3><p>主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现），当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程的操作。</p><p>换句话说就是，如果在线程A中，调用线程B的 join() 并成功返回，那么线程B中的任意操作Happens-Before 于该 join() 操作的返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">B</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 此处对共享变量var修改</span></span><br><span class="line">  <span class="keyword">var</span> = <span class="number">66</span>;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 例如此处对共享变量修改，</span></span><br><span class="line"><span class="comment">// 则这个修改结果对线程B可见</span></span><br><span class="line"><span class="comment">// 主线程启动子线程</span></span><br><span class="line">B.start();</span><br><span class="line">B.join()</span><br><span class="line"><span class="comment">// 子线程所有对共享变量的修改</span></span><br><span class="line"><span class="comment">// 在主线程调用B.join()之后皆可见</span></span><br><span class="line"><span class="comment">// 此例中，var==66</span></span><br></pre></td></tr></table></figure><h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><ul><li><strong>原子性</strong>：通过互斥锁保证代码块的原子性。</li><li><strong>可见性</strong>：线程在进入 <code>synchronized</code> 块时，会清空工作内存，从主内存重新加载共享变量。在退出 <code>synchronized</code> 块时，会把工作内存中的修改刷新到主内存。</li></ul><p>sychronized 是一种互斥锁，一次只能允许一个线程进入被锁住的代码块。<br>sychronized 是 Java 的一个关键字，它能将代码块&#x2F;方法锁起来。<br>如果 sychronized 修饰的是实例方法，对应的锁则是对象实例。<br>如果 sychronized 修饰的是静态方法，对应的锁则是当前类的 Class 实例。<br>如果 sychronized 修饰的是代码块，对应的锁则是传入 synchronized 的对象实例。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>通过反编译发现，编译器会生成 ACC_SYNCHRONIZED 关键字来标识。<br>当修饰代码块的时候，会依赖 monitorenter 和 monitorexit 指令。<br>无论 sychronized 修饰的是方法还是代码块，对应的锁都是一个实例对象。</p><p>在内存中，对象一般由三部分组成，分别是对象头，对象实际数据和对齐填充。<br>重点在于对象头，对象头又由几部分组成，但是我们重点关注对象头 Mark Word 的信息就好。<br>Mark Word 会记录对象关于锁的信息。<br>又因为每个对象都会有一个与之对应的 monitor 对象，monitor 对象中存储着当前持有锁的线程和等待锁的线程队列。<br>了解 Mark Word 和 monitor 对象是理解 synchronized 原理的前提。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ba882269a61a2af588f03893d2c73c498ea9ea7f.png" alt="image-20250910164612128"></p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>在 JDK1.6 之前是重量级锁，线程进入同步代码块&#x2F;方法时，monitor 对象会把当前进入线程的 id 进行存储，设置 Mark Word 的 monitor 对象地址，并把阻塞的线程存储到 monitor 的等待线程队列中，它加锁是依赖底层操作系统的 mutex 相关指令实现，所以会有用户态和内核态之间的切换，性能损耗十分明显。</p><p>而 JDK1.6 以后引入偏向锁和轻量级锁在 JVM 层面实现加锁逻辑，不依赖底层操作系统，就没有切换的消耗。在使用 synchronized 加锁的时候，Java 并不会直接调用操作系统内核加锁，而是根据线程的竞争情况采用不同的策略逐渐升级锁，直至调用操作系统加锁。</p><p>锁的升级包含以下几个过程：</p><ul><li>调研发现，在大多数情况下，锁不仅不会存在竞争情况，而且通常会由同一个线程多次获取。在这种情况下，JVM 会将锁设置为偏向锁。偏向锁会在对象头中记录拥有偏向锁的线程的ID，并将锁标识位设置为偏向锁状态。这样，当同一个线程再次请求获取这个对象的锁时，不需要进行任何同步操作，可以直接获取到锁，提高了程序的性能。<ul><li>另一种情况是，当线程B尝试获取偏向锁时，如果此时拥有偏向锁的线程A已经执行完毕并释放了锁，JVM 会尝试撤销偏向锁，并进行锁的竞争。如果在撤销偏向锁的过程中，没有其他线程来竞争锁，JVM 会将锁的状态设置为偏向线程B，并更新对象头中记录的线程ID为线程B的ID。在这种情况下，并不会发生锁的升级。只有当线程B尝试获取锁时，线程A还没有执行完毕，即出现了竞争情况，才会发生锁的升级，进而转为轻量级锁或重量级锁。</li></ul></li><li>当系统线程出现多个线程竞争的情况时，synchronized 会从偏向锁升级为轻量级锁。需要注意的是，轻量级锁通常出现在竞争不激烈、任务执行时间短的情况下。当出现锁竞争时，例如线程A正在执行过程中，线程B开始尝试获取锁，此时synchronized会进行自旋等待。synchronized并不会立即升级为重量级锁，而是会尝试使用自适应自旋锁来获取锁。如果自旋一段时间后仍未获取到锁，synchronized会正式升级为重量级锁。</li></ul><p>整体 synchronized 的锁升级过程为：<strong>偏向锁 -&gt; 轻量级锁（自旋锁） -&gt; 重量级锁</strong>。</p><ul><li><strong>无锁状态</strong>：锁标志位为 <code>01</code>，此时不存在线程执行任务。</li><li><strong>偏向锁</strong>：系统会在 MarkWord 中记录一个<strong>线程</strong> <strong>id</strong>，当该线程再次获取锁的时候，无需再申请锁，直接获取以增加效率。</li><li><strong>轻量级锁</strong>：系统会将对象头中的锁标志位修正为”00”，加锁和解锁操作使用CAS指令来修改锁标志位。当出现锁竞争的情况时，JVM 会尝试进行一段短暂的自旋（也称为空闲自旋或忙等待），以等待锁的释放。这个自旋过程是为了避免线程进入阻塞状态，以提高锁竞争的效率。</li><li><strong>重量级锁</strong>：JVM 会尝试调用操作系统进行加锁，同时会将锁的标记位 CAS 修正为 “10” ，表示锁已经升级为重量级锁。没有抢占到锁的线程会被加入到系统内的等待队列中等待唤醒。</li></ul><p><strong>我们可以近似地理解，偏向锁和轻量级锁都是系统通过 CAS 修改对象头中的锁标记位来实现的，只有重量级锁才会调用操作系统内核进行加锁或者入队操作</strong>。一个是只需要修改点东西就能实现，一个是需要入队、阻塞、唤醒、出队等诸多步骤才能实现，谁快谁慢不言而喻！</p><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ul><li><strong>可见性</strong>：保证对 <code>volatile</code> 变量的写操作会<strong>立即刷新</strong>到主内存，并且每次读操作都会从主内存重新读取，绕过工作内存。</li><li><strong>有序性</strong>：通过添加<strong>内存屏障</strong>来禁止指令重排序。</li><li><strong>注意</strong>：<code>volatile</code> <strong>不保证原子性</strong>（例如 <code>volatile int i; i++</code> 仍然不是原子操作）。</li></ul><h2 id="final"><a href="#final" class="headerlink" title="final"></a>final</h2><p>只要在构造函数中正确初始化了 <code>final</code> 字段，并且没有“this”引用逸出，那么其他线程就能看到最终初始化后的值，无需同步。</p><p>“逸出”有点抽象，我们还是举个例子吧，在下面例子中，在构造函数里面将this赋值给了全局变量global.obj，这就是“逸出”，线程通过global.obj读取x是有可能读到0的。因此我们一定要避免“逸出”。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">int</span> x;</span><br><span class="line"><span class="comment">// 错误的构造函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">FinalFieldExample</span><span class="params">()</span> &#123; </span><br><span class="line">  x = <span class="number">3</span>;</span><br><span class="line">  y = <span class="number">4</span>;</span><br><span class="line">  <span class="comment">// 此处就是讲this逸出，</span></span><br><span class="line">  global.obj = <span class="built_in">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="如何预防死锁"><a href="#如何预防死锁" class="headerlink" title="如何预防死锁"></a>如何预防死锁</h1><p>并发程序一旦死锁，一般没有特别好的方法，很多时候我们只能重启应用。因此，解决死锁问题最好的办法还是规避死锁。</p><p>只有以下这四个条件都发生时才会出现死锁：</p><ol><li>互斥，共享资源X和Y只能被一个线程占用；</li><li>占有且等待，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X；</li><li>不可抢占，其他线程不能强行抢占线程T1占有的资源；</li><li>循环等待，线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源，就是循环等待。</li></ol><p>反过来分析，<strong>也就是说只要我们破坏其中一个，就可以成功避免死锁的发生</strong>。</p><p>其中，互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？</p><ol><li>对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。</li><li>对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。</li><li>对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。</li></ol><h1 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h1><p><strong>有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”</strong>。</p><p>以类比现实世界里的例子，路人甲从左手边出门，路人乙从右手边进门，两人为了不相撞，互相谦让，路人甲让路走右手边，路人乙也让路走左手边，结果是两人又相撞了。这种情况，基本上谦让几次就解决了，因为人会交流啊。可是如果这种情况发生在编程世界了，就有可能会一直没完没了地“谦让”下去，成为没有发生阻塞但依然执行不下去的“活锁”。</p><p>解决“<strong>活锁</strong>”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。</p><h1 id="饥饿"><a href="#饥饿" class="headerlink" title="饥饿"></a>饥饿</h1><p><strong>所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况</strong>。</p><p>如果线程优先级“不均”，在CPU繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。</p><p>解决“<strong>饥饿</strong>”问题的方案很简单，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些。</p><h1 id="用“等待-通知”机制优化循环等待"><a href="#用“等待-通知”机制优化循环等待" class="headerlink" title="用“等待-通知”机制优化循环等待"></a>用“等待-通知”机制优化循环等待</h1><p>在<strong>破坏占用且等待条件</strong>的时候，如果不能一次性申请到所有资源，就用死循环的方式来循环等待。如果apply()操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，但是如果apply()操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗CPU了。</p><h2 id="用synchronized实现等待-通知机制"><a href="#用synchronized实现等待-通知机制" class="headerlink" title="用synchronized实现等待-通知机制"></a>用synchronized实现等待-通知机制</h2><p>在Java语言里，等待-通知机制可以有多种实现方式，比如Java语言内置的synchronized配合wait()、notify()、notifyAll()这三个方法就能轻松实现。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ad501ac0c02918d98708c918dd086fe19602731e.png" alt="image-20250908174313597"></p><p>在并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，Java对象的wait()方法就能够满足这种需求。如上图所示，当调用wait()方法后，当前线程就会被阻塞，并且进入到右边的等待队列中，<strong>这个等待队列也是互斥锁的等待队列</strong>。 线程在进入等待队列的同时，<strong>会释放持有的互斥锁</strong>，线程释放锁后，其他线程就有机会获得锁，并进入临界区了。</p><p>那线程要求的条件满足时，该怎么通知这个等待的线程呢？很简单，就是Java对象的notify()和notifyAll()方法。我在下面这个图里为你大致描述了这个过程，当条件满足时调用notify()，会通知等待队列（<strong>互斥锁的等待队列</strong>）中的线程，告诉它<strong>条件曾经满足过</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/986f66069e6becb1ea8874539f76215c071a5cfb.png" alt="image-20250908174338238"></p><p>为什么说是曾经满足过呢？因为<strong>notify()只能保证在通知时间点，条件是满足的</strong>。而被通知线程的<strong>执行时间点和通知的时间点</strong>基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。这一点你需要格外注意。</p><p>除此之外，还有一个需要注意的点，被通知的线程要想重新执行，仍然需要获取到互斥锁（因为曾经获取的锁在调用wait()时已经释放了）。</p><p><strong>notify()是会随机地通知等待队列中的一个线程，而notifyAll()会通知等待队列中的所有线程</strong>。</p><p>假设我们有资源A、B、C、D，线程1申请到了AB，线程2申请到了CD，此时线程3申请AB，会进入等待队列（AB分配给线程1，线程3要求的条件不满足），线程4申请CD也会进入等待队列。我们再假设之后线程1归还了资源AB，如果使用notify()来通知等待队列中的线程，有可能被通知的是线程4，但线程4申请的是CD，所以此时线程4还是会继续等待，而真正该唤醒的线程3就再也没有机会被唤醒了。</p><h1 id="创建多少线程才是合适的"><a href="#创建多少线程才是合适的" class="headerlink" title="创建多少线程才是合适的"></a>创建多少线程才是合适的</h1><p><strong>在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升I&#x2F;O的利用率和CPU的利用率</strong>。</p><p>如果只有一个线程，执行CPU计算的时候，I&#x2F;O设备空闲；执行I&#x2F;O操作的时候，CPU空闲，所以CPU的利用率和I&#x2F;O设备的利用率都是50%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9494c5be4b39fddb9a4d56bf8cf478250f851a8e.png" alt="image-20250909094950235"></p><p>如果有两个线程，如下图所示，当线程A执行CPU计算的时候，线程B执行I&#x2F;O操作；当线程A执行I&#x2F;O操作的时候，线程B执行CPU计算，这样CPU的利用率和I&#x2F;O设备的利用率就都达到了100%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b403f285ecd457ccead4c404e1dc8bf94e6c640b.png" alt="image-20250909095012687"></p><p>通过上面的图示，很容易看出：单位时间处理的请求数量翻了一番，也就是说吞吐量提高了1倍。</p><p>对于CPU密集型计算，多线程本质上是提升多核CPU的利用率，所以对于一个4核的CPU，每个核一个线程，理论上创建4个线程就可以了，再多创建线程也只是增加线程切换的成本。所以，<strong>对于CPU密集型的计算场景，理论上“线程的数量&#x3D;CPU核数”就是最合适的</strong>。不过在工程上，<strong>线程的数量一般会设置为“CPU核数+1”</strong>，这样的话，当线程因为偶尔的内存页失效或其他原因导致阻塞时，这个额外的线程可以顶上，从而保证CPU的利用率。</p><p>对于I&#x2F;O密集型的计算场景，比如前面我们的例子中，如果CPU计算和I&#x2F;O操作的耗时是1:1，那么2个线程是最合适的。如果CPU计算和I&#x2F;O操作的耗时是1:2，那多少个线程合适呢？是3个线程，如下图所示：CPU在A、B、C三个线程之间切换，对于线程A，当CPU从B、C切换回来时，线程A正好执行完I&#x2F;O操作。这样CPU和I&#x2F;O设备的利用率都达到了100%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8956e749062492cb16f162fd344cdbf10093526f.png" alt="image-20250909095149313"></p><p>通过上面这个例子，我们会发现，对于I&#x2F;O密集型计算场景，最佳的线程数是与程序中CPU计算和I&#x2F;O操作的耗时比相关的，我们可以总结出这样一个公式：</p><blockquote><p>最佳线程数&#x3D;1 +（I&#x2F;O耗时 &#x2F; CPU耗时）</p></blockquote><p>不过上面这个公式是针对单核CPU的，至于多核CPU，也很简单，只需要等比扩大就可以了，计算公式如下：</p><blockquote><p>最佳线程数&#x3D;CPU核数 * [ 1 +（I&#x2F;O耗时 &#x2F; CPU耗时）]</p></blockquote><p>最佳线程数最终还是靠压测来确定的，实际工作中大家面临的系统，“I&#x2F;O耗时 &#x2F; CPU耗时”往往都大于1，所以基本上都是在这个<strong>初始值的基础上增加</strong>。增加的过程中，应关注线程数是如何影响吞吐量和延迟的。</p><p>实际工作中，不同的I&#x2F;O模型对最佳线程数的影响非常大，例如大名鼎鼎的Nginx用的是非阻塞I&#x2F;O，采用的是多进程单线程结构，Nginx本来是一个I&#x2F;O密集型系统，但是最佳进程数设置的却是CPU的核数，完全参考的是CPU密集型的算法。所以，理论我们还是要活学活用。</p><h1 id="Semaphore：快速实现一个限流器"><a href="#Semaphore：快速实现一个限流器" class="headerlink" title="Semaphore：快速实现一个限流器"></a>Semaphore：快速实现一个限流器</h1><p><strong>Semaphore可以允许多个线程访问一个临界区</strong>。</p><p>比较常见的需求就是我们工作中遇到的各种池化资源，例如连接池、对象池、线程池等等。所谓对象池呢，指的是一次性创建出N个对象，之后所有的线程重复利用这N个对象，当然对象在被释放前，也是不允许其他线程使用的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ObjPool</span>&lt;T, R&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> List&lt;T&gt; pool;</span><br><span class="line">  <span class="comment">// 用信号量实现限流器</span></span><br><span class="line">  <span class="keyword">final</span> Semaphore sem;</span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  ObjPool(<span class="type">int</span> size, T t)&#123;</span><br><span class="line">    pool = <span class="keyword">new</span> <span class="title class_">Vector</span>&lt;T&gt;()&#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;size; i++)&#123;</span><br><span class="line">      pool.add(t);</span><br><span class="line">    &#125;</span><br><span class="line">    sem = <span class="keyword">new</span> <span class="title class_">Semaphore</span>(size);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 利用对象池的对象，调用func</span></span><br><span class="line">  R <span class="title function_">exec</span><span class="params">(Function&lt;T,R&gt; func)</span> &#123;</span><br><span class="line">    <span class="type">T</span> <span class="variable">t</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    sem.acquire();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      t = pool.remove(<span class="number">0</span>);</span><br><span class="line">      <span class="keyword">return</span> func.apply(t);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      pool.add(t);</span><br><span class="line">      sem.release();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 创建对象池</span></span><br><span class="line">ObjPool&lt;Long, String&gt; pool = <span class="keyword">new</span> <span class="title class_">ObjPool</span>&lt;Long, String&gt;(<span class="number">10</span>, <span class="number">2</span>);</span><br><span class="line"><span class="comment">// 通过对象池获取t，之后执行  </span></span><br><span class="line">pool.exec(t -&gt; &#123;</span><br><span class="line">    System.out.println(t);</span><br><span class="line">    <span class="keyword">return</span> t.toString();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>我们用一个List来保存对象实例，用Semaphore实现限流器。关键的代码是ObjPool里面的exec()方法，这个方法里面实现了限流的功能。</p><p>在这个方法里面，我们首先调用acquire()方法（与之匹配的是在finally里面调用release()方法），假设对象池的大小是10，信号量的计数器初始化为10，那么前10个线程调用acquire()方法，都能继续执行，相当于通过了信号灯，而其他线程则会阻塞在acquire()方法上。对于通过信号灯的线程，我们为每个线程分配了一个对象 t（这个分配工作是通过pool.remove(0)实现的），分配完之后会执行一个回调函数func，而函数的参数正是前面分配的对象 t ；执行完回调函数之后，它们就会释放对象（这个释放工作是通过pool.add(t)实现的），同时调用release()方法来更新信号量的计数器。如果此时信号量里计数器的值小于等于0，那么说明有线程在等待，此时会自动唤醒等待的线程。</p><p>简言之，使用信号量，我们可以轻松地实现一个限流器。</p><h1 id="ReadWriteLock：快速实现一个完备的缓存"><a href="#ReadWriteLock：快速实现一个完备的缓存" class="headerlink" title="ReadWriteLock：快速实现一个完备的缓存"></a>ReadWriteLock：快速实现一个完备的缓存</h1><p>用ReadWriteLock快速实现一个通用的缓存工具类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Cache</span>&lt;K,V&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> Map&lt;K, V&gt; m = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="comment">// 读锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="comment">// 写锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line">  <span class="comment">// 读缓存</span></span><br><span class="line">  V <span class="title function_">get</span><span class="params">(K key)</span> &#123;</span><br><span class="line">    r.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123; <span class="keyword">return</span> m.get(key); &#125;</span><br><span class="line">    <span class="keyword">finally</span> &#123; r.unlock(); &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 写缓存</span></span><br><span class="line">  V <span class="title function_">put</span><span class="params">(K key, V value)</span> &#123;</span><br><span class="line">    w.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123; <span class="keyword">return</span> m.put(key, v); &#125;</span><br><span class="line">    <span class="keyword">finally</span> &#123; w.unlock(); &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果源头数据的数据量不大，就可以采用一次性加载的方式，这种方式最简单（可参考下图），只需在应用启动的时候把源头数据查询出来，依次调用类似上面示例代码中的put()方法就可以了。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9e2858eac1adea40a283eafbcb683eac52fbc9e4.png" alt="image-20250909104647306"></p><p>如果源头数据量非常大，那么就需要按需加载了，按需加载也叫懒加载，指的是只有当应用查询缓存，并且数据不在缓存里的时候，才触发加载源头相关数据进缓存的操作。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/79c545d9fac4aa013452c7aa0cff4a7ec9384a82.png" alt="image-20250909104709132"></p><p>下面你可以结合文中示意图看看如何利用ReadWriteLock 来实现缓存的按需加载。</p><p>如果缓存中没有缓存目标对象，那么就需要从数据库中加载，然后写入缓存，写缓存需要用到写锁，所以在代码中的⑤处，我们调用了 <code>w.lock()</code> 来获取写锁。</p><p>另外，还需要注意的是，在获取写锁之后，我们并没有直接去查询数据库，而是在代码⑥⑦处，重新验证了一次缓存中是否存在，再次验证如果还是不存在，我们才去查询数据库并更新本地缓存。为什么我们要再次验证呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Cache</span>&lt;K,V&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> Map&lt;K, V&gt; m = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line"></span><br><span class="line">  V <span class="title function_">get</span><span class="params">(K key)</span> &#123;</span><br><span class="line">    <span class="type">V</span> <span class="variable">v</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">//读缓存</span></span><br><span class="line">    r.lock();         ①</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      v = m.get(key); ②</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      r.unlock();     ③</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//缓存中存在，返回</span></span><br><span class="line">    <span class="keyword">if</span>(v != <span class="literal">null</span>) &#123;   ④</span><br><span class="line">      <span class="keyword">return</span> v;</span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">//缓存中不存在，查询数据库</span></span><br><span class="line">    w.lock();         ⑤</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//再次验证</span></span><br><span class="line">      <span class="comment">//其他线程可能已经查询过数据库</span></span><br><span class="line">      v = m.get(key); ⑥</span><br><span class="line">      <span class="keyword">if</span>(v == <span class="literal">null</span>)&#123;  ⑦</span><br><span class="line">        <span class="comment">//查询数据库</span></span><br><span class="line">        v=省略代码无数</span><br><span class="line">        m.put(key, v);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      w.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> v; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原因是在高并发的场景下，有可能会有多线程竞争写锁。假设缓存是空的，没有缓存任何东西，如果此时有三个线程T1、T2和T3同时调用get()方法，并且参数key也是相同的。那么它们会同时执行到代码⑤处，但此时只有一个线程能够获得写锁，假设是线程T1，线程T1获取写锁之后查询数据库并更新缓存，最终释放写锁。此时线程T2和T3会再有一个线程能够获取写锁，假设是T2，如果不采用再次验证的方式，此时T2会再次查询数据库。T2释放写锁之后，T3也会再次查询一次数据库。而实际上线程T1已经把缓存的值设置好了，T2、T3完全没有必要再次查询数据库。所以，再次验证的方式，能够避免高并发场景下重复查询数据的问题。</p><h2 id="读写锁的升级与降级"><a href="#读写锁的升级与降级" class="headerlink" title="读写锁的升级与降级"></a>读写锁的升级与降级</h2><p>上面按需加载的示例代码中，在①处获取读锁，在③处释放读锁，那是否可以在②处的下面增加验证缓存并更新缓存的逻辑呢？详细的代码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读缓存</span></span><br><span class="line">r.lock();         ①</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  v = m.get(key); ②</span><br><span class="line">  <span class="keyword">if</span> (v == <span class="literal">null</span>) &#123;</span><br><span class="line">    w.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//再次验证并更新缓存</span></span><br><span class="line">      <span class="comment">//省略详细代码</span></span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      w.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">  r.unlock();     ③</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样看上去好像是没有问题的，先是获取读锁，然后再升级为写锁，对此还有个专业的名字，叫<strong>锁的升级</strong>。可惜ReadWriteLock并不支持这种升级。在上面的代码示例中，读锁还没有释放，此时获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会被唤醒。锁的升级是不允许的，这个你一定要注意。</p><p>不过，虽然锁的升级是不允许的，但是锁的降级却是允许的。以下代码来源自ReentrantReadWriteLock的官方示例，略做了改动。你会发现在代码①处，获取读锁的时候线程还是持有写锁的，这种锁的降级是支持的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CachedData</span> &#123;</span><br><span class="line">  Object data;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">boolean</span> cacheValid;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="comment">// 读锁  </span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="comment">//写锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">processCachedData</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 获取读锁</span></span><br><span class="line">    r.lock();</span><br><span class="line">    <span class="keyword">if</span> (!cacheValid) &#123;</span><br><span class="line">      <span class="comment">// 释放读锁，因为不允许读锁的升级</span></span><br><span class="line">      r.unlock();</span><br><span class="line">      <span class="comment">// 获取写锁</span></span><br><span class="line">      w.lock();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 再次检查状态  </span></span><br><span class="line">        <span class="keyword">if</span> (!cacheValid) &#123;</span><br><span class="line">          data = ...</span><br><span class="line">          cacheValid = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 释放写锁前，降级为读锁</span></span><br><span class="line">        <span class="comment">// 降级是可以的</span></span><br><span class="line">        r.lock(); ①</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 释放写锁</span></span><br><span class="line">        w.unlock(); </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 此处仍然持有读锁</span></span><br><span class="line">    <span class="keyword">try</span> &#123;use(data);&#125; </span><br><span class="line">    <span class="keyword">finally</span> &#123;r.unlock();&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="StampedLock：读多写少性能最佳锁"><a href="#StampedLock：读多写少性能最佳锁" class="headerlink" title="StampedLock：读多写少性能最佳锁"></a>StampedLock：读多写少性能最佳锁</h1><h2 id="StampedLock支持的三种锁模式"><a href="#StampedLock支持的三种锁模式" class="headerlink" title="StampedLock支持的三种锁模式"></a>StampedLock支持的三种锁模式</h2><p>StampedLock支持三种模式，分别是：<strong>写锁</strong>、<strong>悲观读锁</strong>和<strong>乐观读</strong>。其中，写锁、悲观读锁的语义和ReadWriteLock的写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。不同的是：StampedLock里的写锁和悲观读锁加锁成功之后，都会返回一个stamp；然后解锁的时候，需要传入这个stamp。相关的示例代码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">StampedLock</span> <span class="variable">sl</span> <span class="operator">=</span>  <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取/释放悲观读锁示意代码</span></span><br><span class="line"><span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.readLock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//省略业务相关代码</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  sl.unlockRead(stamp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取/释放写锁示意代码</span></span><br><span class="line"><span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.writeLock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//省略业务相关代码</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  sl.unlockWrite(stamp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>StampedLock的性能之所以比ReadWriteLock还要好，其关键是StampedLock支持乐观读的方式。ReadWriteLock支持多个线程同时读，但是当多个线程同时读的时候，所有的写操作会被阻塞；而StampedLock提供的乐观读，是允许一个线程获取写锁的，也就是说不是所有的写操作都被阻塞。</p><p><strong>乐观读这个操作是无锁的</strong>，所以相比较ReadWriteLock的读锁，乐观读的性能更好一些。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> x, y;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">StampedLock</span> <span class="variable">sl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line">  <span class="comment">//计算到原点的距离  </span></span><br><span class="line">  <span class="type">int</span> <span class="title function_">distanceFromOrigin</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 乐观读</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.tryOptimisticRead();</span><br><span class="line">    <span class="comment">// 读入局部变量，</span></span><br><span class="line">    <span class="comment">// 读的过程数据可能被修改</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curX</span> <span class="operator">=</span> x, curY = y;</span><br><span class="line">    <span class="comment">//判断执行读操作期间，是否存在写操作</span></span><br><span class="line">    <span class="comment">//如果存在，则sl.validate返回false</span></span><br><span class="line">    <span class="keyword">if</span> (!sl.validate(stamp))&#123;</span><br><span class="line">      <span class="comment">// 升级为悲观读锁</span></span><br><span class="line">      stamp = sl.readLock();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        curX = x;</span><br><span class="line">        curY = y;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//释放悲观读锁</span></span><br><span class="line">        sl.unlockRead(stamp);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Math.sqrt(</span><br><span class="line">      curX * curX + curY * curY);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果执行乐观读操作的期间，存在写操作，会把乐观读升级为悲观读锁。这个做法挺合理的，否则你就需要在一个循环里反复执行乐观读，直到执行乐观读操作的期间没有写操作（只有这样才能保证x和y的正确性和一致性），而循环读会浪费大量的CPU。</p><p>StampedLock在命名上并没有增加Reentrant，<strong>StampedLock不支持重入</strong>。</p><p>还有一点需要特别注意，那就是：如果线程阻塞在StampedLock的readLock()或者writeLock()上时，此时调用该阻塞线程的interrupt()方法，会导致CPU飙升。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">inal <span class="type">StampedLock</span> <span class="variable">lock</span></span><br><span class="line">  <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line"><span class="type">Thread</span> <span class="variable">T1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 获取写锁</span></span><br><span class="line">  lock.writeLock();</span><br><span class="line">  <span class="comment">// 永远阻塞在此处，不释放写锁</span></span><br><span class="line">  LockSupport.park();</span><br><span class="line">&#125;);</span><br><span class="line">T1.start();</span><br><span class="line"><span class="comment">// 保证T1获取写锁</span></span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line"><span class="type">Thread</span> <span class="variable">T2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;</span><br><span class="line">  <span class="comment">//阻塞在悲观读锁</span></span><br><span class="line">  lock.readLock()</span><br><span class="line">);</span><br><span class="line">T2.start();</span><br><span class="line"><span class="comment">// 保证T2阻塞在读锁</span></span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line"><span class="comment">//中断线程T2</span></span><br><span class="line"><span class="comment">//会导致线程T2所在CPU飙升</span></span><br><span class="line">T2.interrupt();</span><br><span class="line">T2.join();</span><br></pre></td></tr></table></figure><p>所以，**使用StampedLock一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的悲观读锁readLockInterruptibly()和写锁writeLockInterruptibly()**。</p><h1 id="CountDownLatch和CyclicBarrier：如何让多线程步调一致"><a href="#CountDownLatch和CyclicBarrier：如何让多线程步调一致" class="headerlink" title="CountDownLatch和CyclicBarrier：如何让多线程步调一致"></a>CountDownLatch和CyclicBarrier：如何让多线程步调一致</h1><p>CountDownLatch和CyclicBarrier都是线程同步的工具类。</p><p><strong>CountDownLatch</strong>允许一个或多个线程一直等待，直到这些线程完成它们的操作。</p><p>而<strong>CyclicBarrier</strong>是允许一组线程之间互相等待，它往往是当线程到达某状态后，暂停下来等待其他线程，等到所有线程均到达后，才继续执行。</p><p>可以发现这两者等待的主体是不一样的。<br>CountDownLatch调用await()通常是主线程&#x2F;调用线程，而CyclicBarrier调用await()是在任务线程调用的。<br>所以，CyclicBarrier中的阻塞的是任务的线程，而主线程是不受影响的。</p><p>这两个类都是基于AQS实现的。<br>当我们构建CountDownLatch对象时，传入的值其实就会赋值给AQS的关键变量state<br>执行countDown方法时，其实就是利用CAS将state减1。<br>执行await方法时，其实就是判断state是否为0，不为0则加入到队列中，将该线程阻塞掉（除了头节点）。<br>因为头节点会一直自旋等待state为0，当state为0时，头节点把剩余的在队列中阻塞的节点也一并唤醒。</p><p>而CyclicBarrier是直接借助ReentranLock加上Condition等待唤醒功能，进而实现的。<br>在构建CyclicBarrier时，传入的值会赋值给CyclicBarrier内部维护的count变量，也会赋值给parties变量（这是可以复用的关键）。<br>每次调用await时，会将count-1，操作count值是直接使用ReentrantLock来保证线程安全性。<br>如果count不为0，则添加condition队列中，<br>如果count等于0，则把节点从condition队列添加至AQS的队列中进行全部唤醒，并且将parties的值重新赋值为count的值（实现复用）。</p><h1 id="并发容器"><a href="#并发容器" class="headerlink" title="并发容器"></a>并发容器</h1><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>List里面只有一个实现类就是<strong>CopyOnWriteArrayList</strong>。CopyOnWrite，顾名思义就是写的时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁。</p><p>CopyOnWriteArrayList内部维护了一个数组，成员变量array就指向这个内部数组，所有的读操作都是基于array进行的，如下图所示，迭代器Iterator遍历的就是array数组。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f06c4663e699c62822545b9340e0d5dcf4ec93d4.png" alt="image-20250909114326977"></p><p>如果在遍历array的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList是如何处理的呢？CopyOnWriteArrayList会将array复制一份，然后在新复制处理的数组上执行增加元素的操作，执行完之后再将array指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍历操作一直都是基于原array执行，而写操作则是基于新array进行。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/423092db2304b5e43058d78561138deb1c4cf172.png" alt="image-20250909114354086"></p><p>使用CopyOnWriteArrayList需要注意的“坑”主要有两个方面。一个是应用场景，CopyOnWriteArrayList仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致。例如上面的例子中，写入的新元素并不能立刻被遍历到。另一个需要注意的是，CopyOnWriteArrayList迭代器是只读的，不支持增删改。因为迭代器遍历的仅仅是一个快照，而对快照进行增删改是没有意义的。</p><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>Map接口的两个实现是ConcurrentHashMap和ConcurrentSkipListMap，它们从应用的角度来看，主要区别在于<strong>ConcurrentHashMap的key是无序的，而ConcurrentSkipListMap的key是有序的</strong>。所以如果你需要保证key的顺序，就只能使用ConcurrentSkipListMap。</p><p>使用ConcurrentHashMap和ConcurrentSkipListMap需要注意的地方是，它们的key和value都不能为空，否则会抛出<code>NullPointerException</code>这个运行时异常。</p><blockquote><p>ConcurrentHashMap 为什么 key 和 value 不能为 null？</p></blockquote><p>key 和 value 不能为 null 主要是为了避免二义性。null 是一个特殊的值，表示没有对象或没有引用。如果你用null作为键，那么你就无法区分这个键是否存在于ConcurrentHashMap中，还是根本没有这个键。同样，如果你用null作为值，那么你就无法区分这个值是否是真正存储在ConcurrentHashMap中的，还是因为找不到对应的键而返回的。<br>拿 get 方法取值来说，返回的结果为 null 存在两种情况： - 值没有在集合中 ； - 值本身就是 null。 这也就是二义性的由来。 具体可以参考 [ConcurrentHashMap 源码分析]( <a href="https://javaguide.cn/java/collection/concurrent-hash-map-source-code.html" title="ConcurrentHashMap 源码分析 | JavaGuide(Java面试   学习指南)">ConcurrentHashMap 源码分析 | JavaGuide(Java面试 学习指南)</a> ) 。<br>多线程环境下，存在一个线程操作该ConcurrentHashMap时，其他的线程将该ConcurrentHashMap修改的情况，所以无法通过 containsKey(key)来判断否存在这个键值对，也就没办法解决二义性问题了。 与此形成对比的是，HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。如果传入null作为参数，就会返回hash值为0的位置的值。单线程环境下，不存在一个线程操作该HashMap时，其他的线程将该HashMap修改的情况，所以可以通过contains(key)来做判断是否存在这个键值对，从而做相应的处理，也就不存在二义性问题。 </p><blockquote><p>为什么源码不设计成可以判断是否存在null值的key？</p></blockquote><p>正如上面所述，如果允许key为null，那么就会带来很多不必要的麻烦和开销。比如，你需要用额外的数据结构或者标志位来记录哪些key是null的，而且在多线程环境下，还要保证对这些额外的数据结构或者标志位的操作也是线程安全的。而且，key为null的意义也不大，因为它并不能表示任何有用的信息。 如果你确实需要在 ConcurrentHashMap 中使用 null 的话，可以使用一个特殊的静态空对象来代替 null。 <code>java public static final Object NULL = new Object(); </code> </p><blockquote><p>containsKey方法后被修改，导致不可重复读，算线程不安全吗? </p></blockquote><p>ConcurrentHashMap 是线程安全的，但它不能保证所有的复合操作都是原子性的。如果需要保证复合操作的原子性，就要使用额外的同步或协调机制。这并不违反线程安全的定义，而是属于不同层次的一致性要求。 containsKey() 和 get() 方法都是单独的操作，它们之间没有同步保证。因此，如果在调用 containsKey() 后，另一个线程修改或删除了相应的键值对，那么 get() 方法可能会返回 null 或者过期的值。这确实是不可重复读的情况，但这并不违反线程安全的定义。 为什么不提供类似for update的方法呢？ Java 8中，ConcurrentHashMap增加了一些原子更新操作的方法，如compute、computeIfAbsent、computeIfPresent、merge等等。这些方法都可以接受一个函数作为参数，根据给定的key和value来计算一个新的value，并且将其更新到map中。</p><p>ConcurrentSkipListMap里面的SkipList本身就是一种数据结构，中文一般都翻译为“跳表”。跳表插入、删除、查询操作平均的时间复杂度是 O(log n)，理论上和并发线程数没有关系，所以在并发度非常高的情况下，若你对ConcurrentHashMap的性能还不满意，可以尝试一下ConcurrentSkipListMap。</p><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Set接口的两个实现是CopyOnWriteArraySet和ConcurrentSkipListSet，使用场景可以参考前面讲述的CopyOnWriteArrayList和ConcurrentSkipListMap，它们的原理都是一样的，这里就不再赘述了。</p><h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2><p>Java并发包里面Queue这类并发容器是最复杂的，你可以从以下两个维度来分类。</p><p>一个维度是<strong>阻塞与非阻塞</strong>，所谓阻塞指的是当队列已满时，入队操作阻塞；当队列已空时，出队操作阻塞。</p><p>另一个维度是<strong>单端与双端</strong>，单端指的是只能队尾入队，队首出队；而双端指的是队首队尾皆可入队出队。Java并发包里<strong>阻塞队列都用Blocking关键字标识，单端队列使用Queue标识，双端队列使用Deque标识</strong>。</p><p>这两个维度组合后，可以将Queue细分为四大类，分别是：</p><p>1.<strong>单端阻塞队列</strong>：其实现有ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、LinkedTransferQueue、PriorityBlockingQueue和DelayQueue。</p><p>内部一般会持有一个队列，这个队列可以是数组（其实现是ArrayBlockingQueue）也可以是链表（其实现是LinkedBlockingQueue）；甚至还可以不持有队列（其实现是SynchronousQueue），此时生产者线程的入队操作必须等待消费者线程的出队操作。</p><p>而LinkedTransferQueue融合LinkedBlockingQueue和SynchronousQueue的功能，性能比LinkedBlockingQueue更好；</p><p>PriorityBlockingQueue支持按照优先级出队；</p><p>DelayQueue支持延时出队。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/57bc6af2b278aa6012275440033164e8de07de08.png" alt="image-20250909140930497"></p><p>2.<strong>双端阻塞队列</strong>：其实现是LinkedBlockingDeque。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b74ef2deac8b873cefa72a16256582935d15f30e.png" alt="image-20250909140951805"></p><p>3.<strong>单端非阻塞队列</strong>：其实现是ConcurrentLinkedQueue。</p><p>4.<strong>双端非阻塞队列</strong>：其实现是ConcurrentLinkedDeque。</p><p>使用队列时，需要格外注意队列是否支持有界（所谓有界指的是内部的队列是否有容量限制）。实际工作中，一般都不建议使用无界的队列，因为数据量大了之后很容易导致OOM。</p><p>上面我们提到的这些Queue中，只有ArrayBlockingQueue和LinkedBlockingQueue是支持有界的，所以<strong>在使用其他无界队列时，一定要充分考虑是否存在导致OOM的隐患</strong>。</p><h2 id="无锁方案实现原理"><a href="#无锁方案实现原理" class="headerlink" title="无锁方案实现原理"></a>无锁方案实现原理</h2><h2 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h2><p><strong>只有当目前count的值和期望值expect相等时，才会将count更新为newValue</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimulatedCAS</span>&#123;</span><br><span class="line">  <span class="type">int</span> count；</span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">int</span> <span class="title function_">cas</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">int</span> expect, <span class="type">int</span> newValue)</span>&#123;</span><br><span class="line">    <span class="comment">// 读目前count的值</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curValue</span> <span class="operator">=</span> count;</span><br><span class="line">    <span class="comment">// 比较目前count值是否==期望值</span></span><br><span class="line">    <span class="keyword">if</span>(curValue == expect)&#123;</span><br><span class="line">      <span class="comment">// 如果是，则更新count的值</span></span><br><span class="line">      count = newValue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回写入前的值</span></span><br><span class="line">    <span class="keyword">return</span> curValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用CAS来解决并发问题，一般都会伴随着自旋，而所谓自旋，其实就是循环尝试。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimulatedCAS</span>&#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> count;</span><br><span class="line">  <span class="comment">// 实现count+=1</span></span><br><span class="line">  addOne()&#123;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      newValue = count+<span class="number">1</span>; <span class="comment">//①</span></span><br><span class="line">    &#125;<span class="keyword">while</span>(count !=</span><br><span class="line">      cas(count,newValue) <span class="comment">//②</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 模拟实现CAS，仅用来帮助理解</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">int</span> <span class="title function_">cas</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">int</span> expect, <span class="type">int</span> newValue)</span>&#123;</span><br><span class="line">    <span class="comment">// 读目前count的值</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curValue</span> <span class="operator">=</span> count;</span><br><span class="line">    <span class="comment">// 比较目前count值是否==期望值</span></span><br><span class="line">    <span class="keyword">if</span>(curValue == expect)&#123;</span><br><span class="line">      <span class="comment">// 如果是，则更新count的值</span></span><br><span class="line">      count= newValue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回写入前的值</span></span><br><span class="line">    <span class="keyword">return</span> curValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是在CAS方案中，有一个问题可能会常被你忽略，那就是<strong>ABA</strong>的问题。</p><p>前面我们提到“如果cas(count,newValue)返回的值<strong>不等于</strong>count，意味着线程在执行完代码①处之后，执行代码②处之前，count的值被其他线程<strong>更新过</strong>”，那如果cas(count,newValue)返回的值<strong>等于</strong>count，是否就能够认为count的值没有被其他线程<strong>更新过</strong>呢？显然不是的，假设count原本是A，线程T1在执行完代码①处之后，执行代码②处之前，有可能count被线程T2更新成了B，之后又被T3更新回了A，这样线程T1虽然看到的一直是A，但是其实已经被其他线程更新过了，这就是ABA问题。</p><p>解决ABA问题的最简单粗暴的方式就是加个版本号，每更新过一次就+1，这样即使更新回了原值，也会被记录下来。</p><p>我们所熟知的原子类AtomicLong的底层就是CAS实现的，在Java 1.8版本中，getAndIncrement()方法会转调unsafe.getAndAddLong()方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">long</span> <span class="title function_">getAndIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> unsafe.getAndAddLong(<span class="built_in">this</span>, valueOffset, <span class="number">1L</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>unsafe.getAndAddLong()方法的源码如下，该方法首先会在内存中读取共享变量的值，之后循环调用compareAndSwapLong()方法来尝试设置共享变量的值，直到成功为止。compareAndSwapLong()是一个native方法，只有当内存中共享变量的值等于expected时，才会将共享变量的值更新为x，并且返回true；否则返回fasle。compareAndSwapLong的语义和CAS指令的语义的差别仅仅是返回值不同而已。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="type">long</span> <span class="title function_">getAndAddLong</span><span class="params">(</span></span><br><span class="line"><span class="params">  Object o, <span class="type">long</span> offset, <span class="type">long</span> delta)</span>&#123;</span><br><span class="line">  <span class="type">long</span> v;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="comment">// 读取内存中的值</span></span><br><span class="line">    v = getLongVolatile(o, offset);</span><br><span class="line">  &#125; <span class="keyword">while</span> (!compareAndSwapLong(</span><br><span class="line">      o, offset, v, v + delta));</span><br><span class="line">  <span class="keyword">return</span> v;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//原子性地将变量更新为x</span></span><br><span class="line"><span class="comment">//条件是内存中的值等于expected</span></span><br><span class="line"><span class="comment">//更新成功则返回true</span></span><br><span class="line"><span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">compareAndSwapLong</span><span class="params">(</span></span><br><span class="line"><span class="params">  Object o, <span class="type">long</span> offset, </span></span><br><span class="line"><span class="params">  <span class="type">long</span> expected,</span></span><br><span class="line"><span class="params">  <span class="type">long</span> x)</span>;</span><br></pre></td></tr></table></figure><p>Java提供的原子类里面CAS一般被实现为compareAndSet()，compareAndSet()的语义和CAS指令的语义的差别仅仅是返回值不同而已，compareAndSet()里面如果更新成功，则会返回true，否则返回false。</p><h1 id="AQS：保证并发安全的终极奥秘"><a href="#AQS：保证并发安全的终极奥秘" class="headerlink" title="AQS：保证并发安全的终极奥秘"></a>AQS：保证并发安全的终极奥秘</h1><p>AQS 是 Java 并发包的核心，它的理念和设计思想贯穿于 Java 中许多并发工具和框架，如 ReentrantLock、Semaphore、CountDownLatch 等。</p><h2 id="AQS-在-ReentrantLock-的应用"><a href="#AQS-在-ReentrantLock-的应用" class="headerlink" title="AQS 在 ReentrantLock 的应用"></a>AQS 在 ReentrantLock 的应用</h2><p>我们来使用一张图来描述 ReentrantLock 对于 AQS 的应用：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ea862502337fb6abaafaf9a8af032c003df49741.png" alt="image-20250910174354523"></p><p>我们分析下上图，在 ReetrantLock 中存在加锁和解锁两个方法，这两个方法是借助 Sync 这个内部类来完成的。Sync 这个内部类实现了 AQS 抽象类，并实现了公平锁和非公平锁两种加锁方式！</p><p>公平锁的 <strong>FairSync#tryAcquire</strong> </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">    <span class="comment">//获取当前的线程</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="comment">//获取当前的加锁状态 在ReentrantLock中，state=0的时候是没有加锁，state=1的时候是加锁状态</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState();</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 没有人占用锁的时候，因为是公平锁，所以优先判断队列中是否存在排队的</span></span><br><span class="line">        <span class="comment">// 如果没有排队的，直接使用CAS进行加锁，将0 替换为 1，</span></span><br><span class="line">        <span class="keyword">if</span> (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">            compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            <span class="comment">// 将当前线程设置到exclusiveOwnerThread变量，表示这个线程持有锁</span></span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            <span class="comment">//返回加锁成功</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//我们在前面讲过，ReentrantLock是可重入锁，当前面逻辑加锁失败，则判断是不是当前线程持有的锁，如果是当前线程持有锁，则符合可重入规则</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        <span class="comment">//将state 累加  由 1  变成 2</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">nextc</span> <span class="operator">=</span> c + acquires;</span><br><span class="line">        <span class="keyword">if</span> (nextc &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果存在排队任务，或者CAS变换state的值失败，则证明当前不能加锁，直接返回false加锁失败</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码的注释能够印证出我们前面所学的，公平锁、可重入锁、CAS 的特性。</p><ul><li>首先进行加锁的时候，因为公平锁的原因，会先判断等待队列中是否存在任务。如果存在，就不能去加锁，需要去排队！如果没有排队的任务，那么就开始使用 CAS 进行加锁，此时可能会出现其他线程也在加锁，如果其他线程加锁成功，那么此时 CAS 就会返回 false。</li><li>假设上面的加锁条件全部满足，就能够加锁成功，它会将 state 变为 1，将当前线程设置到一个变量中去，并且为了保证重入锁的特性，将当前线程保存到变量中，表示这个线程持有这把锁。</li><li>如果上面的加锁条件不满足，不会第一时间就返回加锁失败，因为 ReentrantLock 是可重入锁，所以在加锁失败后，会判断当前持有锁的线程和所需要加锁的线程是不是一个，如果是一个就附和可重入锁的特性，那么就把加锁数量 +1，同时返回加锁成功。</li><li>如果全部都不满足，则直接返回 false，加锁失败。</li></ul><p>我们使用一个图来理解这个流程：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/40a848f019bb80afa664c3876b24d128db5462c3.png" alt="image-20250910174532176"></p><p>线程加锁失败后，会开始进行入队操作，也就是 <strong>addWaiter</strong> 方法。AQS 的队列与传统队列不同，AQS 的队列是一个双向链表，排队的线程都是用 next 指向下一个节点任务。head 节点可能为空，因为当第一个任务入队的时候，会初始化 head 节点，head 节点内线程数据为空，但是 head 节点的 next 会指向第一个等待线程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Node <span class="title function_">addWaiter</span><span class="params">(Node mode)</span> &#123;</span><br><span class="line">    <span class="comment">//创建一个node节点 排它锁的mode = null</span></span><br><span class="line">    <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>(Thread.currentThread(), mode);</span><br><span class="line">    <span class="comment">// 获取当前的尾节点</span></span><br><span class="line">    <span class="type">Node</span> <span class="variable">pred</span> <span class="operator">=</span> tail;</span><br><span class="line">    <span class="keyword">if</span> (pred != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">//将当前节点的上一个节点设置为尾节点</span></span><br><span class="line">        node.prev = pred;</span><br><span class="line">        <span class="comment">// cas替换 将当前节点设置为tail节点</span></span><br><span class="line">        <span class="keyword">if</span> (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">            <span class="comment">//将当前的尾节点的下一节点设为当前追加的节点</span></span><br><span class="line">            pred.next = node;</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//针对第一个任务初始化head节点操作</span></span><br><span class="line">    enq(node);</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是整个AQS的执行流程及加锁逻辑：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c62be37f9d8c32e0db046409ffcf7921a1e095d5.png" alt="Pasted image 20230719091028"></p><p>简单来说，加锁无非就是通过 CAS 去改变 State 的值，等于 0 且能改变成功就加锁成功，如果改变失败，就入队后阻塞。</p><p>解锁流程：</p><ol><li>解锁就是对 state 进行减一操作（重入次数 -1），当 state &#x3D; 0 的时候，就将持有锁的线程设置为 null，且返回解锁的结果。</li><li>因为 <code>ReentrantLock</code> 是可重入锁，一个线程多次获取锁，state 的数量会大于 1，当解锁的时候，必须当前<strong>线程解锁次数 &#x3D; 加锁次数</strong>才能解锁成功，否则解锁失败。</li><li>无论是解锁成功与否，都必须将当前 state 的数量使用 CAS 更新为最新的。</li></ol><p>解锁成功后，会调用 head 节点后的等到任务的 unPark 解锁线程，使得阻塞的线程重新开始循环获取锁的操作，直到获取锁成功。</p><ul><li><strong>公平锁当发现 state &#x3D; 0 也就是没有任务占有锁的情况下，会判断队列中是存在等待任务，如果存在就会加锁失败，然后执行入队操作。</strong></li><li><strong>而非公平锁发现 state &#x3D; 0 也就是没有任务占有锁的情况下，会直接进行 CAS 加锁，只要 CAS 加锁成功了，就会直接返回加锁成功而不会进行入队操作</strong></li></ul><h2 id="AQS-在-CountDownLatch-的应用"><a href="#AQS-在-CountDownLatch-的应用" class="headerlink" title="AQS 在 CountDownLatch 的应用"></a>AQS 在 CountDownLatch 的应用</h2><p>与 ReentrantLock 相同的是，我们同样可以在 CountDownLatch 中寻找到 AQS 的实现类 Sync。没错，CountDownLatch 的实现也是基于 AQS 来做的。</p><p>在初始化 CountDownLatch 的时候，我们传递了 10，然后开启了 10 个线程执行任务，每一个线程执行完毕之后都会调用 <code>countDownLatch.countDown();</code> 来进行递减操作。我们在主线程调用 <code>countDownLatch.await();</code> 来等待 CountDownLatch 变为 0 后，它会解除阻塞继续向下执行！</p><p>当 state 的值不为 0 的时候，证明 CountDown 还没有释放完毕，此时应该阻塞，先将当前节点加入到等待队列，然后同 ReentrantLock 一样，在阻塞之前也会先判断自己是不是 head 的下一个节点，如果是的话会再次尝试判断一下 state 是不是等于 0 了，如果此时等于 0 了，就不用阻塞了，可以直接返回。</p><p>此时如果 state 依旧不为 0，则开始与 ReentrantLock 一样调用 park 进行阻塞等待唤醒。</p><p>事实上，await 阻塞的逻辑十分简单。我们总结来说，就是当程序调用 await 方法的时候，会判断 state 的值是不是 0，如果不是 0 就阻塞，是 0 就直接返回。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9f0ba1d75a6936cc20df70470f5f42465e6fde4b.png" alt="image-20250910175742428"></p><p>countDown 方法主要就是对 AQS 中 State 的值进行 -1 操作，当 State 的值为 0 的时候，就开始唤醒等待队列中的任务。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/29157b26ff0dd978d0b72cfb2327de6522c6f44f.png" alt="image-20250910175837917"></p><h2 id="AQS-在-ReentrantReadWriteLock-的应用"><a href="#AQS-在-ReentrantReadWriteLock-的应用" class="headerlink" title="AQS 在 ReentrantReadWriteLock 的应用"></a>AQS 在 ReentrantReadWriteLock 的应用</h2><p>AQS 中 state 主要是为了记录加锁的次数或者计数次数，但是在 ReentrantReadWriteLock 中存在读锁（共享锁）和写锁（独占锁）两种，那么此时只有一个 state 肯定是无法满足的，因为 state 是一个 int 值，我们知道 int 在 Java 占 32 位字节，所以我们考虑<strong>将 32 位分为高 16 位和低 16 位</strong>，如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/5e8b8730fb45c3d0758136f4d194368fa76aae26.png" alt="image-20250910180229529"></p><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><p>共享锁的加锁逻辑就是先判断是不是存在写锁，存在写锁就直接加锁失败入队，不存在就加锁成功并修改 state 的高 16 位数据，并在每一个线程维护一个计数器，来计算每一个线程加锁的次数。</p><p>共享锁的解锁比较简单，解锁过程简单来说无非就是将累加器中的累加次数 -1，同时将 state 中的高 16 位 -1（state - 65536），然后再通知等待队列中的任务进行解除阻塞。</p><h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3><p>首先，它是一个独占锁，所以我们需要先判断 state 的低 16 位是不是已经存在独占锁了，如果已经存在独占锁了，那么我们就需要判断是不是重入锁！如果 state 中已经存在独占锁了，而且也不是重入锁，那么直接加锁失败，将任务放到任务队列中就可以了。</p><p>了解了写锁的加锁步骤之后，解锁步骤能猜出来：</p><ol><li>将 state - 1；</li><li>判断当前 state 的写锁数量，如果为 0 的话证明重入锁释放完毕，直接将加锁线程置空，并解锁成功。</li></ol><h1 id="Executor与线程池：如何创建正确的线程池"><a href="#Executor与线程池：如何创建正确的线程池" class="headerlink" title="Executor与线程池：如何创建正确的线程池"></a>Executor与线程池：如何创建正确的线程池</h1><h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><p>ThreadPoolExecutor的构造函数非常复杂，如下面代码所示，这个最完备的构造函数有7个参数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ThreadPoolExecutor</span>(</span><br><span class="line">  <span class="type">int</span> corePoolSize,</span><br><span class="line">  <span class="type">int</span> maximumPoolSize,</span><br><span class="line">  <span class="type">long</span> keepAliveTime,</span><br><span class="line">  TimeUnit unit,</span><br><span class="line">  BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">  ThreadFactory threadFactory,</span><br><span class="line">  RejectedExecutionHandler handler) </span><br></pre></td></tr></table></figure><p>下面我们一一介绍这些参数的意义，你可以<strong>把线程池类比为一个项目组，而线程就是项目组的成员</strong>。</p><ul><li><p><strong>corePoolSize</strong>：表示线程池保有的最小线程数。有些项目很闲，但是也不能把人都撤了，至少要留corePoolSize个人坚守阵地。</p></li><li><p><strong>maximumPoolSize</strong>：表示线程池创建的最大线程数。当项目很忙时，就需要加人，但是也不能无限制地加，最多就加到maximumPoolSize个人。当项目闲下来时，就要撤人了，最多能撤到corePoolSize个人。</p></li><li><p><strong>keepAliveTime &amp; unit</strong>：上面提到项目根据忙闲来增减人员，那在编程世界里，如何定义忙和闲呢？很简单，一个线程如果在一段时间内，都没有执行任务，说明很闲，keepAliveTime 和 unit 就是用来定义这个“一段时间”的参数。也就是说，如果一个线程空闲了<code>keepAliveTime &amp; unit</code>这么久，而且线程池的线程数大于 corePoolSize ，那么这个空闲的线程就要被回收了。</p></li><li><p><strong>workQueue</strong>：工作队列，和上面示例代码的工作队列同义。</p></li><li><p><strong>threadFactory</strong>：通过这个参数你可以自定义如何创建线程，例如你可以给线程指定一个有意义的名字。</p></li><li><p>handler</p><p>：通过这个参数你可以自定义任务的拒绝策略。如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），那么此时提交任务，线程池就会拒绝接收。至于拒绝的策略，你可以通过handler这个参数来指定。ThreadPoolExecutor已经提供了以下4种策略。</p><ul><li>CallerRunsPolicy：提交任务的线程自己去执行该任务。</li><li>AbortPolicy：默认的拒绝策略，会throws RejectedExecutionException。</li><li>DiscardPolicy：直接丢弃任务，没有任何异常抛出。</li><li>DiscardOldestPolicy：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入到工作队列。</li></ul></li></ul><h2 id="线程池处理任务流程"><a href="#线程池处理任务流程" class="headerlink" title="线程池处理任务流程"></a>线程池处理任务流程</h2><p>当我们向线程池中提交了大量的任务后，提交的任务会经历以下的历程：</p><ul><li>任务开始提交后，当线程池中的线程数小于 corePoolSize 的时候，那么线程池会立即创建一个新的线程去执行这个任务，因此这个任务会被立即运行。</li><li>随着任务数量的提升，当线程池中的线程数大于等于 corePoolSize 且小于 maximumPoolSize 的时候，线程池会将这些任务暂时存放在 workQueue 中等待核心线程运行完毕后，来消费这些等待的任务。</li><li>随着任务数量还在不停地上涨，任务队列（workQueue）也放不下了，任务已经被放满，此时会开始继续新建线程去消费任务队列的任务，直到当前线程池中存活的线程数量等于 maximumPoolSize 为止。</li><li>此时，如果系统还在不停地提交任务，workQueue 被放满了，线程池中存活的线程数量也等于 maximumPoolSize 了，那么线程池会认为它执行不了这么多任务。为了避免出现不可预测的问题，那么超出线程池极限的这部分任务，会被线程池调用拒绝策略（Handler）来拒绝执行。</li><li>终于，一波任务高峰过去了，系统终于不再提交新的任务，此时 maximumPoolSize 个线程会赶紧将手头的任务执行完毕，然后开始协助消费 workQueue 中等待的任务，直至将等待队列中的任务消费完毕。此时 maximumPoolSize 个线程开始没活干了，就开始闲着，当空闲时间超过了 <strong>keepAliveTime 与 unit</strong> 所规定的空闲时间，线程池就开始回收这些空闲的线程，直至线程池中存活的线程数量等于 corePoolSize 为止。</li></ul><h2 id="使用线程池要注意些什么"><a href="#使用线程池要注意些什么" class="headerlink" title="使用线程池要注意些什么"></a>使用线程池要注意些什么</h2><p>不建议使用Executors的最重要的原因是：Executors提供的很多方法默认使用的都是无界的LinkedBlockingQueue，高负载情境下，无界队列很容易导致OOM，而OOM会导致所有请求都无法处理，这是致命问题。所以<strong>强烈建议使用有界队列</strong>。</p><p>使用有界队列，当任务过多时，线程池会触发执行拒绝策略，线程池默认的拒绝策略会throw RejectedExecutionException 这是个运行时异常，对于运行时异常编译器并不强制catch它，所以开发人员很容易忽略。因此<strong>默认拒绝策略要慎重使用</strong>。如果线程池处理的任务非常重要，建议自定义自己的拒绝策略；并且在实际工作中，自定义的拒绝策略往往和降级策略配合使用。</p><p>使用线程池，还要注意异常处理的问题，例如通过ThreadPoolExecutor对象的execute()方法提交任务时，如果任务在执行的过程中出现运行时异常，会导致执行任务的线程终止；不过，最致命的是任务虽然异常了，但是你却获取不到任何通知，这会让你误以为任务都执行得很正常。虽然线程池提供了很多用于异常处理的方法，但是最稳妥和简单的方案还是捕获所有异常并按需处理，你可以参考下面的示例代码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//业务逻辑</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">  <span class="comment">//按需处理</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">  <span class="comment">//按需处理</span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h1 id="ThreadLocal：线程本地存储模式"><a href="#ThreadLocal：线程本地存储模式" class="headerlink" title="ThreadLocal：线程本地存储模式"></a>ThreadLocal：线程本地存储模式</h1><p>Java的实现里面也有一个Map，叫做ThreadLocalMap，不过持有ThreadLocalMap的不是ThreadLocal，而是Thread。Thread这个类内部有一个私有属性threadLocals，其类型就是ThreadLocalMap，ThreadLocalMap的Key是ThreadLocal。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ad2c2e1196e4cc6bf4a0d507c4cc8524489fa836.png" alt="image-20250909190952775"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">  <span class="comment">//内部持有ThreadLocalMap</span></span><br><span class="line">  ThreadLocal.ThreadLocalMap  threadLocals;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ThreadLocal</span>&lt;T&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span> T <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//首先获取线程持有的</span></span><br><span class="line">    <span class="comment">//ThreadLocalMap</span></span><br><span class="line">    <span class="type">ThreadLocalMap</span> <span class="variable">map</span> <span class="operator">=</span> Thread.currentThread().threadLocals;</span><br><span class="line">    <span class="comment">//在ThreadLocalMap中</span></span><br><span class="line">    <span class="comment">//查找变量</span></span><br><span class="line">    <span class="type">Entry</span> <span class="variable">e</span> <span class="operator">=</span>  map.getEntry(<span class="built_in">this</span>);</span><br><span class="line">    <span class="keyword">return</span> e.value;  </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ThreadLocalMap</span>&#123;</span><br><span class="line">    <span class="comment">//内部是数组而不是Map</span></span><br><span class="line">    Entry[] table;</span><br><span class="line">    <span class="comment">//根据ThreadLocal查找Entry</span></span><br><span class="line">    Entry <span class="title function_">getEntry</span><span class="params">(ThreadLocal key)</span>&#123;</span><br><span class="line">      <span class="comment">//省略查找逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Entry定义</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Entry</span> <span class="keyword">extends</span></span><br><span class="line">    <span class="title class_">WeakReference</span>&lt;ThreadLocal&gt;&#123;</span><br><span class="line">      Object value;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在Java的实现方案里面，ThreadLocal仅仅是一个代理工具类，内部并不持有任何与线程相关的数据，所有和线程相关的数据都存储在Thread里面，这样的设计容易理解。而从数据的亲缘性上来讲，ThreadLocalMap属于Thread也更加合理。</p><p>当然还有一个更加深层次的原因，那就是<strong>不容易产生内存泄露</strong>。</p><p>Java的实现中Thread持有ThreadLocalMap，而且ThreadLocalMap里对ThreadLocal的引用还是弱引用（WeakReference），所以只要Thread对象可以被回收，那么ThreadLocalMap就能被回收。</p><h2 id="ThreadLocal与内存泄露"><a href="#ThreadLocal与内存泄露" class="headerlink" title="ThreadLocal与内存泄露"></a>ThreadLocal与内存泄露</h2><blockquote><p>在线程池中使用ThreadLocal为什么可能导致内存泄露呢？</p></blockquote><p>原因就出在线程池中线程的存活时间太长，往往都是和程序同生共死的，这就意味着Thread持有的ThreadLocalMap一直都不会被回收，再加上ThreadLocalMap中的Entry对ThreadLocal是弱引用（WeakReference），所以只要ThreadLocal结束了自己的生命周期是可以被回收掉的。但是Entry中的Value却是被Entry强引用的，所以即便Value的生命周期结束了，Value也是无法被回收的，从而导致内存泄露。</p><p>既然JVM不能做到自动释放对Value的强引用，那我们手动释放就可以了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService es;</span><br><span class="line">ThreadLocal tl;</span><br><span class="line">es.execute(()-&gt;&#123;</span><br><span class="line">  <span class="comment">//ThreadLocal增加变量</span></span><br><span class="line">  tl.set(obj);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 省略业务逻辑代码</span></span><br><span class="line">  &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">//手动清理ThreadLocal </span></span><br><span class="line">    tl.remove();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="高性能限流器Guava-RateLimiter"><a href="#高性能限流器Guava-RateLimiter" class="headerlink" title="高性能限流器Guava RateLimiter"></a>高性能限流器Guava RateLimiter</h1><p>Guava是Google开源的Java类库，提供了一个工具类RateLimiter。我们先来看看RateLimiter的使用，让你对限流有个感官的印象。假设我们有一个线程池，它每秒只能处理两个任务，如果提交的任务过快，可能导致系统不稳定，这个时候就需要用到限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//限流器流速：2个请求/秒</span></span><br><span class="line"><span class="type">RateLimiter</span> <span class="variable">limiter</span> <span class="operator">=</span> RateLimiter.create(<span class="number">2.0</span>);</span><br><span class="line"><span class="comment">//执行任务的线程池</span></span><br><span class="line"><span class="type">ExecutorService</span> <span class="variable">es</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">1</span>);</span><br><span class="line"><span class="comment">//记录上一次执行时间</span></span><br><span class="line">prev = System.nanoTime();</span><br><span class="line"><span class="comment">//测试执行20次</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">20</span>; i++)&#123;</span><br><span class="line">  <span class="comment">//限流器限流</span></span><br><span class="line">  limiter.acquire();</span><br><span class="line">  <span class="comment">//提交任务异步执行</span></span><br><span class="line">  es.execute(()-&gt;&#123;</span><br><span class="line">    <span class="type">long</span> cur=System.nanoTime();</span><br><span class="line">    <span class="comment">//打印时间间隔：毫秒</span></span><br><span class="line">    System.out.println((cur-prev)/<span class="number">1000_000</span>);</span><br><span class="line">    prev = cur;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：<br>…<br>500<br>499<br>499<br>500<br>499</p><h2 id="经典限流算法：令牌桶算法"><a href="#经典限流算法：令牌桶算法" class="headerlink" title="经典限流算法：令牌桶算法"></a>经典限流算法：令牌桶算法</h2><p>Guava采用的是<strong>令牌桶算法</strong>，其<strong>核心是要想通过限流器，必须拿到令牌</strong>。也就是说，只要我们能够限制发放令牌的速率，那么就能控制流速了。令牌桶算法的详细描述如下：</p><ol><li>令牌以固定的速率添加到令牌桶中，假设限流的速率是 r&#x2F;秒，则令牌每 1&#x2F;r 秒会添加一个；</li><li>假设令牌桶的容量是 b ，如果令牌桶已满，则新的令牌会被丢弃；</li><li>请求能够通过限流器的前提是令牌桶中有令牌。</li></ol><p>这个算法中，限流的速率 r 还是比较容易理解的，但令牌桶的容量 b 该怎么理解呢？b 其实是burst的简写，意义是<strong>限流器允许的最大突发流量</strong>。比如b&#x3D;10，而且令牌桶中的令牌已满，此时限流器允许10个请求同时通过限流器，当然只是突发流量而已，这10个请求会带走10个令牌，所以后续的流量只能按照速率 r 通过限流器。</p><p>令牌桶这个算法，如何用Java实现呢？</p><p>很可能你的直觉会告诉你生产者-消费者模式：一个生产者线程定时向阻塞队列中添加令牌，而试图通过限流器的线程则作为消费者线程，只有从阻塞队列中获取到令牌，才允许通过限流器。</p><p>可实际情况却是使用限流的场景大部分都是高并发场景，而且系统压力已经临近极限了，此时这个实现就有问题了。问题就出在定时器上，在高并发场景下，当系统压力已经临近极限的时候，定时器的精度误差会非常大，同时定时器本身会创建调度线程，也会对系统的性能产生影响。</p><h2 id="Guava如何实现令牌桶算法"><a href="#Guava如何实现令牌桶算法" class="headerlink" title="Guava如何实现令牌桶算法"></a>Guava如何实现令牌桶算法</h2><p>Guava实现令牌桶算法，用了一个很简单的办法，其关键是<strong>记录并动态计算下一令牌发放的时间</strong>。</p><p>假设令牌桶的容量为 b&#x3D;1，限流速率 r &#x3D; 1个请求&#x2F;秒，如下图所示，如果当前令牌桶中没有令牌，下一个令牌的发放时间是在第3秒，而在第2秒的时候有一个线程T1请求令牌，此时该如何处理呢？</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ecbcdfd6834fbcb0a5193a2b870bc18528225e63.png" alt="image-20250910160423107"></p><p>对于这个请求令牌的线程而言，很显然需要等待1秒，因为1秒以后（第3秒）它就能拿到令牌了。此时需要注意的是，下一个令牌发放的时间也要增加1秒，为什么呢？因为第3秒发放的令牌已经被线程T1预占了。处理之后如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2152701f00cb9e5cdff36719e4320442e5ef427c.png" alt="image-20250910160451591"></p><p>假设T1在预占了第3秒的令牌之后，马上又有一个线程T2请求令牌，如下图所示。</p><p>很显然，由于下一个令牌产生的时间是第4秒，所以线程T2要等待两秒的时间，才能获取到令牌，同时由于T2预占了第4秒的令牌，所以下一令牌产生时间还要增加1秒，完全处理之后，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a17f801cf65aa8d6bc99e6bb17cc64cfb425b688.png" alt="image-20250910160522162"></p><p>上面线程T1、T2都是在<strong>下一令牌产生时间之前</strong>请求令牌，如果线程在<strong>下一令牌产生时间之后</strong>请求令牌会如何呢？假设在线程T1请求令牌之后的5秒，也就是第7秒，线程T3请求令牌，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/373c0630e3f88b7e13312e3aff8d092369778874.png" alt="image-20250910160539644"></p><p>由于在第5秒已经产生了一个令牌，所以此时线程T3可以直接拿到令牌，而无需等待。在第7秒，实际上限流器能够产生3个令牌，第5、6、7秒各产生一个令牌。由于我们假设令牌桶的容量是1，所以第6、7秒产生的令牌就丢弃了，其实等价地你也可以认为是保留的第7秒的令牌，丢弃的第5、6秒的令牌，也就是说第7秒的令牌被线程T3占有了，于是下一令牌的的产生时间应该是第8秒，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ee575bff63b1ab97666a92a7ab81b6acb1fb7eb0.png" alt="image-20250910160614686"></p><p>通过上面简要地分析，你会发现，我们<strong>只需要记录一个下一令牌产生的时间，并动态更新它，就能够轻松完成限流功能</strong>。</p><p>关键是<strong>reserve()方法</strong>，这个方法会为请求令牌的线程预分配令牌，同时返回该线程能够获取令牌的时间。其实现逻辑就是上面提到的：如果线程请求令牌的时间在下一令牌产生时间之后，那么该线程立刻就能够获取令牌；反之，如果请求时间在下一令牌产生时间之前，那么该线程是在下一令牌产生的时间获取令牌。由于此时下一令牌已经被该线程预占，所以下一令牌产生的时间需要加上1秒。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleLimiter</span> &#123;</span><br><span class="line">  <span class="comment">//下一令牌产生时间</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">next</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">  <span class="comment">//发放令牌间隔：纳秒</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">interval</span> <span class="operator">=</span> <span class="number">1000_000_000</span>;</span><br><span class="line">  <span class="comment">//预占令牌，返回能够获取令牌的时间</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">long</span> <span class="title function_">reserve</span><span class="params">(<span class="type">long</span> now)</span>&#123;</span><br><span class="line">    <span class="comment">//请求时间在下一令牌产生时间之后</span></span><br><span class="line">    <span class="comment">//重新计算下一令牌产生时间</span></span><br><span class="line">    <span class="keyword">if</span> (now &gt; next)&#123;</span><br><span class="line">      <span class="comment">//将下一令牌产生时间重置为当前时间</span></span><br><span class="line">      next = now;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//能够获取令牌的时间</span></span><br><span class="line">    <span class="type">long</span> at=next;</span><br><span class="line">    <span class="comment">//设置下一令牌产生时间</span></span><br><span class="line">    next += interval;</span><br><span class="line">    <span class="comment">//返回线程需要等待的时间</span></span><br><span class="line">    <span class="keyword">return</span> Math.max(at, <span class="number">0L</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//申请令牌</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//申请令牌时的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">    <span class="comment">//预占令牌</span></span><br><span class="line">    <span class="type">long</span> at=reserve(now);</span><br><span class="line">    <span class="type">long</span> waitTime=max(at-now, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">//按照条件等待</span></span><br><span class="line">    <span class="keyword">if</span>(waitTime &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        TimeUnit.NANOSECONDS</span><br><span class="line">          .sleep(waitTime);</span><br><span class="line">      &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果令牌桶的容量大于1，又该如何处理呢？按照令牌桶算法，令牌要首先从令牌桶中出，所以我们需要按需计算令牌桶中的数量，当有线程请求令牌时，先从令牌桶中出。具体的代码实现如下所示。</p><p>我们增加了一个<strong>resync()方法</strong>，在这个方法中，如果线程请求令牌的时间在下一令牌产生时间之后，会重新计算令牌桶中的令牌数，<strong>新产生的令牌的计算公式是：(now-next)&#x2F;interval</strong>，你可对照上面的示意图来理解。reserve()方法中，则增加了先从令牌桶中出令牌的逻辑，不过需要注意的是，如果令牌是从令牌桶中出的，那么next就无需增加一个 interval 了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleLimiter</span> &#123;</span><br><span class="line">  <span class="comment">//当前令牌桶中的令牌数量</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">storedPermits</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">  <span class="comment">//令牌桶的容量</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">maxPermits</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line">  <span class="comment">//下一令牌产生时间</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">next</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">  <span class="comment">//发放令牌间隔：纳秒</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">interval</span> <span class="operator">=</span> <span class="number">1000_000_000</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//请求时间在下一令牌产生时间之后,则</span></span><br><span class="line">  <span class="comment">// 1.重新计算令牌桶中的令牌数</span></span><br><span class="line">  <span class="comment">// 2.将下一个令牌发放时间重置为当前时间</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">resync</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (now &gt; next) &#123;</span><br><span class="line">      <span class="comment">//新产生的令牌数</span></span><br><span class="line">      <span class="type">long</span> newPermits=(now-next)/interval;</span><br><span class="line">      <span class="comment">//新令牌增加到令牌桶</span></span><br><span class="line">      storedPermits=min(maxPermits, storedPermits + newPermits);</span><br><span class="line">      <span class="comment">//将下一个令牌发放时间重置为当前时间</span></span><br><span class="line">      next = now;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//预占令牌，返回能够获取令牌的时间</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">long</span> <span class="title function_">reserve</span><span class="params">(<span class="type">long</span> now)</span>&#123;</span><br><span class="line">    resync(now);</span><br><span class="line">    <span class="comment">//能够获取令牌的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">at</span> <span class="operator">=</span> next;</span><br><span class="line">    <span class="comment">//令牌桶中能提供的令牌</span></span><br><span class="line">    <span class="type">long</span> fb=min(<span class="number">1</span>, storedPermits);</span><br><span class="line">    <span class="comment">//令牌净需求：首先减掉令牌桶中的令牌</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">nr</span> <span class="operator">=</span> <span class="number">1</span> - fb;</span><br><span class="line">    <span class="comment">//重新计算下一令牌产生时间</span></span><br><span class="line">    next = next + nr*interval;</span><br><span class="line">    <span class="comment">//重新计算令牌桶中的令牌</span></span><br><span class="line">    <span class="built_in">this</span>.storedPermits -= fb;</span><br><span class="line">    <span class="keyword">return</span> at;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//申请令牌</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//申请令牌时的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">    <span class="comment">//预占令牌</span></span><br><span class="line">    <span class="type">long</span> at=reserve(now);</span><br><span class="line">    <span class="type">long</span> waitTime=max(at-now, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">//按照条件等待</span></span><br><span class="line">    <span class="keyword">if</span>(waitTime &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        TimeUnit.NANOSECONDS.sleep(waitTime);</span><br><span class="line">      &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;可见性、原子性和有序性问题：并发编程Bug的源头&quot;&gt;&lt;a href=&quot;#可见性、原子性和有序性问题：并发编程Bug的源头&quot; class=&quot;headerlink&quot; title=&quot;可见性、原子性和有序性问题：并发编程Bug的源头&quot;&gt;&lt;/a&gt;可见性、原子性和有序性问题：</summary>
      
    
    
    
    <category term="JUC" scheme="https://palette-k.github.io/categories/JUC/"/>
    
    
    <category term="JUC" scheme="https://palette-k.github.io/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>uhr考勤</title>
    <link href="https://palette-k.github.io/2025/07/14/uhr%E8%80%83%E5%8B%A4%E6%A8%A1%E5%9D%97%E6%A0%B8%E5%BF%83%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91/"/>
    <id>https://palette-k.github.io/2025/07/14/uhr%E8%80%83%E5%8B%A4%E6%A8%A1%E5%9D%97%E6%A0%B8%E5%BF%83%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91/</id>
    <published>2025-07-14T09:01:45.000Z</published>
    <updated>2025-10-13T03:31:37.629Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1自动生成年假"><a href="#1自动生成年假" class="headerlink" title="1自动生成年假"></a>1自动生成年假</h1><h2 id="1-1基本业务场景"><a href="#1-1基本业务场景" class="headerlink" title="1.1基本业务场景"></a>1.1基本业务场景</h2><p>假期类型为定额类且规则是自动生成的需要定时任务自动生成假期，根据基准值和生成条件来确定年假生成的额度。<br><img src="https://i0.hdslb.com/bfs/openplatform/f0088aaee1cdc5c9bb9796c0aac8fd0f055648ec.png" alt="image-20250714170445623"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/f2a257b70f9cf40c4a976c8c7627830453b19c82.png" alt="image-20250714170504252"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/555ded81855f9ee25dd4f9e7a2deeea258148e3c.png" alt="image-20250714170518878"></p><p><strong>基准值</strong>：福利工龄日期、社会工龄日期<br>!!#ff0000 <strong>生成条件</strong>!!：福利工龄日期满N个月、社会工龄日期满N个月</p><p><strong>是否预支年假</strong>：是、否。即是生成已工作年份年假和未来为工作时间的年假（预支，员工刚入职生成今年一年的年假）<br><strong>基准值单位：</strong>月、自然年<br><strong>例如：基准值以月为单位：</strong><br>基准值单位选择为“月”，非预支类型年假，若起始日期为2022年10月1日，则2023年10月1日基准值满12个月<br>示例：若年假计算规则：以“福利工龄”为基准值+“福利工龄”为基础条件+“自然年”为计算周期+取整方式为“向下取整”+额度单位为“天”+基准值单位为“月”： 小王于2015年7月12日首次参加工作，于2022年2月10日加入公司，公司规定：福利工龄满12个月（2023年2月10日）后给予年假，年假阶梯是福利工龄12个月<del>60个月给予5天，60个月</del>120个月给予7天。 小王于2022年5月10日，入职满12个月，此时生成年假。 计算规则为：（20221231-20220211）&#x2F;365<em>7&#x3D;6.19，向下取整为6天。<br><strong>基准值以自然年为单位：</strong><br>基准值单位选择为“自然年”，非预支类型年假，若起始日期为2022年10月1日，2023年1月1日开始则为第二个自然年。<br>示例：若年假计算规则：以“福利工龄”为基准值+“福利工龄”为基础条件+“自然年”为计算周期+取整方式为“向下取整”+额度单位为“天”+基准值单位为“自然年”： 小王于2018年7月12日首次参加工作，于2022年2月10日加入公司，公司规定：福利工龄满12个月（2023年2月10日）后给予年假，年假阶梯是社会工龄第1-5自然年给予5天， 小王于2023年2月10日，入职满12个月，此时生成年假。 计算规则为：（20221231-20220210）&#x2F;365</em>5&#x3D;4.42，向下取整为4天。</p><h2 id="1-2业务实现逻辑梳理"><a href="#1-2业务实现逻辑梳理" class="headerlink" title="1.2业务实现逻辑梳理"></a>1.2业务实现逻辑梳理</h2><h3 id="整体逻辑流程图"><a href="#整体逻辑流程图" class="headerlink" title="整体逻辑流程图"></a>整体逻辑流程图</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/9a074dde5b69432d6346787bf1b3cef3d6452e90.png" alt="image-20250714170735668"></p><h3 id="以自然年为计算周期逻辑"><a href="#以自然年为计算周期逻辑" class="headerlink" title="以自然年为计算周期逻辑"></a>以自然年为计算周期逻辑</h3><p>名词解释：</p><ul><li><p>基准：基准值日期（社会工龄日期 or 福利工龄日期）</p></li><li><p>M：以基准值日期为准，生成条件满M个月</p></li><li><p>T：当前时间</p></li><li><p>司内（红点）：入职日期</p></li><li><p>司内年底（黑点）：入职当年的自然年底</p></li><li><p>司内2年底（黑点）：入职第二年的自然年底</p></li></ul><p><strong>1.不预支年假，即满足年假生成条件，生成上年应休年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/fd077ccfa48ea3c644fb11471b12ed1577c0ef98.png" alt="image-20250714170540813"><br><strong>2.预支年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/6915b5e655025e6781644f25d991079854a21f93.png" alt="image-20250714170551746"><br><strong>3.不预支年假，即满足年假生成条件</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/aa281597ee5d251c57bf70a49c85e6156068e903.png" alt="image-20250714170603847"><br><strong>4.预支年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/b6a8d35bc7053bb3aca9a8526556dc76162a5791.png" alt="image-20250714170616417"></p><p><em>代码逻辑：通过比较当前时间在哪个时间段、是否预支年假，传入不同的额度开始计算日期参数，再根据是否存在跨额度的情况计算出最终的应休年假。</em></p><h2 id="1-3特殊场景-年假跨额度生成处理方式"><a href="#1-3特殊场景-年假跨额度生成处理方式" class="headerlink" title="1.3特殊场景-年假跨额度生成处理方式"></a>1.3特殊场景-年假跨额度生成处理方式</h2><p>1 员工当前年年假生成数刚好在两个阶段中是，需要对两个阶段进行合并计算出最终的年假<br>年假跨阶段7天&#x2F;10天； 计算公式：(153&#x2F;365)*7+(173&#x2F;365)*10<br><img src="https://i0.hdslb.com/bfs/openplatform/d44ec787f485b1cfd751d3442de69dbb3119be00.png" alt="image-20250714170640952"></p><h2 id="1-4测试用例"><a href="#1-4测试用例" class="headerlink" title="1.4测试用例"></a>1.4测试用例</h2><p>根据以下测试用例可以和上面的流程图相结合，便于理解年假生成逻辑。</p><p><strong>不预支年假：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/d03b5acc62ec9451080fc00e675a68dc62938a9a.png" alt="image-20250714171231119"></p><p><strong>预支年假：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/db530e93d367b991b894228030bc5d5cacbb3315.png"></p><p><strong>高管类个性化规则：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/17ad2f8c00bf767a0a1bfed325b1d8b0b41f7bec.png" alt="image-20250714171407722"></p><h1 id="2初始化有效打卡记录"><a href="#2初始化有效打卡记录" class="headerlink" title="2初始化有效打卡记录"></a>2初始化有效打卡记录</h1><p>一般来讲，考勤计算需要先拿到每个员工每天每个班次的有效打卡记录，以这个记录为基准来计算考勤。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d290f8e750aa53a54a87946ebd8668e5d9e08c13.png" alt="image-20250715172749571"></p><h1 id="3考勤计算全流程"><a href="#3考勤计算全流程" class="headerlink" title="3考勤计算全流程"></a>3考勤计算全流程</h1><p>考勤计算分为数据准备、数据验证、组装数据、数据拆分计算这四个步骤，其中涉及的表及业务逻辑如下图。</p><p>考勤计算的定时任务也和初始化有效打卡记录的整体逻辑一致，都是根据员工的pdc时间筛选出需要计算考勤的员工和考勤日期，按照日期给每个员工计算考勤。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/fd1b6cb9f2ff196d1e4d0f1966dabbeba83acd69.png" alt="image-20250715172047166"></p><p>考勤计算涉及的相关表：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0726a8b1949c0b2b501f83e7e26a00767a45de1d.png" alt="image-20250717151034055"></p><h2 id="3-1数据准备"><a href="#3-1数据准备" class="headerlink" title="3.1数据准备"></a>3.1数据准备</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/d3fe75c1771bb5643c18803617374d2eefe31a43.png" alt="image-20250715171507019"></p><h2 id="3-2数据验证"><a href="#3-2数据验证" class="headerlink" title="3.2数据验证"></a>3.2数据验证</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/41716aab8440e3ac1aa8e55e6e293400bdcc676b.png" alt="image-20250715171624480"></p><h2 id="3-3组装数据"><a href="#3-3组装数据" class="headerlink" title="3.3组装数据"></a>3.3组装数据</h2><p>此处获取班次信息（标记0点）的作用是，跨天班次可能会存在休息时间跨天的情况，也可能跨天时是排班的情况，需要将0点前后的考勤状态拆分。</p><p>例如：跨天班次B(19:00-5:00)，休息时间为23:00–1:00,3:00–4:00</p><p>拆分0点后，班次结果为：   [2025-07-16  19:00,2025-07-16 23:00]【排班】</p><p>​[2025-07-16  23:00,2025-07-16 0:00] 【休息】</p><p>​[2025-07-17  0:00,2025-07-17 1:00] 【休息】</p><p>​[2025-07-17  1:00,2025-07-17 3:00] 【排班】</p><p>​[2025-07-17  3:00,2025-07-17 4:00] 【休息】</p><p>​[2025-07-17  4:00,2025-07-17 5:00] 【排班】</p><p>后续的考勤拆分是以这个拆分了0点后的班次作为循环条件，与打卡、请假、销假、出差等数据进行比较。<img src="https://i0.hdslb.com/bfs/openplatform/9287b759e47205192f431f45ef7e1284d893a0fd.png" alt="image-20250715171644104"></p><h2 id="3-4数据拆分计算"><a href="#3-4数据拆分计算" class="headerlink" title="3.4数据拆分计算"></a>3.4数据拆分计算</h2><h3 id="考勤核算流程图"><a href="#考勤核算流程图" class="headerlink" title="考勤核算流程图"></a>考勤核算流程图</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/1250b18924e17d13981b40a42ac836ea5c7ec625.png" alt="image-20250715171705033"></p><h3 id="考勤核算规则"><a href="#考勤核算规则" class="headerlink" title="考勤核算规则"></a>考勤核算规则</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/712f8d78d39fd934dee9bb7225f3ab269d7f88f1.png" alt="image-20250715172024559"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/dcf709c964d1d3bc88900189570ffdd7c6100be6.png" alt="image-20250715172037235"></p><h3 id="考勤状态"><a href="#考勤状态" class="headerlink" title="考勤状态"></a>考勤状态</h3><p><code>休息</code>、<code>请假</code>、<code>出差</code>、<code>正常出勤</code>、<code>早到</code>、<code>迟到</code>、<code>早退</code>、<code>延迟下班</code>、<code>旷工</code>、<code>排班</code>、<code>弹性排班</code></p><p><strong>三、数据处理（考勤计算前）</strong><br>1、数据准备：所有数据需分段存储至GtdAttendanceResult对象中，并标识出该段目前的考勤状态<br>例：班次为9:00-18:00，休息时间为12:00-14:00<br>分段存储后：9:00-12:00（排班），12:00-14:00（休息），14:00-18:00（排班）</p><h3 id="考勤计算"><a href="#考勤计算" class="headerlink" title="考勤计算"></a>考勤计算</h3><p><strong>1、初次比较</strong><br>1.1、以班次作为基础数据，打卡、请假、销假、出差等数据作为比较数据</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c20c5e47e668d47e7a3bbfe9a2f2caa8c5cc3286.png" alt="image-20250715172448644"></p><p>1.2、根据考勤核算规则优先级，将比较数据逐一与基础数据进行比对，不重合时间段保留当前考勤状态，重合时间段按照优先级比对出两段考勤状态<br>1.3、为了提升比对效率，若当前比较数据比对完毕，则终止循环，进入下一次比较数据的循环<br><img src="https://i0.hdslb.com/bfs/openplatform/fffc12387eeedafe635dc4aba6a7841bfdf57ff9.png" alt="image-20250715172416478"></p><p><strong>2、二次比较</strong><br>2.1、二次比较确定考勤异常最终状态，例：初次比较得出迟到、早退，需要与系统配置的时长进行比对，确定是否为旷工</p><p><strong>3、弹性班次注意事项</strong><br>3.1、需先计算员工应下班时间（根据上班打卡时间和上班总时长计算）<br>3.2、班次时间需这样拆分 -&gt; 最早到岗时间,最晚到岗时间 ; 最晚到岗时间,实际下班时间 ; 实际下班时间,最晚下班时间</p><p><strong>4、多段班注意事项</strong><br>4.1、多段班需要逐段班次进行比较</p><p><strong>五、考勤结果、明细存储</strong><br>1、保存考勤明细存在转换天数精度丢失问题<br>现采用减法计算：1 - 请假天数 - 实际出勤天数(包含出差天数) &#x3D; 旷工天数<br>特殊处理：若考勤结果无旷工时间段，且减法后旷工天数 &gt; 0 ,则将旷工天数补入实际出勤天数</p><h1 id="4考勤处理流程"><a href="#4考勤处理流程" class="headerlink" title="4考勤处理流程"></a>4考勤处理流程</h1><p>考勤一般都是与OA流程挂钩的，员工的请假、加班、出差、销假等操作在OA系统发起，对接到UHR系统，对接后考勤处理流程如下。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/654e3789730d7e6c9b95b2a3dac3ac6515ff602d.png" alt="image-20250715173137044"></p><h2 id="4-1拆分请假-出差数据"><a href="#4-1拆分请假-出差数据" class="headerlink" title="4.1拆分请假&#x2F;出差数据"></a>4.1拆分请假&#x2F;出差数据</h2><p>员工提交整段请假记录时，后台需要按照员工班次进行拆分，存储到数据库时请假结果按天存储，销假是也要删除对应拆分结果。</p><p>而且对于员工排班发生变更前的请假&#x2F;出差记录，计算考勤前需要重新拆分。</p><p>具体拆分逻辑如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/7c1af1dfc15a95bc298c721c4151fc215107f6ad.png" alt="image-20250715173311178"></p><h1 id="5考勤日历"><a href="#5考勤日历" class="headerlink" title="5考勤日历"></a>5考勤日历</h1><h2 id="5-1相关表设计"><a href="#5-1相关表设计" class="headerlink" title="5.1相关表设计"></a>5.1相关表设计</h2><p>其中 gtd_emp_calendar 因数据量过大，不再使用。</p><p>gtd_work_calendar_details工作日历明细表，精确到天，每天绑定一个班次。</p><p>sys_organization为组织表，emp_org_allocation为员工的组织分配表（员工有异动时添加一条数据）。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/21e03b05f82fb068d2c9e64eb9c4bd72080e5905.png" alt="image-20250716142327119"></p><ul><li>gtd_holiday_manage：节假日管理实体，包含节假日名称、代码、开始日期、结束日期、法定节假日、调休日期等信息。</li><li>gtd_work_calendar_details：工作日历明细表，记录每个工作日历的具体日期安排，包括班次、日期类型等。</li><li>gtd_holiday_calendar_history：工作日历和节假日关联历史表，用于记录工作日历应用节假日前的原始数据，便于后续恢复或修改。</li></ul><h2 id="5-2相关业务逻辑"><a href="#5-2相关业务逻辑" class="headerlink" title="5.2相关业务逻辑"></a>5.2相关业务逻辑</h2><h3 id="工作日历按周期顺延"><a href="#工作日历按周期顺延" class="headerlink" title="工作日历按周期顺延"></a>工作日历按周期顺延</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/f968b9835cb84efae8ed4b508cad7112780e82bc.png" alt="image-20250716193716828"></p><h3 id="节假日应用工作日历"><a href="#节假日应用工作日历" class="headerlink" title="节假日应用工作日历"></a>节假日应用工作日历</h3><p>节假日管理信息配置中，支持编辑法定节假日日期、关联调休日期、法定节假日（非3倍计薪）</p><p><img src="https://i0.hdslb.com/bfs/openplatform/230b79f95edb3a2fee6717963695671162af55c8.png" alt="image-20250717102302183"></p><p>一个节假日支持应用到多个工作日历上</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a863988dcccef29b887e5a622622d3f6ed9ddd30.png" alt="image-20250717103717525"></p><p>节假日应用到多个工作日历的业务流程图如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2693723abd13324a138173e8113fe4d5429a698d.png" alt="image-20250717111533223"></p><p>整个节假日历史关联表的业务逻辑可以总结为：</p><ol><li><p>历史记录管理 ：</p><ul><li>保存原始工作日历数据（ holidayId 为 null ）</li><li>保存节假日应用后的工作日历数据（ holidayId 为节假日ID）</li><li>当修改节假日设置时，先恢复原始数据，再应用新设置</li></ul></li><li><p>节假日应用 ：</p><ul><li>将节假日期间的工作日设置为休息日（ classId 为 null ）</li><li>根据节假日类型设置不同的 holidayType （法定节假日或普通节假日）</li></ul></li><li><p>调休处理 ：</p><ul><li>将调休日设置为工作日（ holidayType 为普通日期）</li><li>为调休日分配合适的班次（通过查找最近的班次）</li></ul></li><li><p>数据一致性 ：</p><ul><li>通过事务保证工作日历明细和历史记录的一致性</li><li>通过批量操作提高性能</li></ul></li></ol><h3 id="获取员工班次步骤"><a href="#获取员工班次步骤" class="headerlink" title="获取员工班次步骤"></a>获取员工班次步骤</h3><p><strong>员工班次有两种来源：</strong><br>①.直接导入员工班次到员工班次明细表；<br>②.通过部门绑定工作日历或直接给员工绑定工作日历；<br>两者都存在时①优先级高于②</p><p><img src="https://i0.hdslb.com/bfs/openplatform/739fc29e74f303da58a471285da004af7e9ca6dd.png" alt="image-20250716143401092"></p><h3 id="员工工作日历变更"><a href="#员工工作日历变更" class="headerlink" title="员工工作日历变更"></a>员工工作日历变更</h3><h4 id="组织绑定工作日历"><a href="#组织绑定工作日历" class="headerlink" title="组织绑定工作日历"></a>组织绑定工作日历</h4><p><img src="https://i0.hdslb.com/bfs/openplatform/3c6a0d7a66d3aac073c529851903a18791b9f1e8.png" alt="image-20250716162159584"></p><h4 id="入职-异动刷新员工考勤日历逻辑"><a href="#入职-异动刷新员工考勤日历逻辑" class="headerlink" title="入职&#x2F;异动刷新员工考勤日历逻辑"></a>入职&#x2F;异动刷新员工考勤日历逻辑</h4><p><strong>组织与日历绑定关系</strong></p><ul><li>组织1 （2024-01-01 日历A），（2024-01-25 日历B）<br>组织1组 （2024-01-30 日历C），（2024-05-02 日历D）</li><li>组织2 （2024-01-01 日历E）<br>组织2组</li><li>组织3 （2024-01-01 日历F）<br>组织3组</li></ul><p><strong>员工异动流程</strong></p><p>在2024-01-01号入职组织2组<br>在2024-01-20号从组织2组异动至组织1组<br>在2024-05-01号从组织1组异动至组织3组</p><p>组织2组：[2024-01-01,2024-01-20]<br>组织1组：[2024-01-20,2024-05-01] 异动时间段<br>组织3组：[2024-05-01,9999-12-31]<br>异动时间段需生成的考勤日历：20号，25号，30号共三条</p><p><strong>获取组织1组及上级所有考勤日历</strong></p><p>倒序排序（2024-05-02，2024-01-30，2024-01-25，2024-01-01）</p><p>如此以下遍历员工所在的各个组织比较…</p><p><img src="https://i0.hdslb.com/bfs/openplatform/477a1f0b5e395c27f8a9bdbf5ecfa602308faccb.png" alt="image-20250716151015869"></p><h1 id="6生成员工补卡余额"><a href="#6生成员工补卡余额" class="headerlink" title="6生成员工补卡余额"></a>6生成员工补卡余额</h1><p>每个月会给员工生成补卡余额，定时任务会每天更新该员工的补卡余额。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b1c9ddc3793b9a9a27a9e0060dc7f342f98f1fb0.png" alt="image-20250716164814345"></p><h1 id="7加班审核"><a href="#7加班审核" class="headerlink" title="7加班审核"></a>7加班审核</h1><p><img src="https://i0.hdslb.com/bfs/openplatform/8c9c198048126f68657611239069028322fdb0d1.png" alt="image-20250716175428067"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1自动生成年假&quot;&gt;&lt;a href=&quot;#1自动生成年假&quot; class=&quot;headerlink&quot; title=&quot;1自动生成年假&quot;&gt;&lt;/a&gt;1自动生成年假&lt;/h1&gt;&lt;h2 id=&quot;1-1基本业务场景&quot;&gt;&lt;a href=&quot;#1-1基本业务场景&quot; class=&quot;header</summary>
      
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/categories/%E5%9C%BA%E6%99%AF/"/>
    
    
    <category term="业务" scheme="https://palette-k.github.io/tags/%E4%B8%9A%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes</title>
    <link href="https://palette-k.github.io/2025/07/09/kubernetes/"/>
    <id>https://palette-k.github.io/2025/07/09/kubernetes/</id>
    <published>2025-07-09T08:43:45.000Z</published>
    <updated>2025-10-13T03:31:48.220Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>虽然容器技术开启了云原生时代，但它也只走出了一小步，再继续前进就无能为力了，因为这已经不再是隔离一两个进程的普通问题，而是要隔离数不清的进程，还有它们之间互相通信、互相协作的超级问题，困难程度可以说是指数级别的上升。</p><p>这些容器之上的管理、调度工作，就是这些年最流行的词汇：“<strong>容器编排</strong>”（Container Orchestration）。</p><p>面对单机上的几个容器，“人肉”编排调度还可以应付，但如果规模上到几百台服务器、成千上万的容器，处理它们之间的复杂联系就必须要依靠计算机了，而目前计算机用来调度管理的“事实标准”，就是：Kubernetes。</p><p>Kubernetes就是一个<strong>生产级别的容器编排平台和集群管理系统</strong>，不仅能够创建、调度容器，还能够监控、管理服务器。</p><h1 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h1><p><img src="https://i0.hdslb.com/bfs/openplatform/79bb57777a6a9f4496d72b0b436a15e1039038c9.png" alt="image-20250709171226550"></p><p>Kubernetes采用了现今流行的“<strong>控制面&#x2F;数据面</strong>”（Control Plane &#x2F; Data Plane）架构，集群里的计算机被称为“<strong>节点</strong>”（Node），可以是实机也可以是虚机，少量的节点用作控制面来执行集群的管理维护工作，其他的大部分节点都被划归数据面，用来跑业务应用。</p><p>控制面的节点在Kubernetes里叫做<strong>Master Node</strong>，一般简称为<strong>Master</strong>，它是整个集群里最重要的部分，可以说是Kubernetes的大脑和心脏。</p><p>数据面的节点叫做<strong>Worker Node</strong>，一般就简称为<strong>Worker</strong>或者<strong>Node</strong>，相当于Kubernetes的手和脚，在Master的指挥下干活。</p><p>Node的数量非常多，构成了一个资源池，Kubernetes就在这个池里分配资源，调度应用。因为资源被“池化”了，所以管理也就变得比较简单，可以在集群中任意添加或者删除节点。</p><p>在这张架构图里，我们还可以看到有一个kubectl，它就是Kubernetes的客户端工具，用来操作Kubernetes，但它位于集群之外，理论上不属于集群。</p><p>你可以使用命令 <code>kubectl get node</code> 来查看Kubernetes的节点状态：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/openplatform/dfd4a2527bef0983fad179df40bc3b305de1a6e5.png" alt="image-20250709171414500"></p><h2 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h2><p>Master里有4个组件，分别是<strong>apiserver</strong>、<strong>etcd</strong>、<strong>scheduler</strong>、<strong>controller-manager</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2d59b019a9e9faeaa05cbba7953a42212b505735.png" alt="image-20250710101927564"></p><p>apiserver是Master节点——同时也是整个Kubernetes系统的唯一入口，它对外公开了一系列的RESTful API，并且加上了验证、授权等功能，所有其他组件都只能和它直接通信，可以说是Kubernetes里的联络员。</p><p>etcd是一个高可用的分布式Key-Value数据库，用来持久化存储系统里的各种资源对象和状态，相当于Kubernetes里的配置管理员。注意它只与apiserver有直接联系，也就是说任何其他组件想要读写etcd里的数据都必须经过apiserver。</p><p>scheduler负责容器的编排工作，检查节点的资源状态，把Pod调度到最适合的节点上运行，相当于部署人员。因为节点状态和Pod信息都存储在etcd里，所以scheduler必须通过apiserver才能获得。</p><p>controller-manager负责维护容器和节点等资源的状态，实现故障检测、服务迁移、应用伸缩等功能，相当于监控运维人员。同样地，它也必须通过apiserver获得存储在etcd里的信息，才能够实现对资源的各种操作。</p><p>这4个组件也都被容器化了，运行在集群的Pod里，我们可以用kubectl来查看它们的状态，使用命令：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod <span class="literal">-n</span> kube<span class="literal">-system</span></span><br></pre></td></tr></table></figure><h2 id="Worker-Node"><a href="#Worker-Node" class="headerlink" title="Worker Node"></a>Worker Node</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/2d76640bd8013f0ed5517cf78e154cdfb0646e75.png" alt="image-20250710102645156"></p><p>kubelet是Node的代理，负责管理Node相关的绝大部分操作，Node上只有它能够与apiserver通信，实现状态报告、命令下发、启停容器等功能，相当于是Node上的一个“小管家”。</p><p>kube-proxy的作用有点特别，它是Node的网络代理，只负责管理容器的网络通信，简单来说就是为Pod转发TCP&#x2F;UDP数据包，相当于是专职的“小邮差”。</p><p>第三个组件container-runtime我们就比较熟悉了，它是容器和镜像的实际使用者，在kubelet的指挥下创建容器，管理Pod的生命周期，是真正干活的“苦力”。</p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>现在，我们再把Node里的组件和Master里的组件放在一起来看，就能够明白Kubernetes的大致工作流程了：</p><ul><li>每个Node上的kubelet会定期向apiserver上报节点状态，apiserver再存到etcd里。</li><li>每个Node上的kube-proxy实现了TCP&#x2F;UDP反向代理，让容器对外提供稳定的服务。</li><li>scheduler通过apiserver得到当前的节点状态，调度Pod，然后apiserver下发命令给某个Node的kubelet，kubelet调用container-runtime启动容器。</li><li>controller-manager也通过apiserver得到实时的节点状态，监控可能的异常情况，再使用相应的手段去调节恢复。</li></ul><h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><p>Docker Desktop 自带了 Kubernetes 支持，可以通过 Docker Desktop 的应用程序界面开启 Kubernetes 集群。</p><p>而且Docker Desktop 启动 Kubernetes 后，会自动配置 kubectl 命令行工具，便于我们日常学习，减少安装成本。</p><h2 id="Kuboard"><a href="#Kuboard" class="headerlink" title="Kuboard"></a>Kuboard</h2><p>Kuboard 是一款免费的 Kubernetes 管理工具，旨在帮助用户快速在 Kubernetes 上落地微服务。它提供了丰富的功能，包括但不限于 Kubernetes 基本管理功能、节点管理、名称空间管理、存储类&#x2F;存储卷管理、控制器管理、Service&#x2F;Ingress 管理、ConfigMap&#x2F;Secret 管理、CustomerResourceDefinition 管理、问题诊断、容器日志及终端、认证与授权、CI&#x2F;CD集成等。</p><p>拉取镜像：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull eipwork/kuboard:v3</span><br></pre></td></tr></table></figure><p>运行命令(挂载的路径需要更改)：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run <span class="literal">-d</span> <span class="literal">--name</span>=kuboard <span class="literal">-p</span> <span class="number">8089</span>:<span class="number">80</span>/tcp <span class="literal">-p</span> <span class="number">10081</span>:<span class="number">10081</span>/tcp <span class="literal">-e</span> KUBOARD_ENDPOINT=<span class="string">&quot;http://192.168.3.220:8089&quot;</span> <span class="literal">-e</span> KUBOARD_AGENT_SERVER_TCP_PORT=<span class="string">&quot;10081&quot;</span> <span class="literal">-v</span> F:\docker\wsl\DockerDesktopWSL\mount\k8s eipwork/kuboard:v3</span><br></pre></td></tr></table></figure><p>访问 Kuboard：</p><p>地址： <a href="http://127.0.0.1:8089/">http://127.0.0.1:8089/</a></p><p>账号：admin</p><p>密码：Kuboard123</p><p>登录进去后，<strong>添加 Kubernetes 集群到 Kuboard</strong></p><p>![image-20250709172637479](<a href="https://i0.hdslb.com/bfs/openplatform/60c473e12d77b12fd152e25a23d26125f3574ac3.png">https://i0.hdslb.com/bfs/openplatform/60c473e12d77b12fd152e25a23d26125f3574ac3.png</a></p><p><img src="https://i0.hdslb.com/bfs/openplatform/69a5b05ea94f6a685f67b5b03b86d009957df83c.png" alt="image-20250709175827891"></p><p>按照以下步骤执行：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/7186fb0f2c24d373756ddafcc9ee8150aa7aa6a5.png" alt="image-20250709180129062"></p><p><strong>导入Kuboard</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> curl.exe <span class="literal">-k</span> <span class="string">&#x27;http://192.168.3.220:8089/kuboard-api/cluster/Ashley-k8s/kind/KubernetesCluster/Ashley-k8s/resource/installAgentToKubernetes?token=wfzV3KBKl48kGMr6lO6CQ2lIrDGdNj5j&#x27;</span> <span class="literal">-o</span> kuboard<span class="literal">-agent</span>.yaml</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line"><span class="number">100</span>  <span class="number">5611</span>    <span class="number">0</span>  <span class="number">5611</span>    <span class="number">0</span>     <span class="number">0</span>   <span class="number">314</span>k      <span class="number">0</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span>  <span class="number">322</span>k</span><br></pre></td></tr></table></figure><p>导入之前先要执行以下两个命令</p><p>获取当前 Kubernetes 集群中的所有 <code>Pod</code></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl get pods</span><br><span class="line">No resources found <span class="keyword">in</span> default namespace.</span><br></pre></td></tr></table></figure><p>显示当前 Kubernetes 配置中所有上下文</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl config <span class="built_in">get-contexts</span></span><br><span class="line">CURRENT   NAME             CLUSTER          AUTHINFO         NAMESPACE</span><br><span class="line">*         docker<span class="literal">-desktop</span>   docker<span class="literal">-desktop</span>   docker<span class="literal">-desktop</span></span><br></pre></td></tr></table></figure><p>切换 <code>kubectl</code> 操作的上下文到名为 <code>docker-desktop</code> 的上下文</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl config <span class="built_in">use-context</span> docker<span class="literal">-desktop</span></span><br><span class="line">Switched to context <span class="string">&quot;docker-desktop&quot;</span>.</span><br></pre></td></tr></table></figure><p>获取（列出）当前 Kubernetes 集群中的所有节点（Node）的信息</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl get nodes</span><br><span class="line">NAME             STATUS   ROLES           AGE   VERSION</span><br><span class="line">docker<span class="literal">-desktop</span>   Ready    control<span class="literal">-plane</span>   <span class="number">26</span>m   v1.<span class="number">28.2</span></span><br></pre></td></tr></table></figure><p>将本地文件 <code>.\kuboard-agent.yaml</code> 中定义的 <code>Kubernetes</code> 资源对象应用到 <code>Kubernetes</code> 集群中。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl apply <span class="operator">-f</span> ./kuboard<span class="literal">-agent</span>.yaml</span><br><span class="line">namespace/kuboard unchanged</span><br><span class="line">serviceaccount/kuboard<span class="literal">-admin</span> unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard<span class="literal">-admin-crb</span> unchanged</span><br><span class="line">serviceaccount/kuboard<span class="literal">-viewer</span> unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard<span class="literal">-viewer-crb</span> unchanged</span><br><span class="line">deployment.apps/kuboard<span class="literal">-agent-ashley</span> created</span><br><span class="line">deployment.apps/kuboard<span class="literal">-agent-ashley-2</span> created</span><br></pre></td></tr></table></figure><p>导入成功！</p><p><img src="https://i0.hdslb.com/bfs/openplatform/70902d2bfdd82244b17079d484f06c07c6a5290f.png" alt="image-20250709180841125"></p><h1 id="API对象"><a href="#API对象" class="headerlink" title="API对象"></a>API对象</h1><h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>Pod是对容器的“打包”，里面的容器是一个整体，总是能够一起调度、一起运行，绝不会出现分离的情况，而且Pod属于Kubernetes，可以在不触碰下层容器的情况下任意定制修改。</p><p>Kubernetes让Pod去编排处理容器，然后把Pod作为应用调度部署的<strong>最小单位</strong>，Pod也因此成为了Kubernetes世界里的“原子”（当然这个“原子”内部是有结构的，不是铁板一块），基于Pod就可以构建出更多更复杂的业务形态了。</p><h2 id="Job-CronJob"><a href="#Job-CronJob" class="headerlink" title="Job&#x2F;CronJob"></a>Job&#x2F;CronJob</h2><p>Kubernetes里有两大类业务。一类是像Nginx这样长时间运行的“<strong>在线业务</strong>”，另一类是像busybox这样短时间运行的“<strong>离线业务</strong>”。</p><p>“在线业务”类型的应用有很多，比如Nginx、Node.js、MySQL、Redis等等，一旦运行起来基本上不会停，也就是永远在线。</p><p>而“离线业务”类型的应用也并不少见，它们一般不直接服务于外部用户，只对内部用户有意义，比如日志分析、数据建模、视频转码等等，虽然计算量很大，但只会运行一段时间。“离线业务”的特点是<strong>必定会退出</strong>，不会无期限地运行下去，所以它的调度策略也就与“在线业务”存在很大的不同，需要考虑运行超时、状态检查、失败重试、获取计算结果等管理事项。</p><p>而这些业务特性与容器管理没有必然的联系，如果由Pod来实现就会承担不必要的义务，违反了“单一职责”，所以我们应该把这部分功能分离到另外一个对象上实现，让这个对象去控制Pod的运行，完成附加的工作。</p><p>“离线业务”也可以分为两种。一种是“<strong>临时任务</strong>”，跑完就完事了，下次有需求了说一声再重新安排；另一种是“<strong>定时任务</strong>”，可以按时按点周期运行，不需要过多干预。</p><p>对应到Kubernetes里，“临时任务”就是API对象<strong>Job</strong>，“定时任务”就是API对象<strong>CronJob</strong>，使用这两个对象你就能够在Kubernetes里调度管理任意的离线业务了。</p><p>可以看到，Job对象里应用了组合模式，<code>template</code> 字段定义了一个“<strong>应用模板</strong>”，里面嵌入了一个Pod，这样Job就可以从这个模板来创建出Pod。而这个Pod因为受Job的管理控制，不直接和apiserver打交道，也就没必要重复apiVersion等“头字段”，只需要定义好关键的 <code>spec</code>，描述清楚容器相关的信息就可以了，可以说是一个“无头”的Pod对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c0824e862bf99bc953f78ffe2f66d9503bee7086.png" alt="image-20250710111135700"></p><p>而定时任务”的CronJob对象也很好理解了，使用schedule指定了执行周期，又组合了Job而生成的新对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b1bcabe3ca8354818e418913c673451e73d8a837.png" alt="image-20250710111413288"></p><p>CronJob使用定时规则控制Job，Job使用并发数量控制Pod，Pod再定义参数控制容器，容器再隔离控制进程，进程最终实现业务功能，层层递进的形式有点像设计模式里的Decorator（装饰模式），链条里的每个环节都各司其职，在Kubernetes的统一指挥下完成任务。</p><h2 id="Deployment：让应用永不宕机"><a href="#Deployment：让应用永不宕机" class="headerlink" title="Deployment：让应用永不宕机"></a>Deployment：让应用永不宕机</h2><p>在线业务远不是单纯启动一个Pod这么简单，还有多实例、高可用、版本更新等许多复杂的操作。比如最简单的多实例需求，为了提高系统的服务能力，应对突发的流量和压力，我们需要创建多个应用的副本，还要即时监控它们的状态。如果还是只使用Pod，那就会又走回手工管理的老路，没有利用好Kubernetes自动化运维的优势。</p><p>Deployment，就是用来管理Pod，实现在线业务应用的新API对象。</p><p> <code>replicas</code> 字段。它的含义比较简单明了，就是“副本数量”的意思，也就是说，指定要在Kubernetes集群里运行多少个Pod实例。</p><p>接下来Kubernetes还会持续地监控Pod的运行状态，万一有Pod发生意外消失了，数量不满足“期望状态”，它就会通过apiserver、scheduler等核心组件去选择新的节点，创建出新的Pod，直至数量与“期望状态”一致。</p><p> <code>selector</code>，它的作用是“筛选”出要被Deployment管理的Pod对象，下属字段“<strong>matchLabels</strong>”定义了Pod对象应该携带的label，它必须和“template”里Pod定义的“labels”完全相同，否则Deployment就会找不到要控制的Pod对象，apiserver也会告诉你YAML格式校验错误无法创建。</p><p>Kubernetes采用的是这种“贴标签”的方式，通过在API对象的“metadata”元信息里加各种标签（labels），我们就可以使用类似关系数据库里查询语句的方式，筛选出具有特定标识的那些对象。<strong>通过标签这种设计，Kubernetes就解除了Deployment和模板里Pod的强绑定，把组合关系变成了“弱引用”</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f50ba2a6e58009faefceefa1106ef497dc22df56.png" alt="image-20250710115117565"></p><p><strong>在Deployment部署成功之后，你还可以随时调整Pod的数量，实现所谓的“应用伸缩”</strong>。这项工作在Kubernetes出现之前对于运维来说是一件很困难的事情，而现在由于有了Deployment就变得轻而易举了。</p><h2 id="DaemonSet：节点的守护者"><a href="#DaemonSet：节点的守护者" class="headerlink" title="DaemonSet：节点的守护者"></a>DaemonSet：节点的守护者</h2><p>Deployment并不关心这些Pod会在集群的哪些节点上运行，<strong>在它看来，Pod的运行环境与功能是无关的，只要Pod的数量足够，应用程序应该会正常工作</strong>。</p><p>这个假设对于大多数业务来说是没问题的，比如Nginx、WordPress、MySQL，它们不需要知道集群、节点的细节信息，只要配置好环境变量和存储卷，在哪里“跑”都是一样的。</p><p>但是有一些业务比较特殊，它们不是完全独立于系统运行的，而是与主机存在“绑定”关系，必须要依附于节点才能产生价值，比如说：</p><ul><li>网络应用（如kube-proxy），必须每个节点都运行一个Pod，否则节点就无法加入Kubernetes网络。</li><li>监控应用（如Prometheus），必须每个节点都有一个Pod用来监控节点的状态，实时上报信息。</li><li>日志应用（如Fluentd），必须在每个节点上运行一个Pod，才能够搜集容器运行时产生的日志数据。</li><li>安全应用，同样的，每个节点都要有一个Pod来执行安全审计、入侵检查、漏洞扫描等工作。</li></ul><p>所以，Kubernetes就定义了新的API对象DaemonSet，它在形式上和Deployment类似，都是管理控制Pod，但管理调度策略却不同。DaemonSet的目标是在集群的每个节点上运行且仅运行一个Pod，就好像是为节点配上一只“看门狗”，忠实地“守护”着节点，这就是DaemonSet名字的由来。</p><p>DaemonSet仅仅是在Pod的部署调度策略上和Deployment不同，其他的都是相同的，某种程度上我们也可以把DaemonSet看做是Deployment的一个特例。</p><p>我还是把YAML描述文件画了一张图，好让你看清楚与Deployment的差异：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ed917d93f0354d88671162e734856f1f935a6229.png" alt="image-20250710141911055"></p><h1 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h1><p>首先你要知道，应用程序有很多类别的配置信息，但从数据安全的角度来看可以分成两类：</p><ul><li>一类是明文配置，也就是不保密，可以任意查询修改，比如服务端口、运行参数、文件路径等等。</li><li>另一类则是机密配置，由于涉及敏感信息需要保密，不能随便查看，比如密码、密钥、证书等等。</li></ul><p>这两类配置信息本质上都是字符串，只是由于安全性的原因，在存放和使用方面有些差异，所以Kubernetes也就定义了两个API对象，<strong>ConfigMap</strong>用来保存明文配置，<strong>Secret</strong>用来保存秘密配置。</p><p>因为ConfigMap和Secret只是一些存储在etcd里的字符串，所以如果想要在运行时产生效果，就必须要以某种方式“<strong>注入</strong>”到Pod里，让应用去读取。在这方面的处理上Kubernetes和Docker是一样的，也是两种途径：<strong>环境变量</strong>和<strong>加载文件</strong>。</p><h2 id="环境变量注入"><a href="#环境变量注入" class="headerlink" title="环境变量注入"></a>环境变量注入</h2><p>从这张图你就应该能够比较清楚地看出Pod与ConfigMap、Secret的“松耦合”关系，它们不是直接嵌套包含，而是使用“KeyRef”字段间接引用对象，这样，同一段配置信息就可以在不同的对象之间共享。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8e60029d79e1da7e50de61ed9749eeefe1da454e.png" alt="image-20250710113004281"></p><h2 id="文件加载注入"><a href="#文件加载注入" class="headerlink" title="文件加载注入"></a>文件加载注入</h2><p>Kubernetes为Pod定义了一个“<strong>Volume</strong>”的概念，可以翻译成是“存储卷”。如果把Pod理解成是一个虚拟机，那么Volume就相当于是虚拟机里的磁盘。</p><p>我们可以为Pod“挂载（mount）”多个Volume，里面存放供Pod访问的数据，这种方式有点类似 <code>docker run -v</code>，虽然用法复杂了一些，但功能也相应强大一些。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b7f9270835ea7ba5452a9515c7f37d34a0c1735c.png" alt="image-20250710113256011"></p><p>挂载Volume的方式和环境变量又不太相同。环境变量是直接引用了ConfigMap&#x2F;Secret，而Volume又多加了一个环节，需要先用Volume引用ConfigMap&#x2F;Secret，然后在容器里挂载Volume。</p><p>这种方式的好处在于：以Volume的概念统一抽象了所有的存储，不仅现在支持ConfigMap&#x2F;Secret，以后还能够支持临时卷、持久卷、动态卷、快照卷等许多形式的存储，扩展性非常好。</p><p>因为这种形式上的差异，以Volume的方式来使用ConfigMap&#x2F;Secret，就和环境变量不太一样。环境变量用法简单，更适合存放简短的字符串，而Volume更适合存放大数据量的配置文件，在Pod里加载成文件后让应用直接读取使用。</p><h1 id="Service：微服务架构的应对之道"><a href="#Service：微服务架构的应对之道" class="headerlink" title="Service：微服务架构的应对之道"></a>Service：微服务架构的应对之道</h1><p>在Kubernetes集群里Pod的生命周期是比较“短暂”的，虽然Deployment和DaemonSet可以维持Pod总体数量的稳定，但在运行过程中，难免会有Pod销毁又重建，这就会导致Pod集合处于动态的变化之中。</p><p>这种“动态稳定”对于现在流行的微服务架构来说是非常致命的，试想一下，后台Pod的IP地址老是变来变去，客户端该怎么访问呢？如果不处理好这个问题，Deployment和DaemonSet把Pod管理得再完善也是没有价值的。</p><p>其实，这个问题也并不是什么难事，业内早就有解决方案来针对这样“不稳定”的后端服务，那就是“<strong>负载均衡</strong>”，典型的应用有LVS、Nginx等等。它们在前端与后端之间加入了一个“中间层”，屏蔽后端的变化，为前端提供一个稳定的服务。</p><p>但LVS、Nginx毕竟不是云原生技术，所以Kubernetes就按照这个思路，定义了新的API对象：<strong>Service</strong>。</p><p>Kubernetes会给Service分配一个静态IP地址，然后它再去自动管理、维护后面动态变化的Pod集合，当客户端访问Service，它就根据某种策略，把流量转发给后面的某个Pod。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/516cf8ccd1a88d24082699e5e3c0c5b499b40e49.png" alt="image-20250710145331433"></p><p><code>selector</code> 和Deployment&#x2F;DaemonSet里的作用是一样的，用来过滤出要代理的那些Pod。因为我们指定要代理Deployment，所以Kubernetes就为我们自动填上了ngx-dep的标签，会选择这个Deployment对象部署的所有Pod。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e9e6e6f453efca2e173de96475441c69b13fb2ff.png" alt="image-20250710145555926"></p><p>Pod被Deployment对象管理，删除后会自动重建，而Service又会通过controller-manager实时监控Pod的变化情况，所以就会立即更新它代理的IP地址。</p><h2 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h2><p>Kubernetes有一个默认的名字空间，叫“<strong>default</strong>”，如果不显式指定，API对象都会在这个“default”名字空间里。而其他的名字空间都有各自的用途，比如“kube-system”就包含了apiserver、etcd等核心组件的Pod。</p><p>通常我们会使用namespce区分线上环境。</p><p>Service对象的域名完全形式是“<strong>对象.名字空间.svc.cluster.local</strong>”，但很多时候也可以省略后面的部分，直接写“<strong>对象.名字空间</strong>”甚至“<strong>对象名</strong>”就足够了，默认会使用对象所在的名字空间（比如这里就是default）。</p><p>我们不再关心Service对象的IP地址，只需要知道它的名字，就可以用DNS的方式去访问后端服务。</p><h1 id="Ingress：集群进出流量的总管"><a href="#Ingress：集群进出流量的总管" class="headerlink" title="Ingress：集群进出流量的总管"></a>Ingress：集群进出流量的总管</h1><p><strong>Ingress的意思是集群内外边界上的入口，它作为流量的总入口，统管集群的进出口数据</strong>，“扇入”“扇出”流量（也就是我们常说的“南北向”），让外部用户能够安全、顺畅、便捷地访问内部服务。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/fef1938ec77144482a19e396dc7dd2fd59235dcd.png" alt="image-20250710174017411"></p><p>再对比一下Service我们就能更透彻地理解Ingress。</p><p>Ingress可以说是在七层上另一种形式的Service，它同样会代理一些后端的Pod，也有一些路由规则来定义流量应该如何分配、转发，只不过这些规则都使用的是HTTP&#x2F;HTTPS协议。</p><p>你应该知道，Service本身是没有服务能力的，它只是一些iptables规则，<strong>真正配置、应用这些规则的实际上是节点里的kube-proxy组件</strong>。如果没有kube-proxy，Service定义得再完善也没有用。</p><p>同样的，Ingress也只是一些HTTP路由规则的集合，相当于一份静态的描述文件，真正要把这些规则在集群里实施运行，还需要有另外一个东西，这就是 <code>Ingress Controller</code>，它的作用就相当于Service的kube-proxy，能够读取、应用Ingress规则，处理、调度流量。</p><p>理来说，Kubernetes应该把Ingress Controller内置实现，作为基础设施的一部分，就像kube-proxy一样。</p><p><strong>不过Ingress Controller要做的事情太多，与上层业务联系太密切，所以Kubernetes把Ingress Controller的实现交给了社区</strong>，任何人都可以开发Ingress Controller，只要遵守Ingress规则就好。</p><p>这就造成了Ingress Controller“百花齐放”的盛况。</p><p>由于Ingress Controller把守了集群流量的关键入口，掌握了它就拥有了控制集群应用的“话语权”，所以众多公司纷纷入场，精心打造自己的Ingress Controller，意图在Kubernetes流量进出管理这个领域占有一席之地。</p><p>这些实现中最著名的，就是老牌的反向代理和负载均衡软件Nginx了。从Ingress Controller的描述上我们也可以看到，HTTP层面的流量管理、安全控制等功能其实就是经典的反向代理，而Nginx则是其中稳定性最好、性能最高的产品，所以它也理所当然成为了Kubernetes里应用得最广泛的Ingress Controller。</p><p>根据Docker Hub上的统计，<strong>Nginx公司的开发实现是下载量最多的Ingress Controller</strong>，所以我将以它为例，讲解Ingress和Ingress Controller的用法。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c4aab8c9306f5ef219e3edc97d4fb0a1774d7ba6.png" alt="image-20250710174349077"></p><h2 id="IngressClass"><a href="#IngressClass" class="headerlink" title="IngressClass"></a>IngressClass</h2><p>那么到现在，有了Ingress和Ingress Controller，我们是不是就可以完美地管理集群的进出流量了呢？</p><p>最初Kubernetes也是这么想的，一个集群里有一个Ingress Controller，再给它配上许多不同的Ingress规则，应该就可以解决请求的路由和分发问题了。</p><p>但随着Ingress在实践中的大量应用，很多用户发现这种用法会带来一些问题，比如：</p><ul><li>由于某些原因，项目组需要引入不同的Ingress Controller，但Kubernetes不允许这样做；</li><li>Ingress规则太多，都交给一个Ingress Controller处理会让它不堪重负；</li><li>多个Ingress对象没有很好的逻辑分组方式，管理和维护成本很高；</li><li>集群里有不同的租户，他们对Ingress的需求差异很大甚至有冲突，无法部署在同一个Ingress Controller上。</li></ul><p>所以，Kubernetes就又提出了一个 <code>Ingress Class</code> 的概念，让它插在Ingress和Ingress Controller中间，作为流量规则和控制器的协调人，解除了Ingress和Ingress Controller的强绑定关系。</p><p>现在，<strong>Kubernetes用户可以转向管理Ingress Class，用它来定义不同的业务逻辑分组，简化Ingress规则的复杂度</strong>。比如说，我们可以用Class A处理博客流量、Class B处理短视频流量、Class C处理购物流量。</p><p>有了Ingress Controller，这些API对象的关联就更复杂了，你可以用下面的这张图来看出它们是如何使用对象名字联系起来的：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/cb7dff89b0e7076adfc7a1e0b13c1ec3d535cd91.png" alt="image-20250710174938720"></p><h1 id="PersistentVolume：数据持久化"><a href="#PersistentVolume：数据持久化" class="headerlink" title="PersistentVolume：数据持久化"></a>PersistentVolume：数据持久化</h1><p>前面说到，pod是kubernetes中运行的最小单位，但是其中存在一个很严重的问题：Pod没有持久化功能，因为Pod里的容器是由镜像产生的，而镜像文件本身是只读的，进程要读写磁盘只能用一个临时的存储空间，一旦Pod销毁，临时存储也就会立即回收释放，数据也就丢失了。</p><p>为了保证即使Pod销毁后重建数据依然存在，我们就需要找出一个解决方案，让Pod用上真正的“虚拟盘”。Kubernetes延伸出了<strong>PersistentVolume</strong>对象，它专门用来表示持久存储设备。<strong>作为存储的抽象，PV实际上就是一些存储设备、文件系统</strong>，比如Ceph、GlusterFS、NFS，甚至是本地磁盘，管理它们已经超出了Kubernetes的能力范围，所以，一般会由系统管理员单独维护，然后再在Kubernetes里创建对应的PV。</p><p>要注意的是，PV属于集群的系统资源，是和Node平级的一种对象，Pod对它没有管理权，只有使用权。</p><h2 id="PersistentVolumeClaim"><a href="#PersistentVolumeClaim" class="headerlink" title="PersistentVolumeClaim"></a>PersistentVolumeClaim</h2><p>PersistentVolumeClaim，简称PVC，从名字上看比较好理解，就是用来向Kubernetes申请存储资源的。PVC是给Pod使用的对象，它相当于是Pod的代理，代表Pod向系统申请PV。一旦资源申请成功，Kubernetes就会把PV和PVC关联在一起，这个动作叫做“<strong>绑定</strong>”（bind）。</p><p>但是，系统里的存储资源非常多，如果要PVC去直接遍历查找合适的PV也很麻烦，所以就要用到StorageClass。</p><h2 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h2><p>StorageClass抽象了特定类型的存储系统（比如Ceph、NFS），在PVC和PV之间充当“协调人”的角色，帮助PVC找到合适的PV。也就是说它可以简化Pod挂载“虚拟盘”的过程，让Pod看不到PV的实现细节。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/cf9a383122edf826ccd7ece51440ae077ecab02e.png" alt="image-20250711153617343"></p><h1 id="StatefulSet：管理有状态的应用"><a href="#StatefulSet：管理有状态的应用" class="headerlink" title="StatefulSet：管理有状态的应用"></a>StatefulSet：管理有状态的应用</h1><p>用Deployment来保证高可用，用PersistentVolume来存储数据，确实可以部分达到管理“有状态应用”的目的。但“状态”不仅仅是数据持久化，在集群化、分布式的场景里，还有多实例的依赖关系、启动顺序和网络标识等问题需要解决，而这些问题恰恰是Deployment力所不及的。</p><p>因为只使用Deployment，多个实例之间是无关的，启动的顺序不固定，Pod的名字、IP地址、域名也都是完全随机的，这正是“无状态应用”的特点。</p><p>但对于“有状态应用”，多个实例之间可能存在依赖关系，比如master&#x2F;slave、active&#x2F;passive，需要依次启动才能保证应用正常运行，外界的客户端也可能要使用固定的网络标识来访问实例，而且这些信息还必须要保证在Pod重启后不变。</p><p>所以，Kubernetes就在Deployment的基础之上定义了一个新的API对象，名字也很好理解，就叫StatefulSet，专门用来管理有状态的应用。</p><p>前面提到，Service自己会有一个域名，格式是“<strong>对象名.名字空间</strong>”，每个Pod也会有一个域名，形式是“<strong>IP地址.名字空间</strong>”。但因为IP地址不稳定，所以Pod的域名并不实用，一般我们会使用稳定的Service域名。</p><p>当我们把Service对象应用于StatefulSet的时候，情况就不一样了。</p><p>Service发现这些Pod不是一般的应用，而是有状态应用，需要有稳定的网络标识，所以就会为Pod再多创建出一个新的域名，格式是“<strong>Pod名.服务名.名字空间.svc.cluster.local</strong>”。当然，这个域名也可以简写成“<strong>Pod名.服务名</strong>”。</p><p>显然，在StatefulSet里的这两个Pod都有了各自的域名，也就是稳定的网络标识。那么接下来，外部的客户端只要知道了StatefulSet对象，就可以用固定的编号去访问某个具体的实例了，虽然Pod的IP地址可能会变，但这个有编号的域名由Service对象维护，是稳定不变的。</p><h2 id="StatefulSet的数据持久化"><a href="#StatefulSet的数据持久化" class="headerlink" title="StatefulSet的数据持久化"></a>StatefulSet的数据持久化</h2><p>现在StatefulSet已经有了固定的名字、启动顺序和网络标识，只要再给它加上数据持久化功能，我们就可以实现对“有状态应用”的管理了。</p><p>不过，为了强调持久化存储与StatefulSet的一对一绑定关系，Kubernetes为StatefulSet专门定义了一个字段“<strong>volumeClaimTemplates</strong>”，直接把PVC定义嵌入StatefulSet的YAML文件里。这样能保证创建StatefulSet的同时，就会为每个Pod自动创建PVC，让StatefulSet的可用性更高。</p><h1 id="滚动更新：平滑的应用升降级"><a href="#滚动更新：平滑的应用升降级" class="headerlink" title="滚动更新：平滑的应用升降级"></a>滚动更新：平滑的应用升降级</h1><h2 id="应用升级"><a href="#应用升级" class="headerlink" title="应用升级"></a>应用升级</h2><p>在Kubernetes里，版本更新使用的不是API对象，而是两个命令：<code>kubectl apply</code> 和 <code>kubectl rollout</code>，当然它们也要搭配部署应用所需要的Deployment、DaemonSet等YAML文件。</p><p>Kubernetes里应用都是以Pod的形式运行的，而Pod通常又会被Deployment等对象来管理，<strong>所以应用的“版本更新”实际上更新的是整个Pod</strong>。</p><p>Pod是由YAML描述文件来确定的，更准确地说，是Deployment等对象里的字段 <code>template</code>。所以，<strong>在Kubernetes里应用的版本变化就是 <code>template</code> 里Pod的变化</strong>，哪怕 <code>template</code> 里只变动了一个字段，那也会形成一个新的版本，也算是版本变化。</p><p>Kubernetes不是把旧Pod全部销毁再一次性创建出新Pod，而是在逐个地创建新Pod，同时也在销毁旧Pod，保证系统里始终有足够数量的Pod在运行，不会有“空窗期”中断服务。</p><p>新Pod数量增加的过程有点像是“滚雪球”，从零开始，越滚越大，所以这就是所谓的“<strong>滚动更新</strong>”（rolling update）。</p><p>其实“滚动更新”就是由Deployment控制的两个同步进行的“应用伸缩”操作，老版本缩容到0，同时新版本扩容到指定值，是一个“此消彼长”的过程。</p><h2 id="应用回滚"><a href="#应用回滚" class="headerlink" title="应用回滚"></a>应用回滚</h2><p>对于更新后出现的问题，Kubernetes为我们提供了“后悔药”，也就是更新历史，你可以查看之前的每次更新记录，并且回退到任何位置，和我们开发常用的Git等版本控制软件非常类似。</p><p>如果想要回退到上一个版本，就可以使用命令 <code>kubectl rollout undo</code>，也可以加上参数 <code>--to-revision</code> 回退到任意一个历史版本。<code>kubectl rollout undo</code> 的操作过程其实和 <code>kubectl apply</code> 是一样的，执行的仍然是“滚动更新”，只不过使用的是旧版本Pod模板，把新版本Pod数量收缩到0，同时把老版本Pod扩展到指定值。</p><h1 id="应用保障：如何让Pod运行得更健康？"><a href="#应用保障：如何让Pod运行得更健康？" class="headerlink" title="应用保障：如何让Pod运行得更健康？"></a>应用保障：如何让Pod运行得更健康？</h1><h2 id="容器资源配额"><a href="#容器资源配额" class="headerlink" title="容器资源配额"></a>容器资源配额</h2><p>创建容器有三大隔离技术：namespace、cgroup、chroot。其中的namespace实现了独立的进程空间，cgroup的作用是管控CPU、内存，保证容器不会无节制地占用基础资源，进而影响到系统里的其他应用，chroot实现了独立的文件系统。</p><p>与PersistentVolumeClaim用法有些类似，就是容器需要先提出一个“书面申请”，Kubernetes再依据这个“申请”决定资源是否分配和如何分配。使用 <code>resources</code> 字段加上资源配额之后，Pod在Kubernetes里的运行就有了初步保障，Kubernetes会监控Pod的资源使用情况，让它既不会“饿死”也不会“撑死”。</p><p>Kubernetes会根据每个Pod声明的需求，像搭积木或者玩俄罗斯方块一样，把节点尽量“塞满”，充分利用每个节点的资源，让集群的效益最大化。</p><h2 id="容器状态探针"><a href="#容器状态探针" class="headerlink" title="容器状态探针"></a>容器状态探针</h2><p>一个程序即使正常启动了，它也有可能因为某些原因无法对外提供服务。其中最常见的情况就是运行时发生“死锁”或者“死循环”的故障，这个时候从外部来看进程一切都是正常的，但内部已经是一团糟了。</p><p>Kubernetes为检查应用状态定义了三种探针，它们分别对应容器不同的状态：</p><ul><li><strong>Startup</strong>，启动探针，用来检查应用是否已经启动成功，适合那些有大量初始化工作要做，启动很慢的应用。</li><li><strong>Liveness</strong>，存活探针，用来检查应用是否正常运行，是否存在死锁、死循环。</li><li><strong>Readiness</strong>，就绪探针，用来检查应用是否可以接收流量，是否能够对外提供服务。</li></ul><p>你需要注意这三种探针是递进的关系：应用程序先启动，加载完配置文件等基本的初始化数据就进入了Startup状态，之后如果没有什么异常就是Liveness存活状态，但可能有一些准备工作没有完成，还不一定能对外提供服务，只有到最后的Readiness状态才是一个容器最健康可用的状态。</p><p>那Kubernetes具体是如何使用状态和探针来管理容器的呢？</p><p>如果一个Pod里的容器配置了探针，<strong>Kubernetes在启动容器后就会不断地调用探针来检查容器的状态</strong>：</p><ul><li>如果Startup探针失败，Kubernetes会认为容器没有正常启动，就会尝试反复重启，当然其后面的Liveness探针和Readiness探针也不会启动。</li><li>如果Liveness探针失败，Kubernetes就会认为容器发生了异常，也会重启容器。</li><li>如果Readiness探针失败，Kubernetes会认为容器虽然在运行，但内部有错误，不能正常提供服务，就会把容器从Service对象的负载均衡集合中排除，不会给它分配流量。</li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/76404447854f331194c43631155b944c36c2d4e7.png" alt="image-20250711172041991"></p><h1 id="集群管理：如何用名字空间分隔系统资源？"><a href="#集群管理：如何用名字空间分隔系统资源？" class="headerlink" title="集群管理：如何用名字空间分隔系统资源？"></a>集群管理：如何用名字空间分隔系统资源？</h1><p>Kubernetes的名字空间并不是一个实体对象，只是一个逻辑上的概念。它可以把集群切分成一个个彼此独立的区域，然后我们把对象放到这些区域里，就实现了类似容器技术里namespace的隔离效果，应用只能在自己的名字空间里分配资源和运行，不会干扰到其他名字空间里的应用。</p><h2 id="资源配额"><a href="#资源配额" class="headerlink" title="资源配额"></a>资源配额</h2><p>有了名字空间，我们就可以像管理容器一样，给名字空间设定配额，把整个集群的计算资源分割成不同的大小，按需分配给团队或项目使用。</p><p>不过集群和单机不一样，除了限制最基本的CPU和内存，还必须限制各种对象的数量，否则对象之间也会互相挤占资源。</p><h2 id="默认资源配额"><a href="#默认资源配额" class="headerlink" title="默认资源配额"></a>默认资源配额</h2><p>学到这里估计你也发现了，在名字空间加上了资源配额限制之后，它会有一个合理但比较“烦人”的约束：要求所有在里面运行的Pod都必须用字段 <code>resources</code> 声明资源需求，否则就无法创建。</p><p>Kubernetes这样做的原因也很好理解，如果Pod里没有 <code>resources</code> 字段，就可以无限制地使用CPU和内存，这显然与名字空间的资源配额相冲突。<strong>为了保证名字空间的资源总量可管可控，Kubernetes就只能拒绝创建这样的Pod了。</strong></p><p>那么能不能让Kubernetes自动为Pod加上资源限制呢？也就是说给个默认值，这样就可以省去反复设置配额的烦心事。</p><p>这个时候就要用到一个<strong>很小但很有用的辅助对象了—— <code>LimitRange</code>，简称是 <code>limits</code>，它能为API对象添加默认的资源配额限制</strong>。</p><h1 id="系统监控：如何使用Metrics-Server和Prometheus？"><a href="#系统监控：如何使用Metrics-Server和Prometheus？" class="headerlink" title="系统监控：如何使用Metrics Server和Prometheus？"></a>系统监控：如何使用Metrics Server和Prometheus？</h1><p>希望给集群也安装上“检查探针”，观察到集群的资源利用率和其他指标，让集群的整体运行状况对我们“透明可见”，这样才能更准确更方便地做好集群的运维工作。</p><h2 id="Metrics-Server"><a href="#Metrics-Server" class="headerlink" title="Metrics Server"></a>Metrics Server</h2><p>Metrics Server是一个专门用来收集Kubernetes核心资源指标（metrics）的工具，它定时从所有节点的kubelet里采集信息，但是对集群的整体性能影响极小，每个节点只大约会占用1m的CPU和2MB的内存，所以性价比非常高。</p><p>它调用kubelet的API拿到节点和Pod的指标，再把这些信息交给apiserver，这样kubectl、HPA就可以利用apiserver来读取指标了：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a3506f759b38d478201c9ae99c841c0e5082fd54.png" alt="image-20250711172952961"></p><h2 id="HorizontalPodAutoscaler"><a href="#HorizontalPodAutoscaler" class="headerlink" title="HorizontalPodAutoscaler"></a>HorizontalPodAutoscaler</h2><p>有了Metrics Server，我们就可以轻松地查看集群的资源使用状况了，不过它另外一个更重要的功能是辅助实现应用的“<strong>水平自动伸缩</strong>”。</p><p>“<strong>HorizontalPodAutoscaler</strong>”，简称是“<strong>hpa</strong>”。顾名思义，它是专门用来自动伸缩Pod数量的对象，适用于Deployment和StatefulSet，但不能用于DaemonSet。</p><p>HorizontalPodAutoscaler的能力完全基于Metrics Server，它从Metrics Server获取当前应用的运行指标，主要是CPU使用率，再依据预定的策略增加或者减少Pod的数量。</p><p>因为Metrics Server大约每15秒采集一次数据，所以HorizontalPodAutoscaler的自动化扩容和缩容也是按照这个时间点来逐步处理的。</p><p>当它发现目标的CPU使用率超过了预定的5%后，就会以2的倍数开始扩容，一直到数量上限，然后持续监控一段时间，如果CPU使用率回落，就会再缩容到最小值。</p><h2 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h2><p>显然，有了Metrics Server和HorizontalPodAutoscaler的帮助，我们的应用管理工作又轻松了一些。不过，Metrics Server能够获取的指标还是太少了，只有CPU和内存，想要监控到更多更全面的应用运行状况，还得请出这方面的权威项目“<strong>Prometheus</strong>”。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/bacc77beade046913111576c813dbc1027ebdf7e.png" alt="image-20250711173914580"></p><p>Prometheus系统的核心是它的Server，里面有一个时序数据库TSDB，用来存储监控数据，另一个组件Retrieval使用拉取（Pull）的方式从各个目标收集数据，再通过HTTP Server把这些数据交给外界使用。</p><p>在Prometheus Server之外还有三个重要的组件：</p><ul><li>Push Gateway，用来适配一些特殊的监控目标，把默认的Pull模式转变为Push模式。</li><li>Alert Manager，告警中心，预先设定规则，发现问题时就通过邮件等方式告警。</li><li>Grafana是图形化界面，可以定制大量直观的监控仪表盘。</li></ul><h1 id="网络通信"><a href="#网络通信" class="headerlink" title="网络通信"></a>网络通信</h1><p>Kubernetes提出了一个自己的网络模型“<strong>IP-per-pod</strong>”，能够很好地适应集群系统的网络需求，它有下面的这4点基本假设：</p><ul><li>集群里的每个Pod都会有唯一的一个IP地址。</li><li>Pod里的所有容器共享这个IP地址。</li><li>集群里的所有Pod都属于同一个网段。</li><li>Pod直接可以基于IP地址直接访问另一个Pod，不需要做麻烦的网络地址转换（NAT）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;虽然容器技术开启了云原生时代，但它也只走出了一小步，再继续前进就无能为力了，因为这已经不再是隔离一两个进程的普通问题，而是要</summary>
      
    
    
    
    <category term="k8s" scheme="https://palette-k.github.io/categories/k8s/"/>
    
    
    <category term="k8s" scheme="https://palette-k.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>docker的使用技巧</title>
    <link href="https://palette-k.github.io/2025/07/09/docker%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    <id>https://palette-k.github.io/2025/07/09/docker%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</id>
    <published>2025-07-09T07:03:45.000Z</published>
    <updated>2025-10-13T03:32:08.931Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><p>镜像是容器的静态形式，它打包了应用程序的所有运行依赖项，方便保存和传输。使用容器技术运行镜像，就形成了动态的容器，由于镜像只读不可修改，所以应用程序的运行环境总是一致的。</p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><ol><li>容器就是操作系统里一个特殊的“沙盒”环境，里面运行的进程只能看到受限的信息，与外部系统实现了隔离。</li><li>容器隔离的目的是为了系统安全，限制了进程能够访问的各种资源。</li><li>相比虚拟机技术，容器更加轻巧、更加高效，消耗的系统资源非常少，在云计算时代极具优势。</li></ol><p>进入容器命令</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec <span class="literal">-it</span> <span class="number">062</span> sh</span><br></pre></td></tr></table></figure><h1 id="Docker-Desktop"><a href="#Docker-Desktop" class="headerlink" title="Docker Desktop"></a>Docker Desktop</h1><p>Docker Desktop 是<strong>容器化应用开发与部署的一体化工具</strong>，支持在本地环境创建、管理和运行Docker容器。</p><p>很多人以为，只要换了新电脑或者格式化电脑后，在docker desktop拉取的镜像、容器都会消失，现在我就来介绍一下将 Docker Desktop 的容器打包成镜像，上传到 docker hub 的方法，以后就可以像代码一样管理维护自己的docker镜像。</p><h2 id="Docker-Hub"><a href="#Docker-Hub" class="headerlink" title="Docker Hub"></a>Docker Hub</h2><p>在使用 <code>docker pull</code> 获取镜像的时候，我们并没有明确地指定镜像仓库。在这种情况下，Docker就会使用一个默认的镜像仓库，也就是大名鼎鼎的“<strong>Docker Hub</strong>”。</p><p>docker hub地址：<a href="https://hub.docker.com/repository/docker/wuziqing/planet/general">hub.docker.com</a></p><p>Docker Hub里面不仅有Docker自己打包的镜像，而且还对公众免费开放，任何人都可以上传自己的作品。经过这8年的发展，Docker Hub已经不再是一个单纯的镜像仓库了，更应该说是一个丰富而繁荣的容器社区。</p><p>如果想覆盖仓库中已有镜像，可以在本地重新构建镜像后，使用相同的标签推送镜像到仓库。</p><ol><li><p>docker hub 账号在本地验证登录</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login</span><br></pre></td></tr></table></figure></li><li><p>将容器commit成镜像</p></li></ol><p>docker tag <existing-image>  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></existing-image></p><p>   docker commit <existing-container>  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></existing-container></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit <span class="number">277</span>e80820516 hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure><ol start="3"><li><p>docker push 镜像到 docker hub 仓库</p><p>docker push  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure></li><li><p>验证</p><p>命令验证：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure><p>线上仓库验证：登录docker hub，刷新仓库页，查看是否推送成功。</p></li><li><p>拉取镜像到本地</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure></li></ol><h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><p>镜像就是一个打包文件，里面包含了应用程序还有它运行所依赖的环境，例如文件系统、环境变量、配置参数等等。</p><p>环境变量、配置参数这些东西还是比较简单的，随便用一个manifest清单就可以管理，真正麻烦的是文件系统。为了保证容器运行环境的一致性，镜像必须把应用程序所在操作系统的根目录，也就是rootfs，都包含进来。</p><p>由此引出容器镜像的一个重大创新点：分层，术语叫“<strong>Layer</strong>”。就是把重复的部分抽取出来，只存放一份Ubuntu根目录文件，然后让这一千个镜像以某种方式共享这部分数据。</p><p>Dockerfile非常普通，它就是一个纯文本，里面记录了一系列的构建指令，比如选择基础镜像、拷贝文件、运行脚本等等，每个指令都会生成一个Layer，而Docker顺序执行这个文件里的所有步骤，最后就会创建出一个新的镜像出来。</p><p>创建镜像命令：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build <span class="operator">-f</span> Dockerfile.busybox .</span><br></pre></td></tr></table></figure><h2 id="docker-build-是怎么工作的"><a href="#docker-build-是怎么工作的" class="headerlink" title="docker build 是怎么工作的"></a>docker build 是怎么工作的</h2><p>命令行“docker”是一个简单的客户端，真正的镜像构建工作是由服务器端的“Docker daemon”来完成的，所以“docker”客户端就只能把“构建上下文”目录打包上传（显示信息 <code>Sending build context to Docker daemon</code> ），这样服务器才能够获取本地的这些文件。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f631fc44deb0f0ccb46b3e68dcfbd2d123f4e13a.png" alt="image-20250709160506558"></p><h2 id="Dockerfile-编写规范"><a href="#Dockerfile-编写规范" class="headerlink" title="Dockerfile 编写规范"></a>Dockerfile 编写规范</h2><ol><li>创建镜像需要编写Dockerfile，写清楚创建镜像的步骤，每个指令都会生成一个Layer。</li><li>Dockerfile里，第一个指令必须是 <code>FROM</code>，用来选择基础镜像，常用的有Alpine、Ubuntu等。其他常用的指令有：<code>COPY</code>、<code>RUN</code>、<code>EXPOSE</code>，分别是拷贝文件，运行Shell命令，声明服务端口号。</li><li><code>docker build</code> 需要用 <code>-f</code> 来指定Dockerfile，如果不指定就使用当前目录下名字是“Dockerfile”的文件。</li><li><code>docker build</code> 需要指定“构建上下文”，其中的文件会打包上传到Docker daemon，所以尽量不要在“构建上下文”中存放多余的文件。</li><li>创建镜像的时候应当尽量使用 <code>-t</code> 参数，为镜像起一个有意义的名字，方便管理。</li></ol><h1 id="Docker-compose"><a href="#Docker-compose" class="headerlink" title="Docker-compose"></a>Docker-compose</h1><p>在Docker把容器技术大众化之后，Docker周边涌现出了数不胜数的扩展、增强产品，其中有一个名字叫“Fig”的小项目格外令人瞩目。</p><p>Fig为Docker引入了“容器编排”的概念，使用YAML来定义容器的启动参数、先后顺序和依赖关系，让用户不再有Docker冗长命令行的烦恼，第一次见识到了“声明式”的威力。因此，docker-compose自身的定位是管理和运行多个Docker容器的工具。</p><p>docker-compose里管理容器的核心概念是“<strong>service</strong>”。注意，它与Kubernetes里的 <code>Service</code> 虽然名字很像，但却是完全不同的东西。docker-compose里的“service”就是一个容器化的应用程序，通常是一个后台服务，用YAML定义这些容器的参数和相互之间的关系。</p><p>如果硬要和Kubernetes对比的话，和“service”最像的API对象应该算是Pod里的container了，同样是管理容器运行，但docker-compose的“service”又融合了一些Service、Deployment的特性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;镜像&quot;&gt;&lt;a href=&quot;#镜像&quot; class=&quot;headerlink&quot; title=&quot;镜像&quot;&gt;&lt;/a&gt;镜像&lt;/h</summary>
      
    
    
    
    <category term="Docker" scheme="https://palette-k.github.io/categories/Docker/"/>
    
    
    <category term="docker" scheme="https://palette-k.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Redis实战：场景设计</title>
    <link href="https://palette-k.github.io/2025/07/07/Redis%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    <id>https://palette-k.github.io/2025/07/07/Redis%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/</id>
    <published>2025-07-07T02:40:26.000Z</published>
    <updated>2025-10-13T03:33:44.420Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-热升级"><a href="#Redis-热升级" class="headerlink" title="Redis 热升级"></a>Redis 热升级</h1><p>对于线上较大流量的业务，单个 Redis 实例的内存占用很容易达到数 G 的容量，对应的 aof 会占用数十 G 的空间。即便每天流量低峰时间，对 Redis 进行 rewriteaof，减少数据冗余，但由于业务数据多，写操作多，aof 文件仍然会达到 10G 以上。</p><p>此时，在 Redis 需要升级版本或修复 bug 时，如果直接重启变更，由于需要数据恢复，这个过程需要近 10 分钟的时间，时间过长，会严重影响系统的可用性。</p><p>首先构建一个 Redis 壳程序，将 redisServer 的所有属性（包括redisDb、client等）保存为全局变量。然后将 Redis 的处理逻辑代码全部封装到动态连接库 so 文件中。Redis 第一次启动，从磁盘加载恢复数据，在后续升级时，通过指令，壳程序重新加载 Redis 新的 so 文件，即可完成功能升级，毫秒级完成 Redis 的版本升级。而且整个过程中，所有 Client 连接仍然保留，在升级成功后，原有 Client 可以继续进行读写操作，整个过程对业务完全透明。</p><h1 id="Redis-功能扩展"><a href="#Redis-功能扩展" class="headerlink" title="Redis 功能扩展"></a>Redis 功能扩展</h1><p>在 Redis 使用中，也经常会遇到一些特殊业务场景，是当前 Redis 的数据结构无法很好满足的。此时可以对 Redis 进行定制化扩展。可以根据业务数据特点，扩展新的数据结构，甚至扩展新的 Redis 存储模型，来提升 Redis 的内存效率和处理性能。</p><p>在微博中，有个业务类型是关注列表。关注列表存储的是一个用户所有关注的用户 uid。关注列表可以用来验证关注关系，也可以用关注列表，进一步获取所有关注人的微博列表等。由于用户数量过于庞大，存储关注列表的 Redis 是作为一个缓存使用的，即不活跃的关注列表会很快被踢出 Redis。在再次需要这个用户的关注列表时，重新从 DB 加载，并写回 Redis。关注列表的元素全部 long，最初使用 set 存储，回种 set 时，使用 sadd 进行批量添加。线上发现，对于关注数比较多的关注列表，比如关注数有数千上万个用户，需要 sadd 上成千上万个 uid，即便分几次进行批量添加，每次也会消耗较多时间，数据回种效率较低，而且会导致 Redis 卡顿。另外，用 set 存关注列表，内存效率也比较低。</p><p>于是，我们对 Redis 扩展了 longset 数据结构。longset 本质上是一个 long 型的一维开放数组。可以采用 double-hash 进行寻址。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f8431237bd0f6b0a50fdcd1d1807a555e2786814.png" alt="image-20250709141345697"></p><p>从 DB 加载到用户的关注列表，准备写入 Redis 前。Client 首先根据关注的 uid 列表，构建成 long 数组的二进制格式，然后通过扩展的 lsset 指令写入 Redis。</p><p>longset 中的 long 数组，采用 double-hash 进行寻址，即对每个 long 值采用 2 个哈希函数计算，然后按 (h1 + n*h2)% 数组长度 的方式，确定 long 值的位置。n 从 0 开始计算，如果出现哈希冲突，即计算的哈希位置，已经有其他元素，则 n 加 1，继续向前推进计算，最大计算次数是数组的长度。</p><p>在向 longset 数据结构不断增加 long 值元素的过程中，当数组的填充率超过阀值，Redis 则返回 longset 过满的异常。此时 Client 会根据最新全量数据，构建一个容量加倍的一维 long 数组，再次 lsset 回 Redis 中。</p><h2 id="完全增量复制"><a href="#完全增量复制" class="headerlink" title="完全增量复制"></a>完全增量复制</h2><p>微博整合 Redis 的 rdb 和 aof 策略，构建了完全增量复制方案。</p><p>在完全增量方案中，aof 文件不再只有一个，而是按后缀 id 进行递增，如 aof.00001、aof.00002，当 aof 文件超过阀值，则创建下一个 id 加 1 的文件，从而滚动存储最新的写指令。在 bgsave 构建 rdb 时，rdb 文件除了记录当前的内存数据快照，还会记录 rdb 构建时间，对应 aof 文件的 id 及位置。这样 rdb 文件和其记录 aof 文件位置之后的写指令，就构成一份完整的最新数据记录。</p><p>主从复制时，master 通过独立的复制线程向 slave 同步数据。每个 slave 会创建一个复制线程。第一次复制是全量复制，之后的复制，不管 slave 断开复制连接有多久，只要 aof 文件没有被删除，都是增量复制。</p><p>第一次全量复制时，复制线程首先将 rdb 发给 slave，然后再将 rdb 记录的 aof 文件位置之后的所有数据，也发送给 slave，即可完成。整个过程不用重新构建 rdb。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/14de3f441fc9bb6f9c597c228c18c7e02b4fa8db.png" alt="image-20250709141402578"></p><p>后续同步时，slave 首先传递之前复制的 aof 文件的 id 及位置。master 的复制线程根据这个信息，读取对应 aof 文件位置之后的所有内容，发送给 slave，即可完成数据同步。</p><p>由于整个复制过程，master 在独立复制线程中进行，所以复制过程不影响用户的正常请求。为了减轻 master 的复制压力，全增量复制方案仍然支持 slave 嵌套，即可以在 slave 后继续挂载多个 slave，从而把复制压力分散到多个不同的 Redis 实例。</p><h1 id="如何为秒杀系统设计缓存体系"><a href="#如何为秒杀系统设计缓存体系" class="headerlink" title="如何为秒杀系统设计缓存体系"></a>如何为秒杀系统设计缓存体系</h1><p>在设计秒杀系统时，有两个设计原则。</p><p>首先，要尽力将请求拦截在系统上游，层层设阻拦截，过滤掉无效或超量的请求。因为访问量远远大于商品数量，所有的请求打到后端服务的最后一步，其实并没有必要，反而会严重拖慢真正能成交的请求，降低用户体验。</p><p>其次，要充分利用缓存，提升系统的性能和可用性。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0247772e6c2f55ffc860328565ffef5bff57208f.png" alt="image-20250709141433518"></p><p>秒杀系统专为秒杀活动服务，售卖商品确定，因此可以在设计秒杀商品页面时，将商品信息提前设计为静态信息，将静态的商品信息以及常规的 CSS、JS、宣传图片等静态资源，一起独立存放到 CDN 节点，加速访问，且降低系统访问压力。</p><p>在访问前端也可以制定种种限制策略，比如活动没开始时，抢购按钮置灰，避免抢先访问，用户抢购一次后，也将按钮置灰，让用户排队等待，避免反复刷新。</p><p>用户所有的请求进入秒杀系统前，通过负载均衡策略均匀分发到不同 Web 服务器，避免节点过载。在 Web 服务器中，首先进行各种服务预处理，检查用户的访问权限，识别并发刷订单的行为。同时在真正服务前，也要进行服务前置检查，避免超售发生。如果发现售出数量已经达到秒杀数量，则直接返回结束。</p><p>秒杀系统在处理抢购业务逻辑时，除了对用户进行权限校验，还需要访问商品服务，对库存进行修改，访问订单服务进行订单创建，最后再进行支付、物流等后续服务。这些依赖服务，可以专门为秒杀业务设计排队策略，或者额外部署实例，对秒杀系统进行专门服务，避免影响其他常规业务系统。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1366a88cadb61bd665fb9cffdb884430bed63509.png" alt="image-20250709141443825"></p><p>由于秒杀的参与者远大于商品数，为了提高抢购的概率，时常会出现一些利用脚本和僵尸账户并发频繁调用接口进行强刷的行为，秒杀系统需要构建访问记录缓存，记录访问 IP、用户的访问行为，发现异常访问，提前进行阻断及返回。同时还需要构建用户缓存，并针对历史数据分析，提前缓存僵尸强刷专业户，方便在秒杀期间对其进行策略限制。这些访问记录、用户数据，通过缓存进行存储，可以加速访问，另外，对用户数据还进行缓存预热，避免活动期间大量穿透。</p><p>在业务请求处理时，所有操作尽可能由缓存交互完成。由于秒杀商品较少，相关信息全部加载到内存，把缓存暂时当作存储用，并不会带来过大成本负担。</p><p>为秒杀商品构建商品信息缓存，并对全部目标商品进行预热加载。同时对秒杀商品构建独立的库存缓存，加速库存检测。这样通过秒杀商品列表缓存，进行快速商品信息查询，通过库存缓存，可以快速确定秒杀活动进程，方便高效成交或无可售商品后的快速检测及返回。在用户抢购到商品后，要进行库存事务变更，进行库存、订单、支付等相关的构建和修改，这些操作可以尽量由系统只与缓存组件交互完成初步处理。后续落地等操作，必须要入DB库的操作，可以先利用消息队列机，记录成交事件信息，然后再逐步分批执行，避免对 DB 造成过大压力。</p><p>总之，在秒杀系统中，除了常规的分拆访问内容和服务，最重要的是尽量将所有数据访问进行缓存化，尽量减少 DB 的访问，在大幅提升系统性能的同时，提升用户体验。</p><h1 id="如何为海量计数场景设计缓存体系"><a href="#如何为海量计数场景设计缓存体系" class="headerlink" title="如何为海量计数场景设计缓存体系"></a>如何为海量计数场景设计缓存体系</h1><h2 id="计数常规方案"><a href="#计数常规方案" class="headerlink" title="计数常规方案"></a>计数常规方案</h2><p>计数服务在互联网系统中非常常见，用户的关注粉丝数、帖子数、评论数等都需要进行计数存储。计数的存储格式也很简单，key 一般是用户 uid 或者帖子 id 加上后缀，value 一般是 8 字节的 long 型整数。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/302df249ad520edfdd0d51b42abe7f69b0bda7bc.png" alt="image-20250709141501087"></p><p>最常见的计数方案是采用缓存 + DB 的存储方案。当计数变更时，先变更计数 DB，计数加 1，然后再变更计数缓存，修改计数存储的 Memcached 或 Redis。这种方案比较通用且成熟，但在高并发访问场景，支持不够友好。在互联网社交系统中，有些业务的计数变更特别频繁，比如微博 feed 的阅读数，计数的变更次数和访问次数相当，每秒十万到百万级以上的更新量，如果用 DB 存储，会给 DB 带来巨大的压力，DB 就会成为整个计数服务的瓶颈所在。即便采用聚合延迟更新 DB 的方案，由于总量特别大，同时请求均衡分散在大量不同的业务端，巨大的写压力仍然是 DB 的不可承受之重。因此这种方案只适合中小规模的计数服务使用。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d8fdb89f1386e9102e52a06292f559feea9eb23f.png" alt="image-20250709141514173"></p><p>在 Redis 问世并越来越成熟后，很多互联网系统会直接把计数全部存储在 Redis 中。通过 hash 分拆的方式，可以大幅提升计数服务在 Redis 集群的写性能，通过主从复制，在 master 后挂载多个从库，利用读写分离，可以大幅提升计数服务在 Redis 集群的读性能。而且 Redis 有持久化机制，不会丢数据，在很多大中型互联网场景，这都是一个比较适合的计数服务方案。</p><p>在互联网移动社交领域，由于用户基数巨大，每日发表大量状态数据，且相互之间有大量的交互动作，从而产生了海量计数和超高并发访问，如果直接用 Redis 进行存储，会带来巨大的成本和性能问题。</p><h2 id="海量计数场景"><a href="#海量计数场景" class="headerlink" title="海量计数场景"></a>海量计数场景</h2><p>以微博为例，系统内有大量的待计数对象。如从用户维度，日活跃用户 2 亿+，月活跃用户接近 5 亿。从 Feed 维度，微博历史 Feed 有数千亿条，而且每日新增数亿条的新 Feed。这些用户和 Feed 不但需要进行计数，而且需要进行多个计数。比如，用户维度，每个用户需要记录关注数、粉丝数、发表 Feed 数等。而从 Feed 维度，每条 Feed 需要记录转发数、评论数、赞、阅读等计数。</p><p>而且，在微博业务场景下，每次请求都会请求多个对象的多个计数。比如查看用户时，除了获取该用户的基本信息，还需要同时获取用户的关注数、粉丝数、发表 Feed 数。获取微博列表时，除了获取 Feed 内容，还需要同时获取 Feed 的转发数、评论数、赞数，以及阅读数。因此，微博计数服务的总访问量特别大，很容易达到百万级以上的 QPS。</p><p><strong>方案选择：</strong></p><p>因此，在海量计数高并发访问场景，如果采用缓存 + DB 的架构，首先 DB 在计数更新就会存在瓶颈，其次，单个请求一次请求数十个计数，一旦缓存 miss，穿透到 DB，DB 的读也会成为瓶颈。因为 DB 能支撑的 TPS 不过 3000~6000 之间，远远无法满足高并发计数访问场景的需要。</p><p>采用 Redis 全量存储方案，通过分片和主从复制，读写性能不会成为主要问题，但容量成本却会带来巨大开销。</p><p>因为，一方面 Redis 作为通用型存储来存储计数，<strong>内存存储效率低</strong>。以存储一个 key 为 long 型 id、value 为 4 字节的计数为例，Redis 至少需要 65 个字节左右，不同版本略有差异。但这个计数理论只需要占用 12 个字节即可。内存有效负荷只有 12⁄65&#x3D;18.5%。如果再考虑一个 long 型 id 需要存 4 个不同类型的 4 字节计数，内存有效负荷只有 (8+16)&#x2F;(65*4)&#x3D; 9.2%。</p><p>另一方面，Redis 所有数据均存在内存，单存储历史千亿级记录，单份数据拷贝需要 10T 以上，要考虑核心业务上 1 主 3 从，需要 40T 以上的内存，再考虑多 IDC 部署，<strong>轻松占用上百 T 内存</strong>。就按单机 100G 内存来算，计数服务就要占用上千台大内存服务器。存储成本太高。</p><h2 id="海量计数服务架构"><a href="#海量计数服务架构" class="headerlink" title="海量计数服务架构"></a>海量计数服务架构</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/0580bed1c59bb8eb3ad4c2035e37592012c8216c.png" alt="image-20250709141528777"></p><p>为了解决海量计数的存储及访问的问题，微博基于 Redis 定制开发了计数服务系统，该计数服务兼容 Redis 协议，将所有数据分别存储在内存和磁盘 2 个区域。首先，内存会预分配 N 块大小相同的 Table 空间，线上一般每个 Table 占用 1G 字节，最大分配 10 个左右的 Table 空间。首先使用 Table0，当存储填充率超过阀值，就使用 Table1，依次类推。每个 Table 中，key 是微博 id，value 是自定义的多个计数。</p><p>微博的 id 按时间递增，因此每个内存 Table 只用存储一定范围内的 id 即可。内存 Table 预先按设置分配为相同 size 大小的 key-value 槽空间。每插入一个新 key，就占用一个槽空间，当槽位填充率超过阀值，就滚动使用下一个 Table，当所有预分配的 Table 使用完毕，还可以根据配置，继续从内存分配更多新的 Table 空间。当内存占用达到阀值，就会把内存中 id 范围最小的 Table 落盘到 SSD 磁盘。落盘的 Table 文件称为 DDB。每个内存 Table 对应落盘为 1 个 DDB 文件。</p><p>计数服务会将落盘 DDB 文件的索引记录在内存，这样当查询需要从内存穿透到磁盘时，可以直接定位到磁盘文件，加快查询速度。</p><p>计数服务可以设置 Schema 策略，使一个 key 的 value 对应存储多个计数。每个计数占用空间根据 Schema 确定，可以精确到 bit。key 中的各个计数，设置了最大存储空间，所以只能支持有限范围内的计数。如果计数超过设置的阀值，则需要将这个 key 从 Table 中删除，转储到 aux dict 辅助词典中。</p><p>同时每个 Table 负责一定范围的 id，由于微博 id 随时间增长，而非逐一递增，Table 滚动是按照填充率达到阀值来进行的。当系统发生异常时，或者不同区域网络长时间断开重连后，在老数据修复期间，可能在之前的 Table 中插入较多的计数 key。如果旧 Table 插入数据量过大，超过容量限制，或者持续搜索存储位置而不得，查找次数超过阀值，则将新 key 插入到 extend dict 扩展词典中。</p><p>微博中的 feed 一般具有明显的冷热区分，并且越新的 feed 越热，访问量越大，越久远的 feed 越冷。新的热 key 存放内存 Table，老的冷 key 随所在的 Table 被置换到 DDB 文件。当查询 DDB 文件中的冷 key 时，会采用多线程异步并行查询，基本不影响业务的正常访问。同时，这些冷 key 从 DDB 中查询后，会被存放到 LRU 中，从而方便后续的再次访问。</p><p>计数服务的内存数据快照仍然采用前面讲的 RDB + 滚动 AOF 策略。RDB 记录构建时刻对应的 AOF 文件 id 及 pos 位置。全量复制时，master 会将磁盘中的 DDB 文件，以及内存数据快照对应的 RDB 和 AOF 全部传送给 slave。</p><p>在之后的所有复制就是全增量复制，slave 在断开连接，再次重连 master 时，汇报自己同步的 AOF 文件 id 及位置，master 将对应文件位置之后的内容全部发送给 slave，即可完成同步。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/02cf1e7531de2672ca7a37ed4776e0710bb09a9a.png" alt="image-20250709141539168"></p><p>计数服务中的内存 Table 是一个一维开放数据，每个 key-value 按照 Schema 策略占用相同的内存。每个 key-value 内部，key 和多个计数紧凑部署。首先 8 字节放置 long 型 key，然后按Schema 设置依次存放各个计数。</p><p>key 在插入及查询时，流程如下。</p><p>首先根据所有 Table 的 id 范围，确定 key 所在的内存 Table。</p><p>然后再根据 double-hash 算法计算 hash，用 2 个 hash 函数分别计算出 2 个 hash 值，采用公示 h1+N*h2 来定位查找。</p><p>在对计数插入或变更时，如果查询位置为空，则立即作为新值插入 key&#x2F;value，否则对比 key，如果 key 相同，则进行计数增减；如果 key 不同，则将 N 加 1，然后进入到下一个位置，继续进行前面的判断。如果查询的位置一直不为空，且 key 不同，则最多查询设置的阀值次数，如果仍然没查到，则不再进行查询。将该 key 记录到 extend dict 扩展词典中。</p><p>在对计数 key 查找时，如果查询的位置为空，说明 key 不存在，立即停止。如果 key 相同，返回计数，否则 N 加 1，继续向后查询，如果查询达到阀值次数，没有遇到空，且 key 不同，再查询 aux dict 辅助字典 和 extend dict 扩展字典，如果也没找到该 key，则说明该 key 不存在，即计数为 0。</p><h2 id="海量计数服务收益"><a href="#海量计数服务收益" class="headerlink" title="海量计数服务收益"></a>海量计数服务收益</h2><p>微博计数服务，多个计数按 Schema 进行紧凑存储，共享同一个 key，每个计数的 size 按 bit 设计大小，没有额外的指针开销，内存占用只有 Redis 的 10% 以下。同时，由于 key 的计数 size 固定，如果计数超过阀值，则独立存储 aux dict 辅助字典中。</p><p>同时由于一个 key 存储多个计数，同时这些计数一般都需要返回，这样一次查询即可同时获取多个计数，查询性能相比每个计数独立存储的方式提升 3~5 倍。</p><h1 id="如何为社交feed场景设计缓存体系"><a href="#如何为社交feed场景设计缓存体系" class="headerlink" title="如何为社交feed场景设计缓存体系"></a>如何为社交feed场景设计缓存体系</h1><h2 id="Feed-流场景分析"><a href="#Feed-流场景分析" class="headerlink" title="Feed 流场景分析"></a>Feed 流场景分析</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/449049dfc24eacb62e14241de43667710b3173d6.png" alt="image-20250709141559577"></p><p>Feed 流是很多移动互联网系统的重要一环，如微博、微信朋友圈、QQ 好友动态、头条&#x2F;抖音信息流等。虽然这些产品形态各不相同，但业务处理逻辑却大体相同。用户日常的“刷刷刷”，就是在获取 Feed 流，这也是 Feed 流的一个最重要应用场景。用户刷新获取 Feed 流的过程，对于服务后端，就是一个获取用户感兴趣的 Feed，并对 Feed 进行过滤、动态组装的过程。</p><p>接下来，我将以微博为例，介绍用户在发出刷新 Feed 流的请求后，服务后端是如何进行处理的。</p><p>获取 Feed 流操作是一个重操作，后端数据处理存在 100 ~ 1000 倍以上的读放大。也就是说，前端用户发出一个接口请求，服务后端需要请求数百甚至数千条数据，然后进行组装处理并返回响应。因此，为了提升处理性能、快速响应用户，微博 Feed 平台重度依赖缓存，几乎所有的数据都从缓存获取。如用户的关注关系从 Redis 缓存中获取，用户发出的 Feed 或收到特殊 Feed 从 Memcached 中获取，用户及 Feed 的各种计数从计数服务中获取。</p><h2 id="Feed-流流程分析"><a href="#Feed-流流程分析" class="headerlink" title="Feed 流流程分析"></a>Feed 流流程分析</h2><p>Feed 流业务作为微博系统的核心业务，为了保障用户体验，SLA 要求较高，核心接口的可用性要达到 4 个 9，接口耗时要在 50<del>100ms 以内，后端数据请求平均耗时要在 3</del>5ms 以内，因此为了满足亿级庞大用户群的海量并发访问需求，需要对缓存体系进行良好架构且不断改进。</p><p>在 Feed 流业务中，核心业务数据的缓存命中率基本都在 99% 以上，这些缓存数据，由 Feed 系统进行多线程并发获取及组装，从而及时发送响应给用户。</p><p>Feed 流获取的处理流程如下。</p><p>首先，根据用户信息，获取用户的关注关系，一般会得到 300~2000 个关注用户的 UID。</p><p>然后，再获取用户自己的 Feed inbox 收件箱。收件箱主要存放其他用户发表的供部分特定用户可见的微博 ID 列表。</p><p>接下来，再获取所有关注列表用户的微博 ID 列表，即关注者发表的所有用户或者大部分用户可见的 Feed ID 列表。这些 Feed ID 列表都以 vector 数组的形式存储在缓存。由于一般用户的关注数会达到数百甚至数千，因此这一步需要获取数百或数千个 Feed vector。</p><p>然后，Feed 系统将 inbox 和关注用户的所有 Feed vector 进行合并，并排序、分页，即得到目标 Feed 的 ID 列表。</p><p>接下来，再根据 Feed ID 列表获取对应的 Feed 内容，如微博的文字、视频、发表时间、源微博 ID 等。</p><p>然后，再进一步获取所有微博的发表者 user 详细信息、源微博内容等信息，并进行内容组装。</p><p>之后，如果用户设置的过滤词，还要将这些 Feed 进行过滤筛选，剔除用户不感兴趣的 Feed。</p><p>接下来，再获取用户对这些 Feed 的收藏、赞等状态，并设置到对应微博中。</p><p>最后，获取这些 Feed 的转发数、评论数、赞数等，并进行计数组装。至此，Feed 流获取处理完毕，Feed 列表以 JSON 形式返回给前端，用户刷新微博首页成功完成。</p><h2 id="Feed-流缓存架构"><a href="#Feed-流缓存架构" class="headerlink" title="Feed 流缓存架构"></a>Feed 流缓存架构</h2><p>Feed 流处理中，缓存核心业务数据主要分为 6 大类。</p><p>第一类是用户的 inbox 收件箱，在用户发表仅供少量用户可见的 Feed 时，为了提升访问效率，这些 Feed ID 并不会进入公共可见的 outbox 发件箱，而会直接推送到目标客户的收件箱。</p><p>第二类是用户的 outbox 发件箱。用户发表的普通微博都进入 outbox，这些微博几乎所有人都可见，由粉丝在刷新 Feed 列表首页时，系统直接拉取组装。</p><p>第三类是 Social Graph 即用户的关注关系，如各种关注列表、粉丝列表。</p><p>第四类是 Feed Content 即 Feed 的内容，包括 Feed 的文字、视频、发表时间、源微博 ID 等。</p><p>第五类是 Existence 存在性判断缓存，用来判断用户是否阅读了某条 Feed，是否赞了某条 Feed 等。对于存在性判断，微博是采用自研的 phantom 系统，通过 bloomfilter 算法进行存储的。</p><p>第六类是 Counter 计数服务，用来存储诸如关注数、粉丝数，Feed 的转发、评论、赞、阅读等各种计数。</p><p>对于 Feed 的 inbox 收件箱、outbox 发件箱，Feed 系统通过 Memcached 进行缓存，以 feed id的一维数组格式进行存储。</p><p>对于关注列表，Feed 系统采用 Redis 进行缓存，存储格式为 longset。longset 在之前的课时介绍过，是微博扩展的一种数据结构，它是一个采用 double-hash 寻址的一维数组。当缓存 miss 后，业务 client 可以从 DB 加载，并直接构建 longset 的二进制格式数据作为 value写入Redis，Redis 收到后直接 restore 到内存，而不用逐条加入。这样，即便用户有成千上万个关注，也不会引发阻塞。</p><p>Feed content 即 Feed 内容，采用 Memcached 存储。由于 Feed 内容有众多的属性，且时常需要根据业务需要进行扩展，Feed 系统采用 Google 的 protocol bufers 的格式进行存放。protocol buffers 序列化后的所生成的二进制消息非常紧凑，二进制存储空间比 XML 小 3~10 倍，而序列化及反序列化的性能却高 10 倍以上，而且扩展及变更字段也很方便。微博的 Feed content 最初采用 XML 和 JSON 存储，在 2011 年之后逐渐全部改为 protocol buffers 存储。</p><p>对于存在性判断，微博 Feed 系统采用自研的 phantom 进行存储。数据存储采用 bloom filter 存储结构。实际上 phantom 本身就是一个分段存储的 bloomfilter 结构。bloomFilter 采用 bit 数组来表示一个集合，整个数组最初所有 bit 位都是 0，插入 key 时，采用 k 个相互独立的 hash 函数计算，将对应 hash 位置置 1。而检测某个 key 是否存在时，通过对 key 进行多次 hash，检查对应 hash 位置是否为 1 即可，如果有一个为 0，则可以确定该 key 肯定不存在，但如果全部为 1，大概率说明该 key 存在，但该 key 也有可能不存在，即存在一定的误判率，不过这个误判率很低，一般平均每条记录占用 1.2 字节时，误判率即可降低到 1%，1.8 字节，误判率可以降到千分之一。基本可以满足大多数业务场景的需要。</p><p>对于计数服务，微博就是用前面讲到的 CounterService。CounterService 采用 schema 策略，支持一个 key 对应多个计数，只用 5<del>10% 的空间，却提升 3</del>5 倍的读取性能。</p><p>对于 Feed 流中的 Redis 存储访问，业务的 Redis 部署基本都采用 1 主多从的方式。同时多个子业务按类型分为 cluster 集群，通过多租户 proxy 进行访问。对于一些数据量很小的业务，还可以共享 Redis 存储，进行混合读写。对于一些响应时间敏感的业务，基于性能考虑，也支持smart client 直接访问 Redis 集群。整个 Redis 集群，由 clusterManager 进行运维、slot 维护及迁移。配置中心记录集群相关的 proxy 部署及 Redis 配置及部署等。这个架构在之前的经典分布式缓存系统课程中有详细介绍，此处不再赘述。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis-热升级&quot;&gt;&lt;a href=&quot;#Redis-热升级&quot; class=&quot;headerlink&quot; title=&quot;Redis 热升级&quot;&gt;&lt;/a&gt;Redis 热升级&lt;/h1&gt;&lt;p&gt;对于线上较大流量的业务，单个 Redis 实例的内存占用很容易达到数 G 的容量，对</summary>
      
    
    
    
    <category term="缓存" scheme="https://palette-k.github.io/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
    <category term="缓存" scheme="https://palette-k.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Spring循环依赖及解决原理</title>
    <link href="https://palette-k.github.io/2025/06/19/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E7%90%86/"/>
    <id>https://palette-k.github.io/2025/06/19/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E7%90%86/</id>
    <published>2025-06-19T02:28:27.000Z</published>
    <updated>2025-10-13T03:31:22.685Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是循环依赖"><a href="#什么是循环依赖" class="headerlink" title="什么是循环依赖"></a>什么是循环依赖</h1><p>字面上理解就是A依赖B的同时，B也依赖了A。</p><p>体现在启动控制台就是以下的日志：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">┌─────┐</span><br><span class="line">|  asyncServiceImpl defined in file [D:\Download\GitLabProject\uhr\jr-uhr-provider\jr-uhr-attendance\target\classes\com\jr\uhr\gtd\service\impl\AsyncServiceImpl.class]</span><br><span class="line">↑     ↓</span><br><span class="line">|  gtdClassServiceImpl defined in file [D:\Download\GitLabProject\uhr\jr-uhr-provider\jr-uhr-attendance\target\classes\com\jr\uhr\gtd\service\impl\GtdClassServiceImpl.class]</span><br><span class="line">└─────┘</span><br></pre></td></tr></table></figure><p>体现在代码层次就是这个样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了B</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> B b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="comment">// B中也注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比较特殊的还有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自己依赖自己</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="什么情况下循环依赖可以被处理"><a href="#什么情况下循环依赖可以被处理" class="headerlink" title="什么情况下循环依赖可以被处理"></a>什么情况下循环依赖可以被处理</h1><p>在回答这个问题之前首先要明确一点，Spring解决循环依赖是有前置条件的</p><ol><li>出现循环依赖的Bean必须要是单例</li><li>依赖注入的方式不能全是构造器注入的方式</li></ol><p>其中第一点应该很好理解，第二点：不能全是构造器注入是什么意思呢？我们还是用代码说话</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line"><span class="comment">//@Autowired</span></span><br><span class="line"><span class="comment">//private B b;</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">A</span><span class="params">(B b)</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//@Autowired</span></span><br><span class="line"><span class="comment">//private A a;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">B</span><span class="params">(A a)</span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的例子中，A中注入B的方式是通过构造器，B中注入A的方式也是通过构造器，这个时候循环依赖是无法被解决，如果你的项目中有两个这样相互依赖的Bean，在启动时就会报出以下错误：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name <span class="string">&#x27;a&#x27;</span>: Requested bean is currently in creation: Is there an unresolvable circular reference?</span><br></pre></td></tr></table></figure><p>为了测试循环依赖的解决情况跟注入方式的关系，我们做如下四种情况的测试</p><table><thead><tr><th>依赖情况</th><th>依赖注入方式</th><th>循环依赖是否被解决</th></tr></thead><tbody><tr><td>AB相互依赖（循环依赖）</td><td>均采用setter方法注入</td><td>是</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>均采用构造器注入</td><td>否</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>A中注入B的方式为setter方法，B中注入A的方式为构造器</td><td>是</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>B中注入A的方式为setter方法，A中注入B的方式为构造器</td><td>否</td></tr></tbody></table><h1 id="Spring是如何解决的循环依赖"><a href="#Spring是如何解决的循环依赖" class="headerlink" title="Spring是如何解决的循环依赖"></a>Spring是如何解决的循环依赖</h1><h2 id="简单的循环依赖（没有AOP）"><a href="#简单的循环依赖（没有AOP）" class="headerlink" title="简单的循环依赖（没有AOP）"></a>简单的循环依赖（没有AOP）</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了B</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> B b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="comment">// B中也注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上文我们已经知道了这种情况下的循环依赖是能够被解决的，那么具体的流程是什么呢？我们一步步分析</p><p>首先，我们要知道<strong>Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A</strong>。</p><p>与此同时，我们应该知道，Spring在创建Bean的过程中分为三步</p><ol><li>实例化，对应方法：<code>AbstractAutowireCapableBeanFactory</code>中的<code>createBeanInstance</code>方法</li><li>属性注入，对应方法：<code>AbstractAutowireCapableBeanFactory</code>的<code>populateBean</code>方法</li><li>初始化，对应方法：<code>AbstractAutowireCapableBeanFactory</code>的<code>initializeBean</code></li></ol><p>简单翻译下，就是：</p><ol><li>实例化，简单理解就是new了一个对象</li><li>属性注入，为实例化中new出来的对象填充属性</li><li>初始化，执行aware接口中的方法，初始化方法，完成<code>AOP</code>代理</li></ol><p>整个创建A这个Bean的流程图如下：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjEzMzAxODY2OS5wbmc?x-oss-process=image/format,png" alt="image-20200706133018669"></p><p>从上图中我们可以看到，虽然在创建B时会提前给B注入了一个还未初始化的A对象，但是在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化，所以这是没有问题的。</p><h2 id="结合了AOP的循环依赖"><a href="#结合了AOP的循环依赖" class="headerlink" title="结合了AOP的循环依赖"></a>结合了AOP的循环依赖</h2><p>对A进行了<code>AOP</code>代理的话，那么此时<code>getEarlyBeanReference</code>将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE2MTcwOTgyOS5wbmc?x-oss-process=image/format,png" alt="image-20200706161709829"></p><p>看到这个图你可能会产生下面这些疑问</p><ol><li>在给B注入的时候为什么要注入一个代理对象？</li></ol><p>答：当我们对A进行了<code>AOP</code>代理时，说明我们希望从容器中获取到的就是A代理后的对象而不是A本身，因此把A当作依赖进行注入时也要注入它的代理对象</p><ol start="2"><li>明明初始化的时候是A对象，那么Spring是在哪里将代理对象放入到容器中的呢？</li></ol><p>在完成初始化后，Spring又调用了一次<code>getSingleton</code>方法，这一次传入的参数又不一样了，false可以理解为禁用三级缓存，前面图中已经提到过了，在为B中注入A时已经将三级缓存中的工厂取出，并从工厂中获取到了一个对象放入到了二级缓存中，所以这里的这个<code>getSingleton</code>方法做的时间就是从二级缓存中获取到这个代理后的A对象。</p><ol start="3"><li>初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？</li></ol><p>答：不会，这是因为不管是<code>cglib</code>代理还是<code>jdk</code>动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化</p><ol start="4"><li>三级缓存为什么要使用工厂而不是直接使用引用？换而言之，为什么需要这个三级缓存，直接通过二级缓存暴露一个引用不行吗？</li></ol><p>答：<strong>这个工厂的目的在于延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象</strong></p><p>我们思考一种简单的情况，就以单独创建A为例，假设AB之间现在没有依赖关系，但是A被代理了，这个时候当A完成实例化后还是会进入下面这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A是单例的，mbd.isSingleton()条件满足</span></span><br><span class="line"><span class="comment">// allowCircularReferences：这个变量代表是否允许循环依赖，默认是开启的，条件也满足</span></span><br><span class="line"><span class="comment">// isSingletonCurrentlyInCreation：正在在创建A，也满足</span></span><br><span class="line"><span class="comment">// 所以earlySingletonExposure=true</span></span><br><span class="line"><span class="type">boolean</span> <span class="variable">earlySingletonExposure</span> <span class="operator">=</span> (mbd.isSingleton() &amp;&amp; <span class="built_in">this</span>.allowCircularReferences &amp;&amp;</span><br><span class="line">                                  isSingletonCurrentlyInCreation(beanName));</span><br><span class="line"><span class="comment">// 还是会进入到这段代码中</span></span><br><span class="line"><span class="keyword">if</span> (earlySingletonExposure) &#123;</span><br><span class="line"><span class="comment">// 还是会通过三级缓存提前暴露一个工厂对象</span></span><br><span class="line">    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看到了吧，即使没有循环依赖，也会将其添加到三级缓存中，而且是不得不添加到三级缓存中，因为到目前为止Spring也不能确定这个Bean有没有跟别的Bean出现循环依赖。</p><p>假设我们在这里直接使用二级缓存的话，那么意味着所有的Bean在这一步都要完成<code>AOP</code>代理。这样做有必要吗？</p><p>不仅没有必要，而且违背了Spring在结合<code>AOP</code>跟Bean的生命周期的设计！Spring结合<code>AOP</code>跟Bean的生命周期本身就是通过<code>AnnotationAwareAspectJAutoProxyCreator</code>这个后置处理器来完成的，在这个后置处理的<code>postProcessAfterInitialization</code>方法中对初始化后的Bean完成<code>AOP</code>代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。</p><h2 id="三级缓存真的提高了效率了吗？"><a href="#三级缓存真的提高了效率了吗？" class="headerlink" title="三级缓存真的提高了效率了吗？"></a>三级缓存真的提高了效率了吗？</h2><p>现在我们已经知道了三级缓存的真正作用，但是这个答案可能还无法说服你，所以我们再最后总结分析一波，三级缓存真的提高了效率了吗？分为两点讨论：</p><ol><li>没有进行<code>AOP</code>的Bean间的循环依赖</li></ol><p>从上文分析可以看出，这种情况下三级缓存根本没用！所以不会存在什么提高了效率的说法</p><ol><li>进行了<code>AOP</code>的Bean间的循环依赖</li></ol><p>就以我们上的A、B为例，其中A被<code>AOP</code>代理，我们先分析下使用了三级缓存的情况下，A、B的创建流程</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE3MTUxNDMyNy5wbmc?x-oss-process=image/format,png" alt="image-20200706171514327"></p><p>假设不使用三级缓存，直接在二级缓存中</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE3MjUyMzI1OC5wbmc?x-oss-process=image/format,png" alt="image-20200706172523258"></p><p>上面两个流程的唯一区别在于为A对象创建代理的时机不同，在使用了三级缓存的情况下为A创建代理的时机是在B中需要注入A的时候，而不使用三级缓存的话在A实例化后就需要马上为A创建代理然后放入到二级缓存中去。对于整个A、B的创建过程而言，消耗的时间是一样的</p><p>综上，不管是哪种情况，三级缓存提高了效率这种说法都是错误的！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>面试官：”Spring是如何解决的循环依赖？“</p><p>答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（<code>singletonObjects</code>）,二级缓存为早期曝光对象<code>earlySingletonObjects</code>，三级缓存为早期曝光对象工厂（<code>singletonFactories</code>）。当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！</p><p>面试官：”为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？“</p><p>答：如果要使用二级缓存解决循环依赖，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过<code>AnnotationAwareAspectJAutoProxyCreator</code>这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是循环依赖&quot;&gt;&lt;a href=&quot;#什么是循环依赖&quot; class=&quot;headerlink&quot; title=&quot;什么是循环依赖&quot;&gt;&lt;/a&gt;什么是循环依赖&lt;/h1&gt;&lt;p&gt;字面上理解就是A依赖B的同时，B也依赖了A。&lt;/p&gt;
&lt;p&gt;体现在启动控制台就是以下的日志：&lt;/p&gt;</summary>
      
    
    
    
    <category term="Spring" scheme="https://palette-k.github.io/categories/Spring/"/>
    
    
    <category term="Spring" scheme="https://palette-k.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>销售提成合并滚动明细逻辑</title>
    <link href="https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E5%90%88%E5%B9%B6%E6%BB%9A%E5%8A%A8%E6%98%8E%E7%BB%86%E9%80%BB%E8%BE%91/"/>
    <id>https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E5%90%88%E5%B9%B6%E6%BB%9A%E5%8A%A8%E6%98%8E%E7%BB%86%E9%80%BB%E8%BE%91/</id>
    <published>2025-05-28T11:28:26.000Z</published>
    <updated>2025-10-13T03:34:20.803Z</updated>
    
    <content type="html"><![CDATA[<h1 id="销售提成合并滚动明细逻辑"><a href="#销售提成合并滚动明细逻辑" class="headerlink" title="销售提成合并滚动明细逻辑"></a>销售提成合并滚动明细逻辑</h1><h2 id="滚动明细"><a href="#滚动明细" class="headerlink" title="滚动明细"></a>滚动明细</h2><p>回款金额暂未发完的账单，会滚动到下一个工资月继续发放</p><p><img src="https://i0.hdslb.com/bfs/openplatform/06f807252c94f6304466fed3e58fdd3301fbd9e4.png" alt="image-20250709140851076"></p><h2 id="同步底表"><a href="#同步底表" class="headerlink" title="同步底表"></a>同步底表</h2><p>增量同步BI底表数据，系统自动给本次拉取的数据打上“工资月份”的标识，BPO(T+2),HRO(T+1)。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2d9552d9da8647d5ce51de4070692878b2540d24.png" alt="image-20250709140905455"></p><h2 id="合并明细"><a href="#合并明细" class="headerlink" title="合并明细"></a>合并明细</h2><p>合并时注意需保留用户编辑后的数据，部分字段需延用（自动带出）上个账单月的数值。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f43b2dc9cf0ae59d05e87d0fccf45dbf0230156f.png" alt="image-20250709140920033"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;销售提成合并滚动明细逻辑&quot;&gt;&lt;a href=&quot;#销售提成合并滚动明细逻辑&quot; class=&quot;headerlink&quot; title=&quot;销售提成合并滚动明细逻辑&quot;&gt;&lt;/a&gt;销售提成合并滚动明细逻辑&lt;/h1&gt;&lt;h2 id=&quot;滚动明细&quot;&gt;&lt;a href=&quot;#滚动明细&quot; cla</summary>
      
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/categories/%E5%9C%BA%E6%99%AF/"/>
    
    
  </entry>
  
  <entry>
    <title>销售提成计算引擎实现</title>
    <link href="https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0/</id>
    <published>2025-05-28T11:28:26.000Z</published>
    <updated>2025-10-13T03:34:31.390Z</updated>
    
    <content type="html"><![CDATA[<h1 id="销售提成计算引擎实现"><a href="#销售提成计算引擎实现" class="headerlink" title="销售提成计算引擎实现"></a>销售提成计算引擎实现</h1><h2 id="1-模块概述"><a href="#1-模块概述" class="headerlink" title="1. 模块概述"></a>1. 模块概述</h2><p>该模块是销售提成计算系统的具体实现层，基于模板方法模式设计，实现了不同业务线（BPO、HRO）的提成计算逻辑。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8c105790c8be2b324e1f4a08f74287ecd5ac54af.png" alt="image-20250709140808203"></p><h2 id="2-目录结构"><a href="#2-目录结构" class="headerlink" title="2. 目录结构"></a>2. 目录结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CopyInsertcalculation/engine/</span><br><span class="line">├── AbstractCalculationEngine.java    # 抽象计算引擎基类</span><br><span class="line">├── CalculationEngine.java           # 计算引擎接口</span><br><span class="line">├── BpoCalculationEngine.java        # BPO业务线计算引擎实现</span><br><span class="line">└── HroCalculationEngine.java        # HRO业务线计算引擎实现</span><br></pre></td></tr></table></figure><h2 id="3-核心组件说明"><a href="#3-核心组件说明" class="headerlink" title="3. 核心组件说明"></a>3. 核心组件说明</h2><h3 id="3-1-计算引擎接口"><a href="#3-1-计算引擎接口" class="headerlink" title="3.1 计算引擎接口"></a>3.1 计算引擎接口</h3><p><code>CalculationEngine</code></p><ul><li><p>定义了计算引擎的基本契约</p></li><li><p>核心方法：</p><ul><li><p><code>calculation(CalculationDto)</code>: 执行业务数据核算</p></li><li><p><code>supportedProductLine()</code>: 声明支持的产品线类型</p></li></ul></li></ul><h3 id="3-2-抽象计算引擎"><a href="#3-2-抽象计算引擎" class="headerlink" title="3.2 抽象计算引擎"></a>3.2 抽象计算引擎</h3><p><code>AbstractCalculationEngine</code></p><ul><li><p>实现了计算引擎的通用逻辑</p></li><li><p>核心功能：</p><ol><li><strong>计算流程控制</strong></li></ol><ul><li><code>calculation(CalculationDto)</code>: 总体计算流程控制<ul><li><code>processCalculation()</code>: 执行具体计算过程</li><li><code>validateCalculationDto()</code>: 验证计算参数</li></ul></li></ul><ol start="2"><li><strong>数据处理</strong><ul><li><code>getDetailData()</code>: 获取业务数据</li><li><code>getBasicSubjectValues()</code>: 获取基础科目值</li><li><code>processTableDataBatch()</code>: 处理单个表数据（in查询批量处理）</li><li><code>setDetailInfoBasicSubjectValues()</code>: 设置明细数据基础科目值</li></ul></li><li><strong>结果处理</strong><ul><li><code>processCalculationResults()</code>: 处理计算结果</li><li><code>writeCalculationDetail()</code>: 写入计算明细</li><li><code>handleCalculationSuccess()</code>: 处理计算成功</li><li><code>handleCalculationFailure()</code>: 处理计算失败</li><li><code>handleErrorResults()</code>: 处理错误结果</li></ul></li></ol></li></ul><h3 id="3-3-具体业务实现"><a href="#3-3-具体业务实现" class="headerlink" title="3.3 具体业务实现"></a>3.3 具体业务实现</h3><h4 id="3-3-1-BPO业务计算引擎"><a href="#3-3-1-BPO业务计算引擎" class="headerlink" title="3.3.1 BPO业务计算引擎"></a>3.3.1 BPO业务计算引擎</h4><p><code>BpoCalculationEngine</code></p><ul><li><p>特点：</p><ul><li><p>继承<code>AbstractCalculationEngine</code></p></li><li><p>实现BPO业务特有的数据获取和处理逻辑</p></li></ul></li><li><p>核心方法：</p><ul><li><p><code>getDetailData()</code>: 获取BPO业务数据</p></li><li><p><code>writeDetailInfo()</code>: 写入BPO计算结果</p></li><li><p><code>supportedProductLine()</code>: 返回BPO产品线标识</p></li></ul></li></ul><h4 id="3-3-2-HRO业务计算引擎"><a href="#3-3-2-HRO业务计算引擎" class="headerlink" title="3.3.2 HRO业务计算引擎"></a>3.3.2 HRO业务计算引擎</h4><p><code>HroCalculationEngine</code></p><ul><li><p>特点：</p><ul><li><p>继承<code>AbstractCalculationEngine</code></p></li><li><p>实现HRO业务特有的数据获取和处理逻辑</p></li></ul></li><li><p>核心方法：</p><ul><li><p><code>getDetailData()</code>: 获取HRO业务数据</p></li><li><p><code>writeDetailInfo()</code>: 写入HRO计算结果</p></li><li><p><code>supportedProductLine()</code>: 返回HRO产品线标识</p></li></ul></li></ul><h2 id="4-核心流程说明"><a href="#4-核心流程说明" class="headerlink" title="4. 核心流程说明"></a>4. 核心流程说明</h2><h3 id="4-1-计算流程"><a href="#4-1-计算流程" class="headerlink" title="4.1 计算流程"></a>4.1 计算流程</h3><ol><li><p>参数验证</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">validateCalculationDto(calculationDto)</span><br></pre></td></tr></table></figure></li><li><p>获取分布式锁</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redissonClient.getLock(RedisConstant.CALCULATION_LOCK_PREFIX + batch.getId());</span><br><span class="line"> <span class="keyword">if</span> (!lock.tryLock()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BusinessException</span>(<span class="string">&quot;核算进行中，请稍后再试&quot;</span>);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></li><li><p>创建计算任务</p></li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SysCalculationProcess</span> <span class="variable">process</span> <span class="operator">=</span> calculationProcessService</span><br><span class="line">                .saveProcess(batch.getId(), calculationDto.getProductLineCode());</span><br></pre></td></tr></table></figure><ol start="4"><li>用户登录信息存入上下文</li></ol><p>  因计算过程是异步的，且区分于定时任务调用、用户手动调用，需在核算开始前添加用户登录信息至上下文，核算结束后生成的错误文件明细数据是用户数据权限下的数据。</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优先从 上下文 获取用户，如果没有再从 ServletUtils 获取</span></span><br><span class="line">      <span class="type">LoginUser</span> <span class="variable">currentUser</span> <span class="operator">=</span>  UserContext.getUser();</span><br><span class="line">      <span class="keyword">if</span> (currentUser == <span class="literal">null</span>) &#123;</span><br><span class="line">          currentUser = ServletUtils.getLoginUser();</span><br><span class="line">      &#125;</span><br><span class="line"> <span class="comment">// 使用装饰器包装任务</span></span><br><span class="line">      taskExecutor.execute(UserContextDecorator.decorate(() -&gt; &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              processCalculation(calculationDto, batch, process, subjects);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (BusinessException e) &#123;</span><br><span class="line">              handleCalculationFailure(batch, process, e);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">              log.error(<span class="string">&quot;计算过程发生异常：&#123;&#125;&quot;</span>, e.getMessage(), e);</span><br><span class="line">              handleCalculationFailure(batch, process, e);</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">              lock.forceUnlock();</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;, currentUser));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  用户装饰器类，这里使用了装饰器模式，不修改原有的代码结构的前提下，动态地在异步任务开始前设置用户上下文，异步任务结束后清理用户的上下文。</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserContextDecorator</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Runnable delegate;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> LoginUser user;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String taskId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">UserContextDecorator</span><span class="params">(Runnable delegate, LoginUser user)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.delegate = delegate;</span><br><span class="line">        <span class="built_in">this</span>.user = user;</span><br><span class="line">        <span class="comment">// 生成唯一任务ID</span></span><br><span class="line">        <span class="built_in">this</span>.taskId = UUID.randomUUID().toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">threadName</span> <span class="operator">=</span> Thread.currentThread().getName();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Task[&#123;&#125;] setting user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">            <span class="comment">// 前置处理：设置用户上下文</span></span><br><span class="line">            UserContext.setUser(user);</span><br><span class="line">              <span class="comment">// 执行原始任务</span></span><br><span class="line">            delegate.run();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Task[&#123;&#125;] clearing user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">             <span class="comment">// 后置处理：清理用户上下文</span></span><br><span class="line">            UserContext.clear();</span><br><span class="line">            <span class="comment">// 额外验证确保清理成功</span></span><br><span class="line">            <span class="keyword">if</span> (UserContext.getUser() != <span class="literal">null</span>) &#123;</span><br><span class="line">                log.error(<span class="string">&quot;Task[&#123;&#125;] failed to clear user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">                <span class="comment">// 再次尝试清理</span></span><br><span class="line">                UserContext.clear();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Runnable <span class="title function_">decorate</span><span class="params">(Runnable task, LoginUser user)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserContextDecorator</span>(task, user);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>获取业务数据</li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;DetailData&gt; details = getDetailData(calculationDto)</span><br></pre></td></tr></table></figure><ol start="6"><li><p>获取基础科目值</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Long, Map&lt;String, Object&gt;&gt; basicSubjectValues = getBasicSubjectValues(subjects, details)</span><br></pre></td></tr></table></figure></li><li><p>执行计算</p></li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 执行计算</span></span><br><span class="line"><span class="type">Calculator</span> <span class="variable">calculator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Calculator</span>(subjects, details);</span><br><span class="line">List&lt;CalculationResult&gt; results = calculator.calculate();</span><br></pre></td></tr></table></figure><p>  为了提升每次核算的速度，将每条明细数据的核算过程并行处理</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 执行计算过程</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> 计算结果列表，每个明细一条结果记录</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> List&lt;CalculationResult&gt; <span class="title function_">calculate</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="comment">// 1. 预先验证所有公式</span></span><br><span class="line">      validateAllMethods();</span><br><span class="line">      <span class="comment">// 2. 使用并行流处理明细</span></span><br><span class="line">      <span class="keyword">return</span> details.parallelStream().map(<span class="built_in">this</span>::calculateDetail).collect(Collectors.toList());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  每次计算都创建一次计算上下文，计算完成后将计算结果存进内存</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> CalculationResult <span class="title function_">calculateDetail</span><span class="params">(DetailData detail)</span> &#123;</span><br><span class="line">       DefaultContext&lt;String, Object&gt; context = createCalculationContext(detail);</span><br><span class="line">       <span class="type">CalculationResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CalculationResult</span>();</span><br><span class="line">       result.setDetailInfoId(detail.getDetailInfoId());</span><br><span class="line">       result.setIsCommissionPaidThisMonth(detail.getIsCommissionPaidThisMonth());</span><br><span class="line">  </span><br><span class="line">       <span class="keyword">for</span> (SysSubject subject : subjects) &#123;</span><br><span class="line">           <span class="type">String</span> <span class="variable">calculationMethod</span> <span class="operator">=</span> subject.getCalculationMethod();</span><br><span class="line">           <span class="keyword">if</span> (StringUtils.isBlank(calculationMethod)) &#123;</span><br><span class="line">               log.warn(<span class="string">&quot;科目计算的公式为空: &#123;&#125;&quot;</span>, subject.getSubjectName());</span><br><span class="line">               <span class="keyword">continue</span>;</span><br><span class="line">           &#125;</span><br><span class="line">  </span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               <span class="comment">// 使用缓存的验证结果</span></span><br><span class="line">               <span class="keyword">if</span> (!methodValidationCache.getOrDefault(calculationMethod, <span class="literal">false</span>)) &#123;</span><br><span class="line">                   <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BusinessException</span>(String.format(<span class="string">&quot;科目[%s]的计算公式配置错误&quot;</span>, subject.getSubjectName()));</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="type">Object</span> <span class="variable">computed</span> <span class="operator">=</span> calculateSubject(detail, subject, context);</span><br><span class="line">               saveCalculateResult(result, subject, computed);</span><br><span class="line">           &#125; <span class="keyword">catch</span> (BusinessException e) &#123;</span><br><span class="line">               <span class="keyword">throw</span> e;</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               handleCalculationError(detail, subject, result, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">  </span><br><span class="line">       <span class="keyword">return</span> result;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>  使用规则引擎进行计算</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 执行单个科目的计算</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> Object <span class="title function_">calculateSubject</span><span class="params">(DetailData detail, SysSubject subject,</span></span><br><span class="line"><span class="params">                                  DefaultContext&lt;String, Object&gt; context)</span> &#123;</span><br><span class="line">      <span class="type">String</span> <span class="variable">method</span> <span class="operator">=</span> subject.getCalculationMethod();</span><br><span class="line">      log.debug(<span class="string">&quot;计算明细表 detail ID: &#123;&#125;, 公式: &#123;&#125;&quot;</span>, detail.getDetailInfoId(), method);</span><br><span class="line">      <span class="type">Object</span> <span class="variable">computed</span> <span class="operator">=</span> QlExpressUtils.computer(method, context);</span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 保留小数位</span></span><br><span class="line">      <span class="keyword">if</span> (subject.getDecimalPlaces() != <span class="literal">null</span> &amp;&amp; computed != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="type">BigDecimal</span> <span class="variable">bigDecimal</span> <span class="operator">=</span> Convert.toBigDecimal(computed, BigDecimal.ZERO);</span><br><span class="line">          computed = bigDecimal.setScale(subject.getDecimalPlaces(), RoundingMode.HALF_UP);</span><br><span class="line">      &#125;</span><br><span class="line">  </span><br><span class="line">      context.put(subject.getSubjectCode(), computed);</span><br><span class="line">      log.debug(<span class="string">&quot;计算后的上下文: &#123;&#125;&quot;</span>, context);</span><br><span class="line">      <span class="keyword">return</span> computed;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  使用懒加载模式，只在首次使用时初始化，避免了类加载时的初始化开销，保持了线程安全性</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title function_">computer</span><span class="params">(String express, DefaultContext&lt;String, Object&gt; context)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (StringUtils.isBlank(express) || Objects.isNull(context)) &#123;</span><br><span class="line">           <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       initializeIfNeeded();</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="comment">// 为每个计算创建独立的上下文</span></span><br><span class="line">           DefaultContext&lt;String, Object&gt; localContext = <span class="keyword">new</span> <span class="title class_">DefaultContext</span>&lt;&gt;();</span><br><span class="line">           localContext.putAll(context);</span><br><span class="line">           <span class="keyword">return</span> expressRunner.execute(express, localContext, <span class="literal">null</span>, <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">       &#125;  <span class="keyword">catch</span> (QLBizException | QLException e) &#123;</span><br><span class="line">           <span class="type">Throwable</span> <span class="variable">cause</span> <span class="operator">=</span> e.getCause();</span><br><span class="line">           <span class="keyword">if</span> (cause != <span class="literal">null</span>) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(cause.getMessage());</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e.getMessage());</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           log.error(<span class="string">&quot;计算运算公式：&#123;&#125; 失败，参数为:&#123;&#125;&quot;</span>, express, JSONObject.toJSONString(context));</span><br><span class="line">           log.error(<span class="string">&quot;计算运算失败&quot;</span>, e);</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e.getMessage());</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 使用懒加载单例模式</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">initializeIfNeeded</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (expressRunner == <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">synchronized</span> (LOCK) &#123;</span><br><span class="line">              <span class="keyword">if</span> (expressRunner == <span class="literal">null</span>) &#123;</span><br><span class="line">                  <span class="comment">// 优先使用Spring容器中的bean</span></span><br><span class="line">                  <span class="type">ExpressRunner</span> <span class="variable">runner</span> <span class="operator">=</span> SpringUtils.getBean(ExpressRunner.class);</span><br><span class="line">                  <span class="keyword">if</span> (runner == <span class="literal">null</span>) &#123;</span><br><span class="line">                      runner = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().expressRunner();</span><br><span class="line">                  &#125;</span><br><span class="line">                  </span><br><span class="line">                  Map&lt;String, String&gt; defineClass = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().selfDefineClass(runner);</span><br><span class="line">                  </span><br><span class="line">                  <span class="type">ExpressParse</span> <span class="variable">parse</span> <span class="operator">=</span> SpringUtils.getBean(ExpressParse.class);</span><br><span class="line">                  <span class="keyword">if</span> (parse == <span class="literal">null</span>) &#123;</span><br><span class="line">                      parse = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().expressParse(runner);</span><br><span class="line">                  &#125;</span><br><span class="line">                  </span><br><span class="line">                  <span class="comment">// 所有初始化完成后才赋值给静态变量</span></span><br><span class="line">                  expressRunner = runner;</span><br><span class="line">                  selfDefineClass = defineClass;</span><br><span class="line">                  expressParse = parse;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol start="8"><li>处理结果</li></ol><ul><li><p>将批次id写入提成明细</p></li><li><p>写入科目计算结果</p></li><li><p>写入销售提成金额</p></li><li><p>处理错误信息，生成错误文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 第一个事务：处理核心计算结果</span></span><br><span class="line">        transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">            writeDetailInfo(results, batch);</span><br><span class="line">            writeCalculationDetail(results, batch);</span><br><span class="line">            writeSaleCommissionDetail(results, batch);</span><br><span class="line">            handleErrorResults(results, process, calculationDto.getSalaryMonth());</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure></li><li><p>实时生成提成统计，并更改任务状态</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="comment">// 第二个事务：处理统计数据</span></span><br><span class="line">         transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">             generateStatisticData(calculationDto);</span><br><span class="line">         &#125;);</span><br><span class="line">         <span class="comment">// 第三个事务：更新状态</span></span><br><span class="line">         transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">             handleCalculationSuccess(batch, process, subjects);</span><br><span class="line">         &#125;);</span><br><span class="line">     &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">         log.error(<span class="string">&quot;生成统计数据或更新状态失败&quot;</span>, e);</span><br><span class="line">         <span class="comment">// 更新为部分完成状态</span></span><br><span class="line">         handlePartialSuccess(batch, process, subjects, e);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-错误处理"><a href="#4-2-错误处理" class="headerlink" title="4.2 错误处理"></a>4.2 错误处理</h3><ul><li>计算失败处理  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">handleCalculationFailure(batch, process, exception)</span><br></pre></td></tr></table></figure></li><li>结果错误处理  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">handleErrorResults(results, process)</span><br></pre></td></tr></table></figure></li></ul><h2 id="5-扩展指南"><a href="#5-扩展指南" class="headerlink" title="5. 扩展指南"></a>5. 扩展指南</h2><h3 id="5-1-添加新的业务线"><a href="#5-1-添加新的业务线" class="headerlink" title="5.1 添加新的业务线"></a>5.1 添加新的业务线</h3><ol><li><p>创建新的业务线计算引擎类，继承<code>AbstractCalculationEngine</code></p></li><li><p>实现必要的抽象方法：</p><ul><li><p><code>getDetailData()</code></p></li><li><p><code>writeDetailInfo()</code></p></li><li><p><code>supportedProductLine()</code></p></li></ul></li><li><p>根据业务需求，可能需要重写其他方法</p></li></ol><h3 id="5-2-修改计算逻辑"><a href="#5-2-修改计算逻辑" class="headerlink" title="5.2 修改计算逻辑"></a>5.2 修改计算逻辑</h3><ol><li>核心计算逻辑在<code>processCalculation()</code>方法中</li><li>基础数据处理逻辑在<code>getBasicSubjectValues()</code>方法中</li><li>结果处理逻辑在<code>processCalculationResults()</code>方法中</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;销售提成计算引擎实现&quot;&gt;&lt;a href=&quot;#销售提成计算引擎实现&quot; class=&quot;headerlink&quot; title=&quot;销售提成计算引擎实现&quot;&gt;&lt;/a&gt;销售提成计算引擎实现&lt;/h1&gt;&lt;h2 id=&quot;1-模块概述&quot;&gt;&lt;a href=&quot;#1-模块概述&quot; class=&quot;</summary>
      
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/categories/%E5%9C%BA%E6%99%AF/"/>
    
    
    <category term="QlExpress" scheme="https://palette-k.github.io/tags/QlExpress/"/>
    
  </entry>
  
  <entry>
    <title>常用的缓存组件Redis是如何运行的</title>
    <link href="https://palette-k.github.io/2025/02/24/%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E7%BB%84%E4%BB%B6Redis%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E7%9A%84/"/>
    <id>https://palette-k.github.io/2025/02/24/%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E7%BB%84%E4%BB%B6Redis%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E7%9A%84/</id>
    <published>2025-02-24T02:17:00.000Z</published>
    <updated>2025-10-13T03:27:12.784Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h1><p>Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组件，它的所有数据结构都存在内存中，可以用作缓存、数据库和消息中间件。</p><p>Redis 是 Remote dictionary server 即远程字典服务的缩写，一个 Redis 实例可以有多个存储数据的字典，客户端可以通过 select 来选择字典即 DB 进行数据存储。</p><h1 id="Redis核心数据类型"><a href="#Redis核心数据类型" class="headerlink" title="Redis核心数据类型"></a>Redis核心数据类型</h1><p>同为 key-value 存储组件，Memcached 只能支持二进制字节块这一种数据类型。而 Redis 的数据类型却丰富的多，它具有 8 种核心数据类型，每种数据类型都有一系列操作指令对应。</p><p>首先，来看一下 Redis 的核心数据类型。Redis 有 8 种核心数据类型，分别是 ：</p><ul><li>string 字符串类型；</li><li>list 列表类型；</li><li>set 集合类型；</li><li>sorted set 有序集合类型；</li><li>hash 类型；</li><li>bitmap 位图类型；</li><li>geo 地理位置类型；</li><li>HyperLogLog 基数统计类型。</li></ul><h2 id="string-字符串"><a href="#string-字符串" class="headerlink" title="string 字符串"></a>string 字符串</h2><p>string 是 Redis 的最基本数据类型。可以把它理解为 Mc 中 key 对应的 value 类型。string 类型是二进制安全的，即 string 中可以包含任何数据。</p><p>Redis 中的普通 string 采用 raw encoding 即原始编码方式，该编码方式会动态扩容，并通过提前预分配冗余空间，来减少内存频繁分配的开销。</p><p>在字符串长度小于 1MB 时，按所需长度的 2 倍来分配，超过 1MB，则按照每次额外增加 1MB 的容量来预分配。</p><p>Redis 中的数字也存为 string 类型，但编码方式跟普通 string 不同，数字采用整型编码，字符串内容直接设为整数值的二进制字节序列。</p><p><strong>需要存储常规数据的场景</strong></p><ul><li>举例 ：缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</li><li>相关命令 ： <code>SET</code>、<code>GET</code>、<code>MSET</code>、<code>INCR</code>、<code>DECR</code>。</li><li>项目相关：jwt + Redis 的 token 存储，在 Redis 上可实现登录过期失效即登出功能</li></ul><p><strong>需要计数的场景</strong></p><ul><li>举例 ：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li><li>相关命令 ：<code>SET</code>、<code>GET</code>、 <code>INCR</code>、<code>DECR</code> 。</li></ul><h2 id="List列表"><a href="#List列表" class="headerlink" title="List列表"></a>List列表</h2><p>Redis 的 list 列表，是一个快速双向链表，存储了一系列的 string 类型的字串值。list 中的元素按照插入顺序排列。插入元素的方式，可以通过 lpush 将一个或多个元素插入到列表的头部，也可以通过 rpush 将一个或多个元素插入到队列尾部，还可以通过 lset、linsert 将元素插入到指定位置或指定元素的前后。</p><p>feed timeline 存储时，由于 feed id 一般是递增的，可以直接存为 list，用户发表新 feed，就直接追加到队尾。另外消息队列、热门 feed 等业务场景，都可以使用 list 数据结构。</p><p><strong>信息流展示</strong></p><ul><li>举例 ：最新文章、最新动态。</li><li>相关命令 ： <code>LPUSH</code>、<code>LRANGE</code>。</li><li>项目相关：漫画项目中，对优惠活动场次的存储，key为起止时间，对应的活动中涉及到的产品idList为value</li></ul><h2 id="set-集合"><a href="#set-集合" class="headerlink" title="set 集合"></a>set 集合</h2><p>set 是 string 类型的无序集合，set 中的元素是唯一的，即 set 中不会出现重复的元素。Redis 中的集合一般是通过 dict 哈希表实现的，所以插入、删除，以及查询元素，可以根据元素 hash 值直接定位，时间复杂度为 O(1)。</p><p>set 集合的特点是查找、插入、删除特别高效，时间复杂度为 O(1)，所以在社交系统中，可以用于存储关注的好友列表，用来判断是否关注，还可以用来做好友推荐使用。另外，还可以利用 set 的唯一性，来对服务的来源业务、来源 IP 进行精确统计。</p><p><strong>需要存放的数据不能重复的场景</strong></p><ul><li>举例：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li><li>相关命令：<code>SCARD</code>（获取集合数量） 。</li></ul><p><strong>需要获取多个数据源交集、并集和差集的场景</strong></p><ul><li>举例 ：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集） 、订阅号推荐（差集+交集） 等场景。</li><li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li></ul><h2 id="Sorted-Set（有序集合）"><a href="#Sorted-Set（有序集合）" class="headerlink" title="Sorted Set（有序集合）"></a>Sorted Set（有序集合）</h2><p>Redis 中的 sorted set 有序集合也称为 zset，有序集合同 set 集合类似，也是 string 类型元素的集合，且所有元素不允许重复。</p><p>但有序集合中，每个元素都会关联一个 double 类型的 score 分数值。有序集合通过这个 score 值进行由小到大的排序。有序集合中，元素不允许重复，但 score 分数值却允许重复。</p><p><strong>需要随机获取数据源中的元素根据某个权重进行排序的场景</strong></p><ul><li>举例 ：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><p><strong>需要存储的数据有优先级或者重要程度的场景</strong> 比如优先级任务队列。</p><ul><li>举例 ：优先级任务队列。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><h2 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h2><p>Redis 中的哈希实际是 field 和 value 的一个映射表。</p><p>hash 数据结构的特点是在单个 key 对应的哈希结构内部，可以记录多个键值对，即 field 和 value 对，value 可以是任何字符串。而且这些键值对查询和修改很高效。</p><p><strong>对象数据存储场景</strong></p><ul><li>举例 ：用户信息、商品信息、文章信息、购物车信息。</li><li>相关命令 ：<code>HSET</code> （设置单个字段的值）、<code>HMSET</code>（设置多个字段的值）、<code>HGET</code>（获取单个字段的值）、<code>HMGET</code>（获取多个字段的值）。</li><li>项目相关：存储产品的详细信息，key为固定字符串（即说明是优惠活动上架的商品信息），field为活动id-产品id，value为序列化后的对象（产品的数量名字起止时间等等，包括设置该产品的随机码（UUID），防恶意攻击）</li></ul><h2 id="Bitmap-位图"><a href="#Bitmap-位图" class="headerlink" title="Bitmap 位图"></a>Bitmap 位图</h2><p>Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。</p><p>你可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。</p><p><strong>需要保存状态信息（0&#x2F;1 即可表示）的场景</strong></p><ul><li>举例 ：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。</li><li>相关命令 ：<code>SETBIT</code>、<code>GETBIT</code>、<code>BITCOUNT</code>、<code>BITOP</code>。</li></ul><blockquote><p>使用 Bitmap 统计活跃用户怎么做？</p></blockquote><p>使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。</p><p>初始化数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; SETBIT 20210308 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">&gt; SETBIT 20210308 2 1</span><br><span class="line">(integer) 0</span><br><span class="line">&gt; SETBIT 20210309 1 1</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><p>统计 20210308~20210309 总活跃用户数:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; BITOP and desk1 20210308 20210309</span><br><span class="line">(integer) 1</span><br><span class="line">&gt; BITCOUNT desk1</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>统计 20210308~20210309 在线活跃用户数:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; BITOP or desk2 20210308 20210309</span><br><span class="line">(integer) 1</span><br><span class="line">&gt; BITCOUNT desk2</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h2 id="hyperLogLog-基数统计"><a href="#hyperLogLog-基数统计" class="headerlink" title="hyperLogLog 基数统计"></a>hyperLogLog 基数统计</h2><p>Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近<code>2^64</code>个不同元素。这是真的厉害，这就是数学的魅力么！并且，Redis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：</p><ul><li><strong>稀疏矩阵</strong> ：计数较少的时候，占用空间很小。</li><li><strong>稠密矩阵</strong> ：计数达到某个阈值的时候，占用 12k 的空间。</li></ul><p>基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）。因此， HyperLogLog 的计数结果并不是一个精确值，存在一定的误差（标准误差为 <code>0.81%</code> 。）。</p><p><strong>数量量巨大（百万、千万级别以上）的计数场景</strong></p><ul><li>举例 ：热门网站每日&#x2F;每周&#x2F;每月访问 ip 数统计、热门帖子 uv 统计、</li><li>相关命令 ：<code>PFADD</code>、<code>PFCOUNT</code> 。</li></ul><h2 id="Geospatial-index"><a href="#Geospatial-index" class="headerlink" title="Geospatial index"></a>Geospatial index</h2><p>Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。</p><p>通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。</p><p><strong>需要管理使用地理空间数据的场景</strong></p><ul><li>举例：附近的人。</li><li>相关命令: <code>GEOADD</code>、<code>GEORADIUS</code>、<code>GEORADIUSBYMEMBER</code></li></ul><h2 id="Redis使用规范小建议"><a href="#Redis使用规范小建议" class="headerlink" title="Redis使用规范小建议"></a>Redis使用规范小建议</h2><h3 id="键值对使用规范"><a href="#键值对使用规范" class="headerlink" title="键值对使用规范"></a>键值对使用规范</h3><p><strong>key命名规范</strong>：通过 key 的前缀区分不同的业务数据，可以使用相应的英文单词的首字母表示（ key 字符串的长度增加时，SDS 中的元数据也会占用更多内存空间）</p><p><strong>避免使用bigKey</strong>：Redis 是使用单线程读写数据，bigkey 的读写操作会阻塞线程。</p><ul><li>情况一：键值对的值大小本身就很大，例如 value 为 1MB 的 String 类型数据。为了避免 String 类型的 bigkey，在业务层，我们要尽量把 String 类型的数据大小控制在 10KB 以下。</li><li>情况二：键值对的值是集合类型，集合元素个数非常多，例如包含 100 万个元素的 Hash 集合类型数据。为了避免集合类型的 bigkey，我给你的设计规范建议是，<strong>尽量把集合类型的元素个数控制在 1 万以下</strong>。</li></ul><p><strong>使用高效序列化方法和压缩方法</strong>：Redis 中的字符串都是使用二进制安全的字节数组来保存的，所以，我们可以把业务数据序列化成二进制数据写入到 Redis 中。</p><p><strong>使用整数对象共享池</strong>：整数是常用的数据类型，Redis 内部维护了 0 到 9999 这 1 万个整数对象，并把这些整数作为一个共享池使用。</p><p>那什么时候不能用整数对象共享池呢？主要有两种情况。</p><p>第一种情况是，<strong>如果 Redis 中设置了 maxmemory，而且启用了 LRU 策略（allkeys-lru 或 volatile-lru 策略），那么，整数对象共享池就无法使用了</strong>。这是因为，LRU 策略需要统计每个键值对的使用时间，如果不同的键值对都共享使用一个整数对象，LRU 策略就无法进行统计了。</p><p>第二种情况是，如果集合类型数据采用 ziplist 编码，而集合元素是整数，这个时候，也不能使用共享池。因为 ziplist 使用了紧凑型内存结构，判断整数对象的共享情况效率低。</p><h3 id="数据保存规范"><a href="#数据保存规范" class="headerlink" title="数据保存规范"></a>数据保存规范</h3><ul><li>使用redis保存热数据</li><li>不同业务数据分实例存储</li><li>数据保存时设置过期时间</li><li>控制Redis实例的容量：设置在 2~6GB</li></ul><h3 id="命令使用规范"><a href="#命令使用规范" class="headerlink" title="命令使用规范"></a>命令使用规范</h3><ol><li>线上禁用部分命令：<ul><li><strong>KEYS</strong>，按照键值对的 key 内容进行匹配，返回符合匹配条件的键值对，该命令需要对 Redis 的全局哈希表进行全表扫描，严重阻塞 Redis 主线程；</li><li><strong>FLUSHALL</strong>，删除 Redis 实例上的所有数据，如果数据量很大，会严重阻塞 Redis 主线程；</li><li><strong>FLUSHDB</strong>，删除当前数据库中的数据，如果数据量很大，同样会阻塞 Redis 主线程。</li></ul></li></ol><p>对于 KEYS 命令来说，你可以用 SCAN 命令代替 KEYS 命令。</p><p>对于FLUSHALL、FLUSHDB命令来说，可以加上ASYNC选项，让这两个命令使用后台线程异步删除数据。</p><ol start="2"><li><p>慎用 MONITOR 命令</p><p>Redis 的 MONITOR 命令在执行后，会持续输出监测到的各个命令操作。如果线上命令的操作很多，输出缓冲区很快就会溢出了，这就会对 Redis 性能造成影响，甚至引起服务崩溃。</p></li><li><p>慎用全量操作命令</p><p> Hash 类型的 HGETALL、Set 类型的 SMEMBERS。这些操作会对 Hash 和 Set 类型的底层数据结构进行全量扫描，如果集合类型数据较多的话，就会阻塞 Redis 主线程。</p><p>如果想要获得集合类型的全量数据，我给你三个小建议。</p><ul><li>你可以使用 SSCAN、HSCAN 命令分批返回集合中的数据，减少对主线程的阻塞。</li><li>你可以化整为零，把一个大的 Hash 集合拆分成多个小的 Hash 集合。这个操作对应到业务层，就是对业务数据进行拆分，按照时间、地域、用户 ID 等属性把一个大集合的业务数据拆分成多个小集合数据。例如，当你统计用户的访问情况时，就可以按照天的粒度，把每天的数据作为一个 Hash 集合。</li><li>最后一个建议是，如果集合类型保存的是业务数据的多个属性，而每次查询时，也需要返回这些属性，那么，你可以使用 String 类型，将这些属性序列化后保存，每次直接返回 String 数据就行，不用再对集合类型做全量扫描了。</li></ul></li></ol><h1 id="Redis存储结构"><a href="#Redis存储结构" class="headerlink" title="Redis存储结构"></a>Redis存储结构</h1><p>Redis 中所有数据都保存在 DB 中，一个 Redis 默认最多支持 16 个 DB。Redis 中的每个 DB 都对应一个 redisDb 结构，即每个 Redis 实例，默认有 16 个 redisDb。用户访问时，默认使用的是 0 号 DB，可以通过 select $dbID 在不同 DB 之间切换。</p><p>redisDb 主要包括 2 个核心 dict 字典、3 个非核心 dict 字典、dbID 和其他辅助属性。2 个核心 dict 包括一个 dict 主字典和一个 expires 过期字典。主 dict 字典用来存储当前 DB 中的所有数据，它将 key 和各种数据类型的 value 关联起来，该 dict 也称 key space。过期字典用来存储过期时间 key，存的是 key 与过期时间的映射。日常的数据存储和访问基本都会访问到 redisDb 中的这两个 dict。</p><p>Redis 的所有内存数据结构都存在全局的 dict 字典中，dict 类似 Memcached 的 hashtable。Redis 的 dict 也有 2 个哈希表，插入新 key 时，一般用 0 号哈希表，随着 key 的插入或删除，当 0 号哈希表的 keys 数大于哈希表桶数，或 kyes 数小于哈希桶的 1⁄10 时，就对 hash 表进行扩缩。dict 中，哈希表解决冲突的方式，与 Memcached 相同，也是使用桶内单链表，来指向多个 hash 相同的 key&#x2F;value 数据。</p><h1 id="Redis淘汰key"><a href="#Redis淘汰key" class="headerlink" title="Redis淘汰key"></a>Redis淘汰key</h1><h2 id="淘汰原理"><a href="#淘汰原理" class="headerlink" title="淘汰原理"></a>淘汰原理</h2><p>当 key 过期后，或者 Redis 实际占用的内存超过阀值后，Redis 就会对 key 进行淘汰，删除过期的或者不活跃的 key，回收其内存，供新的 key 使用。Redis 的内存阀值是通过 maxmemory 设置的，而超过内存阀值后的淘汰策略，是通过 maxmemory-policy 设置的。</p><p>Redis 会在 2 种场景下对 key 进行淘汰，第一种是在定期执行 serverCron 时，检查淘汰 key；第二种是在执行命令时，检查淘汰 key。</p><ul><li><p>第一种场景，Redis 定期执行 serverCron 时，会对 DB 进行检测，清理过期 key。</p><p>清理流程如下。首先轮询每个 DB，检查其 expire dict，即带过期时间的过期 key 字典，从所有带过期时间的 key 中，随机选取 20 个样本 key，检查这些 key 是否过期，如果过期则清理删除。如果 20 个样本中，超过 5 个 key 都过期，即过期比例大于 25%，就继续从该 DB 的 expire dict 过期字典中，再随机取样 20 个 key 进行过期清理，持续循环，直到选择的 20 个样本 key 中，过期的 key 数小于等于 5，当前这个 DB 则清理完毕，然后继续轮询下一个 DB。</p><p>在执行 serverCron 时，如果在某个 DB 中，过期 dict 的填充率低于 1%，则放弃对该 DB 的取样检查，因为效率太低。如果 DB 的过期 dict 中，过期 key 太多，一直持续循环回收，会占用大量主线程时间，所以 Redis 还设置了一个过期时间。这个过期时间根据 serverCron 的执行频率来计算，5.0 版本及之前采用慢循环过期策略，默认是 25ms，如果回收超过 25ms 则停止，6.0 非稳定版本采用快循环策略，过期时间为 1ms。</p></li><li><p>第二种场景，Redis 在执行命令请求时。会检查当前内存占用是否超过 maxmemory 的数值，如果超过，则按照设置的淘汰策略，进行删除淘汰 key 操作。</p></li></ul><h2 id="淘汰方式"><a href="#淘汰方式" class="headerlink" title="淘汰方式"></a>淘汰方式</h2><p>Redis 中 key 的淘汰方式有两种，分别是同步删除淘汰和异步删除淘汰。</p><p><strong>异步删除淘汰：</strong>在 serverCron 定期清理过期 key 时，如果设置了延迟过期配置 lazyfree-lazy-expire，会检查 key 对应的 value 是否为多元素的复合类型，即是否是 list 列表、set 集合、zset 有序集合和 hash 中的一种，并且 value 的元素数大于 64，则在将 key 从 DB 中 expire dict 过期字典和主 dict 中删除后，value 存放到 BIO 任务队列，由 BIO 延迟删除线程异步回收；</p><p><strong>同步删除淘汰：</strong>否则，直接从 DB 的 expire dict 和主 dict 中删除，并回收 key、value 所占用的空间。</p><h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><p>Redis 提供了 8 种 maxmemory_policy 淘汰策略来应对内存超过阀值的情况。</p><p>第一种淘汰策略是 noeviction，它是 Redis 的默认策略。在内存超过阀值后，Redis 不做任何清理工作，然后对所有写操作返回错误，但对读请求正常处理。noeviction 适合数据量不大的业务场景，将关键数据存入 Redis 中，将 Redis 当作 DB 来使用。</p><p>第二种淘汰策略是 volatile-lru，它对带过期时间的 key 采用最近最少访问算法来淘汰。使用这种策略，Redis 会从 redisDb 的 expire dict 过期字典中，首先随机选择 N 个 key，计算 key 的空闲时间，然后插入 evictionPool 中，最后选择空闲时间最久的 key 进行淘汰。这种策略适合的业务场景是，需要淘汰的key带有过期时间，且有冷热区分，从而可以淘汰最久没有访问的key。</p><p>第三种策略是 volatile-lfu，它对带过期时间的 key 采用最近最不经常使用的算法来淘汰。使用这种策略时，Redis 会从 redisDb 中的 expire dict 过期字典中，首先随机选择 N 个 key，然后根据其 value 的 lru 值，计算 key 在一段时间内的使用频率相对值。对于 lfu，要选择使用频率最小的 key，为了沿用 evictionPool 的 idle 概念，Redis 在计算 lfu 的 Idle 时，采用 255 减去使用频率相对值，从而确保 Idle 最大的 key 是使用次数最小的 key，计算 N 个 key 的 Idle 值后，插入 evictionPool，最后选择 Idle 最大，即使用频率最小的 key，进行淘汰。这种策略也适合大多数 key 带过期时间且有冷热区分的业务场景。</p><p>第四种策略是 volatile-ttl，它是对带过期时间的 key 中选择最早要过期的 key 进行淘汰。使用这种策略时，Redis 也会从 redisDb 的 expire dict 过期字典中，首先随机选择 N 个 key，然后用最大无符号 long 值减去 key 的过期时间来作为 Idle 值，计算 N 个 key 的 Idle 值后，插入evictionPool，最后选择 Idle 最大，即最快就要过期的 key，进行淘汰。这种策略适合，需要淘汰的key带过期时间，且有按时间冷热区分的业务场景。</p><p>第五种策略是 volatile-random，它是对带过期时间的 key 中随机选择 key 进行淘汰。使用这种策略时，Redis 从 redisDb 的 expire dict 过期字典中，随机选择一个 key，然后进行淘汰。如果需要淘汰的key有过期时间，没有明显热点，主要被随机访问，那就适合选择这种淘汰策略。</p><p>第六种策略是 allkey-lru，它是对所有 key，而非仅仅带过期时间的 key，采用最近最久没有使用的算法来淘汰。这种策略与 volatile-lru 类似，都是从随机选择的 key 中，选择最长时间没有被访问的 key 进行淘汰。区别在于，volatile-lru 是从 redisDb 中的 expire dict 过期字典中选择 key，而 allkey-lru 是从所有的 key 中选择 key。这种策略适合，需要对所有 key 进行淘汰，且数据有冷热读写区分的业务场景。</p><p><img src="https://i0.hdslb.com/bfs/article/4e748a17cf32172b6cb126927350db7e171301454.png" alt="image-20250226170831894"></p><p>第七种策略是 allkeys-lfu，它也是针对所有 key 采用最近最不经常使用的算法来淘汰。这种策略与 volatile-lfu 类似，都是在随机选择的 key 中，选择访问频率最小的 key 进行淘汰。区别在于，volatile-flu从expire dict 过期字典中选择 key，而 allkeys-lfu 是从主 dict 中选择 key。这种策略适合的场景是，需要从所有的 key 中进行淘汰，但数据有冷热区分，且越热的数据访问频率越高。</p><p>最后一种策略是 allkeys-random，它是针对所有 key 进行随机算法进行淘汰。它也是从主 dict 中随机选择 key，然后进行删除回收。如果需要从所有的 key 中进行淘汰，并且 key 的访问没有明显热点，被随机访问，即可采用这种策略。</p><h1 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h1><p>Redis 的持久化是通过 RDB 和 AOF 文件进行的。</p><ul><li>RDB 只记录某个时间点的快照，可以通过设置指定时间内修改 keys 数的阀值，超过则自动构建 RDB 内容快照，不过线上运维，一般会选择在业务低峰期定期进行。RDB 存储的是构建时刻的数据快照，内存数据一旦落地，不会理会后续的变更。</li><li>AOF，记录是构建整个数据库内容的命令，它会随着新的写操作不断进行追加操作。由于不断追加，AOF 会记录数据大量的中间状态，AOF 文件会变得非常大，此时，可以通过 bgrewriteaof 指令，对 AOF 进行重写，只保留数据的最后内容，来大大缩减 AOF 的内容。</li></ul><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>触发构建 RDB 的场景主要有以下四种。</p><ol><li>第一种场景是通过 save 或 bgsave 命令进行主动 RDB 快照构建。它是由调用方调用 save 或 bgsave 指令进行触发的。</li><li>第二种场景是利用配置 save m n 来进行自动快照生成。它是指在 m 秒中，如果插入或变更 n 个 key，则自动触发 bgsave。这个配置可以设置多个配置行，以便组合使用。由于峰值期间，Redis 的压力大，变更的 key 也比较多，如果再进行构建 RDB 的操作，会进一步增加机器负担，对调用方请求会有一定的影响，所以线上使用时需要谨慎。</li><li>第三种场景是主从复制，如果从库需要进行全量复制，此时主库也会进行 bgsave 生成一个 RDB 快照。</li><li>第四种场景是在运维执行 flushall 清空所有数据，或执行 shutdown 关闭服务时，也会触发 Redis 自动构建 RDB 快照。</li></ol><p>save 是在主进程中进行 RDB 持久化的，持久化期间 Redis 处于阻塞状态，不处理任何客户请求，所以一般使用较少。而 bgsave 是 fork 一个子进程，然后在子进程中构建 RDB 快照，构建快照的过程不直接影响用户的访问，但仍然会增加机器负载。线上 Redis 快照备份，一般会选择凌晨低峰时段，通过 bgsave 主动触发进行备份。</p><p>RDB 快照文件主要由 3 部分组成。</p><ol><li>第一部分是 RDB 头部，主要包括 RDB 的版本，以及 Redis 版本、创建日期、占用内存等辅助信息。</li><li>第二部分是各个 RedisDB 的数据。存储每个 RedisDB 时，会首先记录当前 RedisDB 的DBID，然后记录主 dict 和 expire dict 的记录数量，最后再轮询存储每条数据记录。存储数据记录时，如果数据有过期时间，首先记录过期时间。如果 Redis 的 maxmemory_policy 过期策略采用 LRU 或者 LFU，还会将 key 对应的 LRU、LFU 值进行落地，最后记录数据的类型、key，以及 value。</li><li>第三部部分是 RDB 的尾部。RDB 尾部，首先存储 Redis 中的 Lua 脚本等辅助信息。然后存储 EOF 标记，即值为 255 的字符。最后存 RDB 的 cksum。</li></ol><p>RDB 采用二进制方式存储内存数据，文件小，且启动时恢复速度快。但构建 RDB 时，一个快照文件只能存储，构建时刻的内存数据，无法记录之后的数据变更。构建 RDB 的过程，即便在子进程中进行，但仍然属于 CPU 密集型的操作，而且每次落地全量数据，耗时也比较长，不能随时进行，特别是不能在高峰期进行。由于 RDB 采用二进制存储，可读性差，而且由于格式固定，不同版本之间可能存在兼容性问题。</p><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><p>Redis 的 AOF 持久化是以命令追加的方式进行数据落地的。通过打开 appendonly 配置，Redis 将每一个写指令追加到磁盘 AOF 文件，从而及时记录内存数据的最新状态。这样即便 Redis 被 crash 或异常关闭后，再次启动，也可以通过加载 AOF，来恢复最新的全量数据，基本不会丢失数据。</p><p>AOF 文件中存储的协议是写指令的 multibulk 格式，这是 Redis 的标准协议格式，所以不同的 Redis 版本均可解析并处理，兼容性很好。</p><p>但是，由于 Redis 会记录所有写指令操作到 AOF，大量的中间状态数据，甚至被删除的过期数据，都会存在 AOF 中，冗余度很大，而且每条指令还需通过加载和执行来进行数据恢复，耗时会比较大。</p><p>AOF 数据的落地流程如下。Redis 在处理完写指令后，首先将写指令写入 AOF 缓冲，然后通过 server_cron 定期将 AOF 缓冲写入文件缓冲。最后按照配置策略进行 fsync，将文件缓冲的数据真正同步写入磁盘。</p><p><img src="https://i0.hdslb.com/bfs/article/8432570784b531c74bc5418d935c0abc171301454.png" alt="image-20250303101943498"></p><p>Redis 通过 appendfsync 来设置三种不同的同步文件缓冲策略。</p><ol><li>第一种配置策略是 no，即 Redis 不主动使用 fsync 进行文件数据同步落地，而是由操作系统的 write 函数去确认同步时间，在 Linux 系统中大概每 30 秒会进行一次同步，如果 Redis 发生 crash，就会造成大量的数据丢失。</li><li>第二种配置策略是 always，即每次将 AOF 缓冲写入文件，都会调用 fsync 强制将内核数据写入文件，安全性最高，但性能上会比较低效，而且由于频繁的 IO 读写，磁盘的寿命会大大降低。</li><li>第三种配置策略是 everysec。即每秒通过 BIO 线程进行一次 fsync。这种策略在安全性、性能，以及磁盘寿命之间做较好的权衡，可以较好的满足线上业务需要。</li></ol><p>随着时间的推移，AOF 持续记录所有的写指令，AOF 会越来越大，而且会充斥大量的中间数据、过期数据，为了减少无效数据，提升恢复时间，可以定期对 AOF 进行 rewrite 操作。</p><p>AOF 的 rewrite 操作可以通过运维执行 bgrewiretaof 命令来进行，也可以通过配置重写策略进行，由 Redis 自动触发进行。当对 AOF 进行 rewrite 时，首先会 fork 一个子进程。子进程轮询所有 RedisDB 快照，将所有内存数据转为 cmd，并写入临时文件。在子进程 rewriteaof 时，主进程可以继续执行用户请求，执行完毕后将写指令写入旧的 AOF 文件和 rewrite 缓冲。子进程将 RedisDB 中数据落地完毕后，通知主进程。主进程从而将 AOF rewite 缓冲数据写入 AOF 临时文件，然后用新的 AOF 文件替换旧的 AOF 文件，最后通过 BIO 线程异步关闭旧的 AOF 文件。至此，AOF 的 rewrite 过程就全部完成了。</p><p>AOF 持久化的优势是可以记录全部的最新内存数据，最多也就是 1-2 秒的数据丢失。同时 AOF 通过 Redis 协议来追加记录数据，兼容性高，而且可以持续轻量级的保存最新数据。最后因为是直接通过 Redis 协议存储，可读性也比较好。</p><h2 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h2><p>Redis 在 4.0 版本之后，引入了混合持久化方式，而且在 5.0 版本后默认开启。前面讲到 RDB 加载速度快，但构建慢，缺少最新数据。AOF 持续追加最新写记录，可以包含所有数据，但冗余大，加载速度慢。混合模式一体化使用 RDB 和 AOF，综合 RDB 和 AOF 的好处。即可包含全量数据，加载速度也比较快。可以使用 aof-use-rdb-preamble 配置来明确打开混合持久化模式。</p><p>混合持久化也是通过 bgrewriteaof 来实现的。当启用混合存储后，进行 bgrewriteaof 时，主进程首先依然是 fork 一个子进程，子进程首先将内存数据以 RDB 的二进制格式写入 AOF 临时文件中。然后，再将落地期间缓冲的新增写指令，以命令的方式追加到临时文件。然后再通知主进程落地完毕。主进程将临时文件修改为 AOF 文件，并关闭旧的 AOF 文件。这样主体数据以 RDB 格式存储，新增指令以命令方式追加的混合存储方式进行持久化。后续执行的任务，以正常的命令方式追加到新的 AOF 文件即可。</p><p>混合持久化综合了 RDB 和 AOF 的优缺点，优势是包含全量数据，加载速度快。不足是头部的 RDB 格式兼容性和可读性较差。</p><p><img src="https://i0.hdslb.com/bfs/article/e866239a20926c53ef4056bc353957b2171301454.png" alt="image-20250226175656070"></p><p>为了提升系统的可扩展性，提升读操作的支撑能力，Redis 支持 master-slave 的复制功能。当 Redis 的 slave 部署并设置完毕后，slave 会和 master 建立连接，进行全量同步。</p><p>第一次建立连接，或者长时间断开连接后，缺失的指令超过 master 复制缓冲区的大小，都需要先进行一次全量同步。全量同步时，master 会启动一个子进程，将数据库快照保存到文件中，然后将这个快照文件发给 slave，同时将快照之后的写指令也同步给 slave。</p><p>全量同步完成后，如果 slave 短时间中断，然后重连复制，缺少的写指令长度小于 master 的复制缓冲大小，master 就会把 slave 缺失的内容全部发送给 slave，进行增量复制。</p><p>Redis 的 master 可以挂载多个 slave，同时 slave 还可以继续挂载 slave，通过这种方式，可以有效减轻 master 的压力，同时在 master 挂掉后，可以在 slave 通过 slaveof no one 指令，使当前 slave 停止与 master 的同步，转而成为新的 master。</p><h1 id="Redis高性能"><a href="#Redis高性能" class="headerlink" title="Redis高性能"></a>Redis高性能</h1><p>Redis 性能很高，单线程压测可以达到 10~11w 的 QPS。</p><p>Redis 一般被看作单进程&#x2F;单线程组件，因为 Redis 的网络 IO 和命令处理，都在核心进程中由单线程处理。Redis 基于 Epoll 事件模型开发，可以进行非阻塞网络 IO，同时由于单线程命令处理，整个处理过程不存在竞争，不需要加锁，没有上下文切换开销，所有数据操作都是在内存中操作，所以 Redis 的性能很高，单个实例即可以达到 10w 级的 QPS。核心线程除了负责网络 IO 及命令处理外，还负责写数据到缓冲，以方便将最新写操作同步到 AOF、slave。</p><ul><li>收到 bgrewriteaof 命令时，Redis 调用 fork，构建一个子进程，子进程往临时 AOF文件中，写入重建数据库状态的所有命令，当写入完毕，子进程则通知父进程，父进程把新增的写操作也追加到临时 AOF 文件，然后将临时文件替换老的 AOF 文件，并重命名。</li><li>收到 bgsave 命令时，Redis 构建子进程，子进程将内存中的所有数据通过快照做一次持久化落地，写入到 RDB 中。</li><li>当需要进行全量复制时，master 也会启动一个子进程，子进程将数据库快照保存到 RDB 文件，在写完 RDB 快照文件后，master 就会把 RDB 发给 slave，同时将后续新的写指令都同步给 slave。</li></ul><p><img src="https://i0.hdslb.com/bfs/article/0f0427bdab6125719ce8e29d27fef000171301454.png" alt="image-20250224103803951"></p><p>主进程中，除了主线程处理网络 IO 和命令操作外，还有 3 个辅助 BIO 线程。这 3 个 BIO 线程分别负责处理，文件关闭、AOF 缓冲数据刷新到磁盘，以及清理对象这三个任务队列。这是一个生产-消费模型，一般都是由主线程生产慢任务，放到处理队列中，BIO线程充当消费者来消费任务。</p><p>Redis 在启动时，会同时启动这三个 BIO 线程，然后 BIO 线程休眠等待任务。当需要执行相关类型的后台任务时，就会构建一个 bio_job 结构，记录任务参数，然后将 bio_job 追加到任务队列尾部。然后唤醒 BIO 线程，即可进行任务执行。</p><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>Redis 6.0 的多线程处理流程如下图所示。主线程负责监听端口，注册连接读事件，当有新连接进入时，主线程accept新连接，创建client，并为新连接注册请求读事件。</p><p><img src="https://i0.hdslb.com/bfs/article/d5ce44917fa00607ba06aa02c3964deb171301454.png" alt="image-20250307101658118"></p><h1 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a>Redis主从复制</h1><h2 id="Redis复制原理"><a href="#Redis复制原理" class="headerlink" title="Redis复制原理"></a>Redis复制原理</h2><p>通过数据复制，Redis 的一个 master 可以挂载多个 slave，而 slave 下还可以挂载多个 slave，形成多层嵌套结构。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/32d1c9e07f517779764407af4bd2ffb006f66271.png" alt="image-20250709141026195"></p><p>master 在分发写请求时，同时会将写指令复制一份存入复制积压缓冲，这样当 slave 短时间断开重连时，只要 slave 的复制位置点仍然在复制积压缓冲，则可以从之前的复制位置点之后继续进行复制，提升复制效率。</p><h2 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h2><p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e94fdd5b2c39197abfaeeb8eda4bf8e05c1a2ce6.png" alt="image-20250709141146570"></p><p>但是，在监控和选主这两个任务中，哨兵需要做出两个决策：</p><ul><li>在监控任务中，哨兵需要判断主库是否处于下线状态；</li><li>在选主任务中，哨兵也要决定选择哪个从库实例作为主库。</li></ul><h3 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h3><p><strong>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态</strong>。如果哨兵发现<strong>从库</strong>对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。</p><p><strong>而主库的下线，通常会采用哨兵集群（多实例组成的集群模式进行部署）判断</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/716bf87a3b237d7fd245471a3d8d05a7903d8f2f.png" alt="image-20250709141158788"></p><p>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）。</p><h3 id="选定新主库"><a href="#选定新主库" class="headerlink" title="选定新主库"></a>选定新主库</h3><p>筛选条件：判断从库之前的网络连接状态，检查从库当前的在线状态。</p><p>打分条件：</p><ul><li><strong>第一轮：优先级最高的从库得分高。</strong>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。</li><li><strong>第二轮：和旧主库同步程度最接近的从库得分高。</strong>从库的复制位点离旧主库的复制进度最近。</li><li><strong>第三轮：ID 号小的从库得分高。</strong></li></ul><h4 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h4><p>脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。</p><ol><li>和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。</li><li>主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap（物理机器内存不足），短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。</li></ol><p>Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。</p><ul><li>min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；</li><li>min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。</li></ul><p>有了这两个配置项后，我们就可以轻松地应对脑裂问题了。</p><p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h1 id="Redis集群管理"><a href="#Redis集群管理" class="headerlink" title="Redis集群管理"></a>Redis集群管理</h1><p>Redis 的集群管理有 3 种方式。</p><ul><li><p>client 分片访问，client 对 key 做 hash，然后按取模或一致性 hash，把 key 的读写分散到不同的 Redis 实例上。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8ffa5dc03351ad6983d5f9c1dc23ef3304a75bf0.png" alt="image-20250709141214450"></p></li><li><p>proxy端分区，在 Redis 前加一个 proxy，把路由策略、后端 Redis 状态维护的工作都放到 proxy 中进行，client 直接访问 proxy，后端 Redis 变更，只需修改 proxy 配置即可。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/28ed197a1da98de17944dd059088d8754800346c.png" alt="image-20250709141239383"></p></li><li><p>直接使用 Redis cluster。Redis 创建之初，使用方直接给 Redis 的节点分配 slot，后续访问时，对 key 做 hash 找到对应的 slot，然后访问 slot 所在的 Redis 实例。在需要扩容缩容时，可以在线通过 cluster setslot 指令，以及 migrate 指令，将 slot 下所有 key 迁移到目标节点，即可实现扩缩容的目的。</p></li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/b2d396db5857a6815dee9624d3545b47b169b311.png" alt="image-20250709141228028"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis简介&quot;&gt;&lt;a href=&quot;#Redis简介&quot; class=&quot;headerlink&quot; title=&quot;Redis简介&quot;&gt;&lt;/a&gt;Redis简介&lt;/h1&gt;&lt;p&gt;Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组</summary>
      
    
    
    
    <category term="缓存" scheme="https://palette-k.github.io/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>缓存的基本思想</title>
    <link href="https://palette-k.github.io/2025/02/17/%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/"/>
    <id>https://palette-k.github.io/2025/02/17/%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/</id>
    <published>2025-02-17T10:00:02.000Z</published>
    <updated>2025-10-13T03:33:56.397Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存的基本思想"><a href="#缓存的基本思想" class="headerlink" title="缓存的基本思想"></a>缓存的基本思想</h1><p>空间换时间。</p><p>缓存中的数据通常存储于内存中，因此访问速度非常快。为了避免内存中的数据在重启或者宕机之后丢失，很多缓存中间件会利用磁盘做持久化。</p><p>缓存相比较于我们常用的关系型数据库来说访问速度要快非常多，为了避免用户请求数据库中的数据速度过于缓慢，我们可以在数据库之上增加一层缓存。</p><p>除了能提高访问速度之外，缓存支持的并发量也要大。有了缓存后，数据库的压力也会随之变小。</p><h1 id="缓存的分类"><a href="#缓存的分类" class="headerlink" title="缓存的分类"></a>缓存的分类</h1><h2 id="本地缓存"><a href="#本地缓存" class="headerlink" title="本地缓存"></a>本地缓存</h2><p><img src="https://i0.hdslb.com/bfs/article/05ae15dcc71bb5e395ccd2aee0c5437c171301454.png" alt="Pasted image 20221215181540"><br><strong>本地缓存的方案</strong></p><ol><li>JDK 自带的 HashMap 和 ConcurrentHashMap</li></ol><ul><li>ConcurrentHashMap 是线程安全版本的 HashMap，大部分场景不会使用这两者做缓存，因为只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能。</li></ul><ol start="2"><li>Ehcache、Guava Cache、Spring Cache 比较常用的本地缓存框架</li></ol><ul><li>Ehcache 比其他两者更重量。Ehcache 可以嵌入到 Hibernate 和 MyBatis 作为多级缓存，并且可以将缓存的数据持久化到本地磁盘中</li><li>Guava Cache 和 Spring Cache 两者比较像。Guava 使用更多一点，提供了 API 方便使用，也提供了设置缓存有效时间等功能。</li><li>使用 Spring Cache 注解实现缓存，代码会看着干净优雅，但是很容易出现缓存穿透、内存溢出等问题。</li></ul><ol start="3"><li>Caffeine</li></ol><ul><li>一般建议替代 Guava</li></ul><p>本地缓存缺陷：</p><ul><li>当同一个相同服务部署到多台机器上时，各个服务之间的缓存无法共享，因为本地缓存在当前机器</li><li>如果当前系统服务所耗费的内存多，那么本地缓存可用的容量就很少</li></ul><h2 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h2><p><img src="https://i0.hdslb.com/bfs/article/2a4d9ea416e4a24215f7c89f422c7486171301454.png" alt="Pasted image 20221215181816"><br>使用分布式缓存后，缓存服务可以部署在一台单独的服务器上，即使同一个相同的服务部署在多台机器上，也是使用的同一份缓存。并且，单独的分布式缓存服务的性能、容量和提供的功能都更加强大。</p><h1 id="常见的缓存更新策略"><a href="#常见的缓存更新策略" class="headerlink" title="常见的缓存更新策略"></a>常见的缓存更新策略</h1><h2 id="Cache-Aside-Pattern-旁路缓存模式"><a href="#Cache-Aside-Pattern-旁路缓存模式" class="headerlink" title="Cache Aside Pattern 旁路缓存模式"></a>Cache Aside Pattern 旁路缓存模式</h2><p>Cache Aside Pattern 比较适合读请求比较多的场景。服务端需要同时维系数据库和缓存，以 db 的结果为准。</p><p>写：<br><img src="https://i0.hdslb.com/bfs/article/cd5c0c1a5a9957ea0012ca938d12a9b4171301454.png" alt="Pasted image 20221216124739"></p><blockquote><p>为什么要删除cache，而不是更新cache?</p></blockquote><p><strong>原因：</strong><br>1.对服务端资源造成浪费：删除cache更直接，因为cache中存放的一些数据需要通过服务端经过大量的计算才能得出，会消耗服务端的资源。如果频繁修改db，就会导致频繁更新cache，而cache中的数据可能没有被访问到。<br>2.产生数据不一致的情况：并发场景下，更新cache产生数据不一致的概率会更大。</p><blockquote><p><strong>可以先删除 cache 后更新 db 吗？</strong></p></blockquote><p>不行，会造成数据不一致的情况。</p><ol><li>请求1先删除 cache 中的 A 数据</li><li>请求2从 db 中读取数据</li><li>请求1再把 db 中的 A 数据更新</li><li>导致请求2读取到的 A 数据就是旧值</li></ol><blockquote><p><strong>在写数据过程中，先更新 db，后删除 cache 就没问题了吗？</strong></p></blockquote><p>不一定，有可能会产生数据不一致的问题。</p><ol><li>请求1从 db 读取数据 A</li><li>请求2更新 db 中的数据 A（此时缓存中没有数据A，不需要删除）</li><li>请求1将数据A写入cache</li><li>导致cache中存放的是旧值</li></ol><p>读：<br><img src="https://i0.hdslb.com/bfs/article/a41e75b82d5b209db3af29f1e7e2061e171301454.png" alt="Pasted image 20221216124806"></p><p><strong>Cache Aside Pattern 缺陷及解决方案</strong></p><p>缺陷1：首次请求数据一定不在cache中：可以将热点数据提前放入cache中</p><p>缺陷2：写操作比较频繁导致cache中的数据会被频繁地删除，这样会影响缓存命中率</p><ul><li><p>数据库和缓存数据强一致场景：更新db的时候同样更新cache，不过需要加一个锁&#x2F;分布式锁来保证更新cache的时候不存在线程安全问题</p></li><li><p>可以短暂允许数据库与缓存数据不一致的场景：更新db的时候同样更新cache,但是给缓存一个较短的过期时间，这样可以保证即使数据不一致，影响也比较小。</p></li></ul><h2 id="Read-Write-Through-读写穿透"><a href="#Read-Write-Through-读写穿透" class="headerlink" title="Read&#x2F;Write Through 读写穿透"></a>Read&#x2F;Write Through 读写穿透</h2><p>对于 Cache Aside 模式，业务应用需要同时维护 cache 和 DB 两个数据存储方，过于繁琐，于是就有了 Read&#x2F;Write Through 模式。</p><p>在这种模式下，业务应用只关注一个存储服务即可，业务方的读写 cache 和 DB 的操作，都由存储服务代理。存储服务收到业务应用的写请求时，会首先查 cache，如果数据在 cache 中不存在，则只更新 DB，如果数据在 cache 中存在，则先更新 cache，然后更新 DB。而存储服务收到读请求时，如果命中 cache 直接返回，否则先从 DB 加载，回种到 cache 后返回响应。</p><p>这种模式的特点是，存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。另外，进行写操作时，如果 cache 中没有数据则不更新，有缓存数据才更新，内存效率更高。</p><p>微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。</p><h2 id="Write-Behind-Pattern-异步缓存写入"><a href="#Write-Behind-Pattern-异步缓存写入" class="headerlink" title="Write Behind Pattern 异步缓存写入"></a>Write Behind Pattern 异步缓存写入</h2><p>只更新缓存，不直接更新 db，而是改为异步批量的方式更新 db</p><p>消息队列中消息的异步写入磁盘、Mysql 的 InnoDB Buffer Pool 机制都用到了这种策略</p><p>Write Pool Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、阅读量。</p><p>该模式的特点是，数据存储的写性能最高，非常适合一些变更特别频繁的业务，特别是可以合并写请求的业务，比如对一些计数业务，一条 Feed 被点赞 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。</p><p>但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。比如系统 Crash、机器宕机时，如果有数据还没保存到 DB，则会存在丢失的风险。所以这种读写模式适合变更频率特别高，但对一致性要求不太高的业务，这样写操作可以异步批量写入 DB，减小 DB 压力。</p><h1 id="缓存失效"><a href="#缓存失效" class="headerlink" title="缓存失效"></a>缓存失效</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>缓存里的数据存储基本上都是以 key 为索引进行存储和获取的。业务访问时，如果大量的 key 同时过期，很多缓存数据访问都会 miss，进而穿透到 DB，DB 的压力就会明显上升，由于 DB 的性能较差，只在缓存的 1%~2% 以下，这样请求的慢查率会明显上升。这就是缓存失效的问题。</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>导致缓存失效，特别是很多 key 一起失效的原因，跟我们日常写缓存的过期时间息息相关。</p><p>在某些场景，一大批数据会被系统主动或被动从 DB 批量加载，然后写入缓存。这些数据写入缓存时，由于使用相同的过期时间，在经历这个过期时间之后，这批数据就会一起到期，从而被缓存淘汰。此时，对这批数据的所有请求，都会出现缓存失效，从而都穿透到 DB，DB 由于查询量太大，就很容易压力大增，请求变慢。</p><h2 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h2><p>同一批火车票、飞机票，当可以售卖时，系统会一次性加载到缓存，如果缓存写入时，过期时间按照预先设置的过期值，那过期时间到期后，系统就会因缓存失效出现变慢的问题。</p><p>微博业务，会有后台离线系统，持续计算热门微博，每当计算结束，会将这批热门微博批量写入对应的缓存。</p><p>很多业务，在部署新 IDC 或新业务上线时，会进行缓存预热，也会一次性加载大批热数据。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>设计缓存的过期时间时，使用公式：过期时间&#x3D;baes 时间+随机时间。</p><p>即相同业务数据写缓存时，在基础过期时间之上，再加一个随机的过期时间，让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对 DB 造成过大压力。</p><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h2><p>缓存穿透发生的概率很低，所以一般很难被发现。但是，一旦你发现了，而且量还不小，你可能立即就会经历一个忙碌的夜晚。</p><p>缓存穿透，则意味着有特殊访客在查询一个不存在的 key，导致每次查询都会穿透到 DB，如果这个特殊访客再控制一批肉鸡机器，持续访问你系统里不存在的 key，就会对 DB 产生很大的压力，从而影响正常服务。</p><h2 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h2><p>缓存穿透存在的原因，就是因为我们在系统设计时，更多考虑的是正常访问路径，对特殊访问路径、异常访问路径考虑相对欠缺。</p><p>缓存访问设计的正常路径，是先访问 cache，cache miss 后查 DB，DB 查询到结果后，回种缓存返回。这对于正常的 key 访问是没有问题的，但是如果用户访问的是一个不存在的 key，查 DB 返回空（即一个 NULL），那就不会把这个空写回cache。那以后不管查询多少次这个不存在的 key，都会 cache miss，都会查询 DB。整个系统就会退化成一个“前端+DB“的系统，由于 DB 的吞吐只在 cache 的 1%~2% 以下，如果有特殊访客，大量访问这些不存在的 key，就会导致系统的性能严重退化，影响正常用户的访问。</p><h2 id="业务场景-1"><a href="#业务场景-1" class="headerlink" title="业务场景"></a>业务场景</h2><p>缓存穿透的业务场景很多，比如通过不存在的 UID 访问用户，通过不存在的车次 ID 查看购票信息。用户输入错误，偶尔几个这种请求问题不大，但如果是大量这种请求，就会对系统影响非常大。</p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><ul><li>第一种方案就是，查询这些不存在的数据时，第一次查 DB，虽然没查到结果返回 NULL，仍然记录这个 key 到缓存，只是这个 key 对应的 value 是一个特殊设置的值。</li><li>第二种方案是，构建一个 BloomFilter 缓存过滤器，记录全量数据，这样访问数据时，可以直接通过 BloomFilter 判断这个 key 是否存在，如果不存在直接返回即可，根本无需查缓存和 DB。</li></ul><p>不过这两种方案在设计时仍然有一些要注意的坑。</p><ul><li>对于方案一，如果特殊访客持续访问大量的不存在的 key，这些 key 即便只存一个简单的默认值，也会占用大量的缓存空间，导致正常 key 的命中率下降。所以进一步的改进措施是，对这些不存在的 key 只存较短的时间，让它们尽快过期；或者将这些不存在的 key 存在一个独立的公共缓存，从缓存查找时，先查正常的缓存组件，如果 miss，则查一下公共的非法 key 的缓存，如果后者命中，直接返回，否则穿透 DB，如果查出来是空，则回种到非法 key 缓存，否则回种到正常缓存。</li><li>对于方案二，BloomFilter 要缓存全量的 key，这就要求全量的 key 数量不大，10亿 条数据以内最佳，因为 10亿 条数据大概要占用 1.2GB 的内存。也可以用 BloomFilter 缓存非法 key，每次发现一个 key 是不存在的非法 key，就记录到 BloomFilter 中，这种记录方案，会导致 BloomFilter 存储的 key 持续高速增长，为了避免记录 key 太多而导致误判率增大，需要定期清零处理。</li></ul><h3 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h3><p>BloomFilter 是一个非常有意思的数据结构，不仅仅可以挡住非法 key 攻击，还可以低成本、高性能地对海量数据进行判断，比如一个系统有数亿用户和百亿级新闻 feed，就可以用 BloomFilter 来判断某个用户是否阅读某条新闻 feed。下面来对 BloomFilter 数据结构做一个分析，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/article/bc779ec51bf9095b1365e6bcde13d8dd171301454.png" alt="image-20250218114027598"></p><p>BloomFilter 的目的是检测一个元素是否存在于一个集合内。它的原理，是用 bit 数据组来表示一个集合，对一个 key 进行多次不同的 Hash 检测，如果所有 Hash 对应的 bit 位都是 1，则表明 key 非常大概率存在，平均单记录占用 1.2 字节即可达到 99%，<strong>只要有一次 Hash 对应的 bit 位是 0，就说明这个 key 肯定不存在于这个集合内。</strong></p><p><strong>BloomFilter 的算法：</strong></p><ul><li><p>首先分配一块内存空间做 bit 数组，数组的 bit 位初始值全部设为 0。</p></li><li><p>加入元素时，采用 k 个相互独立的 Hash 函数计算，然后将元素 Hash 映射的 K 个位置全部设置为 1。</p></li><li><p>检测 key 时，仍然用这 k 个 Hash 函数计算出 k 个位置，如果位置全部为 1，则表明 key 存在，否则不存在。</p></li></ul><p><strong>BloomFilter 的优势：</strong>全内存操作，性能很高。空间效率非常高，要达到 1% 的误判率，平均单条记录占用 1.2 字节即可。而且，平均单条记录每增加 0.6 字节，还可让误判率继续变为之前的 1&#x2F;10，即平均单条记录占用 1.8 字节，误判率可以达到 1&#x2F;1000；平均单条记录占用 2.4 字节，误判率可以到 1&#x2F;10000，以此类推。这里的误判率是指，BloomFilter 判断某个 key 存在，但它实际不存在的概率，因为它存的是 key 的 Hash 值，而非 key 的值，所以有概率存在这样的 key，它们内容不同，但多次 Hash 后的 Hash 值都相同。对于 BloomFilter 判断不存在的 key ，则是 100% 不存在的，反证法，如果这个 key 存在，那它每次 Hash 后对应的 Hash 值位置肯定是 1，而不会是 0。</p><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h2><p>系统运行过程中，缓存雪崩是一个非常严重的问题。缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。缓存雪崩按照缓存是否 rehash（即是否漂移）分两种情况：</p><ul><li>缓存不支持 rehash 导致的系统雪崩不可用</li><li>缓存支持 rehash 导致的缓存雪崩不可用</li></ul><h2 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h2><ul><li><p>缓存不进行 rehash 时产生的雪崩，一般是由于较多缓存节点不可用，大量 Cache 访问会失败，根据缓存读写模型，这些请求会进一步访问 DB，而且 DB 可承载的访问量要远比缓存小的多，请求量过大，就很容易造成 DB 过载，大量慢查询，最终阻塞甚至 Crash，从而导致服务异常。</p></li><li><p>缓存支持 rehash 时产生的雪崩，则大多跟流量洪峰有关，流量洪峰到达，引发部分缓存节点过载 Crash，然后因 rehash 扩散到其他缓存节点，最终整个缓存体系异常。</p><p>在缓存分布设计时，很多同学会选择<strong>一致性 Hash 分布方式</strong>，同时在部分节点异常时，<strong>采用 rehash 策略</strong>，即把异常节点请求平均分散到其他缓存节点。在一般情况下，一致性 Hash 分布+rehash 策略可以很好得运行，但在较大的流量洪峰到临之时，如果大流量 key 比较集中，正好在某 1～2 个缓存节点，很容易将这些缓存节点的内存、网卡过载，缓存节点异常 Crash，然后这些异常节点下线，这些大流量 key 请求又被 rehash 到其他缓存节点，进而导致其他缓存节点也被过载 Crash，缓存异常持续扩散，最终导致整个缓存体系异常，无法对外提供服务。</p></li></ul><h2 id="业务场景-2"><a href="#业务场景-2" class="headerlink" title="业务场景"></a>业务场景</h2><p>微博最初很多业务缓存采用一致性 Hash+rehash 策略，在突发洪水流量来临时，部分缓存节点过载 Crash 甚至宕机，然后这些异常节点的请求转到其他缓存节点，又导致其他缓存节点过载异常，最终整个缓存池过载。</p><p>机架断电，导致业务缓存多个节点宕机，大量请求直接打到 DB，也导致 DB 过载而阻塞，整个系统异常。最后缓存机器复电后，DB 重启，数据逐步加热后，系统才逐步恢复正常。</p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>预防缓存雪崩，这里给出 3 个解决方案。</p><ul><li><p>方案一，对业务 DB 的访问增加读写开关，当发现 DB 请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读 DB 的请求进行 failfast 立即返回，待 DB 恢复后再打开读开关，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/9c10f297f7fc8bd7f4656efdd0f228c1171301454.png" alt="image-20250218115208783"></p></li><li><p>方案二，对缓存增加多个副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。</p></li><li><p>方案三，对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。</p></li></ul><p>实际上，微博平台系统，这三种方案都采用了，通过三管齐下，规避缓存雪崩的发生。</p><h1 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a>数据不一致</h1><h2 id="问题描述-3"><a href="#问题描述-3" class="headerlink" title="问题描述"></a>问题描述</h2><p>七大缓存经典问题的第四个问题是数据不一致。同一份数据，可能会同时存在 DB 和缓存之中。那就有可能发生，DB 和缓存的数据不一致。如果缓存有多个副本，多个缓存副本里的数据也可能会发生不一致现象。</p><h2 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h2><p>不一致的问题大多跟缓存更新异常有关。比如更新 DB 后，写缓存失败，从而导致缓存中存的是老数据。另外，如果系统采用一致性 Hash 分布，同时采用 rehash 自动漂移策略，在节点多次上下线之后，也会产生脏数据。缓存有多个副本时，更新某个副本失败，也会导致这个副本的数据是老数据。</p><h2 id="业务场景-3"><a href="#业务场景-3" class="headerlink" title="业务场景"></a>业务场景</h2><p>导致数据不一致的场景也不少。如下图所示，在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。</p><p><img src="https://i0.hdslb.com/bfs/article/5f7ad3c1eca3c42e545bc6b67849fa42171301454.png" alt="image-20250220181055343"></p><h2 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h2><p>要尽量保证数据的一致性。这里也给出了 3 个方案，可以根据实际情况进行选择。</p><ul><li>第一个方案，cache 更新失败后，可以进行重试，如果重试失败，则将失败的 key 写入队列机服务，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性。</li><li>第二个方案，缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。</li><li>第三个方案，不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。</li></ul><p><img src="https://i0.hdslb.com/bfs/article/91fc4102393e9273256f807ea4f3573f171301454.png" alt="image-20250220181337645"></p><h1 id="并发竞争"><a href="#并发竞争" class="headerlink" title="并发竞争"></a>并发竞争</h1><h2 id="问题描述-4"><a href="#问题描述-4" class="headerlink" title="问题描述"></a>问题描述</h2><p>第五个经典问题是数据并发竞争。互联网系统，线上流量较大，缓存访问中很容易出现数据并发竞争的现象。数据并发竞争，是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询 DB，导致 DB 压力大增的现象。</p><p>数据并发竞争，主要是由于多个进程&#x2F;线程中，有大量并发请求获取相同的数据，而这个数据 key 因为正好过期、被剔除等各种原因在缓存中不存在，这些进程&#x2F;线程之间没有任何协调，然后一起并发查询 DB，请求那个相同的 key，最终导致 DB 压力大增，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/3fd4eaf59fa5b9436128c4f9a04adf0a171301454.png" alt="image-20250220181533138"></p><h2 id="业务场景-4"><a href="#业务场景-4" class="headerlink" title="业务场景"></a>业务场景</h2><p>数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成该车次信息、该条微博存在并发竞争读取的问题。</p><h2 id="解决方案-4"><a href="#解决方案-4" class="headerlink" title="解决方案"></a>解决方案</h2><p>要解决并发竞争，有 2 种方案。</p><ul><li><p>方案一是使用全局锁。如下图所示，即当缓存请求 miss 后，先尝试加全局锁，只有加全局锁成功的线程，才可以到 DB 去加载数据。其他进程&#x2F;线程在读取缓存数据 miss 时，如果发现这个 key 有全局锁，就进行等待，待之前的线程将数据从 DB 回种到缓存后，再从缓存获取。</p><p><img src="https://i0.hdslb.com/bfs/article/5ed2a325de08e7c3a060d9c69ee193df171301454.png" alt="image-20250220182352733"></p></li><li><p>方案二是，对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/2b594cbc54242d55dd8619e00442780c171301454.png" alt="image-20250220181834329"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;缓存的基本思想&quot;&gt;&lt;a href=&quot;#缓存的基本思想&quot; class=&quot;headerlink&quot; title=&quot;缓存的基本思想&quot;&gt;&lt;/a&gt;缓存的基本思想&lt;/h1&gt;&lt;p&gt;空间换时间。&lt;/p&gt;
&lt;p&gt;缓存中的数据通常存储于内存中，因此访问速度非常快。为了避免内存中的数据在</summary>
      
    
    
    
    <category term="缓存" scheme="https://palette-k.github.io/categories/%E7%BC%93%E5%AD%98/"/>
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
    <category term="缓存" scheme="https://palette-k.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Java业务开发常见问题</title>
    <link href="https://palette-k.github.io/2025/02/07/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>https://palette-k.github.io/2025/02/07/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2025-02-07T10:00:02.000Z</published>
    <updated>2025-10-13T03:34:10.248Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spring-框架：IoC-和-AOP-是扩展的核心"><a href="#Spring-框架：IoC-和-AOP-是扩展的核心" class="headerlink" title="Spring 框架：IoC 和 AOP 是扩展的核心"></a>Spring 框架：IoC 和 AOP 是扩展的核心</h1><blockquote><p>当 Bean 产生循环依赖时，比如 BeanA 的构造方法依赖 BeanB 作为成员需要注入，BeanB 也依赖 BeanA，你觉得会出现什么问题呢？又有哪些解决方式呢？</p></blockquote><p>答：Bean 产生循环依赖，主要包括两种情况：一种是注入属性或字段涉及循环依赖，另一种是构造方法注入涉及循环依赖。接下来，我分别和你讲一讲。</p><p>第一种，注入属性或字段涉及循环依赖，比如 TestA 和 TestB 相互依赖：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestA</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestB testB;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestB</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestA testA;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对这个问题，Spring 内部通过三个 Map 的方式解决了这个问题，不会出错。基本原理是，因为循环依赖，所以实例的初始化无法一次到位，需要分步进行：</p><p>创建 A（仅仅实例化，不注入依赖）；</p><p>创建 B（仅仅实例化，不注入依赖）；</p><p>为 B 注入 A（此时 B 已健全）；</p><p>为 A 注入 B（此时 A 也健全）。</p><p>网上有很多相关的分析，我找了一篇比较详细的，可供你参考。</p><p>第二种，构造方法注入涉及循环依赖。遇到这种情况的话，程序无法启动，比如 TestC 和 TestD 的相互依赖：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestC</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestD testD;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestC</span><span class="params">(TestD testD)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testD = testD;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestD</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestC testC;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestD</span><span class="params">(TestC testC)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testC = testC;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种循环依赖的主要解决方式，有 2 种：</p><p>改为属性或字段注入；</p><p>使用 @Lazy 延迟注入。比如如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestC</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestD testD;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestC</span><span class="params">(<span class="meta">@Lazy</span> TestD testD)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testD = testD;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实，这种 @Lazy 方式注入的就不是实际的类型了，而是代理类，获取的时候通过代理去拿值（实例化）。所以，它可以解决循环依赖无法实例化的问题。</p><h1 id="数据库索引：索引并不是万能药"><a href="#数据库索引：索引并不是万能药" class="headerlink" title="数据库索引：索引并不是万能药"></a>数据库索引：索引并不是万能药</h1><blockquote><p>索引除了可以用于加速搜索外，还可以在排序时发挥作用，你能通过 EXPLAIN 来证明吗？你知道，针对排序在什么情况下，索引会失效吗？</p></blockquote><p>答：排序使用到索引，在执行计划中的体现就是 key 这一列。如果没有用到索引，会在 Extra 中看到 Using filesort，代表使用了内存或磁盘进行排序。而具体走内存还是磁盘，是由 sort_buffer_size 和排序数据大小决定的。</p><p>排序无法使用到索引的情况有：</p><ul><li><p>对于使用联合索引进行排序的场景，多个字段排序 ASC 和 DESC 混用；</p></li><li><p>a+b 作为联合索引，按照 a 范围查询后按照 b 排序；</p></li><li><p>排序列涉及到的多个字段不属于同一个联合索引；</p></li><li><p>排序列使用了表达式。</p></li></ul><h2 id="为什么联合索引无法优化排序"><a href="#为什么联合索引无法优化排序" class="headerlink" title="为什么联合索引无法优化排序"></a>为什么联合索引无法优化排序</h2><ul><li>联合索引 <code>(a, b)</code> 的设计是为了优化 <code>a</code> 列的查询和 <code>a</code> 列相同情况下的 <code>b</code> 列查询。</li><li>当 <code>a</code> 列是范围查询时，<code>b</code> 列的顺序在索引中被打乱，因此无法直接利用索引来优化 <code>b</code> 列的排序。</li></ul><p>如果需要对 <code>b</code> 列进行排序，同时又有 <code>a</code> 列的范围查询，可以考虑以下优化方法：</p><h3 id="方法-1：调整索引顺序"><a href="#方法-1：调整索引顺序" class="headerlink" title="方法 1：调整索引顺序"></a>方法 1：调整索引顺序</h3><ul><li>如果查询条件中 <code>b</code> 列的排序是必须的，可以尝试调整索引顺序为 <code>(b, a)</code>。</li><li>这样，MySQL 可以先按 <code>b</code> 列排序，然后再按 <code>a</code> 列过滤。但这种方法可能不适用于所有场景，具体取决于查询条件。</li></ul><h3 id="方法-2：覆盖索引"><a href="#方法-2：覆盖索引" class="headerlink" title="方法 2：覆盖索引"></a>方法 2：覆盖索引</h3><ul><li>如果查询只需要 <code>a</code> 和 <code>b</code> 列，可以创建一个覆盖索引 <code>(a, b)</code>，并确保查询只选择 <code>a</code> 和 <code>b</code> 列。</li><li>这样，MySQL 可以直接从索引中获取数据，而不需要回表查询，从而提高性能。</li></ul><h3 id="方法-3：拆分查询"><a href="#方法-3：拆分查询" class="headerlink" title="方法 3：拆分查询"></a>方法 3：拆分查询</h3><ul><li>如果数据量较大，可以将查询拆分为两步：<ol><li>先根据 <code>a</code> 列的范围条件查询出主键。</li><li>再根据主键查询数据，并对 <code>b</code> 列进行排序。</li></ol></li></ul><h1 id="数据源头：任何客户端的东西都不可信任"><a href="#数据源头：任何客户端的东西都不可信任" class="headerlink" title="数据源头：任何客户端的东西都不可信任"></a>数据源头：任何客户端的东西都不可信任</h1><blockquote><p>问题 1：在讲述用户标识不能从客户端获取这个要点的时候，我提到开发同学可能会因为用户信息未打通而通过前端来传用户 ID。那我们有什么好办法，来打通不同的系统甚至不同网站的用户标识吗？</p></blockquote><p>答：打通用户在不同系统之间的登录，大致有以下三种方案。</p><p>第一种，把用户身份放在统一的服务端，每一个系统都需要到这个服务端来做登录状态的确认，确认后在自己网站的 Cookie 中保存会话，这就是单点登录的做法。这种方案要求所有关联系统都对接一套中央认证服务器（中央保存用户会话），在未登录的时候跳转到中央认证服务器进行登录或登录状态确认。因此，这种方案适合一个公司内部的不同域名下的网站。</p><p>第二种，把用户身份信息直接放在 Token 中，在客户端任意传递，Token 由服务端进行校验（如果共享密钥话，甚至不需要同一个服务端进行校验），无需采用中央认证服务器，相对比较松耦合，典型的标准是 JWT。这种方案适合异构系统的跨系统用户认证打通，而且相比单点登录的方案，用户体验会更好一些。</p><p>第三种，如果需要打通不同公司系统的用户登录状态，那么一般都会采用 OAuth 2.0 的标准中的授权码模式，基本流程如下：</p><ul><li><p>第三方网站客户端转到授权服务器，上送 ClientID、重定向地址 RedirectUri 等信息。</p></li><li><p>用户在授权服务器进行登录并且进行授权批准（授权批准这步可以配置为自动完成）。</p></li><li><p>授权完成后，重定向回到之前客户端提供的重定向地址，附上授权码。</p></li><li><p>第三方网站服务端通过授权码 +ClientID+ClientSecret 去授权服务器换取 Token。这里的 Token 包含访问 Token 和刷新 Token，访问 Token 过期后用刷新 Token 去获得新的访问 Token。</p><p>因为我们不会对外暴露 ClientSecret，也不会对外暴露访问 Token，同时使用授权码换取 Token 的过程是服务端进行的，客户端拿到的只是一次性的授权码，所以这种模式比较安全。</p></li></ul><blockquote><p>问题 2：还有一类和客户端数据相关的漏洞非常重要，那就是 URL 地址中的数据。在把匿名用户重定向到登录页面的时候，我们一般会带上 redirectUrl，这样用户登录后可以快速返回之前的页面。黑客可能会伪造一个活动链接，由真实的网站 + 钓鱼的 redirectUrl 构成，发邮件诱导用户进行登录。用户登录时访问的其实是真的网站，所以不容易察觉到 redirectUrl 是钓鱼网站，登录后却来到了钓鱼网站，用户可能会不知不觉就把重要信息泄露了。这种安全问题，我们叫做开放重定向问题。你觉得，从代码层面应该怎么预防开放重定向问题呢？</p></blockquote><p>答：要从代码层面预防开放重定向问题，有以下三种做法可供参考：</p><p>第一种，固定重定向的目标 URL。</p><p>第二种，可采用编号方式指定重定向的目标 URL，也就是重定向的目标 URL 只能是在我们的白名单内的。</p><p>第三种，用合理充分的校验方式来校验跳转的目标地址，如果是非己方地址，就告知用户跳转有风险，小心钓鱼网站的威胁。</p><h1 id="安全兜底：涉及钱时，必须考虑防刷、限量和防重"><a href="#安全兜底：涉及钱时，必须考虑防刷、限量和防重" class="headerlink" title="安全兜底：涉及钱时，必须考虑防刷、限量和防重"></a>安全兜底：涉及钱时，必须考虑防刷、限量和防重</h1><blockquote><p>问题 1：防重、防刷都是事前手段，如果我们的系统正在被攻击或利用，你有什么办法及时发现问题吗？</p></blockquote><p>答：对于及时发现系统正在被攻击或利用，监控是较好的手段，关键点在于报警阈值怎么设置。我觉得可以对比昨天同时、上周同时的量，发现差异达到一定百分比报警，而且报警需要有升级机制。此外，有的时候大盘很大的话，活动给整个大盘带来的变化不明显，如果进行整体监控可能出了问题也无法及时发现，因此可以考虑对于活动做独立的监控报警。</p><blockquote><p>问题 2：任何三方资源的使用一般都会定期对账，如果在对账中发现我们系统记录的调用量低于对方系统记录的使用量，你觉得一般是什么问题引起的呢？</p></blockquote><p>答：我之前遇到的情况是，在事务内调用外部接口，调用超时后本地事务回滚本地就没有留下数据。更合适的做法是：</p><p>请求发出之前先记录请求数据提交事务，记录状态为未知。</p><p>发布调用外部接口的请求，如果可以拿到明确的结果，则更新数据库中记录的状态为成功或失败。如果出现超时或未知异常，不能假设第三方接口调用失败，需要通过查询接口查询明确的结果。</p><p>写一个定时任务补偿数据库中所有未知状态的记录，从第三方接口同步结果。</p><p>值得注意的是，对账的时候一定要对两边，不管哪方数据缺失都可能是因为程序逻辑有 bug，需要重视。此外，任何涉及第三方系统的交互，都建议在数据库中保持明细的请求 &#x2F; 响应报文，方便在出问题的时候定位 Bug 根因。</p><blockquote><p>问题3：开放平台资源的使用需要考虑防刷，该怎么限制短信接口被盗刷？</p></blockquote><p>第一种方式，只有固定的请求头才能发送验证码。</p><p>也就是说，我们通过请求头中网页或 App 客户端传给服务端的一些额外参数，来判断请求是不是 App 发起的。其实，这种方式“防君子不防小人”。</p><p>比如，判断是否存在浏览器或手机型号、设备分辨率请求头。对于那些使用爬虫来抓取短信接口地址的程序来说，往往只能抓取到 URL，而难以分析出请求发送短信还需要的额外请求头，可以看作第一道基本防御。</p><p>第二种方式，只有先到过注册页面才能发送验证码。</p><p>对于普通用户来说，不管是通过 App 注册还是 H5 页面注册，一定是先进入注册页面才能看到发送验证码按钮，再点击发送。我们可以在页面或界面打开时请求固定的前置接口，为这个设备开启允许发送验证码的窗口，之后的请求发送验证码才是有效请求。</p><p>这种方式可以防御直接绕开固定流程，通过接口直接调用的发送验证码请求，并不会干扰普通用户。</p><p>第三种方式，控制相同手机号的发送次数和发送频次。</p><p>除非是短信无法收到，否则用户不太会请求了验证码后不完成注册流程，再重新请求。因此，我们可以限制同一手机号每天的最大请求次数。验证码的到达需要时间，太短的发送间隔没有意义，所以我们还可以控制发送的最短间隔。比如，我们可以控制相同手机号一天只能发送 10 次验证码，最短发送间隔 1 分钟。</p><p>第四种方式，增加前置图形验证码。</p><p>短信轰炸平台一般会收集很多免费短信接口，一个接口只会给一个用户发一次短信，所以控制相同手机号发送次数和间隔的方式不够有效。这时，我们可以考虑对用户体验稍微有影响，但也是最有效的方式作为保底，即将弹出图形验证码作为前置。</p><p>除了图形验证码，我们还可以使用其他更友好的人机验证手段（比如滑动、点击验证码等），甚至是引入比较新潮的无感知验证码方案（比如，通过判断用户输入手机号的打字节奏，来判断是用户还是机器），来改善用户体验。</p><p>此外，我们也可以考虑在监测到异常的情况下再弹出人机检测。比如，短时间内大量相同远端 IP 发送验证码的时候，才会触发人机检测。</p><p>总之，我们要确保，只有正常用户经过正常的流程才能使用开放平台资源，并且资源的用量在业务需求合理范围内。此外，还需要考虑做好短信发送量的实时监控，遇到发送量激增要及时报警。</p><blockquote><p>钱的进出一定要和订单挂钩并且实现幂等</p></blockquote><p>涉及钱的进出，需要做好以下两点。</p><p>第一，任何资金操作都需要在平台侧生成业务属性的订单，可以是优惠券发放订单，可以是返现订单，也可以是借款订单，一定是先有订单再去做资金操作。同时，订单的产生需要有业务属性。业务属性是指，订单不是凭空产生的，否则就没有控制的意义。比如，返现发放订单必须关联到原先的商品订单产生；再比如，借款订单必须关联到同一个借款合同产生。</p><p>第二，一定要做好防重，也就是实现幂等处理，并且幂等处理必须是全链路的。这里的全链路是指，从前到后都需要有相同的业务订单号来贯穿，实现最终的支付防重。</p><p>对于支付操作，我们一定是调用三方支付公司的接口或银行接口进行处理的。一般而言，这些接口都会有商户订单号的概念，对于相同的商户订单号，无法进行重复的资金处理，所以三方公司的接口可以实现唯一订单号的幂等处理。</p><p>但是，业务系统在实现资金操作时容易犯的错是，没有自始至终地使用一个订单号作为商户订单号，透传给三方支付接口。出现这个问题的原因是，比较大的互联网公司一般会把支付独立一个部门。支付部门可能会针对支付做聚合操作，内部会维护一个支付订单号，然后使用支付订单号和三方支付接口交互。最终虽然商品订单是一个，但支付订单是多个，相同的商品订单因为产生多个支付订单导致多次支付。</p><p>如果说，支付出现了重复扣款，我们可以给用户进行退款操作，但给用户付款的操作一旦出现重复付款，就很难把钱追回来了，所以更要小心。</p><p>这，就是全链路的意义，从一开始就需要先有业务订单产生，然后使用相同的业务订单号一直贯穿到最后的资金通路，才能真正避免重复资金操作。</p><h1 id="如何正确保存和传输敏感数据？"><a href="#如何正确保存和传输敏感数据？" class="headerlink" title="如何正确保存和传输敏感数据？"></a>如何正确保存和传输敏感数据？</h1><blockquote><p>问题 1：虽然我们把用户名和密码脱敏加密保存在数据库中，但日志中可能还存在明文的敏感数据。你有什么思路在框架或中间件层面，对日志进行脱敏吗？</p></blockquote><p>答：如果我们希望在日志的源头进行脱敏，那么可以在日志框架层面做。比如对于 logback 日志框架，我们可以自定义 MessageConverter，通过正则表达式匹配敏感信息脱敏。</p><p>需要注意的是，这种方式有两个缺点。</p><p>第一，正则表达式匹配敏感信息的格式不一定精确，会出现误杀漏杀的现象。一般来说，这个问题不会很严重。要实现精确脱敏的话，就只能提供各种脱敏工具类，然后让业务应用在日志中记录敏感信息的时候，先手动调用工具类进行脱敏。</p><p>第二，如果数据量比较大的话，脱敏操作可能会增加业务应用的 CPU 和内存使用，甚至会导致应用不堪负荷出现不可用。考虑到目前大部分公司都引入了 ELK 来集中收集日志，并且一般而言都不允许上服务器直接看文件日志，因此我们可以考虑在日志收集中间件中（比如 logstash）写过滤器进行脱敏。这样可以把脱敏的消耗转义到 ELK 体系中，不过这种方式同样有第一点提到的字段不精确匹配导致的漏杀误杀的缺点。</p><blockquote><p>问题 2：你知道 HTTPS 双向认证的目的是什么吗？流程上又有什么区别呢？</p></blockquote><p>答：单向认证一般用于 Web 网站，浏览器只需要验证服务端的身份。对于移动端 App，如果我们希望有更高的安全性，可以引入 HTTPS 双向认证，也就是除了客户端验证服务端身份之外，服务端也验证客户端的身份。</p><p>单向认证和双向认证的流程区别，主要包括以下三个方面。</p><p>第一，不仅仅服务端需要有 CA 证书，客户端也需要有 CA 证书。</p><p>第二，双向认证的流程中，客户端校验服务端 CA 证书之后，客户端会把自己的 CA 证书发给服务端，然后服务端需要校验客户端 CA 证书的真实性。</p><p>第三，客户端给服务端的消息会使用自己的私钥签名，服务端可以使用客户端 CA 证书中的公钥验签。</p><p>这里还想补充一点，对于移动应用程序考虑到更强的安全性，我们一般也会把服务端的公钥配置在客户端中，这种方式的叫做 SSL Pinning。也就是说由客户端直接校验服务端证书的合法性，而不是通过证书信任链来校验。采用 SSL Pinning，由于客户端绑定了服务端公钥，因此我们无法通过在移动设备上信用根证书实现抓包。不过这种方式的缺点是需要小心服务端 CA 证书过期后续证书注意不要修改公钥。</p><h1 id="缓存设计：缓存可以锦上添花也可以落井下石"><a href="#缓存设计：缓存可以锦上添花也可以落井下石" class="headerlink" title="缓存设计：缓存可以锦上添花也可以落井下石"></a>缓存设计：缓存可以锦上添花也可以落井下石</h1><blockquote><p>问题 1：在聊到缓存并发问题时，我们说到热点 Key 回源会对数据库产生的压力问题，如果 Key 特别热的话，可能缓存系统也无法承受，毕竟所有的访问都集中打到了一台缓存服务器。如果我们使用 Redis 来做缓存，那可以把一个热点 Key 的缓存查询压力，分散到多个 Redis 节点上吗？</p></blockquote><p>答：Redis 4.0 以上如果开启了 LFU 算法作为 maxmemory-policy，那么可以使用–hotkeys 配合 redis-cli 命令行工具来探查热点 Key。此外，我们还可以通过 MONITOR 命令来收集 Redis 执行的所有命令，然后配合redis-faina 工具来分析热点 Key、热点前缀等信息。</p><p>对于重要节假日、线上促销活动、集中推送这些提前已知的事情，可以提前评估出可能的热 key 来。而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行实时分析，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。</p><p>找到热 key 后，就有很多解决办法了。首先可以将这些热 key 进行分散处理，比如一个热 key 名字叫 hotkey，可以被分散为 hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载。</p><p><img src="https://i0.hdslb.com/bfs/article/148b232811c1452b7be86393dd006511171301454.png" alt="image-20250208160154244"></p><p>其次，也可以 key 的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。</p><p>再次，如果热 key 较多，还可以通过监控体系对缓存的 SLA 实时监控，通过快速扩容来减少热 key 的冲击。</p><p>最后，业务端还可以使用本地缓存，将这些热 key 记录在本地缓存，来减少对远程缓存的冲击。</p><p>当然，除了分散 Redis 压力之外，我们也可以考虑再做一层短时间的本地缓存，结合 Redis 的 Keyspace 通知功能，当 Redis 集群压力超过阈值时，熔断降级直接返回本地缓存或默认值。</p><blockquote><p>问题 2：大 Key 也是数据缓存容易出现的一个问题。如果一个 Key 的 Value 特别大，那么可能会对 Redis 产生巨大的性能影响，因为 Redis 是单线程模型，对大 Key 进行查询或删除等操作，可能会引起 Redis 阻塞甚至是高可用切换。你知道怎么查询 Redis 中的大 Key，以及如何在设计上实现大 Key 的拆分吗？</p></blockquote><p>答：Redis 的大 Key 可能会导致集群内存分布不均问题，并且大 Key 的操作可能也会产生阻塞。</p><p>关于查询 Redis 中的大 Key，我们可以使用 <code>redis-cli –bigkeys</code> 命令来实时探查大 Key。此外，我们还可以使用 redis-rdb-tools 工具来分析 Redis 的 RDB 快照，得到包含 Key 的字节数、元素个数、最大元素长度等信息的 CSV 文件。然后，我们可以把这个 CSV 文件导入 MySQL 中，写 SQL 去分析。</p><p>针对大 Key，我们可以考虑几方面的优化：</p><p>第一，是否有必要在 Redis 保存这么多数据。一般情况下，我们在缓存系统中保存面向呈现的数据，而不是原始数据；对于原始数据的计算，我们可以考虑其它文档型或搜索型的 NoSQL 数据库。</p><p>第二，考虑把具有二级结构的 Key（比如 List、Set、Hash）拆分成多个小 Key，来独立获取（或是用 MGET 获取）。将大 key 分拆为多个 key，尽量减少大 key 的存在。同时由于大 key 一旦穿透到 DB，加载耗时很大，所以可以对这些大 key 进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰 key 时，同等条件下，尽量不淘汰这些大 key。</p><p>第三，可以扩展新的数据结构，同时让 client 在这些大 key 写缓存之前，进行序列化构建，然后通过 restore 一次性写入。</p><p>此外值得一提的是，大 Key 的删除操作可能会产生较大性能问题。从 Redis 4.0 开始，我们可以使用 UNLINK 命令而不是 DEL 命令在后台删除大 Key；而对于 4.0 之前的版本，我们可以考虑使用游标删除大 Key 中的数据，而不是直接使用 DEL 命令，比如对于 Hash 使用 HSCAN+HDEL 结合管道功能来删除。</p><h1 id="异步处理好用，但非常容易用错"><a href="#异步处理好用，但非常容易用错" class="headerlink" title="异步处理好用，但非常容易用错"></a>异步处理好用，但非常容易用错</h1><blockquote><p>在用户注册后发送消息到 MQ，然后会员服务监听消息进行异步处理的场景下，有些时候我们会发现，虽然用户服务先保存数据再发送 MQ，但会员服务收到消息后去查询数据库，却发现数据库中还没有新用户的信息。你觉得，这可能是什么问题呢，又该如何解决呢？</p></blockquote><p>答：我先来分享下，我遇到这个问题的真实情况。</p><p>当时，我们是因为业务代码把保存数据和发 MQ 消息放在了一个事务中，收到消息的时候有可能事务还没有提交完成。为了解决这个问题，开发同学当时的处理方式是，收 MQ 消息的时候 Sleep 1 秒再去处理。这样虽然解决了问题，但却大大降低了消息处理的吞吐量。</p><p>更好的做法是先提交事务，完成后再发 MQ 消息。但是，这又引申出来一个问题：MQ 消息发送失败怎么办，如何确保发送消息和本地事务有整体事务性？</p><h2 id="方案-1：本地消息表（Local-Message-Table）"><a href="#方案-1：本地消息表（Local-Message-Table）" class="headerlink" title="方案 1：本地消息表（Local Message Table）"></a>方案 1：<strong>本地消息表（Local Message Table）</strong></h2><p>这是一种经典的分布式事务解决方案，核心思想是通过本地事务保证消息的可靠性。</p><p><strong>实现步骤：</strong></p><ol><li>在用户服务的数据库中创建一个本地消息表，用于存储待发送的 MQ 消息。</li><li>用户服务在保存用户数据的同时，将 MQ 消息写入本地消息表（同一个事务）。</li><li>事务提交后，通过一个后台任务（或定时任务）从本地消息表中读取消息，并发送到 MQ。</li><li>消息发送成功后，删除本地消息表中的记录。</li></ol><p><strong>优点：</strong></p><ul><li>保证了本地事务和消息发送的一致性。</li><li>即使消息发送失败，也可以通过后台任务重试。</li></ul><p><strong>缺点：</strong></p><ul><li>需要维护一个本地消息表，增加了数据库的复杂性。</li><li>需要实现后台任务来发送消息。</li></ul><h2 id="方案-2：事务消息（Transactional-Outbox）"><a href="#方案-2：事务消息（Transactional-Outbox）" class="headerlink" title="方案 2：事务消息（Transactional Outbox）"></a>方案 2：<strong>事务消息（Transactional Outbox）</strong></h2><p>这是一种基于消息队列的事务性解决方案，适用于支持事务消息的 MQ（如 RocketMQ、Kafka）。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据的同时，将 MQ 消息写入本地消息表（同一个事务）。</li><li>使用 MQ 的事务消息功能，将消息发送到 MQ。</li><li>如果消息发送成功，MQ 会通知用户服务删除本地消息表中的记录。</li><li>如果消息发送失败，MQ 会触发重试机制。</li></ol><p><strong>优点：</strong></p><ul><li>消息发送和本地事务具有强一致性。</li><li>不需要额外的后台任务。</li></ul><p><strong>缺点：</strong></p><ul><li>依赖 MQ 的事务消息功能，不是所有 MQ 都支持。</li><li>实现复杂度较高。</li></ul><h2 id="方案-3：消息队列的最终一致性"><a href="#方案-3：消息队列的最终一致性" class="headerlink" title="方案 3：消息队列的最终一致性"></a>方案 3：<strong>消息队列的最终一致性</strong></h2><p>这是一种基于消息队列的最终一致性解决方案，适用于对一致性要求不是特别高的场景。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据后，发送 MQ 消息。</li><li>如果消息发送失败，用户服务会记录日志，并通过定时任务重试发送消息。</li><li>会员服务监听到消息后，处理新用户的信息。如果查询不到新用户的信息，可以等待一段时间后重试。</li></ol><p><strong>优点：</strong></p><ul><li>实现简单，适用于大多数场景。</li><li>不需要依赖复杂的分布式事务机制。</li></ul><p><strong>缺点：</strong></p><ul><li>无法保证强一致性，只能保证最终一致性。</li><li>需要处理消息重复消费的问题（幂等性）。</li></ul><h2 id="方案-4：分布式事务框架（如-Seata）"><a href="#方案-4：分布式事务框架（如-Seata）" class="headerlink" title="方案 4：分布式事务框架（如 Seata）"></a>方案 4：<strong>分布式事务框架（如 Seata）</strong></h2><p>如果业务对一致性要求非常高，可以使用分布式事务框架（如 Seata）来保证本地事务和消息发送的一致性。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据后，发送 MQ 消息。</li><li>Seata 会协调用户服务和 MQ 的事务，确保两者同时提交或回滚。</li></ol><p><strong>优点：</strong></p><ul><li>保证了强一致性。</li><li>适用于复杂的分布式事务场景。</li></ul><p><strong>缺点：</strong></p><ul><li>实现复杂度高，性能开销较大。</li><li>需要引入额外的分布式事务框架。</li></ul><h2 id="推荐方案"><a href="#推荐方案" class="headerlink" title="推荐方案"></a>推荐方案</h2><p>根据你的场景和需求，推荐以下方案：</p><ol><li><strong>如果对一致性要求较高</strong>，可以选择 <strong>本地消息表</strong> 或 <strong>事务消息</strong>。</li><li><strong>如果对一致性要求较低</strong>，可以选择 <strong>消息队列的最终一致性</strong>，并通过重试机制和幂等性来保证数据的正确性。</li></ol><h1 id="数据服务系统架构"><a href="#数据服务系统架构" class="headerlink" title="数据服务系统架构"></a>数据服务系统架构</h1><p>我们设计了一个包含多个数据库系统的、能应对各种高并发场景的一套数据服务的系统架构，其中包含了同步写服务、异步写服务和查询服务三部分，分别实现主数据库写入、辅助数据库写入和查询路由。</p><p>我们按照服务来依次分析下这个架构。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b0001fb75ba9d4897dd4e4b5fc07356f2c555d23.png" alt="image-20250716115523752"></p><p>首先要明确的是，重要的业务主数据只能保存在 MySQL 这样的关系型数据库中，原因有三点：</p><ul><li><p>RDBMS 经过了几十年的验证，已经非常成熟；</p></li><li><p>RDBMS 的用户数量众多，Bug 修复快、版本稳定、可靠性很高；</p></li><li><p>RDBMS 强调 ACID，能确保数据完整。</p></li></ul><p>有两种类型的查询任务可以交给 MySQL 来做，性能会比较好，这也是 MySQL 擅长的地方：</p><ul><li><p>按照主键 ID 的查询。直接查询聚簇索引，其性能会很高。但是单表数据量超过亿级后，性能也会衰退，而且单个数据库无法承受超大的查询并发，因此我们可以把数据表进行 Sharding 操作，均匀拆分到多个数据库实例中保存。我们把这套数据库集群称作 Sharding 集群。</p></li><li><p>按照各种条件进行范围查询，查出主键 ID。对二级索引进行查询得到主键，只需要查询一棵 B+ 树，效率同样很高。但索引的值不宜过大，比如对 varchar(1000) 进行索引不太合适，而索引外键（一般是 int 或 bigint 类型）性能就会比较好。因此，我们可以在 MySQL 中建立一张“索引表”，除了保存主键外，主要是保存各种关联表的外键，以及尽可能少的 varchar 类型的字段。这张索引表的大部分列都可以建上二级索引，用于进行简单搜索，搜索的结果是主键的列表，而不是完整的数据。由于索引表字段轻量并且数量不多（一般控制在 10 个以内），所以即便索引表没有进行 Sharding 拆分，问题也不会很大。</p></li></ul><p>如图上蓝色线所示，写入两种 MySQL 数据表和发送 MQ 消息的这三步，我们用一个同步写服务完成了。我在“异步处理”中提到，所有异步流程都需要补偿，这里的异步流程同样需要。只不过为了简洁，我在这里省略了补偿流程。</p><p>然后，如图中绿色线所示，有一个异步写服务，监听 MQ 的消息，继续完成辅助数据的更新操作。这里我们选用了 ES 和 InfluxDB 这两种辅助数据库，因此整个异步写数据操作有三步：</p><p>MQ 消息不一定包含完整的数据，甚至可能只包含一个最新数据的主键 ID，我们需要根据 ID 从查询服务查询到完整的数据。</p><p>写入 InfluxDB 的数据一般可以按时间间隔进行简单聚合，定时写入 InfluxDB。因此，这里会进行简单的客户端聚合，然后写入 InfluxDB。</p><p>ES 不适合在各索引之间做连接（Join）操作，适合保存扁平化的数据。比如，我们可以把订单下的用户、商户、商品列表等信息，作为内嵌对象嵌入整个订单 JSON，然后把整个扁平化的 JSON 直接存入 ES。</p><p>对于数据写入操作，我们认为操作返回的时候同步数据一定是写入成功的，但是由于各种原因，异步数据写入无法确保立即成功，会有一定延迟，比如：</p><ul><li><p>异步消息丢失的情况，需要补偿处理；</p></li><li><p>写入 ES 的索引操作本身就会比较慢；</p></li><li><p>写入 InfluxDB 的数据需要客户端定时聚合。</p></li></ul><p>因此，对于查询服务，如图中红色线所示，我们需要根据一定的上下文条件（比如查询一致性要求、时效性要求、搜索的条件、需要返回的数据字段、搜索时间区间等）来把请求路由到合适的数据库，并且做一些聚合处理：</p><p>需要根据主键查询单条数据，可以从 MySQL Sharding 集群或 Redis 查询，如果对实时性要求不高也可以从 ES 查询。</p><p>按照多个条件搜索订单的场景，可以从 MySQL 索引表查询出主键列表，然后再根据主键从 MySQL Sharding 集群或 Redis 获取数据详情。</p><p>各种后台系统需要使用比较复杂的搜索条件，甚至全文搜索来查询订单数据，或是定时分析任务需要一次查询大量数据，这些场景对数据实时性要求都不高，可以到 ES 进行搜索。此外，MySQL 中的数据可以归档，我们可以在 ES 中保留更久的数据，而且查询历史数据一般并发不会很大，可以统一路由到 ES 查询。</p><p>监控系统或后台报表系统需要呈现业务监控图表或表格，可以把请求路由到 InfluxDB 查询。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Spring-框架：IoC-和-AOP-是扩展的核心&quot;&gt;&lt;a href=&quot;#Spring-框架：IoC-和-AOP-是扩展的核心&quot; class=&quot;headerlink&quot; title=&quot;Spring 框架：IoC 和 AOP 是扩展的核心&quot;&gt;&lt;/a&gt;Spring 框</summary>
      
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/categories/%E5%9C%BA%E6%99%AF/"/>
    
    
    <category term="Java" scheme="https://palette-k.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java程序从虚拟机迁移到Kubernetes的一些坑</title>
    <link href="https://palette-k.github.io/2025/02/07/Java%E7%A8%8B%E5%BA%8F%E4%BB%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB%E5%88%B0Kubernetes%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
    <id>https://palette-k.github.io/2025/02/07/Java%E7%A8%8B%E5%BA%8F%E4%BB%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB%E5%88%B0Kubernetes%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</id>
    <published>2025-02-07T02:48:02.000Z</published>
    <updated>2025-10-13T03:34:57.506Z</updated>
    
    <content type="html"><![CDATA[<p>在大多数的公司中，Kubernetes 集群由运维来搭建，而程序的发布一般也是由 CI&#x2F;CD 平台完成。从虚拟机到 Kubernetes 的整个迁移过程，基本不需要修改任何代码，可能只是重新发布一次而已。所以，我们 Java 开发人员可能对迁移这个事情本身感知不强烈，认为 Kubernetes 只是运维需要知道的事情。但是程序一旦部署到了 Kubernetes 集群中，在容器环境中运行，总是会出现各种各样之前没有的奇怪的问题。</p><h2 id="Pod-IP-不固定带来的坑"><a href="#Pod-IP-不固定带来的坑" class="headerlink" title="Pod IP 不固定带来的坑"></a>Pod IP 不固定带来的坑</h2><p>Pod 是 Kubernetes 中能够创建和部署应用的最小单元，我们可以通过 Pod IP 来访问到某一个应用实例，但需要注意的是，如果没有经过特殊配置，Pod IP 并不是固定不变的，会在 Pod 重启后会发生变化。</p><p>不过好在，通常我们的 Java 微服务都是没有状态的，我们并不需要通过 Pod IP 来访问到某一个特定的 Java 服务实例。通常来说，要访问到部署在 Kubernetes 中的微服务集群，有两种服务发现和访问的方式：</p><p>通过 Kubernetes 来实现。也就是通过 Service 进行内部服务的互访，通过 Ingress 从外部访问到服务集群。</p><p>通过微服务注册中心（比如 Eureka）来实现。也就是服务之间的互访通过客户端负载均衡后 + 直接访问 Pod IP 进行，外部访问到服务集群通过微服务网关转发请求。</p><p>使用这两种方式进行微服务的访问，我们都没有和 Pod IP 直接打交道，也不会把 Pod IP 记录持久化，所以一般不需要太关注 Pod IP 变动的问题。不过，在一些场景下，Pod IP 的变动会造成一些问题。</p><p>之前我就遇到过这样的情况：某任务调度中间件会记录被调度节点的 IP 到数据库，随后通过访问节点 IP 查看任务节点执行日志的时候，如果节点部署在 Kubernetes 中，那么节点重启后 Pod IP 就会变动。这样，之前记录在数据库中的老节点的 Pod IP 必然访问不到，那么就会发生无法查看任务日志的情况。</p><p>遇到这种情况，我们应该怎么做呢？这时候，可能就需要修改这个中间件，把任务执行日志也进行持久化，从而避免这种访问任务节点来查看日志的行为。</p><p>总之，我们需要意识到 Pod IP 不固定的问题，并且进行“避坑操作”：在迁移到 Kubernetes 集群之前，摸排一下是否会存在需要通过 IP 访问到老节点的情况，如果有的话需要进行改造。</p><h2 id="程序因为-OOM-被杀进程的坑"><a href="#程序因为-OOM-被杀进程的坑" class="headerlink" title="程序因为 OOM 被杀进程的坑"></a>程序因为 OOM 被杀进程的坑</h2><p>在 Kubernetes 集群中部署程序的时候，我们通常会为容器设置一定的内存限制（limit），容器不可以使用超出其资源 limit 属性所设置的资源量。如果容器内的 Java 程序使用了大量内存，可能会出现各种 OOM 的情况。</p><p>第一种情况，是 OS OOM Kill 问题。如果过量内存导致操作系统 Kernel 不稳定，操作系统可能就会杀死 Java 进程。这时候，你能在操作系统 &#x2F;var&#x2F;log&#x2F;messages 日志中找到类似 oom_kill_process 的关键字。</p><p>第二种情况，是我们最常遇到的 Java 程序的 OOM 问题。程序超出堆内存的限制申请内存，导致 Heap OOM，后续可能会因为健康检测没有通过被 Kubernetes 重启 Pod。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/2cf6d48915a0bce6834cf46edb462c04.png" alt="img"></p><p>在 Kubernetes 中部署 Java 程序时，这两种情况都很常见，表现出的症状也都是 OOM 关键字 + 重启。所以，当运维同学说程序因为 OOM 被杀死或重启的时候，我们一定要和运维同学一起去区分清楚，到底是哪一种情况，然后再对症处理。</p><p>对于情况 1，问题的原因往往不是 Java 堆内存不够，更可能是程序使用了太多的堆外内存，超过了内存限制。这个时候，调大 JVM 最大堆内存只会让问题更严重，因为堆内存是可以通过 GC 回收的。我们需要分析 Java 进程哪部分区域内存占用过大，是不是合理，以及是否可能存在内存泄露问题。Java 进程的内存占用除了堆之外，还包括</p><p>直接内存</p><p>元数据区</p><p>线程栈大小 Xss * 线程数</p><p>JIT 代码缓存</p><p>GC、编译器使用额外空间</p><p>……</p><p>我们可以使用 NMT 打印各部分区域大小，从而判断到底是哪部分内存区域占用了过多内存，或是可能有内存泄露问题：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="variable constant_">XX</span><span class="symbol">:NativeMemoryTracking=smmary/detail</span> -<span class="variable constant_">XX</span><span class="symbol">:+UnlockDiagnosticVMOptions</span> -<span class="variable constant_">XX</span><span class="symbol">:+PrintNMTStatistics</span></span><br></pre></td></tr></table></figure><p>如果你确认 OOM 是情况 2，那么我同样不建议直接调大堆内存的限制，防止之后再出现情况 1。我会更建议你把堆内存限制为容器内存限制的 50%~70%，预留出足够多的内存给堆外和 OS 核心。如果需要扩容堆内存的话，那么也需要同步扩容容器的内存 limit。此外，也需要通过 Heap Dump 等手段来排查为什么堆内存占用会这么大，排除潜在的内存泄露的可能性。</p><h2 id="内存和-CPU-资源配置不适配容器的坑"><a href="#内存和-CPU-资源配置不适配容器的坑" class="headerlink" title="内存和 CPU 资源配置不适配容器的坑"></a>内存和 CPU 资源配置不适配容器的坑</h2><p>刚刚我们提到了，堆内存扩容需要结合容器内存 limit 同步进行。其实，我们更希望的是，Java 程序的堆内存配置能随着容器的资源配置，实现自动扩容或缩容，而不是写死 Xmx 和 Xms。这样一来，运维同学可以更方便地针对整个集群进行扩容或缩容。</p><p>对于 JDK&gt;8u191 的版本，我们可以设置下面这些 JVM 参数，来让 JVM 自动根据容器内存限制来设置堆内存用量。比如，下面配置相当于把 Xmx 和 Xms 都设置为了容器内存 limit 的 50%：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable constant_">XX</span><span class="symbol">:MaxRAMPercentage=</span><span class="number">50.0</span> -<span class="variable constant_">XX</span><span class="symbol">:InitialRAMPercentage=</span><span class="number">50.0</span> -<span class="variable constant_">XX</span><span class="symbol">:MinRAMPercentage=</span><span class="number">50.0</span></span><br></pre></td></tr></table></figure><p>接下来，我们看看 CPU 资源配置不适配容器的坑，以及对应的解决方案。</p><p>对于 CPU 资源的使用，我们主要需要注意的是，代码中的各种组件甚至是 JVM 本身，会根据 CPU 数来配置并发数等重要参数指标，那么：</p><p>如果这个值因为 JVM 对容器的兼容性问题取到了 Kubernetes 工作节点的 CPU 数量，那么这个数量可能就不是 4 或 8，而是 128 以上，进而导致并发数过高。</p><p>对于 JDK&gt;8u191 的版本可能会对容器兼容性较好，但是其获取到的 Runtime.getRuntime().availableProcessors() 其实是 request 的值而不是 limit 的值（比如我们设置 request 为 2、limit 为 8、CICompilerCount 和 ParallelGCThreads 可能只是 2），那么可能并发数就会过低，进而影响 JVM 的 GC 或编译性能。</p><p>所以，我的建议是：</p><p>第一，通过 -XX:+PrintFlagsFinal 开关，来确认 ActiveProcessorCount 是不是符合我们的期望，并且确认 CICompilerCount、ParallelGCThreads 等重要参数配置是否合理。</p><p>第二，直接设置 CPU 的 request 和 limit 一致，或是对于 JDK&gt;8u191 的版本可以通过 -XX:ActiveProcessorCount&#x3D;xxx 直接把 ActiveProcessorCount 设置为容器的 CPU limit。</p><h2 id="Pod-重启以及重启后没有现场的坑"><a href="#Pod-重启以及重启后没有现场的坑" class="headerlink" title="Pod 重启以及重启后没有现场的坑"></a>Pod 重启以及重启后没有现场的坑</h2><p>除非宿主机有问题，否则虚拟机不太会自己重启或被重启，而 Kubernetes 中 Pod 的重启绝非小概率事件。在存活检测不通过、Pod 重新进行节点调度等情况下，Pod 都会进行重启。对于 Pod 的重启，我们需要关注两个问题。</p><p>第一个问题是，分析 Pod 为什么会重启。</p><p>其中，除了“程序因为 OOM 被杀进程的坑”这部分提到的 OOM 的问题之外，我们还需要关注存活检查不通过的情况。</p><p>Kubernetes 有 readinessProbe 和 livenessProbe 两个探针，前者用于检查应用是否已经启动完成，后者用于持续探活。一般而言，运维同学会配置这 2 个探针为一个健康检测的断点，如果健康检测访问一次需要消耗比较长的时间（比如涉及到存储或外部服务可用性检测），那么很可能可以通过 readinessProbe 的检查但不通过 livenessProbe 检查（毕竟我们通常会为 readinessProbe 设置比较长的超时时间，而对于 livenessProbe 则没有那么宽容）。此外，健康检测也可能会受到 Full GC 的干扰导致超时。所以，我们需要和运维同学一起确认 livenessProbe 的配置地址和超时时间设置是否合理，防止偶发的 livenessProbe 探活失败导致的 Pod 重启。</p><p>第二个问题是，要理解 Pod 和虚拟机不同。</p><p>虚拟机一般都是有状态的，即便部署在虚拟机内的 Java 程序重启了，我们始终能有现场。而对于 Pod 重启来说，则是新建一个 Pod，这就意味着老的 Pod 无法进入。因此，如果因为堆 OOM 问题导致重启，我们希望事后查看当时 OS 的一些日志或是在现场执行一些命令来分析问题，就不太可能了。</p><p>所以，我们需要想办法在 Pod 关闭之前尽可能保留现场，比如：</p><p>对于程序的应用日志、标准输出、GC 日志等可以直接挂载到持久卷，不要保存在容器内部。</p><p>对于程序的堆栈现场保留，可以配置 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath 在堆 OOM 的时候生成 Dump；还可以让 JVM 调用任一个 shell 脚本，通过脚本来保留线程栈等信息：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:OnOutOfMemoryError=saveinfo</span>.sh</span><br></pre></td></tr></table></figure><p>对于容器的现场保留，可以让运维配置 preStop 钩子，在 Pod 关闭之前把必要的信息上传到持久卷或云上。</p><h2 id="重点回顾"><a href="#重点回顾" class="headerlink" title="重点回顾"></a>重点回顾</h2><p>今天，我们探讨了 Java 应用部署到 Kubernetes 集群会遇到的 4 类问题。</p><p>第一类问题是，我们需要理解应用的 IP 会动态变化，因此要在设计上解除对 Pod IP 的强依赖，使用依赖服务发现来定位到应用。</p><p>第二类问题是，在出现 OOM 问题的时候，首先要区分 OOM 的原因来自 Java 进程层面还是容器层面。如果是容器层面的话，我们还需要进一步分析到底是哪个内存区域占用了过多内存，定位到问题后再根据容器资源设置合理的 JVM 参数或进行资源扩容。</p><p>第三类问题是，需要确保程序使用的内存和 CPU 资源匹配容器的资源限制，既要确保程序所“看”到的主机资源信息是容器本身的而不是物理机的，又要确保程序能尽可能随着容器扩容而扩容其资源限制。</p><p>第四类问题是，我们需要重点关注程序非发布期重启的问题，并且针对 Pod 的重启问题做好现场保留的准备工作，排除资源配置不合理、存活检查不通过等可能性，以避免因为程序频繁重启导致的偶发性能问题或可用性问题。</p><p>只有解决了这些隐患，才能让 Kubernetes 集群更好地发挥作用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在大多数的公司中，Kubernetes 集群由运维来搭建，而程序的发布一般也是由 CI&amp;#x2F;CD 平台完成。从虚拟机到 Kubernetes 的整个迁移过程，基本不需要修改任何代码，可能只是重新发布一次而已。所以，我们 Java 开发人员可能对迁移这个事情本身感知不强</summary>
      
    
    
    
    <category term="k8s" scheme="https://palette-k.github.io/categories/k8s/"/>
    
    
    <category term="Kubernetes" scheme="https://palette-k.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>漫谈RocketMQ消息发送</title>
    <link href="https://palette-k.github.io/2025/01/26/%E6%BC%AB%E8%B0%88RocketMQ%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81/"/>
    <id>https://palette-k.github.io/2025/01/26/%E6%BC%AB%E8%B0%88RocketMQ%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81/</id>
    <published>2025-01-26T10:09:22.000Z</published>
    <updated>2025-10-13T03:35:24.617Z</updated>
    
    <content type="html"><![CDATA[<h1 id="topic路由机制"><a href="#topic路由机制" class="headerlink" title="topic路由机制"></a>topic路由机制</h1><p>消息发送者向某一个topic发送消息时，需要查询topic的路由信息。初次发送时会根据topic的名称向NameServer集群查询topic的路由信息，然后将其缓存在本地内存中，并且每隔30s依次遍历缓存中的topic，向NameServer查询最新的路由信息。如果成功查询到路由信息，会将这些信息更新到本地缓存，实现topic路由信息的动态感知。</p><p>RocketMQ提供了自动创建主题的机制，消息发送者向一个不存在的主题发送消息时，向NameServer查询该主题的路由信息会先返回空，如果开启了自动创建主题机制，会使用一个默认的主题名再次从NameServer查询路由信息，然后消息发送者会使用默认主题的路由信息进行负载均衡，但不会直接使用默认路由信息为新主题创建对应的路由信息。</p><p><img src="https://i0.hdslb.com/bfs/article/7c203d765aa13dc7d121605b562f93e5171301454.png" alt="image-20250126182926724"></p><h2 id="生产环境中，为何不建议自动创建topic"><a href="#生产环境中，为何不建议自动创建topic" class="headerlink" title="生产环境中，为何不建议自动创建topic"></a>生产环境中，为何不建议自动创建topic</h2><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>因为生产环境一般是集群部署多台broker服务器，autoCreateTopicEnable设置为true，表示开启topic自动创建，但新创建的topic的路由信息只包含在其中一台broker服务器上。</p><p>期望回答：为了消息发送的高可用，希望新创建的topic在集群中的每台broker上创建对应的队列，避免broker的单节点故障。</p><p>在RocketMQ中，如果autoCreateTopicEnable设置为true，消息发送者向NameServer查询主题的路由消息返回空时，会尝试用一个系统默认的主题名称(MixAll.AUTO_CREATE_TOPIC_KEY_TOPIC)，此时消息发送者得到的路由信息为：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/Wkp2azia4QFv937FNO2g61wLud0L59P0dS9WndkJ2k15kWPEIyO9TA2hDEpfrf7micsVLukSFptGK84pqicjbs6Og/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>默认Topic在集群的每一台Broker上创建8个队列，那问题来了，为啥新创建的Topic只在一个Broker上创建4个队列呢？</p><p>Step1：在Broker启动流程中，会构建TopicConfigManager对象，其构造方法中首先会判断是否开启了允许自动创建主题，如果启用了自动创建主题，则向topicConfigTable中添加默认主题的路由信息。</p><p>BrokerConfig的defaultTopicQueueNum默认为8。两台Broker服务器都会运行上面的过程，故最终Nameserver中关于默认主题的路由信息中，会包含两个Broker分别各8个队列信息。</p><p>Step2：生产者寻找路由信息<br>生产者首先向NameServer查询路由信息，由于是一个不存在的主题，故此时返回的路由信息为空，RocketMQ会使用默认的主题再次寻找，由于开启了自动创建路由信息，NameServer会向生产者返回默认主题的路由信息。然后从返回的路由信息中选择一个队列（默认轮询）。消息发送者从Nameserver获取到默认的Topic的队列信息后，队列的个数会改变吗？答案是会的。</p><p>消息发送者在到默认路由信息时，其队列数量，会选择DefaultMQProducer#defaultTopicQueueNums与Nameserver返回的的队列数取最小值，<strong>DefaultMQProducer#defaultTopicQueueNums默认值为4，故自动创建的主题，其队列数量默认为4。</strong></p><p>Step3：发送消息</p><p>在消息发送时的请求报文中，设置默认topic名称，消息发送topic名称，使用的队列数量为DefaultMQProducer#defaultTopicQueueNums，即默认为4。</p><p>Step4：Broker端收到消息后的处理流程</p><p>在Broker端，首先会使用TopicConfigManager根据topic查询路由信息，如果Broker端不存在该主题的路由配置(路由信息),且Broker中存在默认主题的路由配置信息，则根据消息发送请求中的队列数量，在Broker创建新Topic的路由信息。这样Broker服务端就会存在主题的路由信息。</p><p>在Broker端的topic配置管理器中存在的路由信息，一会向Nameserver发送心跳包，汇报到Nameserver，另一方面会有一个定时任务，定时存储在broker端，具体路径为${ROCKET_HOME}&#x2F;store&#x2F;config&#x2F;topics.json中，这样在Broker关闭后再重启，并不会丢失路由信息。</p><h3 id="现象分析"><a href="#现象分析" class="headerlink" title="现象分析"></a>现象分析</h3><p>经过上面自动创建路由机制的创建流程，我们可以比较容易的分析得出如下结论：</p><p>因为开启了自动创建路由信息，消息发送者根据Topic去NameServer无法得到路由信息，但接下来根据默认Topic从NameServer是能拿到路由信息(在每个Broker中，存在8个队列)，因为两个Broker在启动时都会向NameServer汇报路由信息。此时消息发送者缓存的路由信息是2个Broker，每个Broker默认4个队列</p><p>消息发送者然后按照轮询机制，发送第一条消息选择(broker-a的messageQueue:0)，向Broker发送消息，Broker服务器在处理消息时，首先会查看自己的路由配置管理器(TopicConfigManager)中的路由信息，此时不存在对应的路由信息，然后尝试查询是否存在默认Topic的路由信息，如果存在，说明启用了autoCreateTopicEnable，则在TopicConfigManager中创建新Topic的路由信息，此时存在与Broker服务端的内存中，然后本次消息发送结束。此时，在NameServer中还不存在新创建的Topic的路由信息。</p><p>这里有三个关键点：</p><ol><li>启用autoCreateTopicEnable创建主题时，在Broker端创建主题的时机为，消息生产者往Broker端发送消息时才会创建。</li><li>然后Broker端会在一个心跳包周期内，将新创建的路由信息发送到NameServer，于此同时，Broker端还会有一个定时任务，定时将内存中的路由信息，持久化到Broker端的磁盘上。</li><li>消息发送者会每隔30s向NameServer更新路由信息，如果消息发送端一段时间内未发送消息，就不会有消息发送集群内的第二台Broker，那么NameServer中新创建的Topic的路由信息只会包含Broker-a，然后消息发送者会向NameServer拉取最新的路由信息，此时就会消息发送者原本缓存了2个broker的路由信息，将会变为一个Broker的路由信息，则该Topic的消息永远不会发送到另外一个Broker，就出现了上述现象。</li></ol><p>原因就分析到这里了，现在我们还可以的大胆假设，开启autoCreateTopicEnable机制，什么情况会在两个Broker上都创建队列，其实，我们只需要连续快速的发送9条消息，就有可能在2个Broker上都创建队列，验证代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> 1public <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException &#123;</span><br><span class="line"> <span class="number">2</span>    <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;please_rename_unique_group_name&quot;</span>);</span><br><span class="line"> <span class="number">3</span>    producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line"> <span class="number">4</span>    producer.start();</span><br><span class="line"> <span class="number">5</span>    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">9</span>; i++) &#123;</span><br><span class="line"> <span class="number">6</span>        <span class="keyword">try</span> &#123;</span><br><span class="line"> <span class="number">7</span>            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(<span class="string">&quot;TopicTest10&quot;</span> ,<span class="string">&quot;TagA&quot;</span> , (<span class="string">&quot;Hello RocketMQ &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"> <span class="number">8</span>            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg);</span><br><span class="line"> <span class="number">9</span>            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line"><span class="number">10</span>        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"><span class="number">11</span>            e.printStackTrace();</span><br><span class="line"><span class="number">12</span>            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"><span class="number">13</span>        &#125;</span><br><span class="line"><span class="number">14</span>    &#125;</span><br><span class="line"><span class="number">15</span>    producer.shutdown();</span><br><span class="line"><span class="number">16</span>&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;topic路由机制&quot;&gt;&lt;a href=&quot;#topic路由机制&quot; class=&quot;headerlink&quot; title=&quot;topic路由机制&quot;&gt;&lt;/a&gt;topic路由机制&lt;/h1&gt;&lt;p&gt;消息发送者向某一个topic发送消息时，需要查询topic的路由信息。初次发送时会根</summary>
      
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/categories/RocketMQ/"/>
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>线程安全小妙招</title>
    <link href="https://palette-k.github.io/2025/01/26/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%8F%E5%A6%99%E6%8B%9B/"/>
    <id>https://palette-k.github.io/2025/01/26/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%8F%E5%A6%99%E6%8B%9B/</id>
    <published>2025-01-26T07:41:22.000Z</published>
    <updated>2025-10-13T03:35:36.483Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TreadLocal的正确打开方式"><a href="#TreadLocal的正确打开方式" class="headerlink" title="TreadLocal的正确打开方式"></a>TreadLocal的正确打开方式</h1><p>我们知道，ThreadLocal 适用于变量在线程间隔离，而在方法或类间共享的场景。如果用户信息的获取比较昂贵（比如从数据库查询用户信息），那么在 ThreadLocal 中缓存数据是比较合适的做法。</p><p>但是如果错误地使用了ThreadLocal，可能会导致有时获取到的用户信息是别人的。为什么会出现用户信息错乱的 Bug 呢？</p><p>我们来复现一下这个场景。</p><p>使用 Spring Boot 创建一个 Web 应用程序，使用 ThreadLocal 存放一个 Integer 的值，来暂且代表需要在线程中保存的用户信息，这个值初始是 null。在业务逻辑中，我先从 ThreadLocal 获取一次值，然后把外部传入的参数设置到 ThreadLocal 中，来模拟从当前上下文获取到用户信息的逻辑，随后再获取一次值，最后输出两次获得的值和线程名称。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;wrong&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Map <span class="title function_">wrong</span><span class="params">(<span class="meta">@RequestParam(&quot;userId&quot;)</span> Integer userId)</span> &#123;</span><br><span class="line">    <span class="comment">//设置用户信息之前先查询一次ThreadLocal中的用户信息</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">before</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    <span class="comment">//设置用户信息到ThreadLocal</span></span><br><span class="line">    currentUser.set(userId);</span><br><span class="line">    <span class="comment">//设置用户信息之后再查询一次ThreadLocal中的用户信息</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">after</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    <span class="comment">//汇总输出两次查询结果</span></span><br><span class="line">    <span class="type">Map</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">    result.put(<span class="string">&quot;before&quot;</span>, before);</span><br><span class="line">    result.put(<span class="string">&quot;after&quot;</span>, after);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>按理说，在设置用户信息之前第一次获取的值始终应该是 null，但我们要意识到，程序运行在 Tomcat 中，执行程序的线程是 Tomcat 的工作线程，而 Tomcat 的工作线程是基于线程池的。</p><p><strong>顾名思义，线程池会重用固定的几个线程，一旦线程重用，那么很可能首次从 ThreadLocal 获取的值是之前其他用户的请求遗留的值。这时，ThreadLocal 中的用户信息就是其他用户的信息。</strong></p><p>为了更快地重现这个问题，我在配置文件中设置一下 Tomcat 的参数，把工作线程池最大线程数设置为 1，这样始终是同一个线程在处理请求：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.tomcat.max-threads</span>=<span class="string">1</span></span><br></pre></td></tr></table></figure><p>运行程序后先让用户 1 来请求接口，可以看到第一和第二次获取到用户 ID 分别是 null 和 1，符合预期：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/4b8f38415d03423132c7a3608ebe2430.png" alt="img"></p><p>随后用户 2 来请求接口，这次就出现了 Bug，第一和第二次获取到用户 ID 分别是 1 和 2，显然第一次获取到了用户 1 的信息，原因就是 Tomcat 的线程池重用了线程。从图中可以看到，两次请求的线程都是同一个线程：http-nio-8080-exec-1。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/a9ccd42716d807687b3acff9a0baf2db.png" alt="img"></p><p>这个例子告诉我们，在写业务代码时，首先要理解代码会跑在什么线程上：</p><ul><li>我们可能会抱怨学多线程没用，因为代码里没有开启使用多线程。但其实，可能只是我们没有意识到，在 Tomcat 这种 Web 服务器下跑的业务代码，本来就运行在一个多线程环境（否则接口也不可能支持这么高的并发），<strong>并不能认为没有显式开启多线程就不会有线程安全问题。</strong></li><li>因为线程的创建比较昂贵，所以 Web 服务器往往会使用线程池来处理请求，这就意味着线程会被重用。这时，<strong>使用类似 ThreadLocal 工具来存放一些数据时，需要特别注意在代码运行完后，显式地去清空设置的数据。</strong>如果在代码中使用了自定义的线程池，也同样会遇到这个问题。</li></ul><p>理解了这个知识点后，我们修正这段代码的方案是，在代码的 finally 代码块中，显式清除 ThreadLocal 中的数据。这样一来，新的请求过来即使使用了之前的线程也不会获取到错误的用户信息了。修正后的代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;right&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Map <span class="title function_">right</span><span class="params">(<span class="meta">@RequestParam(&quot;userId&quot;)</span> Integer userId)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">before</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    currentUser.set(userId);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">after</span> <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">        <span class="type">Map</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">        result.put(<span class="string">&quot;before&quot;</span>, before);</span><br><span class="line">        result.put(<span class="string">&quot;after&quot;</span>, after);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//在finally代码块中删除ThreadLocal中的数据，确保数据不串</span></span><br><span class="line">        currentUser.remove();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重新运行程序可以验证，再也不会出现第一次查询用户信息查询到之前用户请求的 Bug：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/0dfe40fca441b58d491fc799d120a7cc.png" alt="img"></p><p>其实如果使用<code>ThreadLocal</code> 后不及时调用 <code>remove()</code> 方法，可能还会引发内存泄漏问题。</p><p><code>ThreadLocal</code> 的实现依赖于每个线程内部的一个 <code>ThreadLocalMap</code>，<code>ThreadLocal</code> 对象作为键，存储的值作为值。<code>ThreadLocalMap</code> 中的键是对 <code>ThreadLocal</code> 对象的弱引用（<code>WeakReference</code>），而值是强引用。</p><p>当外部对 <code>ThreadLocal</code> 对象的强引用被释放后，由于 <code>ThreadLocalMap</code> 中的键是弱引用，在垃圾回收时，这个 <code>ThreadLocal</code> 实例会被回收，其对应的键会变为 <code>null</code>。但此时值仍然是强引用，只要线程一直存活，<code>ThreadLocalMap</code> 就不会被回收，这些 <code>null</code> 键对应的值就无法被访问到，却仍然占用着内存，从而造成内存泄漏。</p><h1 id="线程池的声明需手动进行"><a href="#线程池的声明需手动进行" class="headerlink" title="线程池的声明需手动进行"></a>线程池的声明需手动进行</h1><p>Java 中的 Executors 类定义了一些快捷的工具方法，来帮助我们快速创建线程池。《阿里巴巴 Java 开发手册》中提到，禁止使用这些方法来创建线程池，而应该手动 new ThreadPoolExecutor 来创建线程池。这一条规则的背后，是大量血淋淋的生产事故，最典型的就是 newFixedThreadPool 和 newCachedThreadPool，可能因为资源耗尽导致 OOM 问题。</p><p>首先，我们来看一下 newFixedThreadPool 为什么可能会出现 OOM 的问题。</p><p>我们写一段测试代码，来初始化一个单线程的 FixedThreadPool，循环 1 亿次向线程池提交任务，每个任务都会创建一个比较大的字符串然后休眠一小时：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;oom1&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">oom1</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">ThreadPoolExecutor</span> <span class="variable">threadPool</span> <span class="operator">=</span> (ThreadPoolExecutor) Executors.newFixedThreadPool(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印线程池的信息，稍后我会解释这段代码</span></span><br><span class="line">    printStats(threadPool); </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100000000</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">        threadPool.execute(() -&gt; &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">payload</span> <span class="operator">=</span> IntStream.rangeClosed(<span class="number">1</span>, <span class="number">1000000</span>)</span><br><span class="line">                    .mapToObj(__ -&gt; <span class="string">&quot;a&quot;</span>)</span><br><span class="line">                    .collect(Collectors.joining(<span class="string">&quot;&quot;</span>)) + UUID.randomUUID().toString();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                TimeUnit.HOURS.sleep(<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            log.info(payload);</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    threadPool.shutdown();</span><br><span class="line">    threadPool.awaitTermination(<span class="number">1</span>, TimeUnit.HOURS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行程序后不久，日志中就出现了如下 OOM：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">&quot;http-nio-45678-ClientPoller&quot;</span> java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br></pre></td></tr></table></figure><p>翻看 newFixedThreadPool 方法的源码不难发现，线程池的工作队列直接 new 了一个 LinkedBlockingQueue，而默认构造方法的 LinkedBlockingQueue 是一个 Integer.MAX_VALUE 长度的队列，可以认为是无界的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title function_">newFixedThreadPool</span><span class="params">(<span class="type">int</span> nThreads)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(nThreads, nThreads,</span><br><span class="line">                                  <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;Runnable&gt;());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LinkedBlockingQueue</span>&lt;E&gt; <span class="keyword">extends</span> <span class="title class_">AbstractQueue</span>&lt;E&gt;</span><br><span class="line">        <span class="keyword">implements</span> <span class="title class_">BlockingQueue</span>&lt;E&gt;, java.io.Serializable &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Creates a &#123;<span class="doctag">@code</span> LinkedBlockingQueue&#125; with a capacity of</span></span><br><span class="line"><span class="comment">     * &#123;<span class="doctag">@link</span> Integer#MAX_VALUE&#125;.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LinkedBlockingQueue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然使用 newFixedThreadPool 可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务较多并且执行较慢的话，队列可能会快速积压，撑爆内存导致 OOM。</p><p>我们再把刚才的例子稍微改一下，改为使用 newCachedThreadPool 方法来获得线程池。程序运行不久后，同样看到了如下 OOM 异常：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[11:30:30.487] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: unable to create new native thread] with root cause</span><br><span class="line"></span><br><span class="line">java.lang.OutOfMemoryError: unable to create new native thread </span><br></pre></td></tr></table></figure><p>从日志中可以看到，这次 OOM 的原因是无法创建线程，翻看 newCachedThreadPool 的源码可以看到，这种线程池的最大线程数是 Integer.MAX_VALUE，可以认为是没有上限的，而其工作队列 SynchronousQueue 是一个没有存储空间的阻塞队列。这意味着，只要有请求到来，就必须找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的。</p><p>由于我们的任务需要 1 小时才能执行完成，大量的任务进来后会创建大量的线程。我们知道线程是需要分配一定的内存空间作为线程栈的，比如 1MB，因此无限制创建线程必然会导致 OOM：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title function_">newCachedThreadPool</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">0</span>, Integer.MAX_VALUE,</span><br><span class="line">                                  <span class="number">60L</span>, TimeUnit.SECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> <span class="title class_">SynchronousQueue</span>&lt;Runnable&gt;());</span><br></pre></td></tr></table></figure><p>其实，大部分 Java 开发同学知道这两种线程池的特性，只是抱有侥幸心理，觉得只是使用线程池做一些轻量级的任务，不可能造成队列积压或开启大量线程。</p><p>但，现实往往是残酷的。我之前就遇到过这么一个事故：用户注册后，我们调用一个外部服务去发送短信，发送短信接口正常时可以在 100 毫秒内响应，TPS 100 的注册量，CachedThreadPool 能稳定在占用 10 个左右线程的情况下满足需求。在某个时间点，外部短信服务不可用了，我们调用这个服务的超时又特别长，比如 1 分钟，1 分钟可能就进来了 6000 用户，产生 6000 个发送短信的任务，需要 6000 个线程，没多久就因为无法创建线程导致了 OOM，整个应用程序崩溃。</p><p>因此，我同样不建议使用 Executors 提供的两种快捷的线程池，原因如下：</p><p>我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数。</p><p>任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题。</p><p>除了建议手动声明线程池以外，我还建议用一些监控手段来观察线程池的状态。线程池这个组件往往会表现得任劳任怨、默默无闻，除非是出现了拒绝策略，否则压力再大都不会抛出一个异常。如果我们能提前观察到线程池队列的积压，或者线程数量的快速膨胀，往往可以提早发现并解决问题。</p><h1 id="线程池核心参数设置"><a href="#线程池核心参数设置" class="headerlink" title="线程池核心参数设置"></a>线程池核心参数设置</h1><p>要根据任务的“轻重缓急”来指定线程池的核心参数，包括线程数、回收策略和任务队列：</p><p>对于执行比较慢、数量不大的 IO 任务，或许要考虑更多的线程数，而不需要太大的队列。</p><p>而对于吞吐量较大的计算型任务，线程数量不宜过多，可以是 CPU 核数或核数 *2（理由是，线程一定调度到某个 CPU 进行执行，如果任务本身是 CPU 绑定的任务，那么过多的线程只会增加线程切换的开销，并不能提升吞吐量），但可能需要较长的队列来做缓冲。</p><p>Java 8 的 parallel stream 功能，可以让我们很方便地并行处理集合中的元素，其背后是共享同一个 ForkJoinPool，默认并行度是 CPU 核数 -1。对于 CPU 绑定的任务来说，使用这样的配置比较合适，但如果集合操作涉及同步 IO 操作的话（比如数据库操作、外部服务调用等），建议自定义一个 ForkJoinPool（或普通线程池）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;TreadLocal的正确打开方式&quot;&gt;&lt;a href=&quot;#TreadLocal的正确打开方式&quot; class=&quot;headerlink&quot; title=&quot;TreadLocal的正确打开方式&quot;&gt;&lt;/a&gt;TreadLocal的正确打开方式&lt;/h1&gt;&lt;p&gt;我们知道，Threa</summary>
      
    
    
    
    <category term="JUC" scheme="https://palette-k.github.io/categories/JUC/"/>
    
    
    <category term="并发" scheme="https://palette-k.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ集群性能调优及运维</title>
    <link href="https://palette-k.github.io/2025/01/24/RocketMQ%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%8A%E8%BF%90%E7%BB%B4/"/>
    <id>https://palette-k.github.io/2025/01/24/RocketMQ%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%8A%E8%BF%90%E7%BB%B4/</id>
    <published>2025-01-24T07:58:52.000Z</published>
    <updated>2025-10-13T03:35:56.547Z</updated>
    
    <content type="html"><![CDATA[<h1 id="系统参数调优"><a href="#系统参数调优" class="headerlink" title="系统参数调优"></a>系统参数调优</h1><p>在解压 RocketMQ 安装包后，在 bin 目录中有个 os.sh 的文件，该文件由 RocketMQ 官方推荐系统参数配置。通常这些参数可以满足系统需求，也可以根据情况进行调整。</p><h2 id="最大文件数"><a href="#最大文件数" class="headerlink" title="最大文件数"></a>最大文件数</h2><p>设置用户的打开的最多文件数：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/security/limits.conf</span><br><span class="line"><span class="section"># End of file</span></span><br><span class="line">baseuser soft nofile 655360</span><br><span class="line">baseuser hard nofile 655360</span><br><span class="line"><span class="bullet">*</span> soft nofile 655360</span><br><span class="line"><span class="bullet">*</span> hard nofile 655360</span><br></pre></td></tr></table></figure><h2 id="系统参数设置"><a href="#系统参数设置" class="headerlink" title="系统参数设置"></a>系统参数设置</h2><p>系统参数的调整以官方给出的为主，下面对各个参数做个说明。设置时可以直接执行 <code>sh os.sh</code> 完成系统参数设定，也可以编辑 <code>vim /etc/sysctl.conf</code> 文件手动添加如下内容，添加后执行 <code>sysctl -p</code> 让其生效。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">vm.overcommit_memory</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">vm.drop_caches</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">vm.zone_reclaim_mode</span>=<span class="number">0</span></span><br><span class="line"><span class="attr">vm.max_map_count</span>=<span class="number">655360</span></span><br><span class="line"><span class="attr">vm.dirty_background_ratio</span>=<span class="number">50</span></span><br><span class="line"><span class="attr">vm.dirty_ratio</span>=<span class="number">50</span></span><br><span class="line"><span class="attr">vm.dirty_writeback_centisecs</span>=<span class="number">360000</span></span><br><span class="line"><span class="attr">vm.page-cluster</span>=<span class="number">3</span></span><br><span class="line"><span class="attr">vm.swappiness</span>=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">overcommit_memory</td><td align="left">是否允许内存的过量分配 overcommit_memory&#x3D;0 当用户申请内存的时候，内核会去检查是否有这么大的内存空间 overcommit_memory&#x3D;1 内核始终认为，有足够大的内存空间，直到它用完了为止 overcommit_memory&#x3D;2 内核禁止任何形式的过量分配内存</td></tr><tr><td align="left">drop_caches</td><td align="left">写入的时候，内核会清空缓存，腾出内存来，相当于 sync drop_caches&#x3D;1 会清空页缓存，就是文件 drop_caches&#x3D;2 会清空 inode 和目录树 drop_caches&#x3D;3 都清空</td></tr><tr><td align="left">zone_reclaim_mode</td><td align="left">zone_reclaim_mode&#x3D;0 系统会倾向于从其他节点分配内存 zone_reclaim_mode&#x3D;1 系统会倾向于从本地节点回收 Cache 内存</td></tr><tr><td align="left">max_map_count</td><td align="left">定义了一个进程能拥有的最多的内存区域，默认为 65536</td></tr><tr><td align="left">dirty_background_ratio&#x2F;dirty_ratio</td><td align="left">当 dirty cache 到了多少的时候，就启动 pdflush 进程，将 dirty cache 写回磁盘 当有 dirty_background_bytes&#x2F;dirty_bytes 存在的时候，dirty_background_ratio&#x2F;dirty_ratio 是被自动计算的</td></tr><tr><td align="left">dirty_writeback_centisecs</td><td align="left">pdflush 每隔多久，自动运行一次（单位是百分之一秒）</td></tr><tr><td align="left">page-cluster</td><td align="left">每次 swap in 或者 swap out 操作多少内存页为 2 的指数 page-cluster&#x3D;0 表示 1 页 page-cluster&#x3D;1 表示 2 页 page-cluster&#x3D;2 表示 4 页 page-cluster&#x3D;3 表示 8 页</td></tr><tr><td align="left">swappiness</td><td align="left">swappiness&#x3D;0 仅在内存不足的情况下，当剩余空闲内存低于 vm.min_free_kbytes limit 时，使用交换空间 swappiness&#x3D;1 内核版本 3.5 及以上、Red Hat 内核版本 2.6.32-303 及以上，进行最少量的交换，而不禁用交换 swappiness&#x3D;10 当系统存在足够内存时，推荐设置为该值以提高性能 swappiness&#x3D;60 默认值 swappiness&#x3D;100 内核将积极的使用交换空间</td></tr></tbody></table><h2 id="集群参数调优"><a href="#集群参数调优" class="headerlink" title="集群参数调优"></a>集群参数调优</h2><h3 id="调优建议"><a href="#调优建议" class="headerlink" title="调优建议"></a>调优建议</h3><p>对 Broker 的几个属性可能影响到集群性能的稳定性，下面进行特别说明。</p><p><strong>1. 开启异步刷盘</strong></p><p>除了一些支付类场景、或者 TPS 较低的场景（例如：TPS 在 2000 以下）生产环境建议开启异步刷盘，提高集群吞吐。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">flushDiskType</span>=ASYNC_FLUSH</span><br></pre></td></tr></table></figure><p><strong>2. 开启 Slave 读权限</strong></p><p>消息占用物理内存的大小通过 accessMessageInMemoryMaxRatio 来配置默认为 40%；如果消费的消息不在内存中，开启 slaveReadEnable 时会从 slave 节点读取；提高 Master 内存利用率。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">slaveReadEnable</span>=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p><strong>3. 消费一次拉取消息数量</strong></p><p>消费时一次拉取的数量由 broker 和 consumer 客户端共同决定，默认为 32 条。Broker 端参数由 maxTransferCountOnMessageInMemory 设置。consumer 端由 pullBatchSize 设置。Broker 端建议设置大一些，例如 1000，给 consumer 端留有较大的调整空间。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">maxTransferCountOnMessageInMemory</span>=<span class="number">1000</span></span><br></pre></td></tr></table></figure><p><strong>4. 发送队列等待时间</strong></p><p>消息发送到 Broker 端，在队列的等待时间由参数 waitTimeMillsInSendQueue 设置，默认为 200ms。建议设置大一些，例如：1000ms~5000ms。设置过短，发送客户端会引起超时。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">waitTimeMillsInSendQueue</span>=<span class="number">1000</span></span><br></pre></td></tr></table></figure><p><strong>5. 主从异步复制</strong></p><p>为提高集群性能，在生成环境建议设置为主从异步复制，经过压力测试主从同步复制性能过低。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">brokerRole</span>=ASYNC_MASTER</span><br></pre></td></tr></table></figure><p><strong>6. 提高集群稳定性</strong></p><p>为了提高集群稳定性，对下面三个参数进行特别说明，在后面踩坑案例中也会提到。</p><p>关闭堆外内存：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">transientStorePoolEnable</span>=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>关闭文件预热：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">warmMapedFileEnable</span>=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>开启堆内传输：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">transferMsgByHeap</span>=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h1 id="集群平滑运维"><a href="#集群平滑运维" class="headerlink" title="集群平滑运维"></a>集群平滑运维</h1><h2 id="优雅摘除节点"><a href="#优雅摘除节点" class="headerlink" title="优雅摘除节点"></a>优雅摘除节点</h2><h3 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h3><p>自建机房 4 主 4 从、异步刷盘、主从异步复制。有一天运维同学遗失其中一个 Master 节点所有账户的密码，该节点在集群中运行正常，然不能登陆该节点机器终究存在安全隐患，所以决定摘除该节点。</p><p>如何平滑地摘除该节点呢？</p><p>直接关机，有部分未同步到从节点的数据会丢失，显然不可行。线上安全的指导思路“先摘除流量”，当没有流量流入流出时，对节点的操作是安全的。</p><h3 id="流量摘除"><a href="#流量摘除" class="headerlink" title="流量摘除"></a>流量摘除</h3><p><strong>1. 摘除写入流量</strong></p><p>我们可以通过关闭 Broker 的写入权限，来摘除该节点的写入流量。RocketMQ 的 broker 节点有 3 种权限设置，brokerPermission&#x3D;2 表示只写权限，brokerPermission&#x3D;4 表示只读权限，brokerPermission&#x3D;6 表示读写权限。通过 updateBrokerConfig 命令将 Broker 设置为只读权限，执行完之后原该 Broker 的写入流量会分配到集群中的其他节点，所以摘除前需要评估集群节点的负载情况。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -<span class="selector-tag">b</span> x<span class="selector-class">.x</span><span class="selector-class">.x</span><span class="selector-class">.x</span>:<span class="number">10911</span> -n x.x.x.x:<span class="number">9876</span> -k brokerPermission -v <span class="number">4</span></span><br><span class="line">Java <span class="built_in">HotSpot</span>(TM) <span class="number">64</span>-Bit Server VM warning: ignoring option PermSize=<span class="number">128</span>m; support was removed in <span class="number">8.0</span></span><br><span class="line">Java HotSpot(TM) <span class="number">64</span>-Bit Server VM warning: ignoring option MaxPermSize=<span class="number">128</span>m; support was removed in <span class="number">8.0</span></span><br><span class="line">update broker config success, x<span class="selector-class">.x</span><span class="selector-class">.x</span><span class="selector-class">.x</span>:<span class="number">10911</span></span><br></pre></td></tr></table></figure><p>将 Broker 设置为只读权限后，观察该节点的流量变化，直到写入流量（InTPS）掉为 0 表示写入流量已摘除。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">bin/mqadmin</span> <span class="string">clusterList</span> <span class="string">-n</span> <span class="string">x.x.x.x:9876</span></span><br><span class="line"><span class="string">Java</span> <span class="string">HotSpot(TM)</span> <span class="attr">64-Bit Server VM warning:</span> <span class="string">ignoring</span> <span class="string">option</span> <span class="string">PermSize=128m;</span> <span class="string">support</span> <span class="string">was</span> <span class="string">removed</span> <span class="string">in</span> <span class="number">8.0</span></span><br><span class="line"><span class="string">Java</span> <span class="string">HotSpot(TM)</span> <span class="attr">64-Bit Server VM warning:</span> <span class="string">ignoring</span> <span class="string">option</span> <span class="string">MaxPermSize=128m;</span> <span class="string">support</span> <span class="string">was</span> <span class="string">removed</span> <span class="string">in</span> <span class="number">8.0</span></span><br><span class="line"><span class="comment">#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #PCWait(ms) #Hour #SPACE</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-a</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2492.95</span><span class="string">(0,0ms)</span> <span class="number">2269.27</span><span class="string">(1,0ms)</span> <span class="number">0</span> <span class="number">137.57</span> <span class="number">0.1861</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-a</span> <span class="number">1</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2485.45</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.26</span> <span class="number">0.3055</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-b</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">26.47</span><span class="string">(0,0ms)</span> <span class="number">26.08</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.24</span> <span class="number">0.1610</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-b</span> <span class="number">1</span> <span class="string">x.x.x.x:10915</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">20.47</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.22</span> <span class="number">0.3055</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-c</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2061.09</span><span class="string">(0,0ms)</span> <span class="number">1967.30</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.28</span> <span class="number">0.2031</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-c</span> <span class="number">1</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2048.20</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.51</span> <span class="number">0.2789</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-d</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2017.40</span><span class="string">(0,0ms)</span> <span class="number">1788.32</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.22</span> <span class="number">0.1261</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-d</span> <span class="number">1</span> <span class="string">x.x.x.x:10915</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2026.50</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.61</span> <span class="number">0.2789</span></span><br></pre></td></tr></table></figure><p><strong>2. 摘除读出流量</strong></p><p>当摘除 Broker 写入流量后，读出消费流量也会逐步降低。可以通过 clusterList 命令中 OutTPS 观察读出流量变化。除此之外，也可以通过 brokerConsumeStats 观察 broker 的积压（Diff）情况，当积压为 0 时，表示消费全部完成。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#Topic</span>             <span class="selector-id">#Group</span>                <span class="selector-id">#Broker</span> <span class="selector-tag">Name</span>    <span class="selector-id">#QID</span>  <span class="selector-id">#Broker</span> <span class="selector-tag">Offset</span>   <span class="selector-id">#Consumer</span> <span class="selector-tag">Offset</span>  <span class="selector-id">#Diff</span>     <span class="selector-id">#LastTime</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">0</span>     <span class="number">2171742</span>           <span class="number">2171742</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">38</span>:<span class="number">09</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">1</span>     <span class="number">2171756</span>           <span class="number">2171756</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">38</span>:<span class="number">50</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">2</span>     <span class="number">2171740</span>           <span class="number">2171740</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">42</span>:<span class="number">58</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">3</span>     <span class="number">2171759</span>           <span class="number">2171759</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">40</span>:<span class="number">44</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">4</span>     <span class="number">2171743</span>           <span class="number">2171743</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">32</span>:<span class="number">48</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">5</span>     <span class="number">2171740</span>           <span class="number">2171740</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">35</span>:<span class="number">58</span></span><br></pre></td></tr></table></figure><p><strong>3. 节点下线</strong></p><p>在观察到该 Broker 的所有积压为 0 时，通常该节点可以摘除了。考虑到可能消息回溯到之前某个时间点重新消费，可以过了日志保存日期再下线该节点。如果日志存储为 3 天，那 3 天后再移除该节点。</p><h2 id="平滑扩所容"><a href="#平滑扩所容" class="headerlink" title="平滑扩所容"></a>平滑扩所容</h2><h3 id="案例背景-1"><a href="#案例背景-1" class="headerlink" title="案例背景"></a>案例背景</h3><p>需要将线上的集群操作系统从 CentOS 6 全部换成 CenOS 7，具体现象和原因在踩坑记中介绍。集群部署架构为 4 主 4 从，见下图，broker-a 为主节点，broker-a-s 是 broker-a 的从节点。</p><p><img src="https://i0.hdslb.com/bfs/article/bf648a1fc83c047875f4bbeba7498e9e171301454.png" alt="image-20250126151748499"></p><p>那需要思考的是如何做到平滑替换？指导思想为“先扩容再缩容”。</p><h3 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h3><p>申请 8 台相同配置的机器，机器操作系统为 CenOS 7。分别组建主从结构加入到原来的集群中，此时集群中架构为 8 主 8 从，如下图：</p><p><img src="https://i0.hdslb.com/bfs/article/aa7cf927ecf92bc1ed29e0eaddf9ccb1171301454.png" alt="image-20250126151837253"></p><p>broker-a、broker-b、broker-c、broker-d 及其从节点为 CentOS 6。broker-a1、broker-b1、broker-c1、broker-d1 及其从节点为 CentOS 7。8 主均有流量流入流出，至此我们完成了集群的平滑扩容操作。</p><h3 id="集群缩容"><a href="#集群缩容" class="headerlink" title="集群缩容"></a>集群缩容</h3><p>按照第二部分“优雅摘除节点”操作，分别摘除 broker-a、broker-b、broker-c、broker-d 及其从节点的流量。为了安全，可以在过了日志保存时间（例如：3 天）后再下线。集群中剩下操作系统为 CentOS 7 的 4 主 4 从的架构，如图。至此，完成集群的平滑缩容操作。</p><p><img src="https://i0.hdslb.com/bfs/article/4528f6a51d45c9c2c1b13343fcbd72db171301454.png" alt="image-20250126151854858"></p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>在扩容中，我们将新申请的 8 台 CentOS 7 节点，命名为 broker-a1、broker-b1、broker-c1、broker-d1 的形式，而不是 broker-e、broker-f、broker-g、broker-h。下面看下这么命名的原因，客户端消费默认采用平均分配算法，假设有四个消费节点。</p><p><strong>第一种形式</strong></p><p>扩容后排序如下，即新加入的节点 broker-e 会排在原集群的最后。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broker-<span class="selector-tag">a</span>,broker-<span class="selector-tag">b</span>,broker-c,broker-d,broker-e,broker-f,broker-g,broker-h</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/article/c0e99ad51ef0b08e43d3874f1f6f9c41171301454.png" alt="image-20250126152106693"></p><p>注：当缩容摘除 broker-a、broker-b、broker-c、broker-d 的流量时，会发现 consumer-01、consumer-02 没有不能分到 Broker 节点，造成流量偏移，存在剩余的一半节点无法承载流量压力的隐患。</p><p><strong>第二种形式</strong></p><p>扩容后的排序如下，即新加入的主节点 broker-a1 紧跟着原来的主节点 broker-a。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broker-<span class="selector-tag">a</span>,broker-a1,broker-<span class="selector-tag">b</span>,broker-b1,broker-c,broker-c1,broker-d,broker-d1</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/article/d2b69fedbeca46dbf4c0a16ac8e919c7171301454.png" alt="image-20250126152157127"></p><p>注：当缩容摘除 broker-a、broker-b、broker-c、broker-d 的流量时，各个 consumer 均分配到了新加入的 Broker 节点，没有流量偏移的情况。</p><h2 id="集群节点进程神秘消失"><a href="#集群节点进程神秘消失" class="headerlink" title="集群节点进程神秘消失"></a>集群节点进程神秘消失</h2><h3 id="现象描述"><a href="#现象描述" class="headerlink" title="现象描述"></a>现象描述</h3><p>接到告警和运维反馈，一个 RocketMQ 的节点不见了。此类现象在以前从未发生过，消失肯定有原因，开始查找日志，从集群的 broker.log、stats.log、storeerror.log、store.log、watermark.log 到系统的 message 日志没发现错误日志。集群流量出入在正常水位、CPU 使用率、CPU Load、磁盘 IO、内存、带宽等无明显变化。</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>继续查原因，最终通过 history 查看了历史运维操作。发现运维同学在启动 Broker 时没有在后台启动，而是在当前 session 中直接启动了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh bin/mqbroker -c conf/broker-a.conf</span><br></pre></td></tr></table></figure><p>问题即出现在此命令，当 session 过期时 Broker 节点也就退出了。</p><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>标准化运维操作，对运维的每次操作进行评审，将标准化的操作实现自动化运维就更好了。</p><p>正确启动 Broker 方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -c conf/broker-a.conf &amp;</span><br></pre></td></tr></table></figure><h2 id="Master-节点-CPU-莫名飙高"><a href="#Master-节点-CPU-莫名飙高" class="headerlink" title="Master 节点 CPU 莫名飙高"></a>Master 节点 CPU 莫名飙高</h2><h3 id="现象描述-1"><a href="#现象描述-1" class="headerlink" title="现象描述"></a>现象描述</h3><p>RocketMQ 主节点 CPU 频繁飙高后回落，业务发送超时严重，由于两个从节点部署在同一个机器上，从节点还出现了直接挂掉的情况。</p><p>主节点 CPU 毛刺截图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910105626655.png" alt="img"></p><p>从节点 CPU 毛刺截图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910105701883.png" alt="img"></p><p>说明：中间缺失部分为掉线，没有采集到的情况。</p><p><strong>系统错误日志一</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020-03-16T17:56:07.505715+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&lt;IRQ&gt;</span>  [<span class="string">&lt;ffffffff81143c31&gt;</span>] <span class="string">?</span> <span class="string">__alloc_pages_nodemask+0x7e1/0x960</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505717+08:00</span> <span class="attr">VECS0xxxx kernel: java:</span> <span class="string">page</span> <span class="string">allocation</span> <span class="string">failure.</span> <span class="string">order:0,</span> <span class="string">mode:0x20</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505719+08:00</span> <span class="attr">VECS0xxxx kernel: Pid:</span> <span class="number">12845</span><span class="string">,</span> <span class="attr">comm:</span> <span class="string">java</span> <span class="string">Not</span> <span class="string">tainted</span> <span class="number">2.6</span><span class="number">.32</span><span class="number">-754.17</span><span class="number">.1</span><span class="string">.el6.x86_64</span> <span class="comment">#1</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505721+08:00</span> <span class="attr">VECS0xxxx kernel: Call Trace:</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505724+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&lt;IRQ&gt;</span>  [<span class="string">&lt;ffffffff81143c31&gt;</span>] <span class="string">?</span> <span class="string">__alloc_pages_nodemask+0x7e1/0x960</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505726+08:00</span> <span class="attr">VECS0xxxx kernel:</span> [<span class="string">&lt;ffffffff8148e700&gt;</span>] <span class="string">?</span> <span class="string">dev_queue_xmit+0xd0/0x360</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505729+08:00</span> <span class="attr">VECS0xxxx kernel:</span> [<span class="string">&lt;ffffffff814cb3e2&gt;</span>] <span class="string">?</span> <span class="string">ip_finish_output+0x192/0x380</span></span><br></pre></td></tr></table></figure><p><strong>系统错误日志二</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">30</span> <span class="number">2020-03-27T10:35:28.769900+08:00</span> <span class="attr">VECSxxxx kernel: INFO:</span> <span class="string">task</span> <span class="string">AliYunDunUpdate:29054</span> <span class="string">blocked</span> <span class="string">for</span> <span class="string">more</span> <span class="string">than</span> <span class="number">120</span> <span class="string">seconds.</span></span><br><span class="line"><span class="number">31</span> <span class="number">2020-03-27T10:35:28.769932+08:00</span> <span class="attr">VECSxxxx kernel:</span>      <span class="string">Not</span> <span class="string">tainted</span> <span class="number">2.6</span><span class="number">.32</span><span class="number">-754.17</span><span class="number">.1</span><span class="string">.el6.x86_64</span> <span class="comment">#1</span></span><br><span class="line"><span class="number">32</span> <span class="number">2020-03-27T10:35:28.771650+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot;</span> <span class="string">disables</span> <span class="string">this</span> <span class="string">message.</span></span><br><span class="line"><span class="number">33</span> <span class="number">2020-03-27T10:35:28.774631+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">AliYunDunUpda</span> <span class="string">D</span> <span class="string">ffffffff815592fb</span>     <span class="number">0</span> <span class="number">29054</span>      <span class="number">1</span> <span class="number">0x10000080</span></span><br><span class="line"><span class="number">34</span> <span class="number">2020-03-27T10:35:28.777500+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">ffff8803ef75baa0</span> <span class="number">0000000000000082</span> <span class="string">ffff8803ef75ba68</span> <span class="string">ffff8803ef75ba64</span></span><br></pre></td></tr></table></figure><p>说明：系统日志显示错误“page allocation failure”和“blocked for more than 120 second”错误，日志目录 &#x2F;var&#x2F;log&#x2F;messages。</p><p><strong>GC 日志</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020-03-16T17:49:13.785</span><span class="string">+0800:</span> <span class="attr">13484510.599: Total time for which application threads were stopped:</span> <span class="number">0.0072354</span> <span class="string">seconds,</span> <span class="attr">Stopping threads took:</span> <span class="number">0.0001536</span> <span class="string">seconds</span></span><br><span class="line"><span class="number">2020-03-16T18:01:23.149</span><span class="string">+0800:</span> <span class="attr">13485239.963:</span> [<span class="string">GC</span> <span class="string">pause</span> <span class="string">(G1</span> <span class="string">Evacuation</span> <span class="string">Pause)</span> <span class="string">(young)</span> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">start</span> <span class="string">choosing</span> <span class="string">CSet</span>, <span class="attr">_pending_cards:</span> <span class="number">7738</span>, <span class="attr">predicted base time:</span> <span class="number">5.74</span> <span class="string">ms</span>, <span class="attr">remaining time:</span> <span class="number">194.26</span> <span class="string">ms</span>, <span class="attr">target pause time:</span> <span class="number">200.00</span> <span class="string">ms</span>]</span><br><span class="line"> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">add</span> <span class="string">young</span> <span class="string">regions</span> <span class="string">to</span> <span class="string">CSet</span>, <span class="attr">eden:</span> <span class="number">255</span> <span class="string">regions</span>, <span class="attr">survivors:</span> <span class="number">1</span> <span class="string">regions</span>, <span class="attr">predicted young region time:</span> <span class="number">0.52</span> <span class="string">ms</span>]</span><br><span class="line"> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">finish</span> <span class="string">choosing</span> <span class="string">CSet</span>, <span class="attr">eden:</span> <span class="number">255</span> <span class="string">regions</span>, <span class="attr">survivors:</span> <span class="number">1</span> <span class="string">regions</span>, <span class="attr">old:</span> <span class="number">0</span> <span class="string">regions</span>, <span class="attr">predicted pause time:</span> <span class="number">6.26</span> <span class="string">ms</span>, <span class="attr">target pause time:</span> <span class="number">200.00</span> <span class="string">ms</span>]</span><br><span class="line">, <span class="number">0.0090963</span> <span class="string">secs</span>]</span><br><span class="line">   [<span class="attr">Parallel Time:</span> <span class="number">2.3</span> <span class="string">ms</span>, <span class="attr">GC Workers:</span> <span class="number">23</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Start</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">13485239965.1</span>, <span class="attr">Avg:</span> <span class="number">13485239965.4</span>, <span class="attr">Max:</span> <span class="number">13485239965.7</span>, <span class="attr">Diff:</span> <span class="number">0.6</span>]</span><br><span class="line">      [<span class="string">Ext</span> <span class="string">Root</span> <span class="string">Scanning</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.3</span>, <span class="attr">Max:</span> <span class="number">0.6</span>, <span class="attr">Diff:</span> <span class="number">0.6</span>, <span class="attr">Sum:</span> <span class="number">8.0</span>]</span><br><span class="line">      [<span class="string">Update</span> <span class="string">RS</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.1</span>, <span class="attr">Avg:</span> <span class="number">0.3</span>, <span class="attr">Max:</span> <span class="number">0.6</span>, <span class="attr">Diff:</span> <span class="number">0.5</span>, <span class="attr">Sum:</span> <span class="number">7.8</span>]</span><br><span class="line">         [<span class="attr">Processed Buffers: Min:</span> <span class="number">2</span>, <span class="attr">Avg:</span> <span class="number">5.7</span>, <span class="attr">Max:</span> <span class="number">11</span>, <span class="attr">Diff:</span> <span class="number">9</span>, <span class="attr">Sum:</span> <span class="number">131</span>]</span><br><span class="line">      [<span class="string">Scan</span> <span class="string">RS</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.1</span>, <span class="attr">Diff:</span> <span class="number">0.1</span>, <span class="attr">Sum:</span> <span class="number">0.8</span>]</span><br><span class="line">      [<span class="string">Code</span> <span class="string">Root</span> <span class="string">Scanning</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.0</span>, <span class="attr">Diff:</span> <span class="number">0.0</span>, <span class="attr">Sum:</span> <span class="number">0.3</span>]</span><br><span class="line">      [<span class="string">Object</span> <span class="string">Copy</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.2</span>, <span class="attr">Avg:</span> <span class="number">0.5</span>, <span class="attr">Max:</span> <span class="number">0.7</span>, <span class="attr">Diff:</span> <span class="number">0.4</span>, <span class="attr">Sum:</span> <span class="number">11.7</span>]</span><br><span class="line">      [<span class="string">Termination</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.0</span>, <span class="attr">Diff:</span> <span class="number">0.0</span>, <span class="attr">Sum:</span> <span class="number">0.3</span>]</span><br><span class="line">         [<span class="attr">Termination Attempts: Min:</span> <span class="number">1</span>, <span class="attr">Avg:</span> <span class="number">1.0</span>, <span class="attr">Max:</span> <span class="number">1</span>, <span class="attr">Diff:</span> <span class="number">0</span>, <span class="attr">Sum:</span> <span class="number">23</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Other</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.2</span>, <span class="attr">Max:</span> <span class="number">0.3</span>, <span class="attr">Diff:</span> <span class="number">0.3</span>, <span class="attr">Sum:</span> <span class="number">3.6</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Total</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">1.0</span>, <span class="attr">Avg:</span> <span class="number">1.4</span>, <span class="attr">Max:</span> <span class="number">1.9</span>, <span class="attr">Diff:</span> <span class="number">0.8</span>, <span class="attr">Sum:</span> <span class="number">32.6</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">End</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">13485239966.7</span>, <span class="attr">Avg:</span> <span class="number">13485239966.9</span>, <span class="attr">Max:</span> <span class="number">13485239967.0</span>, <span class="attr">Diff:</span> <span class="number">0.3</span>]</span><br><span class="line">   [<span class="attr">Code Root Fixup:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Code Root Purge:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Clear CT:</span> <span class="number">0.9</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Other:</span> <span class="number">5.9</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Choose CSet:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Ref Proc:</span> <span class="number">1.9</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Ref Enq:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Redirty Cards:</span> <span class="number">1.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Humongous Register:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Humongous Reclaim:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Free CSet:</span> <span class="number">0.2</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Eden:</span> <span class="number">4080.</span><span class="string">0M(4080.0M)-&gt;0.0B(4080.0M)</span> <span class="attr">Survivors:</span> <span class="number">16.</span><span class="string">0M-&gt;16.0M</span> <span class="attr">Heap:</span> <span class="number">4176.</span><span class="string">5M(8192.0M)-&gt;96.5M(8192.0M)</span>]</span><br><span class="line"> [<span class="attr">Times:</span> <span class="string">user=0.05</span> <span class="string">sys=0.00</span>, <span class="string">real=0.01</span> <span class="string">secs</span>]</span><br></pre></td></tr></table></figure><p>说明：GC 日志正常。</p><p><strong>Broker 错误日志</strong></p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">03</span>-<span class="number">16</span> <span class="number">17</span>:<span class="number">55</span>:<span class="number">15</span> ERROR BrokerControllerScheduledThread1 - SyncTopicConfig <span class="built_in">Exception</span>, x.x.x.x:<span class="number">10911</span> </span><br><span class="line">org.apache.rocketmq.remoting.exception.RemotingTimeoutException: wait response on the channel &lt;x.x.x.x:<span class="number">10909</span>&gt; timeout, <span class="number">3000</span>(ms)</span><br><span class="line">        at org.apache.rocketmq.remoting.netty.NettyRemotingAbstract.<span class="title function_ invoke__">invokeSyncImpl</span>(NettyRemotingAbstract.<span class="attr">java</span>:<span class="number">427</span>) ~[rocketmq-remoting-<span class="number">4.5</span>.<span class="number">2</span>.jar:<span class="number">4.5</span>.<span class="number">2</span>]</span><br><span class="line">        at org.apache.rocketmq.remoting.netty.NettyRemotingClient.<span class="title function_ invoke__">invokeSync</span>(NettyRemotingClient.<span class="attr">java</span>:<span class="number">375</span>) ~[rocketmq-remoting-<span class="number">4.5</span>.<span class="number">2</span>.jar:<span class="number">4.5</span>.<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>说明：通过查看 RocketMQ 的集群和 GC 日志，只能说明但是网络不可用，造成主从同步问题；并未发现 Broker 自身出问题了。</p><h3 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h3><p>系统使用 CentOS 6，内核版本为 2.6。通过摸排并未发现 broker 和 GC 本身的问题，却发现了系统 message 日志有频繁的“page allocation failure”和“blocked for more than 120 second”错误。所以将目光聚焦在系统层面，通过尝试系统参数设置，例如：min_free_kbytes 和 zone_reclaim_mode，然而并不能消除 CPU 毛刺问题。通过与社区朋友的会诊讨论，内核版本 2.6 操作系统内存回收存在 Bug。我们决定更换集群的操作系统。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>将集群的 CentOS 6 升级到 CentOS 7，内核版本也从 2.6 升级到了 3.10，升级后 CPU 毛刺问题不在乎出现。升级方式采取的方式先扩容后缩容，先把 CentOS 7 的节点加入集群后，再将 CentOS 6 的节点移除，详见前面实战部分“RocketMQ 集群平滑运维”。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Linux</span> <span class="selector-tag">version</span> <span class="number">3.10</span><span class="selector-class">.0-1062</span><span class="selector-class">.4</span><span class="selector-class">.1</span><span class="selector-class">.el7</span><span class="selector-class">.x86_64</span> (mockbuild<span class="variable">@kbuilder</span>.bsys.centos.org) (gcc version <span class="number">4.8</span>.<span class="number">5</span> <span class="number">20150623</span> (Red Hat <span class="number">4.8</span>.<span class="number">5</span>-<span class="number">39</span>) (GCC) ) <span class="selector-id">#1</span> <span class="selector-tag">SMP</span> <span class="selector-tag">Fri</span> <span class="selector-tag">Oct</span> <span class="number">18</span> <span class="number">17</span>:<span class="number">15</span>:<span class="number">30</span> <span class="selector-tag">UTC</span> <span class="number">2019</span></span><br></pre></td></tr></table></figure><h2 id="集群频繁抖动发送超时"><a href="#集群频繁抖动发送超时" class="headerlink" title="集群频繁抖动发送超时"></a>集群频繁抖动发送超时</h2><h3 id="现象描述-2"><a href="#现象描述-2" class="headerlink" title="现象描述"></a>现象描述</h3><p>监控和业务同学反馈发送超时，而且频繁出现。具体现象如下图。</p><h3 id="预热现象"><a href="#预热现象" class="headerlink" title="预热现象"></a>预热现象</h3><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095246617.jpg" alt="img"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095328878.jpg" alt="img"></p><p>说明：上图分别为开启预热时（<code>warmMapedFileEnable=true</code>）集群的发送 RT 监控、Broker 开启预热设置时的日志。</p><p><strong>存传输现象</strong></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095358560.jpg" alt="CPU 抖动"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095449761.jpg" alt="img"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095559121.jpg" alt="img"></p><p>说明：上图分别为开启堆外内存传输（<code>transferMsgByHeap=fals</code>e）时的 CPU 抖动截图、系统内存分配不足截图、Broker 日志截图。</p><h3 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h3><p>上面展现的两种显现均会导致集群 CPU 抖动、客户端发送超时，对业务造成影响。</p><p>预热设置：在预热文件时会填充 1 个 G 的假值 0 作为占位符，提前分配物理内存，防止消息写入时发生缺页异常。然而往往伴随着磁盘写入耗时过长、CPU 小幅抖动、业务具体表现为发送耗时过长，超时错误增多。关闭预热配置从集群 TPS 摸高情况来看并未有明显的差异，但是从稳定性角度关闭却很有必要。</p><p>堆外内存：transferMsgByHeap 设置为 false 时，通过堆外内存传输数据，相比堆内存传输减少了数据拷贝、零字节拷贝、效率更高。但是可能造成堆外内存分配不够，触发系统内存回收和落盘操作，设置为 true 时运行更加平稳。</p><h3 id="解决办法-1"><a href="#解决办法-1" class="headerlink" title="解决办法"></a>解决办法</h3><p>预热 warmMapedFileEnable 默认为 false，保持默认即可。如果开启了，可以通过热更新关闭。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -b x.x.x.x:10911 -n x.x.x.x:9876 -k warmMapedFileEnable -v <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>内存传输参数 transferMsgByHeap 默认为 true（即：通过堆内内存传输）保持默认即可。如果关闭了，可以通过热更新开启。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -b x.x.x.x:10911 -n x.x.x.x:9876 -k transferMsgByHeap -v <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="用了此属性消费性能下降一半"><a href="#用了此属性消费性能下降一半" class="headerlink" title="用了此属性消费性能下降一半"></a>用了此属性消费性能下降一半</h2><h3 id="现象描述-3"><a href="#现象描述-3" class="headerlink" title="现象描述"></a>现象描述</h3><p>配置均采用 8C16G，RocketMQ 的消费线程 20 个，通过测试消费性能在 1.5 万 tps 左右。通过 tcpdump 显示在消费的机器存在频繁的域名解析过程；10.x.x.185 向 DNS 服务器 100.x.x.136.domain 和 10.x.x.138.domain 请求解析。而 10.x.x.185 这台机器又是消息发送者的机器 IP，测试的发送和消费分别部署在两台机器上。</p><p>问题：消费时为何会有消息发送方的 IP 呢？而且该 IP 还不断进行域名解析。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200911100907927.jpg" alt="img"></p><h3 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h3><p>通过 dump 线程堆栈，如下图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200911101209514.jpg" alt="img"></p><p>代码定位：在消费时有通过 MessageExt.bornHost.getBornHostNameString 获取消费这信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MessageExt</span> <span class="keyword">extends</span> <span class="title class_">Message</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">5720810158625748049L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> queueId;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> storeSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> queueOffset;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> sysFlag;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> bornTimestamp;</span><br><span class="line">    <span class="keyword">private</span> SocketAddress bornHost;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> storeTimestamp;</span><br><span class="line">    <span class="keyword">private</span> SocketAddress storeHost;</span><br><span class="line">    <span class="keyword">private</span> String msgId;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> commitLogOffset;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> bodyCRC;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> reconsumeTimes;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> preparedTransactionOffset;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 GetBornHostNameString 获取 HostName 时会根据 IP 反查 DNS 服务器：</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">InetSocketAddress inetSocketAddress = (InetSocketAddress)<span class="keyword">this</span>.bornHost;</span><br><span class="line"><span class="keyword">return</span> inetSocketAddress.getAddress().getHostName();</span><br></pre></td></tr></table></figure><h3 id="解决办法-2"><a href="#解决办法-2" class="headerlink" title="解决办法"></a>解决办法</h3><p>消费的时候不要使用 MessageExt.bornHost.getBornHostNameString 即可，去掉该属性，配置 8C16G 的机器消费性能在 3 万 TPS，提升了 1 倍。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;系统参数调优&quot;&gt;&lt;a href=&quot;#系统参数调优&quot; class=&quot;headerlink&quot; title=&quot;系统参数调优&quot;&gt;&lt;/a&gt;系统参数调优&lt;/h1&gt;&lt;p&gt;在解压 RocketMQ 安装包后，在 bin 目录中有个 os.sh 的文件，该文件由 RocketMQ </summary>
      
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/categories/RocketMQ/"/>
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
  </entry>
  
</feed>
