<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Palette</title>
  <icon>https://www.gravatar.com/avatar/f6d0550c9229791f51dcfd63ef1e86d9</icon>
  <subtitle>个人博客</subtitle>
  <link href="https://palette-k.github.io/atom.xml" rel="self"/>
  
  <link href="https://palette-k.github.io/"/>
  <updated>2025-09-12T08:31:33.510Z</updated>
  <id>https://palette-k.github.io/</id>
  
  <author>
    <name>Palette</name>
    <email>1148432487@qq.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>如何设计一个秒杀系统</title>
    <link href="https://palette-k.github.io/2025/09/12/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/"/>
    <id>https://palette-k.github.io/2025/09/12/%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/</id>
    <published>2025-09-12T03:42:27.000Z</published>
    <updated>2025-09-12T08:31:33.510Z</updated>
    
    <content type="html"><![CDATA[<h1 id="不同场景下的不同架构案例"><a href="#不同场景下的不同架构案例" class="headerlink" title="不同场景下的不同架构案例"></a>不同场景下的不同架构案例</h1><p>如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面增加一个“定时上架”功能，仅在秒杀开始时才让用户看到购买按钮，当商品的库存卖完了也就结束了。这就是当时第一个版本的秒杀系统实现方式。</p><p>但随着请求量的加大（比如从1w&#x2F;s到了10w&#x2F;s的量级），这个简单的架构很快就遇到了瓶颈，因此需要做架构改造来提升系统性能。这些架构改造包括：</p><ol><li>把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；</li><li>在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；</li><li>将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；</li><li>增加秒杀答题，防止有秒杀器抢单。</li></ol><p><img src="https://i0.hdslb.com/bfs/openplatform/5d227f416eecc2b7d5d67fc81dadaef7c026170f.png" alt="image-20250912114800915"></p><p>然而这个架构仍然支持不了超过100w&#x2F;s的请求量，所以为了进一步提升秒杀系统的性能，我们又对架构做进一步升级，比如：</p><ol><li>对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；</li><li>在服务端对秒杀商品进行本地缓存，不需要再调用依赖系统的后台服务获取数据，甚至不需要去公共的缓存集群中查询数据，这样不仅可以减少系统调用，而且能够避免压垮公共缓存集群。</li><li>增加系统限流保护，防止最坏情况发生。</li></ol><p>我们对页面进行了进一步的静态化，秒杀过程中不需要刷新整个页面，而只需要向服务端请求很少的动态数据。而且，最关键的详情和交易系统都增加了本地缓存，来提前缓存秒杀商品的信息，热点数据库也做了独立部署，等等。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2b3360a22d998a4d3fc49221fb41aa34da2f7626.png" alt="image-20250912114836701"></p><h1 id="动静分离方案"><a href="#动静分离方案" class="headerlink" title="动静分离方案"></a>动静分离方案</h1><h2 id="何为动静数据"><a href="#何为动静数据" class="headerlink" title="何为动静数据"></a>何为动静数据</h2><p>简单来说，<strong>“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和URL、浏览者、时间、地域相关，以及是否含有Cookie等私密数据</strong>。比如说：</p><ol><li>很多媒体类的网站，某一篇文章的内容不管是你访问还是我访问，它都是一样的。所以它就是一个典型的静态数据，但是它是个动态页面。</li><li>我们如果现在访问淘宝的首页，每个人看到的页面可能都是不一样的，淘宝首页中包含了很多根据访问者特征推荐的信息，而这些个性化的数据就可以理解为动态数据了。</li></ol><p>那么，怎样对静态数据做缓存呢？我在这里总结了几个重点。</p><p><strong>第一，你应该把静态数据缓存到离用户最近的地方</strong>。静态数据就是那些相对不会变化的数据，因此我们可以把它们缓存起来。缓存到哪里呢？常见的就三种，用户浏览器里、CDN上或者在服务端的Cache中。你应该根据情况，把它们尽量缓存到离用户最近的地方。</p><p><strong>第二，静态化改造就是要直接缓存HTTP连接</strong>。相较于普通的数据缓存而言，你肯定还听过系统的静态化改造。静态化改造是直接缓存HTTP连接而不是仅仅缓存数据，如下图所示，Web代理服务器根据请求URL，直接取出对应的HTTP响应头和响应体然后直接返回，这个响应过程简单得连HTTP协议都不用重新组装，甚至连HTTP请求头也不需要解析。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d6b55cefca40b52b2b7b753c5138fbde48a805bc.png" alt="image-20250912115240035"></p><p>第三，让谁来缓存静态数据也很重要。不同语言写的Cache软件处理缓存数据的效率也各不相同。以Java为例，因为Java系统本身也有其弱点（比如不擅长处理大量连接请求，每个连接消耗的内存较多，Servlet容器解析HTTP协议较慢），所以你可以不在Java层做缓存，而是直接在Web服务器层上做，这样你就可以屏蔽Java语言层面的一些弱点；而相比起来，Web服务器（如Nginx、Apache、Varnish）也更擅长处理大并发的静态文件请求。</p><h2 id="如何做动静分离的改造"><a href="#如何做动静分离的改造" class="headerlink" title="如何做动静分离的改造"></a>如何做动静分离的改造</h2><p>下面，我以典型的商品详情系统为例来详细介绍。这里，你可以先打开京东或者淘宝的商品详情页，看看这个页面里都有哪些动静数据。我们从以下5个方面来分离出动态内容。</p><ol><li><strong>URL唯一化</strong>。商品详情系统天然地就可以做到URL唯一化，比如每个商品都由ID来标识，那么<a href="http://item.xxx.com/item.htm?id=xxxx%E5%B0%B1%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA%E5%94%AF%E4%B8%80%E7%9A%84URL%E6%A0%87%E8%AF%86%E3%80%82%E4%B8%BA%E5%95%A5%E8%A6%81URL%E5%94%AF%E4%B8%80%E5%91%A2%EF%BC%9F%E5%89%8D%E9%9D%A2%E8%AF%B4%E4%BA%86%E6%88%91%E4%BB%AC%E6%98%AF%E8%A6%81%E7%BC%93%E5%AD%98%E6%95%B4%E4%B8%AAHTTP%E8%BF%9E%E6%8E%A5%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BB%A5%E4%BB%80%E4%B9%88%E4%BD%9C%E4%B8%BAKey%E5%91%A2%EF%BC%9F%E5%B0%B1%E4%BB%A5URL%E4%BD%9C%E4%B8%BA%E7%BC%93%E5%AD%98%E7%9A%84Key%EF%BC%8C%E4%BE%8B%E5%A6%82%E4%BB%A5id=xxx%E8%BF%99%E4%B8%AA%E6%A0%BC%E5%BC%8F%E8%BF%9B%E8%A1%8C%E5%8C%BA%E5%88%86%E3%80%82">http://item.xxx.com/item.htm?id=xxxx就可以作为唯一的URL标识。为啥要URL唯一呢？前面说了我们是要缓存整个HTTP连接，那么以什么作为Key呢？就以URL作为缓存的Key，例如以id=xxx这个格式进行区分。</a></li><li><strong>分离浏览者相关的因素</strong>。浏览者相关的因素包括是否已登录，以及登录身份等，这些相关因素我们可以单独拆分出来，通过动态请求来获取。</li><li><strong>分离时间因素</strong>。服务端输出的时间也通过动态请求获取。</li><li><strong>异步化地域因素</strong>。详情页面上与地域相关的因素做成异步方式获取，当然你也可以通过动态请求方式获取，只是这里通过异步获取更合适。</li><li><strong>去掉Cookie</strong>。服务端输出的页面包含的Cookie可以通过代码软件来删除，如Web服务器Varnish可以通过unset req.http.cookie 命令去掉Cookie。注意，这里说的去掉Cookie并不是用户端收到的页面就不含Cookie了，而是说，在缓存的静态数据中不含有Cookie。</li></ol><p>分离出动态内容之后，如何组织这些内容页就变得非常关键了。这里我要提醒你一点，因为这其中很多动态内容都会被页面中的其他模块用到，如判断该用户是否已登录、用户ID是否匹配等，所以这个时候我们应该将这些信息JSON化（用JSON格式组织这些数据），以方便前端获取。</p><p>前面我们介绍里用缓存的方式来处理静态数据。而动态内容的处理通常有两种方案：ESI（Edge Side Includes）方案和CSI（Client Side Include）方案。</p><ol><li><strong>ESI方案（或者SSI）</strong>：即在Web代理服务器上做动态内容请求，并将请求插入到静态页面中，当用户拿到页面时已经是一个完整的页面了。这种方式对服务端性能有些影响，但是用户体验较好。</li><li><strong>CSI方案</strong>。即单独发起一个异步JavaScript 请求，以向服务端获取动态内容。这种方式服务端性能更佳，但是用户端页面可能会延时，体验稍差。</li></ol><h2 id="动静分离的几种架构方案"><a href="#动静分离的几种架构方案" class="headerlink" title="动静分离的几种架构方案"></a>动静分离的几种架构方案</h2><p>前面我们通过改造把静态数据和动态数据做了分离，那么如何在系统架构上进一步对这些动态和静态数据重新组合，再完整地输出给用户呢？</p><p>这就涉及对用户请求路径进行合理的架构了。根据架构上的复杂度，有3种方案可选：</p><ol><li>实体机单机部署；</li><li>统一Cache层；</li><li>上CDN。</li></ol><h3 id="方案1：实体机单机部署"><a href="#方案1：实体机单机部署" class="headerlink" title="方案1：实体机单机部署"></a>方案1：实体机单机部署</h3><p>这种方案是将虚拟机改为实体机，以增大Cache的容量，并且采用了一致性Hash分组的方式来提升命中率。这里将Cache分成若干组，是希望能达到命中率和访问热点的平衡。Hash分组越少，缓存的命中率肯定就会越高，但短板是也会使单个商品集中在一个分组中，容易导致Cache被击穿，所以我们应该适当增加多个相同的分组，来平衡访问热点和命中率的问题。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/986972ae2092227affa74c5b03bbcf3ca3f6db57.png" alt="image-20250912115638023"></p><p>实体机单机部署有以下几个优点：</p><ol><li>没有网络瓶颈，而且能使用大内存；</li><li>既能提升命中率，又能减少Gzip压缩；</li><li>减少Cache失效压力，因为采用定时失效方式，例如只缓存3秒钟，过期即自动失效。</li></ol><p>这个方案中，虽然把通常只需要虚拟机或者容器运行的Java应用换成实体机，优势很明显，它会增加单机的内存容量，但是一定程度上也造成了CPU的浪费，因为单个的Java进程很难用完整个实体机的CPU。</p><p>另外就是，一个实体机上部署了Java应用又作为Cache来使用，这造成了运维上的高复杂度，所以这是一个折中的方案。如果你的公司里，没有更多的系统有类似需求，那么这样做也比较合适，如果你们有多个业务系统都有静态化改造的需求，那还是建议把Cache层单独抽出来公用比较合理，如下面的方案2所示。</p><h3 id="方案2：统一Cache层"><a href="#方案2：统一Cache层" class="headerlink" title="方案2：统一Cache层"></a>方案2：统一Cache层</h3><p>所谓统一Cache层，就是将单机的Cache统一分离出来，形成一个单独的Cache集群。统一Cache层是个更理想的可推广方案，该方案的结构图如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e8594ffc6609e96746a9cc8c8eef50a4ac0c22cc.png" alt="image-20250912115702515"></p><p>将Cache层单独拿出来统一管理可以减少运维成本，同时也方便接入其他静态化系统。此外，它还有一些优点。</p><ol><li>单独一个Cache层，可以减少多个应用接入时使用Cache的成本。这样接入的应用只要维护自己的Java系统就好，不需要单独维护Cache，而只关心如何使用即可。</li><li>统一Cache的方案更易于维护，如后面加强监控、配置的自动化，只需要一套解决方案就行，统一起来维护升级也比较方便。</li><li>可以共享内存，最大化利用内存，不同系统之间的内存可以动态切换，从而能够有效应对各种攻击。</li></ol><p>这种方案虽然维护上更方便了，但是也带来了其他一些问题，比如缓存更加集中，导致：</p><ol><li>Cache层内部交换网络成为瓶颈；</li><li>缓存服务器的网卡也会是瓶颈；</li><li>机器少风险较大，挂掉一台就会影响很大一部分缓存数据。</li></ol><p>要解决上面这些问题，可以再对Cache做Hash分组，即一组Cache缓存的内容相同，这样能够避免热点数据过度集中导致新的瓶颈产生。</p><blockquote><p>一个商品数据存储在多个Cache实例中，如何保证数据一致性呢？</p></blockquote><p>这个专栏中提的Hash分组都是基于Nginx+Varnish实现的，Nginx把请求的URL中的商品ID进行Hash并路由到一个upstream中，这个upstream挂载一个Varnish分组（如下图所示）。这样，一个相同的商品就可以随机访问一个分组的任意一台Varnish机器了。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/743f34318cce13b91dcdeb6c671a1325e8f07ed2.png" alt="image-20250912162900348"></p><p>有Cache的地方就必然存在失效问题。为啥要失效？因为要保证数据的一致性。所以要用到Cache必然会问如何保证Cache和DB的数据一致性，如果Cache有分组的话，还要保证一个分组中多个实例之间数据的一致性，就像保证MySQL的主从一致一样。</p><p>其实，失效有主动失效和被动失效两种方式。</p><ul><li>被动失效，主要处理如模板变更和一些对时效性不太敏感数据的失效，采用设置一定时间长度（如只缓存3秒钟）这种自动失效的方式。当然，你也要开发一个后台管理界面，以便能够在紧急情况下手工失效某些Cache。</li><li>主动失效，一般有Cache失效中心监控数据库表变化发送失效请求、系统发布也需要清空Cache数据等几种场景。其中失效中心承担了主要的失效功能，这个失效中心的逻辑图如下：</li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/8b53486d63156810d687cbe61fcc36941c34793d.png" alt="image-20250912163041092"></p><p>失效中心会监控关键数据表的变更（有个中间件来解析MySQL的binglog，然后发现有Insert、Update、Delete等操作时，会把变更前的数据以及要变更的数据转成一个消息发送给订阅方），通过这种方式来发送失效请求给Cache，从而清除Cache数据。如果Cache数据放在CDN上，那么也可以采用类似的方式来设计级联的失效结构，采用主动发请求给Cache软件失效的方式，如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/3607b38a11073d67a13333ea184a8ed537b481c2.png" alt="image-20250912163117755"></p><p>这种失效有失效中心将失效请求发送给每个CDN节点上的Console机，然后Console机来发送失效请求给每台Cache机器。</p><h3 id="方案3：上CDN"><a href="#方案3：上CDN" class="headerlink" title="方案3：上CDN"></a>方案3：上CDN</h3><p>在将整个系统做动静分离后，我们自然会想到更进一步的方案，就是将Cache进一步前移到CDN上，因为CDN离用户最近，效果会更好。</p><p>但是要想这么做，有以下几个问题需要解决。</p><ol><li><strong>失效问题</strong>。前面我们也有提到过缓存时效的问题，不知道你有没有理解，我再来解释一下。谈到静态数据时，我说过一个关键词叫“相对不变”，它的言外之意是“可能会变化”。比如一篇文章，现在不变，但如果你发现个错别字，是不是就会变化了？如果你的缓存时效很长，那用户端在很长一段时间内看到的都是错的。所以，这个方案中也是，我们需要保证CDN可以在秒级时间内，让分布在全国各地的Cache同时失效，这对CDN的失效系统要求很高。</li><li><strong>命中率问题</strong>。Cache最重要的一个衡量指标就是“高命中率”，不然Cache的存在就失去了意义。同样，如果将数据全部放到全国的CDN上，必然导致Cache分散，而Cache分散又会导致访问请求命中同一个Cache的可能性降低，那么命中率就成为一个问题。</li><li><strong>发布更新问题</strong>。如果一个业务系统每周都有日常业务需要发布，那么发布系统必须足够简洁高效，而且你还要考虑有问题时快速回滚和排查问题的简便性。</li></ol><p>从前面的分析来看，将商品详情系统放到全国的所有CDN节点上是不太现实的，因为存在失效问题、命中率问题以及系统的发布更新问题。那么是否可以选择若干个节点来尝试实施呢？答案是“可以”，但是这样的节点需要满足几个条件：</p><ol><li>靠近访问量比较集中的地区；</li><li>离主站相对较远；</li><li>节点到主站间的网络比较好，而且稳定；</li><li>节点容量比较大，不会占用其他CDN太多的资源。</li></ol><p>最后，还有一点也很重要，那就是：节点不要太多。</p><p>基于上面几个因素，选择CDN的二级Cache比较合适，因为二级Cache数量偏少，容量也更大，让用户的请求先回源的CDN的二级Cache中，如果没命中再回源站获取数据，部署方式如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/871f14b3e51d04c89e03e5af239796b4e6237def.png" alt="image-20250912115722599"></p><p>使用CDN的二级Cache作为缓存，可以达到和当前服务端静态化Cache类似的命中率，因为节点数不多，Cache不是很分散，访问量也比较集中，这样也就解决了命中率问题，同时能够给用户最好的访问体验，是当前比较理想的一种CDN化方案。</p><p>除此之外，CDN化部署方案还有以下几个特点：</p><ol><li>把整个页面缓存在用户浏览器中；</li><li>如果强制刷新整个页面，也会请求CDN；</li><li>实际有效请求，只是用户对“刷新抢宝”按钮的点击。</li></ol><p>这样就把90%的静态数据缓存在了用户端或者CDN上，当真正秒杀时，用户只需要点击特殊的“刷新抢宝”按钮，而不需要刷新整个页面。这样一来，系统只是向服务端请求很少的有效数据，而不需要重复请求大量的静态数据。</p><p>秒杀的动态数据和普通详情页面的动态数据相比更少，性能也提升了3倍以上。所以“抢宝”这种设计思路，让我们不用刷新页面就能够很好地请求到服务端最新的动态数据。</p><h1 id="二八原则：有针对性地处理好系统的“热点数据”"><a href="#二八原则：有针对性地处理好系统的“热点数据”" class="headerlink" title="二八原则：有针对性地处理好系统的“热点数据”"></a>二八原则：有针对性地处理好系统的“热点数据”</h1><h2 id="发现热点数据"><a href="#发现热点数据" class="headerlink" title="发现热点数据"></a>发现热点数据</h2><h3 id="发现静态热点数据"><a href="#发现静态热点数据" class="headerlink" title="发现静态热点数据"></a>发现静态热点数据</h3><p>如前面讲的，静态热点数据可以通过商业手段，例如强制让卖家通过报名参加的方式提前把热点商品筛选出来，实现方式是通过一个运营系统，把参加活动的商品数据进行打标，然后通过一个后台系统对这些热点商品进行预处理，如提前进行缓存。但是这种通过报名提前筛选的方式也会带来新的问题，即增加卖家的使用成本，而且实时性较差，也不太灵活。</p><p>不过，除了提前报名筛选这种方式，你还可以通过技术手段提前预测，例如对买家每天访问的商品进行大数据计算，然后统计出TOP N的商品，我们可以认为这些TOP N的商品就是热点商品。</p><h3 id="发现动态热点数据"><a href="#发现动态热点数据" class="headerlink" title="发现动态热点数据"></a>发现动态热点数据</h3><p>我们可以通过卖家报名或者大数据预测这些手段来提前预测静态热点数据，但这其中有一个痛点，就是实时性较差，如果我们的系统能在秒级内自动发现热点商品那就完美了。</p><p>能够动态地实时发现热点不仅对秒杀商品，对其他热卖商品也同样有价值，所以我们需要想办法实现热点的动态发现功能。</p><p>这里我给出一个动态热点发现系统的具体实现。</p><ol><li>构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点Key，如Nginx、缓存、RPC服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。</li><li>建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上Nginx模块统计的热点URL。</li><li>将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。</li></ol><p>这里我给出了一个图，其中用户访问商品时经过的路径有很多，我们主要是依赖前面的导购页面（包括首页、搜索页面、商品详情、购物车等）提前识别哪些商品的访问量高，通过这些系统中的中间件来收集热点数据，并记录到日志中。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/83dcc8c0d1a9284b05c9d5fa8b63e4f61a7b3ce0.png" alt="image-20250912120422769"></p><h2 id="处理热点数据"><a href="#处理热点数据" class="headerlink" title="处理热点数据"></a>处理热点数据</h2><p><strong>处理热点数据通常有几种思路：一是优化，二是限制，三是隔离</strong>。</p><p>先来说说优化。优化热点数据最有效的办法就是缓存热点数据，如果热点数据做了动静分离，那么可以长期缓存静态数据。但是，缓存热点数据更多的是“临时”缓存，即不管是静态数据还是动态数据，都用一个队列短暂地缓存数秒钟，由于队列长度有限，可以采用LRU淘汰算法替换。</p><p>再来说说限制。限制更多的是一种保护机制，限制的办法也有很多，例如对被访问商品的ID做一致性Hash，然后根据Hash做分桶，每个分桶设置一个处理队列，这样可以把热点商品限制在一个请求队列里，防止因某些热点商品占用太多的服务器资源，而使其他请求始终得不到服务器的处理资源。</p><p>最后介绍一下隔离。秒杀系统设计的第一个原则就是将这种热点数据隔离出来，不要让1%的请求影响到另外的99%，隔离出来后也更方便对这1%的请求做针对性的优化。</p><p>具体到“秒杀”业务，我们可以在以下几个层次实现隔离。</p><ol><li><strong>业务隔离</strong>。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来说，卖家报名后对我们来说就有了已知热点，因此可以提前做好预热。</li><li><strong>系统隔离</strong>。系统隔离更多的是运行时的隔离，可以通过分组部署的方式和另外99%分开。秒杀可以申请单独的域名，目的也是让请求落到不同的集群中。</li><li><strong>数据隔离</strong>。秒杀所调用的数据大部分都是热点数据，比如会启用单独的Cache集群或者MySQL数据库来放热点数据，目的也是不想0.01%的数据有机会影响99.99%数据。</li></ol><p>当然了，实现隔离有很多种办法。比如，你可以按照用户来区分，给不同的用户分配不同的Cookie，在接入层，路由到不同的服务接口中；再比如，你还可以在接入层针对URL中的不同Path来设置限流策略。服务层调用不同的服务接口，以及数据层通过给数据打标来区分等等这些措施，其目的都是把已经识别出来的热点请求和普通的请求区分开。</p><h1 id="流量削峰这事应该怎么做？"><a href="#流量削峰这事应该怎么做？" class="headerlink" title="流量削峰这事应该怎么做？"></a>流量削峰这事应该怎么做？</h1><h2 id="排队"><a href="#排队" class="headerlink" title="排队"></a>排队</h2><p>要对流量进行削峰，最容易想到的解决方案就是用消息队列来缓冲瞬时流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑地将消息推送出去。</p><p>但是，如果流量峰值持续一段时间达到了消息队列的处理上限，例如本机的消息积压达到了存储空间的上限，消息队列同样也会被压垮，这样虽然保护了下游的系统，但是和直接把请求丢弃也没多大的区别。就像遇到洪水爆发时，即使是有水库恐怕也无济于事。</p><p>除了消息队列，类似的排队方式还有很多，例如：</p><ol><li>利用线程池加锁等待也是一种常用的排队方式；</li><li>先进先出、先进后出等常用的内存排队算法的实现方式；</li><li>把请求序列化到文件中，然后再顺序地读文件（例如基于MySQL binlog的同步机制）来恢复请求等方式。</li></ol><h2 id="答题"><a href="#答题" class="headerlink" title="答题"></a>答题</h2><p>最早期的秒杀只是纯粹地刷新页面和点击购买按钮，它是后来才增加了答题功能的。那么，为什么要增加答题功能呢？</p><p>这主要是为了增加购买的复杂度，从而达到两个目的。</p><p>第一个目的是防止部分买家使用秒杀器在参加秒杀时作弊。2011年秒杀非常火的时候，秒杀器也比较猖獗，因而没有达到全民参与和营销的目的，所以系统增加了答题来限制秒杀器。增加答题后，下单的时间基本控制在2s后，秒杀器的下单比例也大大下降。</p><p>第二个目的其实就是延缓请求，起到对请求流量进行削峰的作用，从而让系统能够更好地支持瞬时的流量高峰。这个重要的功能就是把峰值的下单请求拉长，从以前的1s之内延长到2s~10s。这样一来，请求峰值基于时间分片了。这个时间的分片对服务端处理并发非常重要，会大大减轻压力。而且，由于请求具有先后顺序，靠后的请求到来时自然也就没有库存了，因此根本到不了最后的下单步骤，所以真正的并发写就非常有限了。这种设计思路目前用得非常普遍，如当年支付宝的“咻一咻”、微信的“摇一摇”都是类似的方式。</p><p>这里，我重点说一下秒杀答题的设计思路。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/013b09c6b0eae6269ad0742ee7059ea59a172628.png" alt="image-20250912155807956"></p><p>如上图所示，整个秒杀答题的逻辑主要分为3部分。</p><ol><li><strong>题库生成模块</strong>，这个部分主要就是生成一个个问题和答案，其实题目和答案本身并不需要很复杂，重要的是能够防止由机器来算出结果，即防止秒杀器来答题。</li><li><strong>题库的推送模块</strong>，用于在秒杀答题前，把题目提前推送给详情系统和交易系统。题库的推送主要是为了保证每次用户请求的题目是唯一的，目的也是防止答题作弊。</li><li><strong>题目的图片生成模块</strong>，用于把题目生成为图片格式，并且在图片里增加一些干扰因素。这也同样是为防止机器直接来答题，它要求只有人才能理解题目本身的含义。这里还要注意一点，由于答题时网络比较拥挤，我们应该把题目的图片提前推送到CDN上并且要进行预热，不然的话当用户真正请求题目时，图片可能加载比较慢，从而影响答题的体验。</li></ol><p>其实真正答题的逻辑比较简单，很好理解：当用户提交的答案和题目对应的答案做比较，如果通过了就继续进行下一步的下单逻辑，否则就失败。我们可以把问题和答案用下面这样的key来进行MD5加密：</p><ul><li>问题key：userId+itemId+question_Id+time+PK</li><li>答案key：userId+itemId+answer+PK</li></ul><p>验证的逻辑如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a984a6e0a560de3994f6c6448eeb307ee697840c.png" alt="image-20250912155917942"></p><p>注意，这里面的验证逻辑，除了验证问题的答案以外，还包括用户本身身份的验证，例如是否已经登录、用户的Cookie是否完整、用户是否重复频繁提交等。</p><p>除了做正确性验证，我们还可以对提交答案的时间做些限制，例如从开始答题到接受答案要超过1s，因为小于1s是人为操作的可能性很小，这样也能防止机器答题的情况。</p><h2 id="分层过滤"><a href="#分层过滤" class="headerlink" title="分层过滤"></a>分层过滤</h2><p>前面介绍的排队和答题要么是少发请求，要么对发出来的请求进行缓冲，而针对秒杀场景还有一种方法，就是对请求进行分层过滤，从而过滤掉一些无效的请求。分层过滤其实就是采用“漏斗”式设计来处理请求的，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c7aa7c6890ffec67c74f2acea3924f7b06230cc7.png" alt="image-20250912160024914"></p><p>假如请求分别经过CDN、前台读系统（如商品详情系统）、后台系统（如交易系统）和数据库这几层，那么：</p><ul><li>大部分数据和流量在用户浏览器或者CDN上获取，这一层可以拦截大部分数据的读取；</li><li>经过第二层（即前台系统）时数据（包括强一致性的数据）尽量得走Cache，过滤一些无效的请求；</li><li>再到第三层后台系统，主要做数据的二次检验，对系统做好保护和限流，这样数据量和请求就进一步减少；</li><li>最后在数据层完成数据的强一致性校验。</li></ul><p>这样就像漏斗一样，尽量把数据量和请求量一层一层地过滤和减少了。</p><p><strong>分层过滤的核心思想是：在不同的层次尽可能地过滤掉无效请求，让“漏斗”最末端的才是有效请求</strong>。而要达到这种效果，我们就必须对数据做分层的校验。</p><p>分层校验的基本原则是：</p><ol><li>将动态请求的读数据缓存（Cache）在Web端，过滤掉无效的数据读；</li><li>对读数据不做强一致性校验，减少因为一致性校验产生瓶颈的问题；</li><li>对写数据进行基于时间的合理分片，过滤掉过期的失效请求；</li><li>对写请求做限流保护，将超出系统承载能力的请求过滤掉；</li><li>对写数据进行强一致性校验，只保留最后有效的数据。</li></ol><h1 id="影响性能的因素有哪些？"><a href="#影响性能的因素有哪些？" class="headerlink" title="影响性能的因素有哪些？"></a>影响性能的因素有哪些？</h1><h2 id="影响性能的因素"><a href="#影响性能的因素" class="headerlink" title="影响性能的因素"></a>影响性能的因素</h2><p>我们讨论的主要是系统服务端性能，一般用QPS（Query Per Second，每秒请求数）来衡量，还有一个影响和QPS也息息相关，那就是响应时间（Response Time，RT），它可以理解为服务器处理响应的耗时。</p><p><strong>首先，我们先来看看响应时间和QPS有啥关系</strong>。</p><p>对于大部分的Web系统而言，响应时间一般都是由CPU执行时间和线程等待时间（比如RPC、IO等待、Sleep、Wait等）组成，即服务器在处理一个请求时，一部分是CPU本身在做运算，还有一部分是在各种等待。</p><p>理解了服务器处理请求的逻辑，估计你会说为什么我们不去减少这种等待时间。很遗憾，根据我们实际的测试发现，减少线程等待时间对提升性能的影响没有我们想象得那么大，它并不是线性的提升关系，这点在很多代理服务器（Proxy）上可以做验证。</p><p>如果代理服务器本身没有CPU消耗，我们在每次给代理服务器代理的请求加个延时，即增加响应时间，但是这对代理服务器本身的吞吐量并没有多大的影响，因为代理服务器本身的资源并没有被消耗，可以通过增加代理服务器的处理线程数，来弥补响应时间对代理服务器的QPS的影响。</p><p>其实，真正对性能有影响的是CPU的执行时间。这也很好理解，因为CPU的执行真正消耗了服务器的资源。经过实际的测试，如果减少CPU一半的执行时间，就可以增加一倍的QPS。</p><p>也就是说，我们应该致力于减少CPU的执行时间。</p><p><strong>其次，我们再来看看线程数对QPS的影响</strong>。</p><p>单看“总QPS”的计算公式，你会觉得线程数越多QPS也就会越高，但这会一直正确吗？显然不是，线程数不是越多越好，因为线程本身也消耗资源，也受到其他因素的制约。例如，线程越多系统的线程切换成本就会越高，而且每个线程也都会耗费一定内存。</p><p>那么，设置什么样的线程数最合理呢？其实<strong>很多多线程的场景都有一个默认配置，即“线程数 &#x3D; 2 * CPU核数 + 1”</strong>。除去这个配置，还有一个根据最佳实践得出来的公式：</p><blockquote><p>线程数 &#x3D; [(线程等待时间 + 线程CPU时间) &#x2F; 线程CPU时间] × CPU数量</p></blockquote><p>当然，最好的办法是通过性能测试来发现最佳的线程数。</p><p>换句话说，要提升性能我们就要减少CPU的执行时间，另外就是要设置一个合理的并发线程数，通过这两方面来显著提升服务器的性能。</p><h2 id="如何发现瓶颈"><a href="#如何发现瓶颈" class="headerlink" title="如何发现瓶颈"></a>如何发现瓶颈</h2><p>那么，如何发现CPU的瓶颈呢？其实有很多CPU诊断工具可以发现CPU的消耗，最常用的就是JProfiler和Yourkit这两个工具，它们可以列出整个请求中每个函数的CPU执行时间，可以发现哪个函数消耗的CPU时间最多，以便你有针对性地做优化。</p><p>当然还有一些办法也可以近似地统计CPU的耗时，例如通过jstack定时地打印调用栈，如果某些函数调用频繁或者耗时较多，那么那些函数就会多次出现在系统调用栈里，这样相当于采样的方式也能够发现耗时较多的函数。</p><h2 id="如何优化系统"><a href="#如何优化系统" class="headerlink" title="如何优化系统"></a>如何优化系统</h2><h3 id="减少编码"><a href="#减少编码" class="headerlink" title="减少编码"></a>减少编码</h3><p>Java的编码运行比较慢，这是Java的一大硬伤。在很多场景下，只要涉及字符串的操作（如输入输出操作、I&#x2F;O操作）都比较耗CPU资源，不管它是磁盘I&#x2F;O还是网络I&#x2F;O，因为都需要将字符转换成字节，而这个转换必须编码。</p><p>那么如何才能减少编码呢？例如，网页输出是可以直接进行流输出的，即用resp.getOutputStream()函数写数据，把一些静态的数据提前转化成字节，等到真正往外写的时候再直接用OutputStream()函数写，就可以减少静态数据的编码转换。</p><p>我在《深入分析Java Web技术内幕》一书中介绍的“Velocity优化实践”一章的内容，就是基于把静态的字符串提前编码成字节并缓存，然后直接输出字节内容到页面，从而大大减少编码的性能消耗的，网页输出的性能比没有提前进行字符到字节转换时提升了30%左右。</p><h3 id="减少序列化"><a href="#减少序列化" class="headerlink" title="减少序列化"></a>减少序列化</h3><p>序列化大部分是在RPC中发生的，因此避免或者减少RPC就可以减少序列化，当然当前的序列化协议也已经做了很多优化来提升性能。有一种新的方案，就是可以将多个关联性比较强的应用进行“合并部署”，而减少不同应用之间的RPC也可以减少序列化的消耗。</p><p>所谓“合并部署”，就是把两个原本在不同机器上的不同应用合并部署到一台机器上，当然不仅仅是部署在一台机器上，还要在同一个Tomcat容器中，且不能走本机的Socket，这样才能避免序列化的产生</p><h3 id="Java极致优化"><a href="#Java极致优化" class="headerlink" title="Java极致优化"></a>Java极致优化</h3><p>Java和通用的Web服务器（如Nginx或Apache服务器）相比，在处理大并发的HTTP请求时要弱一点，所以一般我们都会对大流量的Web系统做静态化改造，让大部分请求和数据直接在Nginx服务器或者Web代理服务器（如Varnish、Squid等）上直接返回（这样可以减少数据的序列化与反序列化），而Java层只需处理少量数据的动态请求。针对这些请求，我们可以使用以下手段进行优化：</p><ul><li>直接使用Servlet处理请求。避免使用传统的MVC框架，这样可以绕过一大堆复杂且用处不大的处理逻辑，节省1ms时间（具体取决于你对MVC框架的依赖程度）。</li><li>直接输出流数据。使用resp.getOutputStream()而不是resp.getWriter()函数，可以省掉一些不变字符数据的编码，从而提升性能；数据输出时推荐使用JSON而不是模板引擎（一般都是解释执行）来输出页面。</li></ul><h3 id="并发读优化"><a href="#并发读优化" class="headerlink" title="并发读优化"></a>并发读优化</h3><ul><li>像商品中的“标题”和“描述”这些本身不变的数据，会在秒杀开始之前全量推送到秒杀机器上，并一直缓存到秒杀结束；</li><li>像库存这类动态数据，会采用“被动失效”的方式缓存一定时间（一般是数秒），失效后再去缓存拉取最新的数据。</li></ul><p>你可能还会有疑问：像库存这种频繁更新的数据，一旦数据不一致，会不会导致超卖？</p><p>这就要用到前面介绍的读数据的分层校验原则了，读的场景可以允许一定的脏数据，因为这里的误判只会导致少量原本无库存的下单请求被误认为有库存，可以等到真正写数据时再保证最终的一致性，通过在数据的高可用性和一致性之间的平衡，来解决高并发的数据读取问题。</p><h1 id="秒杀系统“减库存”设计的核心逻辑"><a href="#秒杀系统“减库存”设计的核心逻辑" class="headerlink" title="秒杀系统“减库存”设计的核心逻辑"></a>秒杀系统“减库存”设计的核心逻辑</h1><p>如果要设计一套秒杀系统，那我想你的老板肯定会先对你说：千万不要超卖，这是大前提。</p><p>我们平常购物都是这样，看到喜欢的商品然后下单，但并不是每个下单请求你都最后付款了。你说系统是用户下单了就算这个商品卖出去了，还是等到用户真正付款了才算卖出了呢？这的确是个问题！</p><p>我们可以先根据减库存是发生在下单阶段还是付款阶段，把减库存做一下划分。</p><h2 id="减库存有哪几种方式"><a href="#减库存有哪几种方式" class="headerlink" title="减库存有哪几种方式"></a>减库存有哪几种方式</h2><p>总结来说，减库存操作一般有如下几个方式：</p><ul><li><strong>下单减库存</strong>，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。</li><li><strong>付款减库存</strong>，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。</li><li><strong>预扣库存</strong>，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如10分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。</li></ul><h2 id="减库存可能存在的问题"><a href="#减库存可能存在的问题" class="headerlink" title="减库存可能存在的问题"></a>减库存可能存在的问题</h2><p>假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。</p><p>“付款减库存”又会导致另外一个问题：库存超卖。假如有100件商品，就可能出现300人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。</p><p>那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？</p><p>这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为10分钟，但是恶意买家完全可以在10分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。</p><p>例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买3件），以及对重复下单不付款的操作进行次数限制等。</p><p>针对“库存超卖”这种情况，在10分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。</p><h2 id="大型秒杀中如何减库存？"><a href="#大型秒杀中如何减库存？" class="headerlink" title="大型秒杀中如何减库存？"></a>大型秒杀中如何减库存？</h2><p>目前来看，业务系统中最常见的就是预扣库存方案，像你在买机票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？</p><p>由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于“下单减库存”比“预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。</p><p>“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种解决方案：一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行SQL语句来报错；再有一种就是使用CASE WHEN判断语句，例如这样的SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> item <span class="keyword">SET</span> inventory <span class="operator">=</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> inventory <span class="operator">&gt;=</span> xxx <span class="keyword">THEN</span> inventory<span class="operator">-</span>xxx <span class="keyword">ELSE</span> inventory <span class="keyword">END</span></span><br></pre></td></tr></table></figure><h2 id="秒杀减库存的极致优化"><a href="#秒杀减库存的极致优化" class="headerlink" title="秒杀减库存的极致优化"></a>秒杀减库存的极致优化</h2><p>由于MySQL存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争InnoDB行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，响应时间（RT）会上升，数据库的吞吐量就会严重受影响。</p><p>这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致0.01%的商品影响99.99%的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。</p><p>而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：</p><ul><li><strong>应用层做排队</strong>。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。</li><li><strong>数据库层做排队</strong>。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种MySQL的InnoDB层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。</li></ul><p>你可能有疑问了，排队和锁竞争不都是要等待吗，有啥区别？</p><p>如果熟悉MySQL的话，你会知道InnoDB内部的死锁检测，以及MySQL Server和InnoDB的切换会比较消耗性能，淘宝的MySQL核心团队还做了很多其他方面的优化，如COMMIT_ON_SUCCESS和ROLLBACK_ON_FAIL的补丁程序，配合在SQL里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条SQL后，直接根据TARGET_AFFECT_ROW的结果进行提交或回滚，可以减少网络等待时间（平均约0.7ms）。据我所知，目前阿里MySQL团队已经将包含这些补丁程序的MySQL开源。</p><p>另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的lastmodifytime字段的）更新会非常频繁，在某些场景下这些多条SQL是可以合并的，一定时间内只要执行最后一条SQL就行了，以便减少对数据库的更新操作。</p><blockquote><p> 如果异步的请求失败了，怎么办？</p></blockquote><p>对秒杀来说，我觉得如果失败了直接丢弃就好了，最坏的结果就是这个人没有抢到而已。但是你非要纠结的话，就要做异步消息的持久化以及重试机制了，要保证异步请求的最终正确处理一般都要借助消息系统，即消息的最终可达，例如阿里的消息中间件是能承诺只要客户端消息发送成功，那么消息系统一定会保证消息最终被送到目的地，即消息不会丢。因为客户端只要成功发送一条消息，下游消费方就一定会消费这条消息，所以也就不存在消息发送失败的问题了。</p><h1 id="准备Plan-B：如何设计兜底方案"><a href="#准备Plan-B：如何设计兜底方案" class="headerlink" title="准备Plan B：如何设计兜底方案"></a>准备Plan B：如何设计兜底方案</h1><h2 id="降级"><a href="#降级" class="headerlink" title="降级"></a>降级</h2><p>所谓“降级”，就是当系统的容量达到一定程度时，限制或者关闭系统的某些非核心功能，从而把有限的资源保留给更核心的业务。它是一个有目的、有计划的执行过程，所以对降级我们一般需要有一套预案来配合执行。如果我们把它系统化，就可以通过预案系统和开关系统来实现降级。</p><p>降级方案可以这样设计：当秒杀流量达到5w&#x2F;s时，把成交记录的获取从展示20条降级到只展示5条。“从20改到5”这个操作由一个开关来实现，也就是设置一个能够从开关系统动态获取的系统参数。</p><p>这里，我给出开关系统的示意图。它分为两部分，一部分是开关控制台，它保存了开关的具体配置信息，以及具体执行开关所对应的机器列表；另一部分是执行下发开关数据的Agent，主要任务就是保证开关被正确执行，即使系统重启后也会生效。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1b7fe21e0720519aff27e1b7c9621e6d482473cb.png" alt="image-20250912161948237"></p><p>执行降级无疑是在系统性能和用户体验之间选择了前者，降级后肯定会影响一部分用户的体验，例如在双11零点时，如果优惠券系统扛不住，可能会临时降级商品详情的优惠信息展示，把有限的系统资源用在保障交易系统正确展示优惠信息上，即保障用户真正下单时的价格是正确的。所以降级的核心目标是牺牲次要的功能和用户体验来保证核心业务流程的稳定，是一个不得已而为之的举措。</p><h2 id="限流"><a href="#限流" class="headerlink" title="限流"></a>限流</h2><p>如果说降级是牺牲了一部分次要的功能和用户的体验效果，那么限流就是更极端的一种保护措施了。限流就是当系统容量达到瓶颈时，我们需要通过限制一部分流量来保护系统，并做到既可以人工执行开关，也支持自动化保护的措施。</p><p>这里，我同样给出了限流系统的示意图。总体来说，限流既可以是在客户端限流，也可以是在服务端限流。此外，限流的实现方式既要支持URL以及方法级别的限流，也要支持基于QPS和线程的限流。</p><p>首先，我以内部的系统调用为例，来分别说下客户端限流和服务端限流的优缺点。</p><ul><li><strong>客户端限流</strong>，好处可以限制请求的发出，通过减少发出无用请求从而减少对系统的消耗。缺点就是当客户端比较分散时，没法设置合理的限流阈值：如果阈值设的太小，会导致服务端没有达到瓶颈时客户端已经被限制；而如果设的太大，则起不到限制的作用。</li><li><strong>服务端限流</strong>，好处是可以根据服务端的性能设置合理的阈值，而缺点就是被限制的请求都是无效的请求，处理这些无效的请求本身也会消耗服务器资源。</li></ul><p>在限流的实现手段上来讲，基于QPS和线程数的限流应用最多，最大QPS很容易通过压测提前获取，例如我们的系统最高支持1w QPS时，可以设置8000来进行限流保护。线程数限流在客户端比较有效，例如在远程调用时我们设置连接池的线程数，超出这个并发线程请求，就将线程进行排队或者直接超时丢弃。</p><p>限流无疑会影响用户的正常请求，所以必然会导致一部分用户请求失败，因此在系统处理这种异常时一定要设置超时时间，防止因被限流的请求不能fast fail（快速失败）而拖垮系统。</p><h2 id="拒绝服务"><a href="#拒绝服务" class="headerlink" title="拒绝服务"></a>拒绝服务</h2><p>如果限流还不能解决问题，最后一招就是直接拒绝服务了。</p><p>当系统负载达到一定阈值时，例如CPU使用率达到90%或者系统load值达到2*CPU核数时，系统直接拒绝所有请求，这种方式是最暴力但也最有效的系统保护方式。例如秒杀系统，我们在如下几个环节设计过载保护：</p><blockquote><p>在最前端的Nginx上设置过载保护，当机器负载达到某个值时直接拒绝HTTP请求并返回503错误码，在Java层同样也可以设计过载保护。</p></blockquote><p>拒绝服务可以说是一种不得已的兜底方案，用以防止最坏情况发生，防止因把服务器压跨而长时间彻底无法提供服务。像这种系统过载保护虽然在过载时无法提供服务，但是系统仍然可以运作，当负载下降时又很容易恢复，所以每个系统和每个环节都应该设置这个兜底方案，对系统做最坏情况下的保护。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;不同场景下的不同架构案例&quot;&gt;&lt;a href=&quot;#不同场景下的不同架构案例&quot; class=&quot;headerlink&quot; title=&quot;不同场景下的不同架构案例&quot;&gt;&lt;/a&gt;不同场景下的不同架构案例&lt;/h1&gt;&lt;p&gt;如果你想快速搭建一个简单的秒杀系统，只需要把你的商品购买页面</summary>
      
    
    
    
    
    <category term="场景" scheme="https://palette-k.github.io/tags/%E5%9C%BA%E6%99%AF/"/>
    
  </entry>
  
  <entry>
    <title>Java并发编程实战</title>
    <link href="https://palette-k.github.io/2025/09/08/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/"/>
    <id>https://palette-k.github.io/2025/09/08/Java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/</id>
    <published>2025-09-08T06:28:27.000Z</published>
    <updated>2025-09-10T10:08:17.141Z</updated>
    
    <content type="html"><![CDATA[<h1 id="可见性、原子性和有序性问题：并发编程Bug的源头"><a href="#可见性、原子性和有序性问题：并发编程Bug的源头" class="headerlink" title="可见性、原子性和有序性问题：并发编程Bug的源头"></a>可见性、原子性和有序性问题：并发编程Bug的源头</h1><h2 id="可见性"><a href="#可见性" class="headerlink" title="可见性"></a>可见性</h2><p>在单核时代，所有的线程都是在一颗CPU上执行，CPU缓存与内存的数据一致性容易解决。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/525e6b4dc17e61d2cb4da7e6f5f4c67ba68a3153.png" alt="image-20250908170705273"></p><p>一个线程对共享变量的修改，另外一个线程能够立刻看到，我们称为<strong>可见性</strong>。</p><p>多核时代，每颗CPU都有自己的缓存，这时CPU缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/39d83dc297f154950222d9a7551da57d130d8abb.png" alt="image-20250908170740063"></p><p>每执行一次add10K()方法，都会循环10000次count+&#x3D;1操作。在calc()方法中我们创建了两个线程，每个线程调用一次add10K()方法，循环10000次count+&#x3D;1操作如果改为循环1亿次，你会发现效果更明显，最终count的值接近1亿，而不是2亿。如果循环10000次，count的值接近20000，原因是两个线程不是同时启动的，有一个时差。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/abc22292dd8bfc85443ce291a89178383ce64afe.png" alt="image-20250908170851695"></p><h2 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h2><p>操作系统允许某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新选择一个进程来执行（我们称为“任务切换”），这个50毫秒称为“<strong>时间片</strong>”。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9226bbf245fc08ebbd74c48bcfed9ef9be99e6a6.png" alt="image-20250908170951720"></p><p>在一个时间片内，如果一个进程进行一个IO操作，例如读个文件，这个时候该进程可以把自己标记为“休眠状态”并出让CPU的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得CPU的使用权了。</p><p>务切换的时机大多数是在时间片结束的时候，我们现在基本都使用高级语言编程，高级语言里一条语句往往需要多条CPU指令完成，例如上面代码中的<code>count += 1</code>，至少需要三条CPU指令。</p><ul><li>指令1：首先，需要把变量count从内存加载到CPU的寄存器；</li><li>指令2：之后，在寄存器中执行+1操作；</li><li>指令3：最后，将结果写入内存（缓存机制导致可能写入的是CPU缓存而不是内存）。</li></ul><p>操作系统做任务切换，可以发生在任何一条<strong>CPU指令</strong>执行完，是的，是CPU指令，而不是高级语言里的一条语句。对于上面的三条指令来说，我们假设count&#x3D;0，如果线程A在指令1执行完后做线程切换，线程A和线程B按照下图的序列执行，那么我们会发现两个线程都执行了count+&#x3D;1的操作，但是得到的结果不是我们期望的2，而是1。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c702606869213089b3670d92e946f27e86248407.png" alt="image-20250908171038462"></p><h2 id="有序性"><a href="#有序性" class="headerlink" title="有序性"></a>有序性</h2><p>在Java领域一个经典的案例就是利用双重检查创建单例对象。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">  <span class="keyword">static</span> Singleton instance;</span><br><span class="line">  <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">synchronized</span>(Singleton.class) &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>)</span><br><span class="line">          instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> instance;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设有两个线程A、B同时调用getInstance()方法，他们会同时发现 <code>instance == null</code> ，于是同时对Singleton.class加锁，此时JVM保证只有一个线程能够加锁成功（假设是线程A），另外一个线程则会处于等待状态（假设是线程B）；线程A会创建一个Singleton实例，之后释放锁，锁释放后，线程B被唤醒，线程B再次尝试加锁，此时是可以加锁成功的，加锁成功后，线程B检查 <code>instance == null</code> 时会发现，已经创建过Singleton实例了，所以线程B不会再创建一个Singleton实例。</p><p>这看上去一切都很完美，无懈可击，但实际上这个getInstance()方法并不完美。问题出在哪里呢？出在new操作上，我们以为的new操作应该是：</p><ol><li>分配一块内存M；</li><li>在内存M上初始化Singleton对象；</li><li>然后M的地址赋值给instance变量。</li></ol><p>但是实际上优化后的执行路径却是这样的：</p><ol><li>分配一块内存M；</li><li>将M的地址赋值给instance变量；</li><li>最后在内存M上初始化Singleton对象。</li></ol><p>优化后会导致什么问题呢？我们假设线程A先执行getInstance()方法，当执行完指令2时恰好发生了线程切换，切换到了线程B上；如果此时线程B也执行getInstance()方法，那么线程B在执行第一个判断时会发现 <code>instance != null</code> ，所以直接返回instance，而此时的instance是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1df032b69cd1d24f984ed4966f34c1f78e2a7439.png" alt="image-20250908171208513"></p><h1 id="Java内存模型：看Java如何解决可见性和有序性问题"><a href="#Java内存模型：看Java如何解决可见性和有序性问题" class="headerlink" title="Java内存模型：看Java如何解决可见性和有序性问题"></a>Java内存模型：看Java如何解决可见性和有序性问题</h1><h2 id="什么是Java内存模型？"><a href="#什么是Java内存模型？" class="headerlink" title="什么是Java内存模型？"></a>什么是Java内存模型？</h2><p>Java 内存模型（JMM）是一组规范和规则，它定义了在多线程环境下，Java 程序中的变量（包括实例字段、静态字段和构成数组对象的元素）如何被写入内存以及如何从内存中读取。它的核心目标是解决在并发编程中由于可见性、原子性和有序性问题而导致的线程不安全问题</p><p>JMM 从逻辑上划分了这两种内存：</p><ul><li><strong>主内存</strong>：所有共享变量都存储在主内存中。它是所有线程共享的区域。</li><li><strong>工作内存</strong>：每个线程都有自己的工作内存，其中保存了该线程使用到的变量的<strong>主内存副本</strong>。线程对所有变量的操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。</li></ul><p><strong>交互流程</strong>：</p><ol><li>线程要读取一个共享变量时，会先从主内存<strong>复制</strong>一份到自己的工作内存。</li><li>然后线程就在自己的工作内存中操作这个副本。</li><li>操作完成后，在某个时间点再将工作内存中的副本<strong>刷新</strong>回主内存。</li></ol><h2 id="Happens-Before-规则"><a href="#Happens-Before-规则" class="headerlink" title="Happens-Before 规则"></a>Happens-Before 规则</h2><p>真正要表达的是：<strong>前面一个操作的结果对后续操作是可见的</strong>。</p><h3 id="程序的顺序性规则"><a href="#程序的顺序性规则" class="headerlink" title="程序的顺序性规则"></a>程序的顺序性规则</h3><p>这条规则是指在一个线程中，按照程序顺序，前面的操作 Happens-Before 于后续的任意操作。这还是比较容易理解的，比如刚才那段示例代码，按照程序的顺序，第6行代码 “x &#x3D; 42;” Happens-Before 于第7行代码 “v &#x3D; true;”，这就是规则1的内容，也比较符合单线程里面的思维：程序前面对某个变量的修改一定是对后续操作可见的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VolatileExample</span> &#123;</span><br><span class="line">  <span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">boolean</span> <span class="variable">v</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writer</span><span class="params">()</span> &#123;</span><br><span class="line">    x = <span class="number">42</span>;</span><br><span class="line">    v = <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">reader</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (v == <span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="comment">// 这里x会是多少呢？</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="volatile变量规则"><a href="#volatile变量规则" class="headerlink" title="volatile变量规则"></a>volatile变量规则</h3><p>这条规则是指对一个volatile变量的写操作， Happens-Before 于后续对这个volatile变量的读操作。</p><h3 id="传递性"><a href="#传递性" class="headerlink" title="传递性"></a>传递性</h3><p>这条规则是指如果A Happens-Before B，且B Happens-Before C，那么A Happens-Before C。</p><p>我们将规则3的传递性应用到我们的例子中，会发生什么呢？可以看下面这幅图：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2e84c7e0cd776461314d31731e24eaed02283e6e.png" alt="image-20250908171850247"></p><p>示例代码中的传递性规则</p><p>从图中，我们可以看到：</p><ol><li>“x&#x3D;42” Happens-Before 写变量 “v&#x3D;true” ，这是规则1的内容；</li><li>写变量“v&#x3D;true” Happens-Before 读变量 “v&#x3D;true”，这是规则2的内容 。</li></ol><p>如果线程B读到了“v&#x3D;true”，那么线程A设置的“x&#x3D;42”对线程B是可见的。也就是说，线程B能看到 “x &#x3D;&#x3D; 42”</p><h3 id="管程中锁的规则"><a href="#管程中锁的规则" class="headerlink" title="管程中锁的规则"></a>管程中锁的规则</h3><p>这条规则是指对一个锁的解锁 Happens-Before 于后续对这个锁的加锁。</p><p><strong>管程</strong>是一种通用的同步原语，在Java中指的就是synchronized，synchronized是Java里对管程的实现。</p><p>管程中的锁在Java里是隐式实现的，例如下面的代码，在进入同步块之前，会自动加锁，而在代码块执行完会自动释放锁，加锁以及释放锁都是编译器帮我们实现的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (<span class="built_in">this</span>) &#123; <span class="comment">//此处自动加锁</span></span><br><span class="line">  <span class="comment">// x是共享变量,初始值=10</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">this</span>.x &lt; <span class="number">12</span>) &#123;</span><br><span class="line">    <span class="built_in">this</span>.x = <span class="number">12</span>; </span><br><span class="line">  &#125;  </span><br><span class="line">&#125; <span class="comment">//此处自动解锁</span></span><br></pre></td></tr></table></figure><p>假设x的初始值是10，线程A执行完代码块后x的值会变成12（执行完自动释放锁），线程B进入代码块时，能够看到线程A对x的写操作，也就是线程B能够看到x&#x3D;&#x3D;12。</p><h3 id="线程-start-规则"><a href="#线程-start-规则" class="headerlink" title="线程 start() 规则"></a>线程 start() 规则</h3><p>主线程A启动子线程B后，子线程B能够看到主线程在启动子线程B前的操作。</p><p>如果线程A调用线程B的 start() 方法（即在线程A中启动线程B），那么该start()操作 Happens-Before 于线程B中的任意操作。具体可参考下面示例代码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">B</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 主线程调用B.start()之前</span></span><br><span class="line">  <span class="comment">// 所有对共享变量的修改，此处皆可见</span></span><br><span class="line">  <span class="comment">// 此例中，var==77</span></span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 此处对共享变量var修改</span></span><br><span class="line"><span class="keyword">var</span> = <span class="number">77</span>;</span><br><span class="line"><span class="comment">// 主线程启动子线程</span></span><br><span class="line">B.start();</span><br></pre></td></tr></table></figure><h3 id="线程-join-规则"><a href="#线程-join-规则" class="headerlink" title="线程 join() 规则"></a>线程 join() 规则</h3><p>主线程A等待子线程B完成（主线程A通过调用子线程B的join()方法实现），当子线程B完成后（主线程A中join()方法返回），主线程能够看到子线程的操作。</p><p>换句话说就是，如果在线程A中，调用线程B的 join() 并成功返回，那么线程B中的任意操作Happens-Before 于该 join() 操作的返回。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Thread</span> <span class="variable">B</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 此处对共享变量var修改</span></span><br><span class="line">  <span class="keyword">var</span> = <span class="number">66</span>;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">// 例如此处对共享变量修改，</span></span><br><span class="line"><span class="comment">// 则这个修改结果对线程B可见</span></span><br><span class="line"><span class="comment">// 主线程启动子线程</span></span><br><span class="line">B.start();</span><br><span class="line">B.join()</span><br><span class="line"><span class="comment">// 子线程所有对共享变量的修改</span></span><br><span class="line"><span class="comment">// 在主线程调用B.join()之后皆可见</span></span><br><span class="line"><span class="comment">// 此例中，var==66</span></span><br></pre></td></tr></table></figure><h2 id="synchronized"><a href="#synchronized" class="headerlink" title="synchronized"></a>synchronized</h2><ul><li><strong>原子性</strong>：通过互斥锁保证代码块的原子性。</li><li><strong>可见性</strong>：线程在进入 <code>synchronized</code> 块时，会清空工作内存，从主内存重新加载共享变量。在退出 <code>synchronized</code> 块时，会把工作内存中的修改刷新到主内存。</li></ul><p>sychronized 是一种互斥锁，一次只能允许一个线程进入被锁住的代码块。<br>sychronized 是 Java 的一个关键字，它能将代码块&#x2F;方法锁起来。<br>如果 sychronized 修饰的是实例方法，对应的锁则是对象实例。<br>如果 sychronized 修饰的是静态方法，对应的锁则是当前类的 Class 实例。<br>如果 sychronized 修饰的是代码块，对应的锁则是传入 synchronized 的对象实例。</p><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>通过反编译发现，编译器会生成 ACC_SYNCHRONIZED 关键字来标识。<br>当修饰代码块的时候，会依赖 monitorenter 和 monitorexit 指令。<br>无论 sychronized 修饰的是方法还是代码块，对应的锁都是一个实例对象。</p><p>在内存中，对象一般由三部分组成，分别是对象头，对象实际数据和对齐填充。<br>重点在于对象头，对象头又由几部分组成，但是我们重点关注对象头 Mark Word 的信息就好。<br>Mark Word 会记录对象关于锁的信息。<br>又因为每个对象都会有一个与之对应的 monitor 对象，monitor 对象中存储着当前持有锁的线程和等待锁的线程队列。<br>了解 Mark Word 和 monitor 对象是理解 synchronized 原理的前提。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ba882269a61a2af588f03893d2c73c498ea9ea7f.png" alt="image-20250910164612128"></p><h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>在 JDK1.6 之前是重量级锁，线程进入同步代码块&#x2F;方法时，monitor 对象会把当前进入线程的 id 进行存储，设置 Mark Word 的 monitor 对象地址，并把阻塞的线程存储到 monitor 的等待线程队列中，它加锁是依赖底层操作系统的 mutex 相关指令实现，所以会有用户态和内核态之间的切换，性能损耗十分明显。</p><p>而 JDK1.6 以后引入偏向锁和轻量级锁在 JVM 层面实现加锁逻辑，不依赖底层操作系统，就没有切换的消耗。在使用 synchronized 加锁的时候，Java 并不会直接调用操作系统内核加锁，而是根据线程的竞争情况采用不同的策略逐渐升级锁，直至调用操作系统加锁。</p><p>锁的升级包含以下几个过程：</p><ul><li>调研发现，在大多数情况下，锁不仅不会存在竞争情况，而且通常会由同一个线程多次获取。在这种情况下，JVM 会将锁设置为偏向锁。偏向锁会在对象头中记录拥有偏向锁的线程的ID，并将锁标识位设置为偏向锁状态。这样，当同一个线程再次请求获取这个对象的锁时，不需要进行任何同步操作，可以直接获取到锁，提高了程序的性能。<ul><li>另一种情况是，当线程B尝试获取偏向锁时，如果此时拥有偏向锁的线程A已经执行完毕并释放了锁，JVM 会尝试撤销偏向锁，并进行锁的竞争。如果在撤销偏向锁的过程中，没有其他线程来竞争锁，JVM 会将锁的状态设置为偏向线程B，并更新对象头中记录的线程ID为线程B的ID。在这种情况下，并不会发生锁的升级。只有当线程B尝试获取锁时，线程A还没有执行完毕，即出现了竞争情况，才会发生锁的升级，进而转为轻量级锁或重量级锁。</li></ul></li><li>当系统线程出现多个线程竞争的情况时，synchronized 会从偏向锁升级为轻量级锁。需要注意的是，轻量级锁通常出现在竞争不激烈、任务执行时间短的情况下。当出现锁竞争时，例如线程A正在执行过程中，线程B开始尝试获取锁，此时synchronized会进行自旋等待。synchronized并不会立即升级为重量级锁，而是会尝试使用自适应自旋锁来获取锁。如果自旋一段时间后仍未获取到锁，synchronized会正式升级为重量级锁。</li></ul><p>整体 synchronized 的锁升级过程为：<strong>偏向锁 -&gt; 轻量级锁（自旋锁） -&gt; 重量级锁</strong>。</p><ul><li><strong>无锁状态</strong>：锁标志位为 <code>01</code>，此时不存在线程执行任务。</li><li><strong>偏向锁</strong>：系统会在 MarkWord 中记录一个<strong>线程</strong> <strong>id</strong>，当该线程再次获取锁的时候，无需再申请锁，直接获取以增加效率。</li><li><strong>轻量级锁</strong>：系统会将对象头中的锁标志位修正为”00”，加锁和解锁操作使用CAS指令来修改锁标志位。当出现锁竞争的情况时，JVM 会尝试进行一段短暂的自旋（也称为空闲自旋或忙等待），以等待锁的释放。这个自旋过程是为了避免线程进入阻塞状态，以提高锁竞争的效率。</li><li><strong>重量级锁</strong>：JVM 会尝试调用操作系统进行加锁，同时会将锁的标记位 CAS 修正为 “10” ，表示锁已经升级为重量级锁。没有抢占到锁的线程会被加入到系统内的等待队列中等待唤醒。</li></ul><p><strong>我们可以近似地理解，偏向锁和轻量级锁都是系统通过 CAS 修改对象头中的锁标记位来实现的，只有重量级锁才会调用操作系统内核进行加锁或者入队操作</strong>。一个是只需要修改点东西就能实现，一个是需要入队、阻塞、唤醒、出队等诸多步骤才能实现，谁快谁慢不言而喻！</p><h2 id="volatile"><a href="#volatile" class="headerlink" title="volatile"></a>volatile</h2><ul><li><strong>可见性</strong>：保证对 <code>volatile</code> 变量的写操作会<strong>立即刷新</strong>到主内存，并且每次读操作都会从主内存重新读取，绕过工作内存。</li><li><strong>有序性</strong>：通过添加<strong>内存屏障</strong>来禁止指令重排序。</li><li><strong>注意</strong>：<code>volatile</code> <strong>不保证原子性</strong>（例如 <code>volatile int i; i++</code> 仍然不是原子操作）。</li></ul><h2 id="final"><a href="#final" class="headerlink" title="final"></a>final</h2><p>只要在构造函数中正确初始化了 <code>final</code> 字段，并且没有“this”引用逸出，那么其他线程就能看到最终初始化后的值，无需同步。</p><p>“逸出”有点抽象，我们还是举个例子吧，在下面例子中，在构造函数里面将this赋值给了全局变量global.obj，这就是“逸出”，线程通过global.obj读取x是有可能读到0的。因此我们一定要避免“逸出”。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">int</span> x;</span><br><span class="line"><span class="comment">// 错误的构造函数</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">FinalFieldExample</span><span class="params">()</span> &#123; </span><br><span class="line">  x = <span class="number">3</span>;</span><br><span class="line">  y = <span class="number">4</span>;</span><br><span class="line">  <span class="comment">// 此处就是讲this逸出，</span></span><br><span class="line">  global.obj = <span class="built_in">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="如何预防死锁"><a href="#如何预防死锁" class="headerlink" title="如何预防死锁"></a>如何预防死锁</h1><p>并发程序一旦死锁，一般没有特别好的方法，很多时候我们只能重启应用。因此，解决死锁问题最好的办法还是规避死锁。</p><p>只有以下这四个条件都发生时才会出现死锁：</p><ol><li>互斥，共享资源X和Y只能被一个线程占用；</li><li>占有且等待，线程T1已经取得共享资源X，在等待共享资源Y的时候，不释放共享资源X；</li><li>不可抢占，其他线程不能强行抢占线程T1占有的资源；</li><li>循环等待，线程T1等待线程T2占有的资源，线程T2等待线程T1占有的资源，就是循环等待。</li></ol><p>反过来分析，<strong>也就是说只要我们破坏其中一个，就可以成功避免死锁的发生</strong>。</p><p>其中，互斥这个条件我们没有办法破坏，因为我们用锁为的就是互斥。不过其他三个条件都是有办法破坏掉的，到底如何做呢？</p><ol><li>对于“占用且等待”这个条件，我们可以一次性申请所有的资源，这样就不存在等待了。</li><li>对于“不可抢占”这个条件，占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，这样不可抢占这个条件就破坏掉了。</li><li>对于“循环等待”这个条件，可以靠按序申请资源来预防。所谓按序申请，是指资源是有线性顺序的，申请的时候可以先申请资源序号小的，再申请资源序号大的，这样线性化后自然就不存在循环了。</li></ol><h1 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h1><p><strong>有时线程虽然没有发生阻塞，但仍然会存在执行不下去的情况，这就是所谓的“活锁”</strong>。</p><p>以类比现实世界里的例子，路人甲从左手边出门，路人乙从右手边进门，两人为了不相撞，互相谦让，路人甲让路走右手边，路人乙也让路走左手边，结果是两人又相撞了。这种情况，基本上谦让几次就解决了，因为人会交流啊。可是如果这种情况发生在编程世界了，就有可能会一直没完没了地“谦让”下去，成为没有发生阻塞但依然执行不下去的“活锁”。</p><p>解决“<strong>活锁</strong>”的方案很简单，谦让时，尝试等待一个随机的时间就可以了。</p><h1 id="饥饿"><a href="#饥饿" class="headerlink" title="饥饿"></a>饥饿</h1><p><strong>所谓“饥饿”指的是线程因无法访问所需资源而无法执行下去的情况</strong>。</p><p>如果线程优先级“不均”，在CPU繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程“饥饿”；持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。</p><p>解决“<strong>饥饿</strong>”问题的方案很简单，有三种方案：一是保证资源充足，二是公平地分配资源，三就是避免持有锁的线程长时间执行。这三个方案中，方案一和方案三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。倒是方案二的适用场景相对来说更多一些。</p><h1 id="用“等待-通知”机制优化循环等待"><a href="#用“等待-通知”机制优化循环等待" class="headerlink" title="用“等待-通知”机制优化循环等待"></a>用“等待-通知”机制优化循环等待</h1><p>在<strong>破坏占用且等待条件</strong>的时候，如果不能一次性申请到所有资源，就用死循环的方式来循环等待。如果apply()操作耗时非常短，而且并发冲突量也不大时，这个方案还挺不错的，但是如果apply()操作耗时长，或者并发冲突量大的时候，循环等待这种方案就不适用了，因为在这种场景下，可能要循环上万次才能获取到锁，太消耗CPU了。</p><h2 id="用synchronized实现等待-通知机制"><a href="#用synchronized实现等待-通知机制" class="headerlink" title="用synchronized实现等待-通知机制"></a>用synchronized实现等待-通知机制</h2><p>在Java语言里，等待-通知机制可以有多种实现方式，比如Java语言内置的synchronized配合wait()、notify()、notifyAll()这三个方法就能轻松实现。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ad501ac0c02918d98708c918dd086fe19602731e.png" alt="image-20250908174313597"></p><p>在并发程序中，当一个线程进入临界区后，由于某些条件不满足，需要进入等待状态，Java对象的wait()方法就能够满足这种需求。如上图所示，当调用wait()方法后，当前线程就会被阻塞，并且进入到右边的等待队列中，<strong>这个等待队列也是互斥锁的等待队列</strong>。 线程在进入等待队列的同时，<strong>会释放持有的互斥锁</strong>，线程释放锁后，其他线程就有机会获得锁，并进入临界区了。</p><p>那线程要求的条件满足时，该怎么通知这个等待的线程呢？很简单，就是Java对象的notify()和notifyAll()方法。我在下面这个图里为你大致描述了这个过程，当条件满足时调用notify()，会通知等待队列（<strong>互斥锁的等待队列</strong>）中的线程，告诉它<strong>条件曾经满足过</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/986f66069e6becb1ea8874539f76215c071a5cfb.png" alt="image-20250908174338238"></p><p>为什么说是曾经满足过呢？因为<strong>notify()只能保证在通知时间点，条件是满足的</strong>。而被通知线程的<strong>执行时间点和通知的时间点</strong>基本上不会重合，所以当线程执行的时候，很可能条件已经不满足了（保不齐有其他线程插队）。这一点你需要格外注意。</p><p>除此之外，还有一个需要注意的点，被通知的线程要想重新执行，仍然需要获取到互斥锁（因为曾经获取的锁在调用wait()时已经释放了）。</p><p><strong>notify()是会随机地通知等待队列中的一个线程，而notifyAll()会通知等待队列中的所有线程</strong>。</p><p>假设我们有资源A、B、C、D，线程1申请到了AB，线程2申请到了CD，此时线程3申请AB，会进入等待队列（AB分配给线程1，线程3要求的条件不满足），线程4申请CD也会进入等待队列。我们再假设之后线程1归还了资源AB，如果使用notify()来通知等待队列中的线程，有可能被通知的是线程4，但线程4申请的是CD，所以此时线程4还是会继续等待，而真正该唤醒的线程3就再也没有机会被唤醒了。</p><h1 id="创建多少线程才是合适的"><a href="#创建多少线程才是合适的" class="headerlink" title="创建多少线程才是合适的"></a>创建多少线程才是合适的</h1><p><strong>在并发编程领域，提升性能本质上就是提升硬件的利用率，再具体点来说，就是提升I&#x2F;O的利用率和CPU的利用率</strong>。</p><p>如果只有一个线程，执行CPU计算的时候，I&#x2F;O设备空闲；执行I&#x2F;O操作的时候，CPU空闲，所以CPU的利用率和I&#x2F;O设备的利用率都是50%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9494c5be4b39fddb9a4d56bf8cf478250f851a8e.png" alt="image-20250909094950235"></p><p>如果有两个线程，如下图所示，当线程A执行CPU计算的时候，线程B执行I&#x2F;O操作；当线程A执行I&#x2F;O操作的时候，线程B执行CPU计算，这样CPU的利用率和I&#x2F;O设备的利用率就都达到了100%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b403f285ecd457ccead4c404e1dc8bf94e6c640b.png" alt="image-20250909095012687"></p><p>通过上面的图示，很容易看出：单位时间处理的请求数量翻了一番，也就是说吞吐量提高了1倍。</p><p>对于CPU密集型计算，多线程本质上是提升多核CPU的利用率，所以对于一个4核的CPU，每个核一个线程，理论上创建4个线程就可以了，再多创建线程也只是增加线程切换的成本。所以，<strong>对于CPU密集型的计算场景，理论上“线程的数量&#x3D;CPU核数”就是最合适的</strong>。不过在工程上，<strong>线程的数量一般会设置为“CPU核数+1”</strong>，这样的话，当线程因为偶尔的内存页失效或其他原因导致阻塞时，这个额外的线程可以顶上，从而保证CPU的利用率。</p><p>对于I&#x2F;O密集型的计算场景，比如前面我们的例子中，如果CPU计算和I&#x2F;O操作的耗时是1:1，那么2个线程是最合适的。如果CPU计算和I&#x2F;O操作的耗时是1:2，那多少个线程合适呢？是3个线程，如下图所示：CPU在A、B、C三个线程之间切换，对于线程A，当CPU从B、C切换回来时，线程A正好执行完I&#x2F;O操作。这样CPU和I&#x2F;O设备的利用率都达到了100%。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8956e749062492cb16f162fd344cdbf10093526f.png" alt="image-20250909095149313"></p><p>通过上面这个例子，我们会发现，对于I&#x2F;O密集型计算场景，最佳的线程数是与程序中CPU计算和I&#x2F;O操作的耗时比相关的，我们可以总结出这样一个公式：</p><blockquote><p>最佳线程数&#x3D;1 +（I&#x2F;O耗时 &#x2F; CPU耗时）</p></blockquote><p>不过上面这个公式是针对单核CPU的，至于多核CPU，也很简单，只需要等比扩大就可以了，计算公式如下：</p><blockquote><p>最佳线程数&#x3D;CPU核数 * [ 1 +（I&#x2F;O耗时 &#x2F; CPU耗时）]</p></blockquote><p>最佳线程数最终还是靠压测来确定的，实际工作中大家面临的系统，“I&#x2F;O耗时 &#x2F; CPU耗时”往往都大于1，所以基本上都是在这个<strong>初始值的基础上增加</strong>。增加的过程中，应关注线程数是如何影响吞吐量和延迟的。</p><p>实际工作中，不同的I&#x2F;O模型对最佳线程数的影响非常大，例如大名鼎鼎的Nginx用的是非阻塞I&#x2F;O，采用的是多进程单线程结构，Nginx本来是一个I&#x2F;O密集型系统，但是最佳进程数设置的却是CPU的核数，完全参考的是CPU密集型的算法。所以，理论我们还是要活学活用。</p><h1 id="Semaphore：快速实现一个限流器"><a href="#Semaphore：快速实现一个限流器" class="headerlink" title="Semaphore：快速实现一个限流器"></a>Semaphore：快速实现一个限流器</h1><p><strong>Semaphore可以允许多个线程访问一个临界区</strong>。</p><p>比较常见的需求就是我们工作中遇到的各种池化资源，例如连接池、对象池、线程池等等。所谓对象池呢，指的是一次性创建出N个对象，之后所有的线程重复利用这N个对象，当然对象在被释放前，也是不允许其他线程使用的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ObjPool</span>&lt;T, R&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> List&lt;T&gt; pool;</span><br><span class="line">  <span class="comment">// 用信号量实现限流器</span></span><br><span class="line">  <span class="keyword">final</span> Semaphore sem;</span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  ObjPool(<span class="type">int</span> size, T t)&#123;</span><br><span class="line">    pool = <span class="keyword">new</span> <span class="title class_">Vector</span>&lt;T&gt;()&#123;&#125;;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;size; i++)&#123;</span><br><span class="line">      pool.add(t);</span><br><span class="line">    &#125;</span><br><span class="line">    sem = <span class="keyword">new</span> <span class="title class_">Semaphore</span>(size);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 利用对象池的对象，调用func</span></span><br><span class="line">  R <span class="title function_">exec</span><span class="params">(Function&lt;T,R&gt; func)</span> &#123;</span><br><span class="line">    <span class="type">T</span> <span class="variable">t</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    sem.acquire();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      t = pool.remove(<span class="number">0</span>);</span><br><span class="line">      <span class="keyword">return</span> func.apply(t);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      pool.add(t);</span><br><span class="line">      sem.release();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 创建对象池</span></span><br><span class="line">ObjPool&lt;Long, String&gt; pool = <span class="keyword">new</span> <span class="title class_">ObjPool</span>&lt;Long, String&gt;(<span class="number">10</span>, <span class="number">2</span>);</span><br><span class="line"><span class="comment">// 通过对象池获取t，之后执行  </span></span><br><span class="line">pool.exec(t -&gt; &#123;</span><br><span class="line">    System.out.println(t);</span><br><span class="line">    <span class="keyword">return</span> t.toString();</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>我们用一个List来保存对象实例，用Semaphore实现限流器。关键的代码是ObjPool里面的exec()方法，这个方法里面实现了限流的功能。</p><p>在这个方法里面，我们首先调用acquire()方法（与之匹配的是在finally里面调用release()方法），假设对象池的大小是10，信号量的计数器初始化为10，那么前10个线程调用acquire()方法，都能继续执行，相当于通过了信号灯，而其他线程则会阻塞在acquire()方法上。对于通过信号灯的线程，我们为每个线程分配了一个对象 t（这个分配工作是通过pool.remove(0)实现的），分配完之后会执行一个回调函数func，而函数的参数正是前面分配的对象 t ；执行完回调函数之后，它们就会释放对象（这个释放工作是通过pool.add(t)实现的），同时调用release()方法来更新信号量的计数器。如果此时信号量里计数器的值小于等于0，那么说明有线程在等待，此时会自动唤醒等待的线程。</p><p>简言之，使用信号量，我们可以轻松地实现一个限流器。</p><h1 id="ReadWriteLock：快速实现一个完备的缓存"><a href="#ReadWriteLock：快速实现一个完备的缓存" class="headerlink" title="ReadWriteLock：快速实现一个完备的缓存"></a>ReadWriteLock：快速实现一个完备的缓存</h1><p>用ReadWriteLock快速实现一个通用的缓存工具类。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Cache</span>&lt;K,V&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> Map&lt;K, V&gt; m = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="comment">// 读锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="comment">// 写锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line">  <span class="comment">// 读缓存</span></span><br><span class="line">  V <span class="title function_">get</span><span class="params">(K key)</span> &#123;</span><br><span class="line">    r.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123; <span class="keyword">return</span> m.get(key); &#125;</span><br><span class="line">    <span class="keyword">finally</span> &#123; r.unlock(); &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 写缓存</span></span><br><span class="line">  V <span class="title function_">put</span><span class="params">(K key, V value)</span> &#123;</span><br><span class="line">    w.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123; <span class="keyword">return</span> m.put(key, v); &#125;</span><br><span class="line">    <span class="keyword">finally</span> &#123; w.unlock(); &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果源头数据的数据量不大，就可以采用一次性加载的方式，这种方式最简单（可参考下图），只需在应用启动的时候把源头数据查询出来，依次调用类似上面示例代码中的put()方法就可以了。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9e2858eac1adea40a283eafbcb683eac52fbc9e4.png" alt="image-20250909104647306"></p><p>如果源头数据量非常大，那么就需要按需加载了，按需加载也叫懒加载，指的是只有当应用查询缓存，并且数据不在缓存里的时候，才触发加载源头相关数据进缓存的操作。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/79c545d9fac4aa013452c7aa0cff4a7ec9384a82.png" alt="image-20250909104709132"></p><p>下面你可以结合文中示意图看看如何利用ReadWriteLock 来实现缓存的按需加载。</p><p>如果缓存中没有缓存目标对象，那么就需要从数据库中加载，然后写入缓存，写缓存需要用到写锁，所以在代码中的⑤处，我们调用了 <code>w.lock()</code> 来获取写锁。</p><p>另外，还需要注意的是，在获取写锁之后，我们并没有直接去查询数据库，而是在代码⑥⑦处，重新验证了一次缓存中是否存在，再次验证如果还是不存在，我们才去查询数据库并更新本地缓存。为什么我们要再次验证呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Cache</span>&lt;K,V&gt; &#123;</span><br><span class="line">  <span class="keyword">final</span> Map&lt;K, V&gt; m = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line"></span><br><span class="line">  V <span class="title function_">get</span><span class="params">(K key)</span> &#123;</span><br><span class="line">    <span class="type">V</span> <span class="variable">v</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="comment">//读缓存</span></span><br><span class="line">    r.lock();         ①</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      v = m.get(key); ②</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      r.unlock();     ③</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//缓存中存在，返回</span></span><br><span class="line">    <span class="keyword">if</span>(v != <span class="literal">null</span>) &#123;   ④</span><br><span class="line">      <span class="keyword">return</span> v;</span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="comment">//缓存中不存在，查询数据库</span></span><br><span class="line">    w.lock();         ⑤</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//再次验证</span></span><br><span class="line">      <span class="comment">//其他线程可能已经查询过数据库</span></span><br><span class="line">      v = m.get(key); ⑥</span><br><span class="line">      <span class="keyword">if</span>(v == <span class="literal">null</span>)&#123;  ⑦</span><br><span class="line">        <span class="comment">//查询数据库</span></span><br><span class="line">        v=省略代码无数</span><br><span class="line">        m.put(key, v);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      w.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> v; </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>原因是在高并发的场景下，有可能会有多线程竞争写锁。假设缓存是空的，没有缓存任何东西，如果此时有三个线程T1、T2和T3同时调用get()方法，并且参数key也是相同的。那么它们会同时执行到代码⑤处，但此时只有一个线程能够获得写锁，假设是线程T1，线程T1获取写锁之后查询数据库并更新缓存，最终释放写锁。此时线程T2和T3会再有一个线程能够获取写锁，假设是T2，如果不采用再次验证的方式，此时T2会再次查询数据库。T2释放写锁之后，T3也会再次查询一次数据库。而实际上线程T1已经把缓存的值设置好了，T2、T3完全没有必要再次查询数据库。所以，再次验证的方式，能够避免高并发场景下重复查询数据的问题。</p><h2 id="读写锁的升级与降级"><a href="#读写锁的升级与降级" class="headerlink" title="读写锁的升级与降级"></a>读写锁的升级与降级</h2><p>上面按需加载的示例代码中，在①处获取读锁，在③处释放读锁，那是否可以在②处的下面增加验证缓存并更新缓存的逻辑呢？详细的代码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读缓存</span></span><br><span class="line">r.lock();         ①</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  v = m.get(key); ②</span><br><span class="line">  <span class="keyword">if</span> (v == <span class="literal">null</span>) &#123;</span><br><span class="line">    w.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//再次验证并更新缓存</span></span><br><span class="line">      <span class="comment">//省略详细代码</span></span><br><span class="line">    &#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">      w.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125; <span class="keyword">finally</span>&#123;</span><br><span class="line">  r.unlock();     ③</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样看上去好像是没有问题的，先是获取读锁，然后再升级为写锁，对此还有个专业的名字，叫<strong>锁的升级</strong>。可惜ReadWriteLock并不支持这种升级。在上面的代码示例中，读锁还没有释放，此时获取写锁，会导致写锁永久等待，最终导致相关线程都被阻塞，永远也没有机会被唤醒。锁的升级是不允许的，这个你一定要注意。</p><p>不过，虽然锁的升级是不允许的，但是锁的降级却是允许的。以下代码来源自ReentrantReadWriteLock的官方示例，略做了改动。你会发现在代码①处，获取读锁的时候线程还是持有写锁的，这种锁的降级是支持的。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CachedData</span> &#123;</span><br><span class="line">  Object data;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">boolean</span> cacheValid;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">ReadWriteLock</span> <span class="variable">rwl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ReentrantReadWriteLock</span>();</span><br><span class="line">  <span class="comment">// 读锁  </span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">r</span> <span class="operator">=</span> rwl.readLock();</span><br><span class="line">  <span class="comment">//写锁</span></span><br><span class="line">  <span class="keyword">final</span> <span class="type">Lock</span> <span class="variable">w</span> <span class="operator">=</span> rwl.writeLock();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">processCachedData</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 获取读锁</span></span><br><span class="line">    r.lock();</span><br><span class="line">    <span class="keyword">if</span> (!cacheValid) &#123;</span><br><span class="line">      <span class="comment">// 释放读锁，因为不允许读锁的升级</span></span><br><span class="line">      r.unlock();</span><br><span class="line">      <span class="comment">// 获取写锁</span></span><br><span class="line">      w.lock();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 再次检查状态  </span></span><br><span class="line">        <span class="keyword">if</span> (!cacheValid) &#123;</span><br><span class="line">          data = ...</span><br><span class="line">          cacheValid = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 释放写锁前，降级为读锁</span></span><br><span class="line">        <span class="comment">// 降级是可以的</span></span><br><span class="line">        r.lock(); ①</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// 释放写锁</span></span><br><span class="line">        w.unlock(); </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 此处仍然持有读锁</span></span><br><span class="line">    <span class="keyword">try</span> &#123;use(data);&#125; </span><br><span class="line">    <span class="keyword">finally</span> &#123;r.unlock();&#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="StampedLock：读多写少性能最佳锁"><a href="#StampedLock：读多写少性能最佳锁" class="headerlink" title="StampedLock：读多写少性能最佳锁"></a>StampedLock：读多写少性能最佳锁</h1><h2 id="StampedLock支持的三种锁模式"><a href="#StampedLock支持的三种锁模式" class="headerlink" title="StampedLock支持的三种锁模式"></a>StampedLock支持的三种锁模式</h2><p>StampedLock支持三种模式，分别是：<strong>写锁</strong>、<strong>悲观读锁</strong>和<strong>乐观读</strong>。其中，写锁、悲观读锁的语义和ReadWriteLock的写锁、读锁的语义非常类似，允许多个线程同时获取悲观读锁，但是只允许一个线程获取写锁，写锁和悲观读锁是互斥的。不同的是：StampedLock里的写锁和悲观读锁加锁成功之后，都会返回一个stamp；然后解锁的时候，需要传入这个stamp。相关的示例代码如下。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">StampedLock</span> <span class="variable">sl</span> <span class="operator">=</span>  <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取/释放悲观读锁示意代码</span></span><br><span class="line"><span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.readLock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//省略业务相关代码</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  sl.unlockRead(stamp);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取/释放写锁示意代码</span></span><br><span class="line"><span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.writeLock();</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//省略业务相关代码</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  sl.unlockWrite(stamp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>StampedLock的性能之所以比ReadWriteLock还要好，其关键是StampedLock支持乐观读的方式。ReadWriteLock支持多个线程同时读，但是当多个线程同时读的时候，所有的写操作会被阻塞；而StampedLock提供的乐观读，是允许一个线程获取写锁的，也就是说不是所有的写操作都被阻塞。</p><p><strong>乐观读这个操作是无锁的</strong>，所以相比较ReadWriteLock的读锁，乐观读的性能更好一些。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Point</span> &#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> x, y;</span><br><span class="line">  <span class="keyword">final</span> <span class="type">StampedLock</span> <span class="variable">sl</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line">  <span class="comment">//计算到原点的距离  </span></span><br><span class="line">  <span class="type">int</span> <span class="title function_">distanceFromOrigin</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 乐观读</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">stamp</span> <span class="operator">=</span> sl.tryOptimisticRead();</span><br><span class="line">    <span class="comment">// 读入局部变量，</span></span><br><span class="line">    <span class="comment">// 读的过程数据可能被修改</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curX</span> <span class="operator">=</span> x, curY = y;</span><br><span class="line">    <span class="comment">//判断执行读操作期间，是否存在写操作</span></span><br><span class="line">    <span class="comment">//如果存在，则sl.validate返回false</span></span><br><span class="line">    <span class="keyword">if</span> (!sl.validate(stamp))&#123;</span><br><span class="line">      <span class="comment">// 升级为悲观读锁</span></span><br><span class="line">      stamp = sl.readLock();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        curX = x;</span><br><span class="line">        curY = y;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//释放悲观读锁</span></span><br><span class="line">        sl.unlockRead(stamp);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Math.sqrt(</span><br><span class="line">      curX * curX + curY * curY);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果执行乐观读操作的期间，存在写操作，会把乐观读升级为悲观读锁。这个做法挺合理的，否则你就需要在一个循环里反复执行乐观读，直到执行乐观读操作的期间没有写操作（只有这样才能保证x和y的正确性和一致性），而循环读会浪费大量的CPU。</p><p>StampedLock在命名上并没有增加Reentrant，<strong>StampedLock不支持重入</strong>。</p><p>还有一点需要特别注意，那就是：如果线程阻塞在StampedLock的readLock()或者writeLock()上时，此时调用该阻塞线程的interrupt()方法，会导致CPU飙升。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">inal <span class="type">StampedLock</span> <span class="variable">lock</span></span><br><span class="line">  <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StampedLock</span>();</span><br><span class="line"><span class="type">Thread</span> <span class="variable">T1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">  <span class="comment">// 获取写锁</span></span><br><span class="line">  lock.writeLock();</span><br><span class="line">  <span class="comment">// 永远阻塞在此处，不释放写锁</span></span><br><span class="line">  LockSupport.park();</span><br><span class="line">&#125;);</span><br><span class="line">T1.start();</span><br><span class="line"><span class="comment">// 保证T1获取写锁</span></span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line"><span class="type">Thread</span> <span class="variable">T2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;</span><br><span class="line">  <span class="comment">//阻塞在悲观读锁</span></span><br><span class="line">  lock.readLock()</span><br><span class="line">);</span><br><span class="line">T2.start();</span><br><span class="line"><span class="comment">// 保证T2阻塞在读锁</span></span><br><span class="line">Thread.sleep(<span class="number">100</span>);</span><br><span class="line"><span class="comment">//中断线程T2</span></span><br><span class="line"><span class="comment">//会导致线程T2所在CPU飙升</span></span><br><span class="line">T2.interrupt();</span><br><span class="line">T2.join();</span><br></pre></td></tr></table></figure><p>所以，**使用StampedLock一定不要调用中断操作，如果需要支持中断功能，一定使用可中断的悲观读锁readLockInterruptibly()和写锁writeLockInterruptibly()**。</p><h1 id="CountDownLatch和CyclicBarrier：如何让多线程步调一致"><a href="#CountDownLatch和CyclicBarrier：如何让多线程步调一致" class="headerlink" title="CountDownLatch和CyclicBarrier：如何让多线程步调一致"></a>CountDownLatch和CyclicBarrier：如何让多线程步调一致</h1><p>CountDownLatch和CyclicBarrier都是线程同步的工具类。</p><p><strong>CountDownLatch</strong>允许一个或多个线程一直等待，直到这些线程完成它们的操作。</p><p>而<strong>CyclicBarrier</strong>是允许一组线程之间互相等待，它往往是当线程到达某状态后，暂停下来等待其他线程，等到所有线程均到达后，才继续执行。</p><p>可以发现这两者等待的主体是不一样的。<br>CountDownLatch调用await()通常是主线程&#x2F;调用线程，而CyclicBarrier调用await()是在任务线程调用的。<br>所以，CyclicBarrier中的阻塞的是任务的线程，而主线程是不受影响的。</p><p>这两个类都是基于AQS实现的。<br>当我们构建CountDownLatch对象时，传入的值其实就会赋值给AQS的关键变量state<br>执行countDown方法时，其实就是利用CAS将state减1。<br>执行await方法时，其实就是判断state是否为0，不为0则加入到队列中，将该线程阻塞掉（除了头节点）。<br>因为头节点会一直自旋等待state为0，当state为0时，头节点把剩余的在队列中阻塞的节点也一并唤醒。</p><p>而CyclicBarrier是直接借助ReentranLock加上Condition等待唤醒功能，进而实现的。<br>在构建CyclicBarrier时，传入的值会赋值给CyclicBarrier内部维护的count变量，也会赋值给parties变量（这是可以复用的关键）。<br>每次调用await时，会将count-1，操作count值是直接使用ReentrantLock来保证线程安全性。<br>如果count不为0，则添加condition队列中，<br>如果count等于0，则把节点从condition队列添加至AQS的队列中进行全部唤醒，并且将parties的值重新赋值为count的值（实现复用）。</p><h1 id="并发容器"><a href="#并发容器" class="headerlink" title="并发容器"></a>并发容器</h1><h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>List里面只有一个实现类就是<strong>CopyOnWriteArrayList</strong>。CopyOnWrite，顾名思义就是写的时候会将共享变量新复制一份出来，这样做的好处是读操作完全无锁。</p><p>CopyOnWriteArrayList内部维护了一个数组，成员变量array就指向这个内部数组，所有的读操作都是基于array进行的，如下图所示，迭代器Iterator遍历的就是array数组。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f06c4663e699c62822545b9340e0d5dcf4ec93d4.png" alt="image-20250909114326977"></p><p>如果在遍历array的同时，还有一个写操作，例如增加元素，CopyOnWriteArrayList是如何处理的呢？CopyOnWriteArrayList会将array复制一份，然后在新复制处理的数组上执行增加元素的操作，执行完之后再将array指向这个新的数组。通过下图你可以看到，读写是可以并行的，遍历操作一直都是基于原array执行，而写操作则是基于新array进行。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/423092db2304b5e43058d78561138deb1c4cf172.png" alt="image-20250909114354086"></p><p>使用CopyOnWriteArrayList需要注意的“坑”主要有两个方面。一个是应用场景，CopyOnWriteArrayList仅适用于写操作非常少的场景，而且能够容忍读写的短暂不一致。例如上面的例子中，写入的新元素并不能立刻被遍历到。另一个需要注意的是，CopyOnWriteArrayList迭代器是只读的，不支持增删改。因为迭代器遍历的仅仅是一个快照，而对快照进行增删改是没有意义的。</p><h2 id="Map"><a href="#Map" class="headerlink" title="Map"></a>Map</h2><p>Map接口的两个实现是ConcurrentHashMap和ConcurrentSkipListMap，它们从应用的角度来看，主要区别在于<strong>ConcurrentHashMap的key是无序的，而ConcurrentSkipListMap的key是有序的</strong>。所以如果你需要保证key的顺序，就只能使用ConcurrentSkipListMap。</p><p>使用ConcurrentHashMap和ConcurrentSkipListMap需要注意的地方是，它们的key和value都不能为空，否则会抛出<code>NullPointerException</code>这个运行时异常。</p><blockquote><p>ConcurrentHashMap 为什么 key 和 value 不能为 null？</p></blockquote><p>key 和 value 不能为 null 主要是为了避免二义性。null 是一个特殊的值，表示没有对象或没有引用。如果你用null作为键，那么你就无法区分这个键是否存在于ConcurrentHashMap中，还是根本没有这个键。同样，如果你用null作为值，那么你就无法区分这个值是否是真正存储在ConcurrentHashMap中的，还是因为找不到对应的键而返回的。<br>拿 get 方法取值来说，返回的结果为 null 存在两种情况： - 值没有在集合中 ； - 值本身就是 null。 这也就是二义性的由来。 具体可以参考 [ConcurrentHashMap 源码分析]( <a href="https://javaguide.cn/java/collection/concurrent-hash-map-source-code.html" title="ConcurrentHashMap 源码分析 | JavaGuide(Java面试   学习指南)">ConcurrentHashMap 源码分析 | JavaGuide(Java面试 学习指南)</a> ) 。<br>多线程环境下，存在一个线程操作该ConcurrentHashMap时，其他的线程将该ConcurrentHashMap修改的情况，所以无法通过 containsKey(key)来判断否存在这个键值对，也就没办法解决二义性问题了。 与此形成对比的是，HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个。如果传入null作为参数，就会返回hash值为0的位置的值。单线程环境下，不存在一个线程操作该HashMap时，其他的线程将该HashMap修改的情况，所以可以通过contains(key)来做判断是否存在这个键值对，从而做相应的处理，也就不存在二义性问题。 </p><blockquote><p>为什么源码不设计成可以判断是否存在null值的key？</p></blockquote><p>正如上面所述，如果允许key为null，那么就会带来很多不必要的麻烦和开销。比如，你需要用额外的数据结构或者标志位来记录哪些key是null的，而且在多线程环境下，还要保证对这些额外的数据结构或者标志位的操作也是线程安全的。而且，key为null的意义也不大，因为它并不能表示任何有用的信息。 如果你确实需要在 ConcurrentHashMap 中使用 null 的话，可以使用一个特殊的静态空对象来代替 null。 <code>java public static final Object NULL = new Object(); </code> </p><blockquote><p>containsKey方法后被修改，导致不可重复读，算线程不安全吗? </p></blockquote><p>ConcurrentHashMap 是线程安全的，但它不能保证所有的复合操作都是原子性的。如果需要保证复合操作的原子性，就要使用额外的同步或协调机制。这并不违反线程安全的定义，而是属于不同层次的一致性要求。 containsKey() 和 get() 方法都是单独的操作，它们之间没有同步保证。因此，如果在调用 containsKey() 后，另一个线程修改或删除了相应的键值对，那么 get() 方法可能会返回 null 或者过期的值。这确实是不可重复读的情况，但这并不违反线程安全的定义。 为什么不提供类似for update的方法呢？ Java 8中，ConcurrentHashMap增加了一些原子更新操作的方法，如compute、computeIfAbsent、computeIfPresent、merge等等。这些方法都可以接受一个函数作为参数，根据给定的key和value来计算一个新的value，并且将其更新到map中。</p><p>ConcurrentSkipListMap里面的SkipList本身就是一种数据结构，中文一般都翻译为“跳表”。跳表插入、删除、查询操作平均的时间复杂度是 O(log n)，理论上和并发线程数没有关系，所以在并发度非常高的情况下，若你对ConcurrentHashMap的性能还不满意，可以尝试一下ConcurrentSkipListMap。</p><h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Set接口的两个实现是CopyOnWriteArraySet和ConcurrentSkipListSet，使用场景可以参考前面讲述的CopyOnWriteArrayList和ConcurrentSkipListMap，它们的原理都是一样的，这里就不再赘述了。</p><h2 id="Queue"><a href="#Queue" class="headerlink" title="Queue"></a>Queue</h2><p>Java并发包里面Queue这类并发容器是最复杂的，你可以从以下两个维度来分类。</p><p>一个维度是<strong>阻塞与非阻塞</strong>，所谓阻塞指的是当队列已满时，入队操作阻塞；当队列已空时，出队操作阻塞。</p><p>另一个维度是<strong>单端与双端</strong>，单端指的是只能队尾入队，队首出队；而双端指的是队首队尾皆可入队出队。Java并发包里<strong>阻塞队列都用Blocking关键字标识，单端队列使用Queue标识，双端队列使用Deque标识</strong>。</p><p>这两个维度组合后，可以将Queue细分为四大类，分别是：</p><p>1.<strong>单端阻塞队列</strong>：其实现有ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、LinkedTransferQueue、PriorityBlockingQueue和DelayQueue。</p><p>内部一般会持有一个队列，这个队列可以是数组（其实现是ArrayBlockingQueue）也可以是链表（其实现是LinkedBlockingQueue）；甚至还可以不持有队列（其实现是SynchronousQueue），此时生产者线程的入队操作必须等待消费者线程的出队操作。</p><p>而LinkedTransferQueue融合LinkedBlockingQueue和SynchronousQueue的功能，性能比LinkedBlockingQueue更好；</p><p>PriorityBlockingQueue支持按照优先级出队；</p><p>DelayQueue支持延时出队。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/57bc6af2b278aa6012275440033164e8de07de08.png" alt="image-20250909140930497"></p><p>2.<strong>双端阻塞队列</strong>：其实现是LinkedBlockingDeque。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b74ef2deac8b873cefa72a16256582935d15f30e.png" alt="image-20250909140951805"></p><p>3.<strong>单端非阻塞队列</strong>：其实现是ConcurrentLinkedQueue。</p><p>4.<strong>双端非阻塞队列</strong>：其实现是ConcurrentLinkedDeque。</p><p>使用队列时，需要格外注意队列是否支持有界（所谓有界指的是内部的队列是否有容量限制）。实际工作中，一般都不建议使用无界的队列，因为数据量大了之后很容易导致OOM。</p><p>上面我们提到的这些Queue中，只有ArrayBlockingQueue和LinkedBlockingQueue是支持有界的，所以<strong>在使用其他无界队列时，一定要充分考虑是否存在导致OOM的隐患</strong>。</p><h2 id="无锁方案实现原理"><a href="#无锁方案实现原理" class="headerlink" title="无锁方案实现原理"></a>无锁方案实现原理</h2><h2 id="CAS"><a href="#CAS" class="headerlink" title="CAS"></a>CAS</h2><p><strong>只有当目前count的值和期望值expect相等时，才会将count更新为newValue</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimulatedCAS</span>&#123;</span><br><span class="line">  <span class="type">int</span> count；</span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">int</span> <span class="title function_">cas</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">int</span> expect, <span class="type">int</span> newValue)</span>&#123;</span><br><span class="line">    <span class="comment">// 读目前count的值</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curValue</span> <span class="operator">=</span> count;</span><br><span class="line">    <span class="comment">// 比较目前count值是否==期望值</span></span><br><span class="line">    <span class="keyword">if</span>(curValue == expect)&#123;</span><br><span class="line">      <span class="comment">// 如果是，则更新count的值</span></span><br><span class="line">      count = newValue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回写入前的值</span></span><br><span class="line">    <span class="keyword">return</span> curValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>使用CAS来解决并发问题，一般都会伴随着自旋，而所谓自旋，其实就是循环尝试。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimulatedCAS</span>&#123;</span><br><span class="line">  <span class="keyword">volatile</span> <span class="type">int</span> count;</span><br><span class="line">  <span class="comment">// 实现count+=1</span></span><br><span class="line">  addOne()&#123;</span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      newValue = count+<span class="number">1</span>; <span class="comment">//①</span></span><br><span class="line">    &#125;<span class="keyword">while</span>(count !=</span><br><span class="line">      cas(count,newValue) <span class="comment">//②</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 模拟实现CAS，仅用来帮助理解</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">int</span> <span class="title function_">cas</span><span class="params">(</span></span><br><span class="line"><span class="params">    <span class="type">int</span> expect, <span class="type">int</span> newValue)</span>&#123;</span><br><span class="line">    <span class="comment">// 读目前count的值</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">curValue</span> <span class="operator">=</span> count;</span><br><span class="line">    <span class="comment">// 比较目前count值是否==期望值</span></span><br><span class="line">    <span class="keyword">if</span>(curValue == expect)&#123;</span><br><span class="line">      <span class="comment">// 如果是，则更新count的值</span></span><br><span class="line">      count= newValue;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回写入前的值</span></span><br><span class="line">    <span class="keyword">return</span> curValue;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是在CAS方案中，有一个问题可能会常被你忽略，那就是<strong>ABA</strong>的问题。</p><p>前面我们提到“如果cas(count,newValue)返回的值<strong>不等于</strong>count，意味着线程在执行完代码①处之后，执行代码②处之前，count的值被其他线程<strong>更新过</strong>”，那如果cas(count,newValue)返回的值<strong>等于</strong>count，是否就能够认为count的值没有被其他线程<strong>更新过</strong>呢？显然不是的，假设count原本是A，线程T1在执行完代码①处之后，执行代码②处之前，有可能count被线程T2更新成了B，之后又被T3更新回了A，这样线程T1虽然看到的一直是A，但是其实已经被其他线程更新过了，这就是ABA问题。</p><p>解决ABA问题的最简单粗暴的方式就是加个版本号，每更新过一次就+1，这样即使更新回了原值，也会被记录下来。</p><p>我们所熟知的原子类AtomicLong的底层就是CAS实现的，在Java 1.8版本中，getAndIncrement()方法会转调unsafe.getAndAddLong()方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">long</span> <span class="title function_">getAndIncrement</span><span class="params">()</span> &#123;</span><br><span class="line">  <span class="keyword">return</span> unsafe.getAndAddLong(<span class="built_in">this</span>, valueOffset, <span class="number">1L</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>unsafe.getAndAddLong()方法的源码如下，该方法首先会在内存中读取共享变量的值，之后循环调用compareAndSwapLong()方法来尝试设置共享变量的值，直到成功为止。compareAndSwapLong()是一个native方法，只有当内存中共享变量的值等于expected时，才会将共享变量的值更新为x，并且返回true；否则返回fasle。compareAndSwapLong的语义和CAS指令的语义的差别仅仅是返回值不同而已。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="type">long</span> <span class="title function_">getAndAddLong</span><span class="params">(</span></span><br><span class="line"><span class="params">  Object o, <span class="type">long</span> offset, <span class="type">long</span> delta)</span>&#123;</span><br><span class="line">  <span class="type">long</span> v;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="comment">// 读取内存中的值</span></span><br><span class="line">    v = getLongVolatile(o, offset);</span><br><span class="line">  &#125; <span class="keyword">while</span> (!compareAndSwapLong(</span><br><span class="line">      o, offset, v, v + delta));</span><br><span class="line">  <span class="keyword">return</span> v;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//原子性地将变量更新为x</span></span><br><span class="line"><span class="comment">//条件是内存中的值等于expected</span></span><br><span class="line"><span class="comment">//更新成功则返回true</span></span><br><span class="line"><span class="keyword">native</span> <span class="type">boolean</span> <span class="title function_">compareAndSwapLong</span><span class="params">(</span></span><br><span class="line"><span class="params">  Object o, <span class="type">long</span> offset, </span></span><br><span class="line"><span class="params">  <span class="type">long</span> expected,</span></span><br><span class="line"><span class="params">  <span class="type">long</span> x)</span>;</span><br></pre></td></tr></table></figure><p>Java提供的原子类里面CAS一般被实现为compareAndSet()，compareAndSet()的语义和CAS指令的语义的差别仅仅是返回值不同而已，compareAndSet()里面如果更新成功，则会返回true，否则返回false。</p><h1 id="AQS：保证并发安全的终极奥秘"><a href="#AQS：保证并发安全的终极奥秘" class="headerlink" title="AQS：保证并发安全的终极奥秘"></a>AQS：保证并发安全的终极奥秘</h1><p>AQS 是 Java 并发包的核心，它的理念和设计思想贯穿于 Java 中许多并发工具和框架，如 ReentrantLock、Semaphore、CountDownLatch 等。</p><h2 id="AQS-在-ReentrantLock-的应用"><a href="#AQS-在-ReentrantLock-的应用" class="headerlink" title="AQS 在 ReentrantLock 的应用"></a>AQS 在 ReentrantLock 的应用</h2><p>我们来使用一张图来描述 ReentrantLock 对于 AQS 的应用：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ea862502337fb6abaafaf9a8af032c003df49741.png" alt="image-20250910174354523"></p><p>我们分析下上图，在 ReetrantLock 中存在加锁和解锁两个方法，这两个方法是借助 Sync 这个内部类来完成的。Sync 这个内部类实现了 AQS 抽象类，并实现了公平锁和非公平锁两种加锁方式！</p><p>公平锁的 <strong>FairSync#tryAcquire</strong> </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="type">boolean</span> <span class="title function_">tryAcquire</span><span class="params">(<span class="type">int</span> acquires)</span> &#123;</span><br><span class="line">    <span class="comment">//获取当前的线程</span></span><br><span class="line">    <span class="keyword">final</span> <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="comment">//获取当前的加锁状态 在ReentrantLock中，state=0的时候是没有加锁，state=1的时候是加锁状态</span></span><br><span class="line">    <span class="type">int</span> <span class="variable">c</span> <span class="operator">=</span> getState();</span><br><span class="line">    <span class="keyword">if</span> (c == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 没有人占用锁的时候，因为是公平锁，所以优先判断队列中是否存在排队的</span></span><br><span class="line">        <span class="comment">// 如果没有排队的，直接使用CAS进行加锁，将0 替换为 1，</span></span><br><span class="line">        <span class="keyword">if</span> (!hasQueuedPredecessors() &amp;&amp;</span><br><span class="line">            compareAndSetState(<span class="number">0</span>, acquires)) &#123;</span><br><span class="line">            <span class="comment">// 将当前线程设置到exclusiveOwnerThread变量，表示这个线程持有锁</span></span><br><span class="line">            setExclusiveOwnerThread(current);</span><br><span class="line">            <span class="comment">//返回加锁成功</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//我们在前面讲过，ReentrantLock是可重入锁，当前面逻辑加锁失败，则判断是不是当前线程持有的锁，如果是当前线程持有锁，则符合可重入规则</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (current == getExclusiveOwnerThread()) &#123;</span><br><span class="line">        <span class="comment">//将state 累加  由 1  变成 2</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">nextc</span> <span class="operator">=</span> c + acquires;</span><br><span class="line">        <span class="keyword">if</span> (nextc &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(<span class="string">&quot;Maximum lock count exceeded&quot;</span>);</span><br><span class="line">        setState(nextc);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//如果存在排队任务，或者CAS变换state的值失败，则证明当前不能加锁，直接返回false加锁失败</span></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面代码的注释能够印证出我们前面所学的，公平锁、可重入锁、CAS 的特性。</p><ul><li>首先进行加锁的时候，因为公平锁的原因，会先判断等待队列中是否存在任务。如果存在，就不能去加锁，需要去排队！如果没有排队的任务，那么就开始使用 CAS 进行加锁，此时可能会出现其他线程也在加锁，如果其他线程加锁成功，那么此时 CAS 就会返回 false。</li><li>假设上面的加锁条件全部满足，就能够加锁成功，它会将 state 变为 1，将当前线程设置到一个变量中去，并且为了保证重入锁的特性，将当前线程保存到变量中，表示这个线程持有这把锁。</li><li>如果上面的加锁条件不满足，不会第一时间就返回加锁失败，因为 ReentrantLock 是可重入锁，所以在加锁失败后，会判断当前持有锁的线程和所需要加锁的线程是不是一个，如果是一个就附和可重入锁的特性，那么就把加锁数量 +1，同时返回加锁成功。</li><li>如果全部都不满足，则直接返回 false，加锁失败。</li></ul><p>我们使用一个图来理解这个流程：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/40a848f019bb80afa664c3876b24d128db5462c3.png" alt="image-20250910174532176"></p><p>线程加锁失败后，会开始进行入队操作，也就是 <strong>addWaiter</strong> 方法。AQS 的队列与传统队列不同，AQS 的队列是一个双向链表，排队的线程都是用 next 指向下一个节点任务。head 节点可能为空，因为当第一个任务入队的时候，会初始化 head 节点，head 节点内线程数据为空，但是 head 节点的 next 会指向第一个等待线程。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Node <span class="title function_">addWaiter</span><span class="params">(Node mode)</span> &#123;</span><br><span class="line">    <span class="comment">//创建一个node节点 排它锁的mode = null</span></span><br><span class="line">    <span class="type">Node</span> <span class="variable">node</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Node</span>(Thread.currentThread(), mode);</span><br><span class="line">    <span class="comment">// 获取当前的尾节点</span></span><br><span class="line">    <span class="type">Node</span> <span class="variable">pred</span> <span class="operator">=</span> tail;</span><br><span class="line">    <span class="keyword">if</span> (pred != <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="comment">//将当前节点的上一个节点设置为尾节点</span></span><br><span class="line">        node.prev = pred;</span><br><span class="line">        <span class="comment">// cas替换 将当前节点设置为tail节点</span></span><br><span class="line">        <span class="keyword">if</span> (compareAndSetTail(pred, node)) &#123;</span><br><span class="line">            <span class="comment">//将当前的尾节点的下一节点设为当前追加的节点</span></span><br><span class="line">            pred.next = node;</span><br><span class="line">            <span class="keyword">return</span> node;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//针对第一个任务初始化head节点操作</span></span><br><span class="line">    enq(node);</span><br><span class="line">    <span class="keyword">return</span> node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以下是整个AQS的执行流程及加锁逻辑：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c62be37f9d8c32e0db046409ffcf7921a1e095d5.png" alt="Pasted image 20230719091028"></p><p>简单来说，加锁无非就是通过 CAS 去改变 State 的值，等于 0 且能改变成功就加锁成功，如果改变失败，就入队后阻塞。</p><p>解锁流程：</p><ol><li>解锁就是对 state 进行减一操作（重入次数 -1），当 state &#x3D; 0 的时候，就将持有锁的线程设置为 null，且返回解锁的结果。</li><li>因为 <code>ReentrantLock</code> 是可重入锁，一个线程多次获取锁，state 的数量会大于 1，当解锁的时候，必须当前<strong>线程解锁次数 &#x3D; 加锁次数</strong>才能解锁成功，否则解锁失败。</li><li>无论是解锁成功与否，都必须将当前 state 的数量使用 CAS 更新为最新的。</li></ol><p>解锁成功后，会调用 head 节点后的等到任务的 unPark 解锁线程，使得阻塞的线程重新开始循环获取锁的操作，直到获取锁成功。</p><ul><li><strong>公平锁当发现 state &#x3D; 0 也就是没有任务占有锁的情况下，会判断队列中是存在等待任务，如果存在就会加锁失败，然后执行入队操作。</strong></li><li><strong>而非公平锁发现 state &#x3D; 0 也就是没有任务占有锁的情况下，会直接进行 CAS 加锁，只要 CAS 加锁成功了，就会直接返回加锁成功而不会进行入队操作</strong></li></ul><h2 id="AQS-在-CountDownLatch-的应用"><a href="#AQS-在-CountDownLatch-的应用" class="headerlink" title="AQS 在 CountDownLatch 的应用"></a>AQS 在 CountDownLatch 的应用</h2><p>与 ReentrantLock 相同的是，我们同样可以在 CountDownLatch 中寻找到 AQS 的实现类 Sync。没错，CountDownLatch 的实现也是基于 AQS 来做的。</p><p>在初始化 CountDownLatch 的时候，我们传递了 10，然后开启了 10 个线程执行任务，每一个线程执行完毕之后都会调用 <code>countDownLatch.countDown();</code> 来进行递减操作。我们在主线程调用 <code>countDownLatch.await();</code> 来等待 CountDownLatch 变为 0 后，它会解除阻塞继续向下执行！</p><p>当 state 的值不为 0 的时候，证明 CountDown 还没有释放完毕，此时应该阻塞，先将当前节点加入到等待队列，然后同 ReentrantLock 一样，在阻塞之前也会先判断自己是不是 head 的下一个节点，如果是的话会再次尝试判断一下 state 是不是等于 0 了，如果此时等于 0 了，就不用阻塞了，可以直接返回。</p><p>此时如果 state 依旧不为 0，则开始与 ReentrantLock 一样调用 park 进行阻塞等待唤醒。</p><p>事实上，await 阻塞的逻辑十分简单。我们总结来说，就是当程序调用 await 方法的时候，会判断 state 的值是不是 0，如果不是 0 就阻塞，是 0 就直接返回。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/9f0ba1d75a6936cc20df70470f5f42465e6fde4b.png" alt="image-20250910175742428"></p><p>countDown 方法主要就是对 AQS 中 State 的值进行 -1 操作，当 State 的值为 0 的时候，就开始唤醒等待队列中的任务。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/29157b26ff0dd978d0b72cfb2327de6522c6f44f.png" alt="image-20250910175837917"></p><h2 id="AQS-在-ReentrantReadWriteLock-的应用"><a href="#AQS-在-ReentrantReadWriteLock-的应用" class="headerlink" title="AQS 在 ReentrantReadWriteLock 的应用"></a>AQS 在 ReentrantReadWriteLock 的应用</h2><p>AQS 中 state 主要是为了记录加锁的次数或者计数次数，但是在 ReentrantReadWriteLock 中存在读锁（共享锁）和写锁（独占锁）两种，那么此时只有一个 state 肯定是无法满足的，因为 state 是一个 int 值，我们知道 int 在 Java 占 32 位字节，所以我们考虑<strong>将 32 位分为高 16 位和低 16 位</strong>，如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/5e8b8730fb45c3d0758136f4d194368fa76aae26.png" alt="image-20250910180229529"></p><h3 id="读锁"><a href="#读锁" class="headerlink" title="读锁"></a>读锁</h3><p>共享锁的加锁逻辑就是先判断是不是存在写锁，存在写锁就直接加锁失败入队，不存在就加锁成功并修改 state 的高 16 位数据，并在每一个线程维护一个计数器，来计算每一个线程加锁的次数。</p><p>共享锁的解锁比较简单，解锁过程简单来说无非就是将累加器中的累加次数 -1，同时将 state 中的高 16 位 -1（state - 65536），然后再通知等待队列中的任务进行解除阻塞。</p><h3 id="写锁"><a href="#写锁" class="headerlink" title="写锁"></a>写锁</h3><p>首先，它是一个独占锁，所以我们需要先判断 state 的低 16 位是不是已经存在独占锁了，如果已经存在独占锁了，那么我们就需要判断是不是重入锁！如果 state 中已经存在独占锁了，而且也不是重入锁，那么直接加锁失败，将任务放到任务队列中就可以了。</p><p>了解了写锁的加锁步骤之后，解锁步骤能猜出来：</p><ol><li>将 state - 1；</li><li>判断当前 state 的写锁数量，如果为 0 的话证明重入锁释放完毕，直接将加锁线程置空，并解锁成功。</li></ol><h1 id="Executor与线程池：如何创建正确的线程池"><a href="#Executor与线程池：如何创建正确的线程池" class="headerlink" title="Executor与线程池：如何创建正确的线程池"></a>Executor与线程池：如何创建正确的线程池</h1><h2 id="ThreadPoolExecutor"><a href="#ThreadPoolExecutor" class="headerlink" title="ThreadPoolExecutor"></a>ThreadPoolExecutor</h2><p>ThreadPoolExecutor的构造函数非常复杂，如下面代码所示，这个最完备的构造函数有7个参数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ThreadPoolExecutor</span>(</span><br><span class="line">  <span class="type">int</span> corePoolSize,</span><br><span class="line">  <span class="type">int</span> maximumPoolSize,</span><br><span class="line">  <span class="type">long</span> keepAliveTime,</span><br><span class="line">  TimeUnit unit,</span><br><span class="line">  BlockingQueue&lt;Runnable&gt; workQueue,</span><br><span class="line">  ThreadFactory threadFactory,</span><br><span class="line">  RejectedExecutionHandler handler) </span><br></pre></td></tr></table></figure><p>下面我们一一介绍这些参数的意义，你可以<strong>把线程池类比为一个项目组，而线程就是项目组的成员</strong>。</p><ul><li><p><strong>corePoolSize</strong>：表示线程池保有的最小线程数。有些项目很闲，但是也不能把人都撤了，至少要留corePoolSize个人坚守阵地。</p></li><li><p><strong>maximumPoolSize</strong>：表示线程池创建的最大线程数。当项目很忙时，就需要加人，但是也不能无限制地加，最多就加到maximumPoolSize个人。当项目闲下来时，就要撤人了，最多能撤到corePoolSize个人。</p></li><li><p><strong>keepAliveTime &amp; unit</strong>：上面提到项目根据忙闲来增减人员，那在编程世界里，如何定义忙和闲呢？很简单，一个线程如果在一段时间内，都没有执行任务，说明很闲，keepAliveTime 和 unit 就是用来定义这个“一段时间”的参数。也就是说，如果一个线程空闲了<code>keepAliveTime &amp; unit</code>这么久，而且线程池的线程数大于 corePoolSize ，那么这个空闲的线程就要被回收了。</p></li><li><p><strong>workQueue</strong>：工作队列，和上面示例代码的工作队列同义。</p></li><li><p><strong>threadFactory</strong>：通过这个参数你可以自定义如何创建线程，例如你可以给线程指定一个有意义的名字。</p></li><li><p>handler</p><p>：通过这个参数你可以自定义任务的拒绝策略。如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），那么此时提交任务，线程池就会拒绝接收。至于拒绝的策略，你可以通过handler这个参数来指定。ThreadPoolExecutor已经提供了以下4种策略。</p><ul><li>CallerRunsPolicy：提交任务的线程自己去执行该任务。</li><li>AbortPolicy：默认的拒绝策略，会throws RejectedExecutionException。</li><li>DiscardPolicy：直接丢弃任务，没有任何异常抛出。</li><li>DiscardOldestPolicy：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入到工作队列。</li></ul></li></ul><h2 id="线程池处理任务流程"><a href="#线程池处理任务流程" class="headerlink" title="线程池处理任务流程"></a>线程池处理任务流程</h2><p>当我们向线程池中提交了大量的任务后，提交的任务会经历以下的历程：</p><ul><li>任务开始提交后，当线程池中的线程数小于 corePoolSize 的时候，那么线程池会立即创建一个新的线程去执行这个任务，因此这个任务会被立即运行。</li><li>随着任务数量的提升，当线程池中的线程数大于等于 corePoolSize 且小于 maximumPoolSize 的时候，线程池会将这些任务暂时存放在 workQueue 中等待核心线程运行完毕后，来消费这些等待的任务。</li><li>随着任务数量还在不停地上涨，任务队列（workQueue）也放不下了，任务已经被放满，此时会开始继续新建线程去消费任务队列的任务，直到当前线程池中存活的线程数量等于 maximumPoolSize 为止。</li><li>此时，如果系统还在不停地提交任务，workQueue 被放满了，线程池中存活的线程数量也等于 maximumPoolSize 了，那么线程池会认为它执行不了这么多任务。为了避免出现不可预测的问题，那么超出线程池极限的这部分任务，会被线程池调用拒绝策略（Handler）来拒绝执行。</li><li>终于，一波任务高峰过去了，系统终于不再提交新的任务，此时 maximumPoolSize 个线程会赶紧将手头的任务执行完毕，然后开始协助消费 workQueue 中等待的任务，直至将等待队列中的任务消费完毕。此时 maximumPoolSize 个线程开始没活干了，就开始闲着，当空闲时间超过了 <strong>keepAliveTime 与 unit</strong> 所规定的空闲时间，线程池就开始回收这些空闲的线程，直至线程池中存活的线程数量等于 corePoolSize 为止。</li></ul><h2 id="使用线程池要注意些什么"><a href="#使用线程池要注意些什么" class="headerlink" title="使用线程池要注意些什么"></a>使用线程池要注意些什么</h2><p>不建议使用Executors的最重要的原因是：Executors提供的很多方法默认使用的都是无界的LinkedBlockingQueue，高负载情境下，无界队列很容易导致OOM，而OOM会导致所有请求都无法处理，这是致命问题。所以<strong>强烈建议使用有界队列</strong>。</p><p>使用有界队列，当任务过多时，线程池会触发执行拒绝策略，线程池默认的拒绝策略会throw RejectedExecutionException 这是个运行时异常，对于运行时异常编译器并不强制catch它，所以开发人员很容易忽略。因此<strong>默认拒绝策略要慎重使用</strong>。如果线程池处理的任务非常重要，建议自定义自己的拒绝策略；并且在实际工作中，自定义的拒绝策略往往和降级策略配合使用。</p><p>使用线程池，还要注意异常处理的问题，例如通过ThreadPoolExecutor对象的execute()方法提交任务时，如果任务在执行的过程中出现运行时异常，会导致执行任务的线程终止；不过，最致命的是任务虽然异常了，但是你却获取不到任何通知，这会让你误以为任务都执行得很正常。虽然线程池提供了很多用于异常处理的方法，但是最稳妥和简单的方案还是捕获所有异常并按需处理，你可以参考下面的示例代码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">//业务逻辑</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">  <span class="comment">//按需处理</span></span><br><span class="line">&#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">  <span class="comment">//按需处理</span></span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure><h1 id="ThreadLocal：线程本地存储模式"><a href="#ThreadLocal：线程本地存储模式" class="headerlink" title="ThreadLocal：线程本地存储模式"></a>ThreadLocal：线程本地存储模式</h1><p>Java的实现里面也有一个Map，叫做ThreadLocalMap，不过持有ThreadLocalMap的不是ThreadLocal，而是Thread。Thread这个类内部有一个私有属性threadLocals，其类型就是ThreadLocalMap，ThreadLocalMap的Key是ThreadLocal。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ad2c2e1196e4cc6bf4a0d507c4cc8524489fa836.png" alt="image-20250909190952775"></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">  <span class="comment">//内部持有ThreadLocalMap</span></span><br><span class="line">  ThreadLocal.ThreadLocalMap  threadLocals;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ThreadLocal</span>&lt;T&gt;&#123;</span><br><span class="line">  <span class="keyword">public</span> T <span class="title function_">get</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//首先获取线程持有的</span></span><br><span class="line">    <span class="comment">//ThreadLocalMap</span></span><br><span class="line">    <span class="type">ThreadLocalMap</span> <span class="variable">map</span> <span class="operator">=</span> Thread.currentThread().threadLocals;</span><br><span class="line">    <span class="comment">//在ThreadLocalMap中</span></span><br><span class="line">    <span class="comment">//查找变量</span></span><br><span class="line">    <span class="type">Entry</span> <span class="variable">e</span> <span class="operator">=</span>  map.getEntry(<span class="built_in">this</span>);</span><br><span class="line">    <span class="keyword">return</span> e.value;  </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">ThreadLocalMap</span>&#123;</span><br><span class="line">    <span class="comment">//内部是数组而不是Map</span></span><br><span class="line">    Entry[] table;</span><br><span class="line">    <span class="comment">//根据ThreadLocal查找Entry</span></span><br><span class="line">    Entry <span class="title function_">getEntry</span><span class="params">(ThreadLocal key)</span>&#123;</span><br><span class="line">      <span class="comment">//省略查找逻辑</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Entry定义</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Entry</span> <span class="keyword">extends</span></span><br><span class="line">    <span class="title class_">WeakReference</span>&lt;ThreadLocal&gt;&#123;</span><br><span class="line">      Object value;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>在Java的实现方案里面，ThreadLocal仅仅是一个代理工具类，内部并不持有任何与线程相关的数据，所有和线程相关的数据都存储在Thread里面，这样的设计容易理解。而从数据的亲缘性上来讲，ThreadLocalMap属于Thread也更加合理。</p><p>当然还有一个更加深层次的原因，那就是<strong>不容易产生内存泄露</strong>。</p><p>Java的实现中Thread持有ThreadLocalMap，而且ThreadLocalMap里对ThreadLocal的引用还是弱引用（WeakReference），所以只要Thread对象可以被回收，那么ThreadLocalMap就能被回收。</p><h2 id="ThreadLocal与内存泄露"><a href="#ThreadLocal与内存泄露" class="headerlink" title="ThreadLocal与内存泄露"></a>ThreadLocal与内存泄露</h2><blockquote><p>在线程池中使用ThreadLocal为什么可能导致内存泄露呢？</p></blockquote><p>原因就出在线程池中线程的存活时间太长，往往都是和程序同生共死的，这就意味着Thread持有的ThreadLocalMap一直都不会被回收，再加上ThreadLocalMap中的Entry对ThreadLocal是弱引用（WeakReference），所以只要ThreadLocal结束了自己的生命周期是可以被回收掉的。但是Entry中的Value却是被Entry强引用的，所以即便Value的生命周期结束了，Value也是无法被回收的，从而导致内存泄露。</p><p>既然JVM不能做到自动释放对Value的强引用，那我们手动释放就可以了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">ExecutorService es;</span><br><span class="line">ThreadLocal tl;</span><br><span class="line">es.execute(()-&gt;&#123;</span><br><span class="line">  <span class="comment">//ThreadLocal增加变量</span></span><br><span class="line">  tl.set(obj);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 省略业务逻辑代码</span></span><br><span class="line">  &#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">//手动清理ThreadLocal </span></span><br><span class="line">    tl.remove();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="高性能限流器Guava-RateLimiter"><a href="#高性能限流器Guava-RateLimiter" class="headerlink" title="高性能限流器Guava RateLimiter"></a>高性能限流器Guava RateLimiter</h1><p>Guava是Google开源的Java类库，提供了一个工具类RateLimiter。我们先来看看RateLimiter的使用，让你对限流有个感官的印象。假设我们有一个线程池，它每秒只能处理两个任务，如果提交的任务过快，可能导致系统不稳定，这个时候就需要用到限流。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//限流器流速：2个请求/秒</span></span><br><span class="line"><span class="type">RateLimiter</span> <span class="variable">limiter</span> <span class="operator">=</span> RateLimiter.create(<span class="number">2.0</span>);</span><br><span class="line"><span class="comment">//执行任务的线程池</span></span><br><span class="line"><span class="type">ExecutorService</span> <span class="variable">es</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">1</span>);</span><br><span class="line"><span class="comment">//记录上一次执行时间</span></span><br><span class="line">prev = System.nanoTime();</span><br><span class="line"><span class="comment">//测试执行20次</span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">20</span>; i++)&#123;</span><br><span class="line">  <span class="comment">//限流器限流</span></span><br><span class="line">  limiter.acquire();</span><br><span class="line">  <span class="comment">//提交任务异步执行</span></span><br><span class="line">  es.execute(()-&gt;&#123;</span><br><span class="line">    <span class="type">long</span> cur=System.nanoTime();</span><br><span class="line">    <span class="comment">//打印时间间隔：毫秒</span></span><br><span class="line">    System.out.println((cur-prev)/<span class="number">1000_000</span>);</span><br><span class="line">    prev = cur;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果：<br>…<br>500<br>499<br>499<br>500<br>499</p><h2 id="经典限流算法：令牌桶算法"><a href="#经典限流算法：令牌桶算法" class="headerlink" title="经典限流算法：令牌桶算法"></a>经典限流算法：令牌桶算法</h2><p>Guava采用的是<strong>令牌桶算法</strong>，其<strong>核心是要想通过限流器，必须拿到令牌</strong>。也就是说，只要我们能够限制发放令牌的速率，那么就能控制流速了。令牌桶算法的详细描述如下：</p><ol><li>令牌以固定的速率添加到令牌桶中，假设限流的速率是 r&#x2F;秒，则令牌每 1&#x2F;r 秒会添加一个；</li><li>假设令牌桶的容量是 b ，如果令牌桶已满，则新的令牌会被丢弃；</li><li>请求能够通过限流器的前提是令牌桶中有令牌。</li></ol><p>这个算法中，限流的速率 r 还是比较容易理解的，但令牌桶的容量 b 该怎么理解呢？b 其实是burst的简写，意义是<strong>限流器允许的最大突发流量</strong>。比如b&#x3D;10，而且令牌桶中的令牌已满，此时限流器允许10个请求同时通过限流器，当然只是突发流量而已，这10个请求会带走10个令牌，所以后续的流量只能按照速率 r 通过限流器。</p><p>令牌桶这个算法，如何用Java实现呢？</p><p>很可能你的直觉会告诉你生产者-消费者模式：一个生产者线程定时向阻塞队列中添加令牌，而试图通过限流器的线程则作为消费者线程，只有从阻塞队列中获取到令牌，才允许通过限流器。</p><p>可实际情况却是使用限流的场景大部分都是高并发场景，而且系统压力已经临近极限了，此时这个实现就有问题了。问题就出在定时器上，在高并发场景下，当系统压力已经临近极限的时候，定时器的精度误差会非常大，同时定时器本身会创建调度线程，也会对系统的性能产生影响。</p><h2 id="Guava如何实现令牌桶算法"><a href="#Guava如何实现令牌桶算法" class="headerlink" title="Guava如何实现令牌桶算法"></a>Guava如何实现令牌桶算法</h2><p>Guava实现令牌桶算法，用了一个很简单的办法，其关键是<strong>记录并动态计算下一令牌发放的时间</strong>。</p><p>假设令牌桶的容量为 b&#x3D;1，限流速率 r &#x3D; 1个请求&#x2F;秒，如下图所示，如果当前令牌桶中没有令牌，下一个令牌的发放时间是在第3秒，而在第2秒的时候有一个线程T1请求令牌，此时该如何处理呢？</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ecbcdfd6834fbcb0a5193a2b870bc18528225e63.png" alt="image-20250910160423107"></p><p>对于这个请求令牌的线程而言，很显然需要等待1秒，因为1秒以后（第3秒）它就能拿到令牌了。此时需要注意的是，下一个令牌发放的时间也要增加1秒，为什么呢？因为第3秒发放的令牌已经被线程T1预占了。处理之后如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2152701f00cb9e5cdff36719e4320442e5ef427c.png" alt="image-20250910160451591"></p><p>假设T1在预占了第3秒的令牌之后，马上又有一个线程T2请求令牌，如下图所示。</p><p>很显然，由于下一个令牌产生的时间是第4秒，所以线程T2要等待两秒的时间，才能获取到令牌，同时由于T2预占了第4秒的令牌，所以下一令牌产生时间还要增加1秒，完全处理之后，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a17f801cf65aa8d6bc99e6bb17cc64cfb425b688.png" alt="image-20250910160522162"></p><p>上面线程T1、T2都是在<strong>下一令牌产生时间之前</strong>请求令牌，如果线程在<strong>下一令牌产生时间之后</strong>请求令牌会如何呢？假设在线程T1请求令牌之后的5秒，也就是第7秒，线程T3请求令牌，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/373c0630e3f88b7e13312e3aff8d092369778874.png" alt="image-20250910160539644"></p><p>由于在第5秒已经产生了一个令牌，所以此时线程T3可以直接拿到令牌，而无需等待。在第7秒，实际上限流器能够产生3个令牌，第5、6、7秒各产生一个令牌。由于我们假设令牌桶的容量是1，所以第6、7秒产生的令牌就丢弃了，其实等价地你也可以认为是保留的第7秒的令牌，丢弃的第5、6秒的令牌，也就是说第7秒的令牌被线程T3占有了，于是下一令牌的的产生时间应该是第8秒，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ee575bff63b1ab97666a92a7ab81b6acb1fb7eb0.png" alt="image-20250910160614686"></p><p>通过上面简要地分析，你会发现，我们<strong>只需要记录一个下一令牌产生的时间，并动态更新它，就能够轻松完成限流功能</strong>。</p><p>关键是<strong>reserve()方法</strong>，这个方法会为请求令牌的线程预分配令牌，同时返回该线程能够获取令牌的时间。其实现逻辑就是上面提到的：如果线程请求令牌的时间在下一令牌产生时间之后，那么该线程立刻就能够获取令牌；反之，如果请求时间在下一令牌产生时间之前，那么该线程是在下一令牌产生的时间获取令牌。由于此时下一令牌已经被该线程预占，所以下一令牌产生的时间需要加上1秒。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleLimiter</span> &#123;</span><br><span class="line">  <span class="comment">//下一令牌产生时间</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">next</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">  <span class="comment">//发放令牌间隔：纳秒</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">interval</span> <span class="operator">=</span> <span class="number">1000_000_000</span>;</span><br><span class="line">  <span class="comment">//预占令牌，返回能够获取令牌的时间</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">long</span> <span class="title function_">reserve</span><span class="params">(<span class="type">long</span> now)</span>&#123;</span><br><span class="line">    <span class="comment">//请求时间在下一令牌产生时间之后</span></span><br><span class="line">    <span class="comment">//重新计算下一令牌产生时间</span></span><br><span class="line">    <span class="keyword">if</span> (now &gt; next)&#123;</span><br><span class="line">      <span class="comment">//将下一令牌产生时间重置为当前时间</span></span><br><span class="line">      next = now;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//能够获取令牌的时间</span></span><br><span class="line">    <span class="type">long</span> at=next;</span><br><span class="line">    <span class="comment">//设置下一令牌产生时间</span></span><br><span class="line">    next += interval;</span><br><span class="line">    <span class="comment">//返回线程需要等待的时间</span></span><br><span class="line">    <span class="keyword">return</span> Math.max(at, <span class="number">0L</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//申请令牌</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//申请令牌时的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">    <span class="comment">//预占令牌</span></span><br><span class="line">    <span class="type">long</span> at=reserve(now);</span><br><span class="line">    <span class="type">long</span> waitTime=max(at-now, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">//按照条件等待</span></span><br><span class="line">    <span class="keyword">if</span>(waitTime &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        TimeUnit.NANOSECONDS</span><br><span class="line">          .sleep(waitTime);</span><br><span class="line">      &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果令牌桶的容量大于1，又该如何处理呢？按照令牌桶算法，令牌要首先从令牌桶中出，所以我们需要按需计算令牌桶中的数量，当有线程请求令牌时，先从令牌桶中出。具体的代码实现如下所示。</p><p>我们增加了一个<strong>resync()方法</strong>，在这个方法中，如果线程请求令牌的时间在下一令牌产生时间之后，会重新计算令牌桶中的令牌数，<strong>新产生的令牌的计算公式是：(now-next)&#x2F;interval</strong>，你可对照上面的示意图来理解。reserve()方法中，则增加了先从令牌桶中出令牌的逻辑，不过需要注意的是，如果令牌是从令牌桶中出的，那么next就无需增加一个 interval 了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleLimiter</span> &#123;</span><br><span class="line">  <span class="comment">//当前令牌桶中的令牌数量</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">storedPermits</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">  <span class="comment">//令牌桶的容量</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">maxPermits</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line">  <span class="comment">//下一令牌产生时间</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">next</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">  <span class="comment">//发放令牌间隔：纳秒</span></span><br><span class="line">  <span class="type">long</span> <span class="variable">interval</span> <span class="operator">=</span> <span class="number">1000_000_000</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//请求时间在下一令牌产生时间之后,则</span></span><br><span class="line">  <span class="comment">// 1.重新计算令牌桶中的令牌数</span></span><br><span class="line">  <span class="comment">// 2.将下一个令牌发放时间重置为当前时间</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">resync</span><span class="params">(<span class="type">long</span> now)</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (now &gt; next) &#123;</span><br><span class="line">      <span class="comment">//新产生的令牌数</span></span><br><span class="line">      <span class="type">long</span> newPermits=(now-next)/interval;</span><br><span class="line">      <span class="comment">//新令牌增加到令牌桶</span></span><br><span class="line">      storedPermits=min(maxPermits, storedPermits + newPermits);</span><br><span class="line">      <span class="comment">//将下一个令牌发放时间重置为当前时间</span></span><br><span class="line">      next = now;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//预占令牌，返回能够获取令牌的时间</span></span><br><span class="line">  <span class="keyword">synchronized</span> <span class="type">long</span> <span class="title function_">reserve</span><span class="params">(<span class="type">long</span> now)</span>&#123;</span><br><span class="line">    resync(now);</span><br><span class="line">    <span class="comment">//能够获取令牌的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">at</span> <span class="operator">=</span> next;</span><br><span class="line">    <span class="comment">//令牌桶中能提供的令牌</span></span><br><span class="line">    <span class="type">long</span> fb=min(<span class="number">1</span>, storedPermits);</span><br><span class="line">    <span class="comment">//令牌净需求：首先减掉令牌桶中的令牌</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">nr</span> <span class="operator">=</span> <span class="number">1</span> - fb;</span><br><span class="line">    <span class="comment">//重新计算下一令牌产生时间</span></span><br><span class="line">    next = next + nr*interval;</span><br><span class="line">    <span class="comment">//重新计算令牌桶中的令牌</span></span><br><span class="line">    <span class="built_in">this</span>.storedPermits -= fb;</span><br><span class="line">    <span class="keyword">return</span> at;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//申请令牌</span></span><br><span class="line">  <span class="keyword">void</span> <span class="title function_">acquire</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">//申请令牌时的时间</span></span><br><span class="line">    <span class="type">long</span> <span class="variable">now</span> <span class="operator">=</span> System.nanoTime();</span><br><span class="line">    <span class="comment">//预占令牌</span></span><br><span class="line">    <span class="type">long</span> at=reserve(now);</span><br><span class="line">    <span class="type">long</span> waitTime=max(at-now, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">//按照条件等待</span></span><br><span class="line">    <span class="keyword">if</span>(waitTime &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        TimeUnit.NANOSECONDS.sleep(waitTime);</span><br><span class="line">      &#125;<span class="keyword">catch</span>(InterruptedException e)&#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;可见性、原子性和有序性问题：并发编程Bug的源头&quot;&gt;&lt;a href=&quot;#可见性、原子性和有序性问题：并发编程Bug的源头&quot; class=&quot;headerlink&quot; title=&quot;可见性、原子性和有序性问题：并发编程Bug的源头&quot;&gt;&lt;/a&gt;可见性、原子性和有序性问题：</summary>
      
    
    
    
    
    <category term="JUC" scheme="https://palette-k.github.io/tags/JUC/"/>
    
  </entry>
  
  <entry>
    <title>uhr考勤</title>
    <link href="https://palette-k.github.io/2025/07/14/uhr%E8%80%83%E5%8B%A4%E6%A8%A1%E5%9D%97%E6%A0%B8%E5%BF%83%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91/"/>
    <id>https://palette-k.github.io/2025/07/14/uhr%E8%80%83%E5%8B%A4%E6%A8%A1%E5%9D%97%E6%A0%B8%E5%BF%83%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E9%80%BB%E8%BE%91/</id>
    <published>2025-07-14T09:01:45.000Z</published>
    <updated>2025-08-28T03:31:52.592Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1自动生成年假"><a href="#1自动生成年假" class="headerlink" title="1自动生成年假"></a>1自动生成年假</h1><h2 id="1-1基本业务场景"><a href="#1-1基本业务场景" class="headerlink" title="1.1基本业务场景"></a>1.1基本业务场景</h2><p>假期类型为定额类且规则是自动生成的需要定时任务自动生成假期，根据基准值和生成条件来确定年假生成的额度。<br><img src="https://i0.hdslb.com/bfs/openplatform/f0088aaee1cdc5c9bb9796c0aac8fd0f055648ec.png" alt="image-20250714170445623"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/f2a257b70f9cf40c4a976c8c7627830453b19c82.png" alt="image-20250714170504252"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/555ded81855f9ee25dd4f9e7a2deeea258148e3c.png" alt="image-20250714170518878"></p><p><strong>基准值</strong>：福利工龄日期、社会工龄日期<br>!!#ff0000 <strong>生成条件</strong>!!：福利工龄日期满N个月、社会工龄日期满N个月</p><p><strong>是否预支年假</strong>：是、否。即是生成已工作年份年假和未来为工作时间的年假（预支，员工刚入职生成今年一年的年假）<br><strong>基准值单位：</strong>月、自然年<br><strong>例如：基准值以月为单位：</strong><br>基准值单位选择为“月”，非预支类型年假，若起始日期为2022年10月1日，则2023年10月1日基准值满12个月<br>示例：若年假计算规则：以“福利工龄”为基准值+“福利工龄”为基础条件+“自然年”为计算周期+取整方式为“向下取整”+额度单位为“天”+基准值单位为“月”： 小王于2015年7月12日首次参加工作，于2022年2月10日加入公司，公司规定：福利工龄满12个月（2023年2月10日）后给予年假，年假阶梯是福利工龄12个月<del>60个月给予5天，60个月</del>120个月给予7天。 小王于2022年5月10日，入职满12个月，此时生成年假。 计算规则为：（20221231-20220211）&#x2F;365<em>7&#x3D;6.19，向下取整为6天。<br><strong>基准值以自然年为单位：</strong><br>基准值单位选择为“自然年”，非预支类型年假，若起始日期为2022年10月1日，2023年1月1日开始则为第二个自然年。<br>示例：若年假计算规则：以“福利工龄”为基准值+“福利工龄”为基础条件+“自然年”为计算周期+取整方式为“向下取整”+额度单位为“天”+基准值单位为“自然年”： 小王于2018年7月12日首次参加工作，于2022年2月10日加入公司，公司规定：福利工龄满12个月（2023年2月10日）后给予年假，年假阶梯是社会工龄第1-5自然年给予5天， 小王于2023年2月10日，入职满12个月，此时生成年假。 计算规则为：（20221231-20220210）&#x2F;365</em>5&#x3D;4.42，向下取整为4天。</p><h2 id="1-2业务实现逻辑梳理"><a href="#1-2业务实现逻辑梳理" class="headerlink" title="1.2业务实现逻辑梳理"></a>1.2业务实现逻辑梳理</h2><h3 id="整体逻辑流程图"><a href="#整体逻辑流程图" class="headerlink" title="整体逻辑流程图"></a>整体逻辑流程图</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/9a074dde5b69432d6346787bf1b3cef3d6452e90.png" alt="image-20250714170735668"></p><h3 id="以自然年为计算周期逻辑"><a href="#以自然年为计算周期逻辑" class="headerlink" title="以自然年为计算周期逻辑"></a>以自然年为计算周期逻辑</h3><p>名词解释：</p><ul><li><p>基准：基准值日期（社会工龄日期 or 福利工龄日期）</p></li><li><p>M：以基准值日期为准，生成条件满M个月</p></li><li><p>T：当前时间</p></li><li><p>司内（红点）：入职日期</p></li><li><p>司内年底（黑点）：入职当年的自然年底</p></li><li><p>司内2年底（黑点）：入职第二年的自然年底</p></li></ul><p><strong>1.不预支年假，即满足年假生成条件，生成上年应休年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/fd077ccfa48ea3c644fb11471b12ed1577c0ef98.png" alt="image-20250714170540813"><br><strong>2.预支年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/6915b5e655025e6781644f25d991079854a21f93.png" alt="image-20250714170551746"><br><strong>3.不预支年假，即满足年假生成条件</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/aa281597ee5d251c57bf70a49c85e6156068e903.png" alt="image-20250714170603847"><br><strong>4.预支年假</strong><br><img src="https://i0.hdslb.com/bfs/openplatform/b6a8d35bc7053bb3aca9a8526556dc76162a5791.png" alt="image-20250714170616417"></p><p><em>代码逻辑：通过比较当前时间在哪个时间段、是否预支年假，传入不同的额度开始计算日期参数，再根据是否存在跨额度的情况计算出最终的应休年假。</em></p><h2 id="1-3特殊场景-年假跨额度生成处理方式"><a href="#1-3特殊场景-年假跨额度生成处理方式" class="headerlink" title="1.3特殊场景-年假跨额度生成处理方式"></a>1.3特殊场景-年假跨额度生成处理方式</h2><p>1 员工当前年年假生成数刚好在两个阶段中是，需要对两个阶段进行合并计算出最终的年假<br>年假跨阶段7天&#x2F;10天； 计算公式：(153&#x2F;365)*7+(173&#x2F;365)*10<br><img src="https://i0.hdslb.com/bfs/openplatform/d44ec787f485b1cfd751d3442de69dbb3119be00.png" alt="image-20250714170640952"></p><h2 id="1-4测试用例"><a href="#1-4测试用例" class="headerlink" title="1.4测试用例"></a>1.4测试用例</h2><p>根据以下测试用例可以和上面的流程图相结合，便于理解年假生成逻辑。</p><p><strong>不预支年假：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/d03b5acc62ec9451080fc00e675a68dc62938a9a.png" alt="image-20250714171231119"></p><p><strong>预支年假：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/db530e93d367b991b894228030bc5d5cacbb3315.png"></p><p><strong>高管类个性化规则：</strong></p><p><img src="https://i0.hdslb.com/bfs/openplatform/17ad2f8c00bf767a0a1bfed325b1d8b0b41f7bec.png" alt="image-20250714171407722"></p><h1 id="2初始化有效打卡记录"><a href="#2初始化有效打卡记录" class="headerlink" title="2初始化有效打卡记录"></a>2初始化有效打卡记录</h1><p>一般来讲，考勤计算需要先拿到每个员工每天每个班次的有效打卡记录，以这个记录为基准来计算考勤。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d290f8e750aa53a54a87946ebd8668e5d9e08c13.png" alt="image-20250715172749571"></p><h1 id="3考勤计算全流程"><a href="#3考勤计算全流程" class="headerlink" title="3考勤计算全流程"></a>3考勤计算全流程</h1><p>考勤计算分为数据准备、数据验证、组装数据、数据拆分计算这四个步骤，其中涉及的表及业务逻辑如下图。</p><p>考勤计算的定时任务也和初始化有效打卡记录的整体逻辑一致，都是根据员工的pdc时间筛选出需要计算考勤的员工和考勤日期，按照日期给每个员工计算考勤。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/fd1b6cb9f2ff196d1e4d0f1966dabbeba83acd69.png" alt="image-20250715172047166"></p><p>考勤计算涉及的相关表：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0726a8b1949c0b2b501f83e7e26a00767a45de1d.png" alt="image-20250717151034055"></p><h2 id="3-1数据准备"><a href="#3-1数据准备" class="headerlink" title="3.1数据准备"></a>3.1数据准备</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/d3fe75c1771bb5643c18803617374d2eefe31a43.png" alt="image-20250715171507019"></p><h2 id="3-2数据验证"><a href="#3-2数据验证" class="headerlink" title="3.2数据验证"></a>3.2数据验证</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/41716aab8440e3ac1aa8e55e6e293400bdcc676b.png" alt="image-20250715171624480"></p><h2 id="3-3组装数据"><a href="#3-3组装数据" class="headerlink" title="3.3组装数据"></a>3.3组装数据</h2><p>此处获取班次信息（标记0点）的作用是，跨天班次可能会存在休息时间跨天的情况，也可能跨天时是排班的情况，需要将0点前后的考勤状态拆分。</p><p>例如：跨天班次B(19:00-5:00)，休息时间为23:00–1:00,3:00–4:00</p><p>拆分0点后，班次结果为：   [2025-07-16  19:00,2025-07-16 23:00]【排班】</p><p>​[2025-07-16  23:00,2025-07-16 0:00] 【休息】</p><p>​[2025-07-17  0:00,2025-07-17 1:00] 【休息】</p><p>​[2025-07-17  1:00,2025-07-17 3:00] 【排班】</p><p>​[2025-07-17  3:00,2025-07-17 4:00] 【休息】</p><p>​[2025-07-17  4:00,2025-07-17 5:00] 【排班】</p><p>后续的考勤拆分是以这个拆分了0点后的班次作为循环条件，与打卡、请假、销假、出差等数据进行比较。<img src="https://i0.hdslb.com/bfs/openplatform/9287b759e47205192f431f45ef7e1284d893a0fd.png" alt="image-20250715171644104"></p><h2 id="3-4数据拆分计算"><a href="#3-4数据拆分计算" class="headerlink" title="3.4数据拆分计算"></a>3.4数据拆分计算</h2><h3 id="考勤核算流程图"><a href="#考勤核算流程图" class="headerlink" title="考勤核算流程图"></a>考勤核算流程图</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/1250b18924e17d13981b40a42ac836ea5c7ec625.png" alt="image-20250715171705033"></p><h3 id="考勤核算规则"><a href="#考勤核算规则" class="headerlink" title="考勤核算规则"></a>考勤核算规则</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/712f8d78d39fd934dee9bb7225f3ab269d7f88f1.png" alt="image-20250715172024559"></p><p><img src="https://i0.hdslb.com/bfs/openplatform/dcf709c964d1d3bc88900189570ffdd7c6100be6.png" alt="image-20250715172037235"></p><h3 id="考勤状态"><a href="#考勤状态" class="headerlink" title="考勤状态"></a>考勤状态</h3><p><code>休息</code>、<code>请假</code>、<code>出差</code>、<code>正常出勤</code>、<code>早到</code>、<code>迟到</code>、<code>早退</code>、<code>延迟下班</code>、<code>旷工</code>、<code>排班</code>、<code>弹性排班</code></p><p><strong>三、数据处理（考勤计算前）</strong><br>1、数据准备：所有数据需分段存储至GtdAttendanceResult对象中，并标识出该段目前的考勤状态<br>例：班次为9:00-18:00，休息时间为12:00-14:00<br>分段存储后：9:00-12:00（排班），12:00-14:00（休息），14:00-18:00（排班）</p><h3 id="考勤计算"><a href="#考勤计算" class="headerlink" title="考勤计算"></a>考勤计算</h3><p><strong>1、初次比较</strong><br>1.1、以班次作为基础数据，打卡、请假、销假、出差等数据作为比较数据</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c20c5e47e668d47e7a3bbfe9a2f2caa8c5cc3286.png" alt="image-20250715172448644"></p><p>1.2、根据考勤核算规则优先级，将比较数据逐一与基础数据进行比对，不重合时间段保留当前考勤状态，重合时间段按照优先级比对出两段考勤状态<br>1.3、为了提升比对效率，若当前比较数据比对完毕，则终止循环，进入下一次比较数据的循环<br><img src="https://i0.hdslb.com/bfs/openplatform/fffc12387eeedafe635dc4aba6a7841bfdf57ff9.png" alt="image-20250715172416478"></p><p><strong>2、二次比较</strong><br>2.1、二次比较确定考勤异常最终状态，例：初次比较得出迟到、早退，需要与系统配置的时长进行比对，确定是否为旷工</p><p><strong>3、弹性班次注意事项</strong><br>3.1、需先计算员工应下班时间（根据上班打卡时间和上班总时长计算）<br>3.2、班次时间需这样拆分 -&gt; 最早到岗时间,最晚到岗时间 ; 最晚到岗时间,实际下班时间 ; 实际下班时间,最晚下班时间</p><p><strong>4、多段班注意事项</strong><br>4.1、多段班需要逐段班次进行比较</p><p><strong>五、考勤结果、明细存储</strong><br>1、保存考勤明细存在转换天数精度丢失问题<br>现采用减法计算：1 - 请假天数 - 实际出勤天数(包含出差天数) &#x3D; 旷工天数<br>特殊处理：若考勤结果无旷工时间段，且减法后旷工天数 &gt; 0 ,则将旷工天数补入实际出勤天数</p><h1 id="4考勤处理流程"><a href="#4考勤处理流程" class="headerlink" title="4考勤处理流程"></a>4考勤处理流程</h1><p>考勤一般都是与OA流程挂钩的，员工的请假、加班、出差、销假等操作在OA系统发起，对接到UHR系统，对接后考勤处理流程如下。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/654e3789730d7e6c9b95b2a3dac3ac6515ff602d.png" alt="image-20250715173137044"></p><h2 id="4-1拆分请假-出差数据"><a href="#4-1拆分请假-出差数据" class="headerlink" title="4.1拆分请假&#x2F;出差数据"></a>4.1拆分请假&#x2F;出差数据</h2><p>员工提交整段请假记录时，后台需要按照员工班次进行拆分，存储到数据库时请假结果按天存储，销假是也要删除对应拆分结果。</p><p>而且对于员工排班发生变更前的请假&#x2F;出差记录，计算考勤前需要重新拆分。</p><p>具体拆分逻辑如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/7c1af1dfc15a95bc298c721c4151fc215107f6ad.png" alt="image-20250715173311178"></p><h1 id="5考勤日历"><a href="#5考勤日历" class="headerlink" title="5考勤日历"></a>5考勤日历</h1><h2 id="5-1相关表设计"><a href="#5-1相关表设计" class="headerlink" title="5.1相关表设计"></a>5.1相关表设计</h2><p>其中 gtd_emp_calendar 因数据量过大，不再使用。</p><p>gtd_work_calendar_details工作日历明细表，精确到天，每天绑定一个班次。</p><p>sys_organization为组织表，emp_org_allocation为员工的组织分配表（员工有异动时添加一条数据）。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/21e03b05f82fb068d2c9e64eb9c4bd72080e5905.png" alt="image-20250716142327119"></p><ul><li>gtd_holiday_manage：节假日管理实体，包含节假日名称、代码、开始日期、结束日期、法定节假日、调休日期等信息。</li><li>gtd_work_calendar_details：工作日历明细表，记录每个工作日历的具体日期安排，包括班次、日期类型等。</li><li>gtd_holiday_calendar_history：工作日历和节假日关联历史表，用于记录工作日历应用节假日前的原始数据，便于后续恢复或修改。</li></ul><h2 id="5-2相关业务逻辑"><a href="#5-2相关业务逻辑" class="headerlink" title="5.2相关业务逻辑"></a>5.2相关业务逻辑</h2><h3 id="工作日历按周期顺延"><a href="#工作日历按周期顺延" class="headerlink" title="工作日历按周期顺延"></a>工作日历按周期顺延</h3><p><img src="https://i0.hdslb.com/bfs/openplatform/f968b9835cb84efae8ed4b508cad7112780e82bc.png" alt="image-20250716193716828"></p><h3 id="节假日应用工作日历"><a href="#节假日应用工作日历" class="headerlink" title="节假日应用工作日历"></a>节假日应用工作日历</h3><p>节假日管理信息配置中，支持编辑法定节假日日期、关联调休日期、法定节假日（非3倍计薪）</p><p><img src="https://i0.hdslb.com/bfs/openplatform/230b79f95edb3a2fee6717963695671162af55c8.png" alt="image-20250717102302183"></p><p>一个节假日支持应用到多个工作日历上</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a863988dcccef29b887e5a622622d3f6ed9ddd30.png" alt="image-20250717103717525"></p><p>节假日应用到多个工作日历的业务流程图如下：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2693723abd13324a138173e8113fe4d5429a698d.png" alt="image-20250717111533223"></p><p>整个节假日历史关联表的业务逻辑可以总结为：</p><ol><li><p>历史记录管理 ：</p><ul><li>保存原始工作日历数据（ holidayId 为 null ）</li><li>保存节假日应用后的工作日历数据（ holidayId 为节假日ID）</li><li>当修改节假日设置时，先恢复原始数据，再应用新设置</li></ul></li><li><p>节假日应用 ：</p><ul><li>将节假日期间的工作日设置为休息日（ classId 为 null ）</li><li>根据节假日类型设置不同的 holidayType （法定节假日或普通节假日）</li></ul></li><li><p>调休处理 ：</p><ul><li>将调休日设置为工作日（ holidayType 为普通日期）</li><li>为调休日分配合适的班次（通过查找最近的班次）</li></ul></li><li><p>数据一致性 ：</p><ul><li>通过事务保证工作日历明细和历史记录的一致性</li><li>通过批量操作提高性能</li></ul></li></ol><h3 id="获取员工班次步骤"><a href="#获取员工班次步骤" class="headerlink" title="获取员工班次步骤"></a>获取员工班次步骤</h3><p><strong>员工班次有两种来源：</strong><br>①.直接导入员工班次到员工班次明细表；<br>②.通过部门绑定工作日历或直接给员工绑定工作日历；<br>两者都存在时①优先级高于②</p><p><img src="https://i0.hdslb.com/bfs/openplatform/739fc29e74f303da58a471285da004af7e9ca6dd.png" alt="image-20250716143401092"></p><h3 id="员工工作日历变更"><a href="#员工工作日历变更" class="headerlink" title="员工工作日历变更"></a>员工工作日历变更</h3><h4 id="组织绑定工作日历"><a href="#组织绑定工作日历" class="headerlink" title="组织绑定工作日历"></a>组织绑定工作日历</h4><p><img src="https://i0.hdslb.com/bfs/openplatform/3c6a0d7a66d3aac073c529851903a18791b9f1e8.png" alt="image-20250716162159584"></p><h4 id="入职-异动刷新员工考勤日历逻辑"><a href="#入职-异动刷新员工考勤日历逻辑" class="headerlink" title="入职&#x2F;异动刷新员工考勤日历逻辑"></a>入职&#x2F;异动刷新员工考勤日历逻辑</h4><p><strong>组织与日历绑定关系</strong></p><ul><li>组织1 （2024-01-01 日历A），（2024-01-25 日历B）<br>组织1组 （2024-01-30 日历C），（2024-05-02 日历D）</li><li>组织2 （2024-01-01 日历E）<br>组织2组</li><li>组织3 （2024-01-01 日历F）<br>组织3组</li></ul><p><strong>员工异动流程</strong></p><p>在2024-01-01号入职组织2组<br>在2024-01-20号从组织2组异动至组织1组<br>在2024-05-01号从组织1组异动至组织3组</p><p>组织2组：[2024-01-01,2024-01-20]<br>组织1组：[2024-01-20,2024-05-01] 异动时间段<br>组织3组：[2024-05-01,9999-12-31]<br>异动时间段需生成的考勤日历：20号，25号，30号共三条</p><p><strong>获取组织1组及上级所有考勤日历</strong></p><p>倒序排序（2024-05-02，2024-01-30，2024-01-25，2024-01-01）</p><p>如此以下遍历员工所在的各个组织比较…</p><p><img src="https://i0.hdslb.com/bfs/openplatform/477a1f0b5e395c27f8a9bdbf5ecfa602308faccb.png" alt="image-20250716151015869"></p><h1 id="6生成员工补卡余额"><a href="#6生成员工补卡余额" class="headerlink" title="6生成员工补卡余额"></a>6生成员工补卡余额</h1><p>每个月会给员工生成补卡余额，定时任务会每天更新该员工的补卡余额。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b1c9ddc3793b9a9a27a9e0060dc7f342f98f1fb0.png" alt="image-20250716164814345"></p><h1 id="7加班审核"><a href="#7加班审核" class="headerlink" title="7加班审核"></a>7加班审核</h1><p><img src="https://i0.hdslb.com/bfs/openplatform/8c9c198048126f68657611239069028322fdb0d1.png" alt="image-20250716175428067"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1自动生成年假&quot;&gt;&lt;a href=&quot;#1自动生成年假&quot; class=&quot;headerlink&quot; title=&quot;1自动生成年假&quot;&gt;&lt;/a&gt;1自动生成年假&lt;/h1&gt;&lt;h2 id=&quot;1-1基本业务场景&quot;&gt;&lt;a href=&quot;#1-1基本业务场景&quot; class=&quot;header</summary>
      
    
    
    
    
    <category term="业务" scheme="https://palette-k.github.io/tags/%E4%B8%9A%E5%8A%A1/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes</title>
    <link href="https://palette-k.github.io/2025/07/09/kubernetes/"/>
    <id>https://palette-k.github.io/2025/07/09/kubernetes/</id>
    <published>2025-07-09T08:43:45.000Z</published>
    <updated>2025-08-28T03:32:00.643Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>虽然容器技术开启了云原生时代，但它也只走出了一小步，再继续前进就无能为力了，因为这已经不再是隔离一两个进程的普通问题，而是要隔离数不清的进程，还有它们之间互相通信、互相协作的超级问题，困难程度可以说是指数级别的上升。</p><p>这些容器之上的管理、调度工作，就是这些年最流行的词汇：“<strong>容器编排</strong>”（Container Orchestration）。</p><p>面对单机上的几个容器，“人肉”编排调度还可以应付，但如果规模上到几百台服务器、成千上万的容器，处理它们之间的复杂联系就必须要依靠计算机了，而目前计算机用来调度管理的“事实标准”，就是：Kubernetes。</p><p>Kubernetes就是一个<strong>生产级别的容器编排平台和集群管理系统</strong>，不仅能够创建、调度容器，还能够监控、管理服务器。</p><h1 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h1><p><img src="https://i0.hdslb.com/bfs/openplatform/79bb57777a6a9f4496d72b0b436a15e1039038c9.png" alt="image-20250709171226550"></p><p>Kubernetes采用了现今流行的“<strong>控制面&#x2F;数据面</strong>”（Control Plane &#x2F; Data Plane）架构，集群里的计算机被称为“<strong>节点</strong>”（Node），可以是实机也可以是虚机，少量的节点用作控制面来执行集群的管理维护工作，其他的大部分节点都被划归数据面，用来跑业务应用。</p><p>控制面的节点在Kubernetes里叫做<strong>Master Node</strong>，一般简称为<strong>Master</strong>，它是整个集群里最重要的部分，可以说是Kubernetes的大脑和心脏。</p><p>数据面的节点叫做<strong>Worker Node</strong>，一般就简称为<strong>Worker</strong>或者<strong>Node</strong>，相当于Kubernetes的手和脚，在Master的指挥下干活。</p><p>Node的数量非常多，构成了一个资源池，Kubernetes就在这个池里分配资源，调度应用。因为资源被“池化”了，所以管理也就变得比较简单，可以在集群中任意添加或者删除节点。</p><p>在这张架构图里，我们还可以看到有一个kubectl，它就是Kubernetes的客户端工具，用来操作Kubernetes，但它位于集群之外，理论上不属于集群。</p><p>你可以使用命令 <code>kubectl get node</code> 来查看Kubernetes的节点状态：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/openplatform/dfd4a2527bef0983fad179df40bc3b305de1a6e5.png" alt="image-20250709171414500"></p><h2 id="Master-Node"><a href="#Master-Node" class="headerlink" title="Master Node"></a>Master Node</h2><p>Master里有4个组件，分别是<strong>apiserver</strong>、<strong>etcd</strong>、<strong>scheduler</strong>、<strong>controller-manager</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2d59b019a9e9faeaa05cbba7953a42212b505735.png" alt="image-20250710101927564"></p><p>apiserver是Master节点——同时也是整个Kubernetes系统的唯一入口，它对外公开了一系列的RESTful API，并且加上了验证、授权等功能，所有其他组件都只能和它直接通信，可以说是Kubernetes里的联络员。</p><p>etcd是一个高可用的分布式Key-Value数据库，用来持久化存储系统里的各种资源对象和状态，相当于Kubernetes里的配置管理员。注意它只与apiserver有直接联系，也就是说任何其他组件想要读写etcd里的数据都必须经过apiserver。</p><p>scheduler负责容器的编排工作，检查节点的资源状态，把Pod调度到最适合的节点上运行，相当于部署人员。因为节点状态和Pod信息都存储在etcd里，所以scheduler必须通过apiserver才能获得。</p><p>controller-manager负责维护容器和节点等资源的状态，实现故障检测、服务迁移、应用伸缩等功能，相当于监控运维人员。同样地，它也必须通过apiserver获得存储在etcd里的信息，才能够实现对资源的各种操作。</p><p>这4个组件也都被容器化了，运行在集群的Pod里，我们可以用kubectl来查看它们的状态，使用命令：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod <span class="literal">-n</span> kube<span class="literal">-system</span></span><br></pre></td></tr></table></figure><h2 id="Worker-Node"><a href="#Worker-Node" class="headerlink" title="Worker Node"></a>Worker Node</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/2d76640bd8013f0ed5517cf78e154cdfb0646e75.png" alt="image-20250710102645156"></p><p>kubelet是Node的代理，负责管理Node相关的绝大部分操作，Node上只有它能够与apiserver通信，实现状态报告、命令下发、启停容器等功能，相当于是Node上的一个“小管家”。</p><p>kube-proxy的作用有点特别，它是Node的网络代理，只负责管理容器的网络通信，简单来说就是为Pod转发TCP&#x2F;UDP数据包，相当于是专职的“小邮差”。</p><p>第三个组件container-runtime我们就比较熟悉了，它是容器和镜像的实际使用者，在kubelet的指挥下创建容器，管理Pod的生命周期，是真正干活的“苦力”。</p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p>现在，我们再把Node里的组件和Master里的组件放在一起来看，就能够明白Kubernetes的大致工作流程了：</p><ul><li>每个Node上的kubelet会定期向apiserver上报节点状态，apiserver再存到etcd里。</li><li>每个Node上的kube-proxy实现了TCP&#x2F;UDP反向代理，让容器对外提供稳定的服务。</li><li>scheduler通过apiserver得到当前的节点状态，调度Pod，然后apiserver下发命令给某个Node的kubelet，kubelet调用container-runtime启动容器。</li><li>controller-manager也通过apiserver得到实时的节点状态，监控可能的异常情况，再使用相应的手段去调节恢复。</li></ul><h1 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h1><p>Docker Desktop 自带了 Kubernetes 支持，可以通过 Docker Desktop 的应用程序界面开启 Kubernetes 集群。</p><p>而且Docker Desktop 启动 Kubernetes 后，会自动配置 kubectl 命令行工具，便于我们日常学习，减少安装成本。</p><h2 id="Kuboard"><a href="#Kuboard" class="headerlink" title="Kuboard"></a>Kuboard</h2><p>Kuboard 是一款免费的 Kubernetes 管理工具，旨在帮助用户快速在 Kubernetes 上落地微服务。它提供了丰富的功能，包括但不限于 Kubernetes 基本管理功能、节点管理、名称空间管理、存储类&#x2F;存储卷管理、控制器管理、Service&#x2F;Ingress 管理、ConfigMap&#x2F;Secret 管理、CustomerResourceDefinition 管理、问题诊断、容器日志及终端、认证与授权、CI&#x2F;CD集成等。</p><p>拉取镜像：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull eipwork/kuboard:v3</span><br></pre></td></tr></table></figure><p>运行命令(挂载的路径需要更改)：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run <span class="literal">-d</span> <span class="literal">--name</span>=kuboard <span class="literal">-p</span> <span class="number">8089</span>:<span class="number">80</span>/tcp <span class="literal">-p</span> <span class="number">10081</span>:<span class="number">10081</span>/tcp <span class="literal">-e</span> KUBOARD_ENDPOINT=<span class="string">&quot;http://192.168.3.220:8089&quot;</span> <span class="literal">-e</span> KUBOARD_AGENT_SERVER_TCP_PORT=<span class="string">&quot;10081&quot;</span> <span class="literal">-v</span> F:\docker\wsl\DockerDesktopWSL\mount\k8s eipwork/kuboard:v3</span><br></pre></td></tr></table></figure><p>访问 Kuboard：</p><p>地址： <a href="http://127.0.0.1:8089/">http://127.0.0.1:8089/</a></p><p>账号：admin</p><p>密码：Kuboard123</p><p>登录进去后，<strong>添加 Kubernetes 集群到 Kuboard</strong></p><p>![image-20250709172637479](<a href="https://i0.hdslb.com/bfs/openplatform/60c473e12d77b12fd152e25a23d26125f3574ac3.png">https://i0.hdslb.com/bfs/openplatform/60c473e12d77b12fd152e25a23d26125f3574ac3.png</a></p><p><img src="https://i0.hdslb.com/bfs/openplatform/69a5b05ea94f6a685f67b5b03b86d009957df83c.png" alt="image-20250709175827891"></p><p>按照以下步骤执行：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/7186fb0f2c24d373756ddafcc9ee8150aa7aa6a5.png" alt="image-20250709180129062"></p><p><strong>导入Kuboard</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> curl.exe <span class="literal">-k</span> <span class="string">&#x27;http://192.168.3.220:8089/kuboard-api/cluster/Ashley-k8s/kind/KubernetesCluster/Ashley-k8s/resource/installAgentToKubernetes?token=wfzV3KBKl48kGMr6lO6CQ2lIrDGdNj5j&#x27;</span> <span class="literal">-o</span> kuboard<span class="literal">-agent</span>.yaml</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line"><span class="number">100</span>  <span class="number">5611</span>    <span class="number">0</span>  <span class="number">5611</span>    <span class="number">0</span>     <span class="number">0</span>   <span class="number">314</span>k      <span class="number">0</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span> <span class="literal">--</span>:<span class="literal">--</span>:<span class="literal">--</span>  <span class="number">322</span>k</span><br></pre></td></tr></table></figure><p>导入之前先要执行以下两个命令</p><p>获取当前 Kubernetes 集群中的所有 <code>Pod</code></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl get pods</span><br><span class="line">No resources found <span class="keyword">in</span> default namespace.</span><br></pre></td></tr></table></figure><p>显示当前 Kubernetes 配置中所有上下文</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl config <span class="built_in">get-contexts</span></span><br><span class="line">CURRENT   NAME             CLUSTER          AUTHINFO         NAMESPACE</span><br><span class="line">*         docker<span class="literal">-desktop</span>   docker<span class="literal">-desktop</span>   docker<span class="literal">-desktop</span></span><br></pre></td></tr></table></figure><p>切换 <code>kubectl</code> 操作的上下文到名为 <code>docker-desktop</code> 的上下文</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl config <span class="built_in">use-context</span> docker<span class="literal">-desktop</span></span><br><span class="line">Switched to context <span class="string">&quot;docker-desktop&quot;</span>.</span><br></pre></td></tr></table></figure><p>获取（列出）当前 Kubernetes 集群中的所有节点（Node）的信息</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl get nodes</span><br><span class="line">NAME             STATUS   ROLES           AGE   VERSION</span><br><span class="line">docker<span class="literal">-desktop</span>   Ready    control<span class="literal">-plane</span>   <span class="number">26</span>m   v1.<span class="number">28.2</span></span><br></pre></td></tr></table></figure><p>将本地文件 <code>.\kuboard-agent.yaml</code> 中定义的 <code>Kubernetes</code> 资源对象应用到 <code>Kubernetes</code> 集群中。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">PS</span> C:\Users\jr10003509&gt; kubectl apply <span class="operator">-f</span> ./kuboard<span class="literal">-agent</span>.yaml</span><br><span class="line">namespace/kuboard unchanged</span><br><span class="line">serviceaccount/kuboard<span class="literal">-admin</span> unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard<span class="literal">-admin-crb</span> unchanged</span><br><span class="line">serviceaccount/kuboard<span class="literal">-viewer</span> unchanged</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kuboard<span class="literal">-viewer-crb</span> unchanged</span><br><span class="line">deployment.apps/kuboard<span class="literal">-agent-ashley</span> created</span><br><span class="line">deployment.apps/kuboard<span class="literal">-agent-ashley-2</span> created</span><br></pre></td></tr></table></figure><p>导入成功！</p><p><img src="https://i0.hdslb.com/bfs/openplatform/70902d2bfdd82244b17079d484f06c07c6a5290f.png" alt="image-20250709180841125"></p><h1 id="API对象"><a href="#API对象" class="headerlink" title="API对象"></a>API对象</h1><h2 id="Pod"><a href="#Pod" class="headerlink" title="Pod"></a>Pod</h2><p>Pod是对容器的“打包”，里面的容器是一个整体，总是能够一起调度、一起运行，绝不会出现分离的情况，而且Pod属于Kubernetes，可以在不触碰下层容器的情况下任意定制修改。</p><p>Kubernetes让Pod去编排处理容器，然后把Pod作为应用调度部署的<strong>最小单位</strong>，Pod也因此成为了Kubernetes世界里的“原子”（当然这个“原子”内部是有结构的，不是铁板一块），基于Pod就可以构建出更多更复杂的业务形态了。</p><h2 id="Job-CronJob"><a href="#Job-CronJob" class="headerlink" title="Job&#x2F;CronJob"></a>Job&#x2F;CronJob</h2><p>Kubernetes里有两大类业务。一类是像Nginx这样长时间运行的“<strong>在线业务</strong>”，另一类是像busybox这样短时间运行的“<strong>离线业务</strong>”。</p><p>“在线业务”类型的应用有很多，比如Nginx、Node.js、MySQL、Redis等等，一旦运行起来基本上不会停，也就是永远在线。</p><p>而“离线业务”类型的应用也并不少见，它们一般不直接服务于外部用户，只对内部用户有意义，比如日志分析、数据建模、视频转码等等，虽然计算量很大，但只会运行一段时间。“离线业务”的特点是<strong>必定会退出</strong>，不会无期限地运行下去，所以它的调度策略也就与“在线业务”存在很大的不同，需要考虑运行超时、状态检查、失败重试、获取计算结果等管理事项。</p><p>而这些业务特性与容器管理没有必然的联系，如果由Pod来实现就会承担不必要的义务，违反了“单一职责”，所以我们应该把这部分功能分离到另外一个对象上实现，让这个对象去控制Pod的运行，完成附加的工作。</p><p>“离线业务”也可以分为两种。一种是“<strong>临时任务</strong>”，跑完就完事了，下次有需求了说一声再重新安排；另一种是“<strong>定时任务</strong>”，可以按时按点周期运行，不需要过多干预。</p><p>对应到Kubernetes里，“临时任务”就是API对象<strong>Job</strong>，“定时任务”就是API对象<strong>CronJob</strong>，使用这两个对象你就能够在Kubernetes里调度管理任意的离线业务了。</p><p>可以看到，Job对象里应用了组合模式，<code>template</code> 字段定义了一个“<strong>应用模板</strong>”，里面嵌入了一个Pod，这样Job就可以从这个模板来创建出Pod。而这个Pod因为受Job的管理控制，不直接和apiserver打交道，也就没必要重复apiVersion等“头字段”，只需要定义好关键的 <code>spec</code>，描述清楚容器相关的信息就可以了，可以说是一个“无头”的Pod对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c0824e862bf99bc953f78ffe2f66d9503bee7086.png" alt="image-20250710111135700"></p><p>而定时任务”的CronJob对象也很好理解了，使用schedule指定了执行周期，又组合了Job而生成的新对象。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b1bcabe3ca8354818e418913c673451e73d8a837.png" alt="image-20250710111413288"></p><p>CronJob使用定时规则控制Job，Job使用并发数量控制Pod，Pod再定义参数控制容器，容器再隔离控制进程，进程最终实现业务功能，层层递进的形式有点像设计模式里的Decorator（装饰模式），链条里的每个环节都各司其职，在Kubernetes的统一指挥下完成任务。</p><h2 id="Deployment：让应用永不宕机"><a href="#Deployment：让应用永不宕机" class="headerlink" title="Deployment：让应用永不宕机"></a>Deployment：让应用永不宕机</h2><p>在线业务远不是单纯启动一个Pod这么简单，还有多实例、高可用、版本更新等许多复杂的操作。比如最简单的多实例需求，为了提高系统的服务能力，应对突发的流量和压力，我们需要创建多个应用的副本，还要即时监控它们的状态。如果还是只使用Pod，那就会又走回手工管理的老路，没有利用好Kubernetes自动化运维的优势。</p><p>Deployment，就是用来管理Pod，实现在线业务应用的新API对象。</p><p> <code>replicas</code> 字段。它的含义比较简单明了，就是“副本数量”的意思，也就是说，指定要在Kubernetes集群里运行多少个Pod实例。</p><p>接下来Kubernetes还会持续地监控Pod的运行状态，万一有Pod发生意外消失了，数量不满足“期望状态”，它就会通过apiserver、scheduler等核心组件去选择新的节点，创建出新的Pod，直至数量与“期望状态”一致。</p><p> <code>selector</code>，它的作用是“筛选”出要被Deployment管理的Pod对象，下属字段“<strong>matchLabels</strong>”定义了Pod对象应该携带的label，它必须和“template”里Pod定义的“labels”完全相同，否则Deployment就会找不到要控制的Pod对象，apiserver也会告诉你YAML格式校验错误无法创建。</p><p>Kubernetes采用的是这种“贴标签”的方式，通过在API对象的“metadata”元信息里加各种标签（labels），我们就可以使用类似关系数据库里查询语句的方式，筛选出具有特定标识的那些对象。<strong>通过标签这种设计，Kubernetes就解除了Deployment和模板里Pod的强绑定，把组合关系变成了“弱引用”</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f50ba2a6e58009faefceefa1106ef497dc22df56.png" alt="image-20250710115117565"></p><p><strong>在Deployment部署成功之后，你还可以随时调整Pod的数量，实现所谓的“应用伸缩”</strong>。这项工作在Kubernetes出现之前对于运维来说是一件很困难的事情，而现在由于有了Deployment就变得轻而易举了。</p><h2 id="DaemonSet：节点的守护者"><a href="#DaemonSet：节点的守护者" class="headerlink" title="DaemonSet：节点的守护者"></a>DaemonSet：节点的守护者</h2><p>Deployment并不关心这些Pod会在集群的哪些节点上运行，<strong>在它看来，Pod的运行环境与功能是无关的，只要Pod的数量足够，应用程序应该会正常工作</strong>。</p><p>这个假设对于大多数业务来说是没问题的，比如Nginx、WordPress、MySQL，它们不需要知道集群、节点的细节信息，只要配置好环境变量和存储卷，在哪里“跑”都是一样的。</p><p>但是有一些业务比较特殊，它们不是完全独立于系统运行的，而是与主机存在“绑定”关系，必须要依附于节点才能产生价值，比如说：</p><ul><li>网络应用（如kube-proxy），必须每个节点都运行一个Pod，否则节点就无法加入Kubernetes网络。</li><li>监控应用（如Prometheus），必须每个节点都有一个Pod用来监控节点的状态，实时上报信息。</li><li>日志应用（如Fluentd），必须在每个节点上运行一个Pod，才能够搜集容器运行时产生的日志数据。</li><li>安全应用，同样的，每个节点都要有一个Pod来执行安全审计、入侵检查、漏洞扫描等工作。</li></ul><p>所以，Kubernetes就定义了新的API对象DaemonSet，它在形式上和Deployment类似，都是管理控制Pod，但管理调度策略却不同。DaemonSet的目标是在集群的每个节点上运行且仅运行一个Pod，就好像是为节点配上一只“看门狗”，忠实地“守护”着节点，这就是DaemonSet名字的由来。</p><p>DaemonSet仅仅是在Pod的部署调度策略上和Deployment不同，其他的都是相同的，某种程度上我们也可以把DaemonSet看做是Deployment的一个特例。</p><p>我还是把YAML描述文件画了一张图，好让你看清楚与Deployment的差异：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/ed917d93f0354d88671162e734856f1f935a6229.png" alt="image-20250710141911055"></p><h1 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h1><p>首先你要知道，应用程序有很多类别的配置信息，但从数据安全的角度来看可以分成两类：</p><ul><li>一类是明文配置，也就是不保密，可以任意查询修改，比如服务端口、运行参数、文件路径等等。</li><li>另一类则是机密配置，由于涉及敏感信息需要保密，不能随便查看，比如密码、密钥、证书等等。</li></ul><p>这两类配置信息本质上都是字符串，只是由于安全性的原因，在存放和使用方面有些差异，所以Kubernetes也就定义了两个API对象，<strong>ConfigMap</strong>用来保存明文配置，<strong>Secret</strong>用来保存秘密配置。</p><p>因为ConfigMap和Secret只是一些存储在etcd里的字符串，所以如果想要在运行时产生效果，就必须要以某种方式“<strong>注入</strong>”到Pod里，让应用去读取。在这方面的处理上Kubernetes和Docker是一样的，也是两种途径：<strong>环境变量</strong>和<strong>加载文件</strong>。</p><h2 id="环境变量注入"><a href="#环境变量注入" class="headerlink" title="环境变量注入"></a>环境变量注入</h2><p>从这张图你就应该能够比较清楚地看出Pod与ConfigMap、Secret的“松耦合”关系，它们不是直接嵌套包含，而是使用“KeyRef”字段间接引用对象，这样，同一段配置信息就可以在不同的对象之间共享。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8e60029d79e1da7e50de61ed9749eeefe1da454e.png" alt="image-20250710113004281"></p><h2 id="文件加载注入"><a href="#文件加载注入" class="headerlink" title="文件加载注入"></a>文件加载注入</h2><p>Kubernetes为Pod定义了一个“<strong>Volume</strong>”的概念，可以翻译成是“存储卷”。如果把Pod理解成是一个虚拟机，那么Volume就相当于是虚拟机里的磁盘。</p><p>我们可以为Pod“挂载（mount）”多个Volume，里面存放供Pod访问的数据，这种方式有点类似 <code>docker run -v</code>，虽然用法复杂了一些，但功能也相应强大一些。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b7f9270835ea7ba5452a9515c7f37d34a0c1735c.png" alt="image-20250710113256011"></p><p>挂载Volume的方式和环境变量又不太相同。环境变量是直接引用了ConfigMap&#x2F;Secret，而Volume又多加了一个环节，需要先用Volume引用ConfigMap&#x2F;Secret，然后在容器里挂载Volume。</p><p>这种方式的好处在于：以Volume的概念统一抽象了所有的存储，不仅现在支持ConfigMap&#x2F;Secret，以后还能够支持临时卷、持久卷、动态卷、快照卷等许多形式的存储，扩展性非常好。</p><p>因为这种形式上的差异，以Volume的方式来使用ConfigMap&#x2F;Secret，就和环境变量不太一样。环境变量用法简单，更适合存放简短的字符串，而Volume更适合存放大数据量的配置文件，在Pod里加载成文件后让应用直接读取使用。</p><h1 id="Service：微服务架构的应对之道"><a href="#Service：微服务架构的应对之道" class="headerlink" title="Service：微服务架构的应对之道"></a>Service：微服务架构的应对之道</h1><p>在Kubernetes集群里Pod的生命周期是比较“短暂”的，虽然Deployment和DaemonSet可以维持Pod总体数量的稳定，但在运行过程中，难免会有Pod销毁又重建，这就会导致Pod集合处于动态的变化之中。</p><p>这种“动态稳定”对于现在流行的微服务架构来说是非常致命的，试想一下，后台Pod的IP地址老是变来变去，客户端该怎么访问呢？如果不处理好这个问题，Deployment和DaemonSet把Pod管理得再完善也是没有价值的。</p><p>其实，这个问题也并不是什么难事，业内早就有解决方案来针对这样“不稳定”的后端服务，那就是“<strong>负载均衡</strong>”，典型的应用有LVS、Nginx等等。它们在前端与后端之间加入了一个“中间层”，屏蔽后端的变化，为前端提供一个稳定的服务。</p><p>但LVS、Nginx毕竟不是云原生技术，所以Kubernetes就按照这个思路，定义了新的API对象：<strong>Service</strong>。</p><p>Kubernetes会给Service分配一个静态IP地址，然后它再去自动管理、维护后面动态变化的Pod集合，当客户端访问Service，它就根据某种策略，把流量转发给后面的某个Pod。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/516cf8ccd1a88d24082699e5e3c0c5b499b40e49.png" alt="image-20250710145331433"></p><p><code>selector</code> 和Deployment&#x2F;DaemonSet里的作用是一样的，用来过滤出要代理的那些Pod。因为我们指定要代理Deployment，所以Kubernetes就为我们自动填上了ngx-dep的标签，会选择这个Deployment对象部署的所有Pod。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e9e6e6f453efca2e173de96475441c69b13fb2ff.png" alt="image-20250710145555926"></p><p>Pod被Deployment对象管理，删除后会自动重建，而Service又会通过controller-manager实时监控Pod的变化情况，所以就会立即更新它代理的IP地址。</p><h2 id="namespace"><a href="#namespace" class="headerlink" title="namespace"></a>namespace</h2><p>Kubernetes有一个默认的名字空间，叫“<strong>default</strong>”，如果不显式指定，API对象都会在这个“default”名字空间里。而其他的名字空间都有各自的用途，比如“kube-system”就包含了apiserver、etcd等核心组件的Pod。</p><p>通常我们会使用namespce区分线上环境。</p><p>Service对象的域名完全形式是“<strong>对象.名字空间.svc.cluster.local</strong>”，但很多时候也可以省略后面的部分，直接写“<strong>对象.名字空间</strong>”甚至“<strong>对象名</strong>”就足够了，默认会使用对象所在的名字空间（比如这里就是default）。</p><p>我们不再关心Service对象的IP地址，只需要知道它的名字，就可以用DNS的方式去访问后端服务。</p><h1 id="Ingress：集群进出流量的总管"><a href="#Ingress：集群进出流量的总管" class="headerlink" title="Ingress：集群进出流量的总管"></a>Ingress：集群进出流量的总管</h1><p><strong>Ingress的意思是集群内外边界上的入口，它作为流量的总入口，统管集群的进出口数据</strong>，“扇入”“扇出”流量（也就是我们常说的“南北向”），让外部用户能够安全、顺畅、便捷地访问内部服务。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/fef1938ec77144482a19e396dc7dd2fd59235dcd.png" alt="image-20250710174017411"></p><p>再对比一下Service我们就能更透彻地理解Ingress。</p><p>Ingress可以说是在七层上另一种形式的Service，它同样会代理一些后端的Pod，也有一些路由规则来定义流量应该如何分配、转发，只不过这些规则都使用的是HTTP&#x2F;HTTPS协议。</p><p>你应该知道，Service本身是没有服务能力的，它只是一些iptables规则，<strong>真正配置、应用这些规则的实际上是节点里的kube-proxy组件</strong>。如果没有kube-proxy，Service定义得再完善也没有用。</p><p>同样的，Ingress也只是一些HTTP路由规则的集合，相当于一份静态的描述文件，真正要把这些规则在集群里实施运行，还需要有另外一个东西，这就是 <code>Ingress Controller</code>，它的作用就相当于Service的kube-proxy，能够读取、应用Ingress规则，处理、调度流量。</p><p>理来说，Kubernetes应该把Ingress Controller内置实现，作为基础设施的一部分，就像kube-proxy一样。</p><p><strong>不过Ingress Controller要做的事情太多，与上层业务联系太密切，所以Kubernetes把Ingress Controller的实现交给了社区</strong>，任何人都可以开发Ingress Controller，只要遵守Ingress规则就好。</p><p>这就造成了Ingress Controller“百花齐放”的盛况。</p><p>由于Ingress Controller把守了集群流量的关键入口，掌握了它就拥有了控制集群应用的“话语权”，所以众多公司纷纷入场，精心打造自己的Ingress Controller，意图在Kubernetes流量进出管理这个领域占有一席之地。</p><p>这些实现中最著名的，就是老牌的反向代理和负载均衡软件Nginx了。从Ingress Controller的描述上我们也可以看到，HTTP层面的流量管理、安全控制等功能其实就是经典的反向代理，而Nginx则是其中稳定性最好、性能最高的产品，所以它也理所当然成为了Kubernetes里应用得最广泛的Ingress Controller。</p><p>根据Docker Hub上的统计，<strong>Nginx公司的开发实现是下载量最多的Ingress Controller</strong>，所以我将以它为例，讲解Ingress和Ingress Controller的用法。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/c4aab8c9306f5ef219e3edc97d4fb0a1774d7ba6.png" alt="image-20250710174349077"></p><h2 id="IngressClass"><a href="#IngressClass" class="headerlink" title="IngressClass"></a>IngressClass</h2><p>那么到现在，有了Ingress和Ingress Controller，我们是不是就可以完美地管理集群的进出流量了呢？</p><p>最初Kubernetes也是这么想的，一个集群里有一个Ingress Controller，再给它配上许多不同的Ingress规则，应该就可以解决请求的路由和分发问题了。</p><p>但随着Ingress在实践中的大量应用，很多用户发现这种用法会带来一些问题，比如：</p><ul><li>由于某些原因，项目组需要引入不同的Ingress Controller，但Kubernetes不允许这样做；</li><li>Ingress规则太多，都交给一个Ingress Controller处理会让它不堪重负；</li><li>多个Ingress对象没有很好的逻辑分组方式，管理和维护成本很高；</li><li>集群里有不同的租户，他们对Ingress的需求差异很大甚至有冲突，无法部署在同一个Ingress Controller上。</li></ul><p>所以，Kubernetes就又提出了一个 <code>Ingress Class</code> 的概念，让它插在Ingress和Ingress Controller中间，作为流量规则和控制器的协调人，解除了Ingress和Ingress Controller的强绑定关系。</p><p>现在，<strong>Kubernetes用户可以转向管理Ingress Class，用它来定义不同的业务逻辑分组，简化Ingress规则的复杂度</strong>。比如说，我们可以用Class A处理博客流量、Class B处理短视频流量、Class C处理购物流量。</p><p>有了Ingress Controller，这些API对象的关联就更复杂了，你可以用下面的这张图来看出它们是如何使用对象名字联系起来的：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/cb7dff89b0e7076adfc7a1e0b13c1ec3d535cd91.png" alt="image-20250710174938720"></p><h1 id="PersistentVolume：数据持久化"><a href="#PersistentVolume：数据持久化" class="headerlink" title="PersistentVolume：数据持久化"></a>PersistentVolume：数据持久化</h1><p>前面说到，pod是kubernetes中运行的最小单位，但是其中存在一个很严重的问题：Pod没有持久化功能，因为Pod里的容器是由镜像产生的，而镜像文件本身是只读的，进程要读写磁盘只能用一个临时的存储空间，一旦Pod销毁，临时存储也就会立即回收释放，数据也就丢失了。</p><p>为了保证即使Pod销毁后重建数据依然存在，我们就需要找出一个解决方案，让Pod用上真正的“虚拟盘”。Kubernetes延伸出了<strong>PersistentVolume</strong>对象，它专门用来表示持久存储设备。<strong>作为存储的抽象，PV实际上就是一些存储设备、文件系统</strong>，比如Ceph、GlusterFS、NFS，甚至是本地磁盘，管理它们已经超出了Kubernetes的能力范围，所以，一般会由系统管理员单独维护，然后再在Kubernetes里创建对应的PV。</p><p>要注意的是，PV属于集群的系统资源，是和Node平级的一种对象，Pod对它没有管理权，只有使用权。</p><h2 id="PersistentVolumeClaim"><a href="#PersistentVolumeClaim" class="headerlink" title="PersistentVolumeClaim"></a>PersistentVolumeClaim</h2><p>PersistentVolumeClaim，简称PVC，从名字上看比较好理解，就是用来向Kubernetes申请存储资源的。PVC是给Pod使用的对象，它相当于是Pod的代理，代表Pod向系统申请PV。一旦资源申请成功，Kubernetes就会把PV和PVC关联在一起，这个动作叫做“<strong>绑定</strong>”（bind）。</p><p>但是，系统里的存储资源非常多，如果要PVC去直接遍历查找合适的PV也很麻烦，所以就要用到StorageClass。</p><h2 id="StorageClass"><a href="#StorageClass" class="headerlink" title="StorageClass"></a>StorageClass</h2><p>StorageClass抽象了特定类型的存储系统（比如Ceph、NFS），在PVC和PV之间充当“协调人”的角色，帮助PVC找到合适的PV。也就是说它可以简化Pod挂载“虚拟盘”的过程，让Pod看不到PV的实现细节。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/cf9a383122edf826ccd7ece51440ae077ecab02e.png" alt="image-20250711153617343"></p><h1 id="StatefulSet：管理有状态的应用"><a href="#StatefulSet：管理有状态的应用" class="headerlink" title="StatefulSet：管理有状态的应用"></a>StatefulSet：管理有状态的应用</h1><p>用Deployment来保证高可用，用PersistentVolume来存储数据，确实可以部分达到管理“有状态应用”的目的。但“状态”不仅仅是数据持久化，在集群化、分布式的场景里，还有多实例的依赖关系、启动顺序和网络标识等问题需要解决，而这些问题恰恰是Deployment力所不及的。</p><p>因为只使用Deployment，多个实例之间是无关的，启动的顺序不固定，Pod的名字、IP地址、域名也都是完全随机的，这正是“无状态应用”的特点。</p><p>但对于“有状态应用”，多个实例之间可能存在依赖关系，比如master&#x2F;slave、active&#x2F;passive，需要依次启动才能保证应用正常运行，外界的客户端也可能要使用固定的网络标识来访问实例，而且这些信息还必须要保证在Pod重启后不变。</p><p>所以，Kubernetes就在Deployment的基础之上定义了一个新的API对象，名字也很好理解，就叫StatefulSet，专门用来管理有状态的应用。</p><p>前面提到，Service自己会有一个域名，格式是“<strong>对象名.名字空间</strong>”，每个Pod也会有一个域名，形式是“<strong>IP地址.名字空间</strong>”。但因为IP地址不稳定，所以Pod的域名并不实用，一般我们会使用稳定的Service域名。</p><p>当我们把Service对象应用于StatefulSet的时候，情况就不一样了。</p><p>Service发现这些Pod不是一般的应用，而是有状态应用，需要有稳定的网络标识，所以就会为Pod再多创建出一个新的域名，格式是“<strong>Pod名.服务名.名字空间.svc.cluster.local</strong>”。当然，这个域名也可以简写成“<strong>Pod名.服务名</strong>”。</p><p>显然，在StatefulSet里的这两个Pod都有了各自的域名，也就是稳定的网络标识。那么接下来，外部的客户端只要知道了StatefulSet对象，就可以用固定的编号去访问某个具体的实例了，虽然Pod的IP地址可能会变，但这个有编号的域名由Service对象维护，是稳定不变的。</p><h2 id="StatefulSet的数据持久化"><a href="#StatefulSet的数据持久化" class="headerlink" title="StatefulSet的数据持久化"></a>StatefulSet的数据持久化</h2><p>现在StatefulSet已经有了固定的名字、启动顺序和网络标识，只要再给它加上数据持久化功能，我们就可以实现对“有状态应用”的管理了。</p><p>不过，为了强调持久化存储与StatefulSet的一对一绑定关系，Kubernetes为StatefulSet专门定义了一个字段“<strong>volumeClaimTemplates</strong>”，直接把PVC定义嵌入StatefulSet的YAML文件里。这样能保证创建StatefulSet的同时，就会为每个Pod自动创建PVC，让StatefulSet的可用性更高。</p><h1 id="滚动更新：平滑的应用升降级"><a href="#滚动更新：平滑的应用升降级" class="headerlink" title="滚动更新：平滑的应用升降级"></a>滚动更新：平滑的应用升降级</h1><h2 id="应用升级"><a href="#应用升级" class="headerlink" title="应用升级"></a>应用升级</h2><p>在Kubernetes里，版本更新使用的不是API对象，而是两个命令：<code>kubectl apply</code> 和 <code>kubectl rollout</code>，当然它们也要搭配部署应用所需要的Deployment、DaemonSet等YAML文件。</p><p>Kubernetes里应用都是以Pod的形式运行的，而Pod通常又会被Deployment等对象来管理，<strong>所以应用的“版本更新”实际上更新的是整个Pod</strong>。</p><p>Pod是由YAML描述文件来确定的，更准确地说，是Deployment等对象里的字段 <code>template</code>。所以，<strong>在Kubernetes里应用的版本变化就是 <code>template</code> 里Pod的变化</strong>，哪怕 <code>template</code> 里只变动了一个字段，那也会形成一个新的版本，也算是版本变化。</p><p>Kubernetes不是把旧Pod全部销毁再一次性创建出新Pod，而是在逐个地创建新Pod，同时也在销毁旧Pod，保证系统里始终有足够数量的Pod在运行，不会有“空窗期”中断服务。</p><p>新Pod数量增加的过程有点像是“滚雪球”，从零开始，越滚越大，所以这就是所谓的“<strong>滚动更新</strong>”（rolling update）。</p><p>其实“滚动更新”就是由Deployment控制的两个同步进行的“应用伸缩”操作，老版本缩容到0，同时新版本扩容到指定值，是一个“此消彼长”的过程。</p><h2 id="应用回滚"><a href="#应用回滚" class="headerlink" title="应用回滚"></a>应用回滚</h2><p>对于更新后出现的问题，Kubernetes为我们提供了“后悔药”，也就是更新历史，你可以查看之前的每次更新记录，并且回退到任何位置，和我们开发常用的Git等版本控制软件非常类似。</p><p>如果想要回退到上一个版本，就可以使用命令 <code>kubectl rollout undo</code>，也可以加上参数 <code>--to-revision</code> 回退到任意一个历史版本。<code>kubectl rollout undo</code> 的操作过程其实和 <code>kubectl apply</code> 是一样的，执行的仍然是“滚动更新”，只不过使用的是旧版本Pod模板，把新版本Pod数量收缩到0，同时把老版本Pod扩展到指定值。</p><h1 id="应用保障：如何让Pod运行得更健康？"><a href="#应用保障：如何让Pod运行得更健康？" class="headerlink" title="应用保障：如何让Pod运行得更健康？"></a>应用保障：如何让Pod运行得更健康？</h1><h2 id="容器资源配额"><a href="#容器资源配额" class="headerlink" title="容器资源配额"></a>容器资源配额</h2><p>创建容器有三大隔离技术：namespace、cgroup、chroot。其中的namespace实现了独立的进程空间，cgroup的作用是管控CPU、内存，保证容器不会无节制地占用基础资源，进而影响到系统里的其他应用，chroot实现了独立的文件系统。</p><p>与PersistentVolumeClaim用法有些类似，就是容器需要先提出一个“书面申请”，Kubernetes再依据这个“申请”决定资源是否分配和如何分配。使用 <code>resources</code> 字段加上资源配额之后，Pod在Kubernetes里的运行就有了初步保障，Kubernetes会监控Pod的资源使用情况，让它既不会“饿死”也不会“撑死”。</p><p>Kubernetes会根据每个Pod声明的需求，像搭积木或者玩俄罗斯方块一样，把节点尽量“塞满”，充分利用每个节点的资源，让集群的效益最大化。</p><h2 id="容器状态探针"><a href="#容器状态探针" class="headerlink" title="容器状态探针"></a>容器状态探针</h2><p>一个程序即使正常启动了，它也有可能因为某些原因无法对外提供服务。其中最常见的情况就是运行时发生“死锁”或者“死循环”的故障，这个时候从外部来看进程一切都是正常的，但内部已经是一团糟了。</p><p>Kubernetes为检查应用状态定义了三种探针，它们分别对应容器不同的状态：</p><ul><li><strong>Startup</strong>，启动探针，用来检查应用是否已经启动成功，适合那些有大量初始化工作要做，启动很慢的应用。</li><li><strong>Liveness</strong>，存活探针，用来检查应用是否正常运行，是否存在死锁、死循环。</li><li><strong>Readiness</strong>，就绪探针，用来检查应用是否可以接收流量，是否能够对外提供服务。</li></ul><p>你需要注意这三种探针是递进的关系：应用程序先启动，加载完配置文件等基本的初始化数据就进入了Startup状态，之后如果没有什么异常就是Liveness存活状态，但可能有一些准备工作没有完成，还不一定能对外提供服务，只有到最后的Readiness状态才是一个容器最健康可用的状态。</p><p>那Kubernetes具体是如何使用状态和探针来管理容器的呢？</p><p>如果一个Pod里的容器配置了探针，<strong>Kubernetes在启动容器后就会不断地调用探针来检查容器的状态</strong>：</p><ul><li>如果Startup探针失败，Kubernetes会认为容器没有正常启动，就会尝试反复重启，当然其后面的Liveness探针和Readiness探针也不会启动。</li><li>如果Liveness探针失败，Kubernetes就会认为容器发生了异常，也会重启容器。</li><li>如果Readiness探针失败，Kubernetes会认为容器虽然在运行，但内部有错误，不能正常提供服务，就会把容器从Service对象的负载均衡集合中排除，不会给它分配流量。</li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/76404447854f331194c43631155b944c36c2d4e7.png" alt="image-20250711172041991"></p><h1 id="集群管理：如何用名字空间分隔系统资源？"><a href="#集群管理：如何用名字空间分隔系统资源？" class="headerlink" title="集群管理：如何用名字空间分隔系统资源？"></a>集群管理：如何用名字空间分隔系统资源？</h1><p>Kubernetes的名字空间并不是一个实体对象，只是一个逻辑上的概念。它可以把集群切分成一个个彼此独立的区域，然后我们把对象放到这些区域里，就实现了类似容器技术里namespace的隔离效果，应用只能在自己的名字空间里分配资源和运行，不会干扰到其他名字空间里的应用。</p><h2 id="资源配额"><a href="#资源配额" class="headerlink" title="资源配额"></a>资源配额</h2><p>有了名字空间，我们就可以像管理容器一样，给名字空间设定配额，把整个集群的计算资源分割成不同的大小，按需分配给团队或项目使用。</p><p>不过集群和单机不一样，除了限制最基本的CPU和内存，还必须限制各种对象的数量，否则对象之间也会互相挤占资源。</p><h2 id="默认资源配额"><a href="#默认资源配额" class="headerlink" title="默认资源配额"></a>默认资源配额</h2><p>学到这里估计你也发现了，在名字空间加上了资源配额限制之后，它会有一个合理但比较“烦人”的约束：要求所有在里面运行的Pod都必须用字段 <code>resources</code> 声明资源需求，否则就无法创建。</p><p>Kubernetes这样做的原因也很好理解，如果Pod里没有 <code>resources</code> 字段，就可以无限制地使用CPU和内存，这显然与名字空间的资源配额相冲突。<strong>为了保证名字空间的资源总量可管可控，Kubernetes就只能拒绝创建这样的Pod了。</strong></p><p>那么能不能让Kubernetes自动为Pod加上资源限制呢？也就是说给个默认值，这样就可以省去反复设置配额的烦心事。</p><p>这个时候就要用到一个<strong>很小但很有用的辅助对象了—— <code>LimitRange</code>，简称是 <code>limits</code>，它能为API对象添加默认的资源配额限制</strong>。</p><h1 id="系统监控：如何使用Metrics-Server和Prometheus？"><a href="#系统监控：如何使用Metrics-Server和Prometheus？" class="headerlink" title="系统监控：如何使用Metrics Server和Prometheus？"></a>系统监控：如何使用Metrics Server和Prometheus？</h1><p>希望给集群也安装上“检查探针”，观察到集群的资源利用率和其他指标，让集群的整体运行状况对我们“透明可见”，这样才能更准确更方便地做好集群的运维工作。</p><h2 id="Metrics-Server"><a href="#Metrics-Server" class="headerlink" title="Metrics Server"></a>Metrics Server</h2><p>Metrics Server是一个专门用来收集Kubernetes核心资源指标（metrics）的工具，它定时从所有节点的kubelet里采集信息，但是对集群的整体性能影响极小，每个节点只大约会占用1m的CPU和2MB的内存，所以性价比非常高。</p><p>它调用kubelet的API拿到节点和Pod的指标，再把这些信息交给apiserver，这样kubectl、HPA就可以利用apiserver来读取指标了：</p><p><img src="https://i0.hdslb.com/bfs/openplatform/a3506f759b38d478201c9ae99c841c0e5082fd54.png" alt="image-20250711172952961"></p><h2 id="HorizontalPodAutoscaler"><a href="#HorizontalPodAutoscaler" class="headerlink" title="HorizontalPodAutoscaler"></a>HorizontalPodAutoscaler</h2><p>有了Metrics Server，我们就可以轻松地查看集群的资源使用状况了，不过它另外一个更重要的功能是辅助实现应用的“<strong>水平自动伸缩</strong>”。</p><p>“<strong>HorizontalPodAutoscaler</strong>”，简称是“<strong>hpa</strong>”。顾名思义，它是专门用来自动伸缩Pod数量的对象，适用于Deployment和StatefulSet，但不能用于DaemonSet。</p><p>HorizontalPodAutoscaler的能力完全基于Metrics Server，它从Metrics Server获取当前应用的运行指标，主要是CPU使用率，再依据预定的策略增加或者减少Pod的数量。</p><p>因为Metrics Server大约每15秒采集一次数据，所以HorizontalPodAutoscaler的自动化扩容和缩容也是按照这个时间点来逐步处理的。</p><p>当它发现目标的CPU使用率超过了预定的5%后，就会以2的倍数开始扩容，一直到数量上限，然后持续监控一段时间，如果CPU使用率回落，就会再缩容到最小值。</p><h2 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h2><p>显然，有了Metrics Server和HorizontalPodAutoscaler的帮助，我们的应用管理工作又轻松了一些。不过，Metrics Server能够获取的指标还是太少了，只有CPU和内存，想要监控到更多更全面的应用运行状况，还得请出这方面的权威项目“<strong>Prometheus</strong>”。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/bacc77beade046913111576c813dbc1027ebdf7e.png" alt="image-20250711173914580"></p><p>Prometheus系统的核心是它的Server，里面有一个时序数据库TSDB，用来存储监控数据，另一个组件Retrieval使用拉取（Pull）的方式从各个目标收集数据，再通过HTTP Server把这些数据交给外界使用。</p><p>在Prometheus Server之外还有三个重要的组件：</p><ul><li>Push Gateway，用来适配一些特殊的监控目标，把默认的Pull模式转变为Push模式。</li><li>Alert Manager，告警中心，预先设定规则，发现问题时就通过邮件等方式告警。</li><li>Grafana是图形化界面，可以定制大量直观的监控仪表盘。</li></ul><h1 id="网络通信"><a href="#网络通信" class="headerlink" title="网络通信"></a>网络通信</h1><p>Kubernetes提出了一个自己的网络模型“<strong>IP-per-pod</strong>”，能够很好地适应集群系统的网络需求，它有下面的这4点基本假设：</p><ul><li>集群里的每个Pod都会有唯一的一个IP地址。</li><li>Pod里的所有容器共享这个IP地址。</li><li>集群里的所有Pod都属于同一个网段。</li><li>Pod直接可以基于IP地址直接访问另一个Pod，不需要做麻烦的网络地址转换（NAT）。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;p&gt;虽然容器技术开启了云原生时代，但它也只走出了一小步，再继续前进就无能为力了，因为这已经不再是隔离一两个进程的普通问题，而是要</summary>
      
    
    
    
    
    <category term="k8s" scheme="https://palette-k.github.io/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>docker的使用技巧</title>
    <link href="https://palette-k.github.io/2025/07/09/docker%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    <id>https://palette-k.github.io/2025/07/09/docker%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/</id>
    <published>2025-07-09T07:03:45.000Z</published>
    <updated>2025-08-28T03:32:45.321Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2><p>镜像是容器的静态形式，它打包了应用程序的所有运行依赖项，方便保存和传输。使用容器技术运行镜像，就形成了动态的容器，由于镜像只读不可修改，所以应用程序的运行环境总是一致的。</p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><ol><li>容器就是操作系统里一个特殊的“沙盒”环境，里面运行的进程只能看到受限的信息，与外部系统实现了隔离。</li><li>容器隔离的目的是为了系统安全，限制了进程能够访问的各种资源。</li><li>相比虚拟机技术，容器更加轻巧、更加高效，消耗的系统资源非常少，在云计算时代极具优势。</li></ol><p>进入容器命令</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec <span class="literal">-it</span> <span class="number">062</span> sh</span><br></pre></td></tr></table></figure><h1 id="Docker-Desktop"><a href="#Docker-Desktop" class="headerlink" title="Docker Desktop"></a>Docker Desktop</h1><p>Docker Desktop 是<strong>容器化应用开发与部署的一体化工具</strong>，支持在本地环境创建、管理和运行Docker容器。</p><p>很多人以为，只要换了新电脑或者格式化电脑后，在docker desktop拉取的镜像、容器都会消失，现在我就来介绍一下将 Docker Desktop 的容器打包成镜像，上传到 docker hub 的方法，以后就可以像代码一样管理维护自己的docker镜像。</p><h2 id="Docker-Hub"><a href="#Docker-Hub" class="headerlink" title="Docker Hub"></a>Docker Hub</h2><p>在使用 <code>docker pull</code> 获取镜像的时候，我们并没有明确地指定镜像仓库。在这种情况下，Docker就会使用一个默认的镜像仓库，也就是大名鼎鼎的“<strong>Docker Hub</strong>”。</p><p>docker hub地址：<a href="https://hub.docker.com/repository/docker/wuziqing/planet/general">hub.docker.com</a></p><p>Docker Hub里面不仅有Docker自己打包的镜像，而且还对公众免费开放，任何人都可以上传自己的作品。经过这8年的发展，Docker Hub已经不再是一个单纯的镜像仓库了，更应该说是一个丰富而繁荣的容器社区。</p><p>如果想覆盖仓库中已有镜像，可以在本地重新构建镜像后，使用相同的标签推送镜像到仓库。</p><ol><li><p>docker hub 账号在本地验证登录</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login</span><br></pre></td></tr></table></figure></li><li><p>将容器commit成镜像</p></li></ol><p>docker tag <existing-image>  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></existing-image></p><p>   docker commit <existing-container>  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></existing-container></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker commit <span class="number">277</span>e80820516 hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure><ol start="3"><li><p>docker push 镜像到 docker hub 仓库</p><p>docker push  <hub-user>&#x2F;<repo-name>[:<tag>]</tag></repo-name></hub-user></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure></li><li><p>验证</p><p>命令验证：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker inspect hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure><p>线上仓库验证：登录docker hub，刷新仓库页，查看是否推送成功。</p></li><li><p>拉取镜像到本地</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull hub<span class="literal">-user</span>/repo<span class="literal">-name</span>:tag</span><br></pre></td></tr></table></figure></li></ol><h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><p>镜像就是一个打包文件，里面包含了应用程序还有它运行所依赖的环境，例如文件系统、环境变量、配置参数等等。</p><p>环境变量、配置参数这些东西还是比较简单的，随便用一个manifest清单就可以管理，真正麻烦的是文件系统。为了保证容器运行环境的一致性，镜像必须把应用程序所在操作系统的根目录，也就是rootfs，都包含进来。</p><p>由此引出容器镜像的一个重大创新点：分层，术语叫“<strong>Layer</strong>”。就是把重复的部分抽取出来，只存放一份Ubuntu根目录文件，然后让这一千个镜像以某种方式共享这部分数据。</p><p>Dockerfile非常普通，它就是一个纯文本，里面记录了一系列的构建指令，比如选择基础镜像、拷贝文件、运行脚本等等，每个指令都会生成一个Layer，而Docker顺序执行这个文件里的所有步骤，最后就会创建出一个新的镜像出来。</p><p>创建镜像命令：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build <span class="operator">-f</span> Dockerfile.busybox .</span><br></pre></td></tr></table></figure><h2 id="docker-build-是怎么工作的"><a href="#docker-build-是怎么工作的" class="headerlink" title="docker build 是怎么工作的"></a>docker build 是怎么工作的</h2><p>命令行“docker”是一个简单的客户端，真正的镜像构建工作是由服务器端的“Docker daemon”来完成的，所以“docker”客户端就只能把“构建上下文”目录打包上传（显示信息 <code>Sending build context to Docker daemon</code> ），这样服务器才能够获取本地的这些文件。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f631fc44deb0f0ccb46b3e68dcfbd2d123f4e13a.png" alt="image-20250709160506558"></p><h2 id="Dockerfile-编写规范"><a href="#Dockerfile-编写规范" class="headerlink" title="Dockerfile 编写规范"></a>Dockerfile 编写规范</h2><ol><li>创建镜像需要编写Dockerfile，写清楚创建镜像的步骤，每个指令都会生成一个Layer。</li><li>Dockerfile里，第一个指令必须是 <code>FROM</code>，用来选择基础镜像，常用的有Alpine、Ubuntu等。其他常用的指令有：<code>COPY</code>、<code>RUN</code>、<code>EXPOSE</code>，分别是拷贝文件，运行Shell命令，声明服务端口号。</li><li><code>docker build</code> 需要用 <code>-f</code> 来指定Dockerfile，如果不指定就使用当前目录下名字是“Dockerfile”的文件。</li><li><code>docker build</code> 需要指定“构建上下文”，其中的文件会打包上传到Docker daemon，所以尽量不要在“构建上下文”中存放多余的文件。</li><li>创建镜像的时候应当尽量使用 <code>-t</code> 参数，为镜像起一个有意义的名字，方便管理。</li></ol><h1 id="Docker-compose"><a href="#Docker-compose" class="headerlink" title="Docker-compose"></a>Docker-compose</h1><p>在Docker把容器技术大众化之后，Docker周边涌现出了数不胜数的扩展、增强产品，其中有一个名字叫“Fig”的小项目格外令人瞩目。</p><p>Fig为Docker引入了“容器编排”的概念，使用YAML来定义容器的启动参数、先后顺序和依赖关系，让用户不再有Docker冗长命令行的烦恼，第一次见识到了“声明式”的威力。因此，docker-compose自身的定位是管理和运行多个Docker容器的工具。</p><p>docker-compose里管理容器的核心概念是“<strong>service</strong>”。注意，它与Kubernetes里的 <code>Service</code> 虽然名字很像，但却是完全不同的东西。docker-compose里的“service”就是一个容器化的应用程序，通常是一个后台服务，用YAML定义这些容器的参数和相互之间的关系。</p><p>如果硬要和Kubernetes对比的话，和“service”最像的API对象应该算是Pod里的container了，同样是管理容器运行，但docker-compose的“service”又融合了一些Service、Deployment的特性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;基本概念&quot;&gt;&lt;a href=&quot;#基本概念&quot; class=&quot;headerlink&quot; title=&quot;基本概念&quot;&gt;&lt;/a&gt;基本概念&lt;/h1&gt;&lt;h2 id=&quot;镜像&quot;&gt;&lt;a href=&quot;#镜像&quot; class=&quot;headerlink&quot; title=&quot;镜像&quot;&gt;&lt;/a&gt;镜像&lt;/h</summary>
      
    
    
    
    
    <category term="docker" scheme="https://palette-k.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Redis实战：场景设计</title>
    <link href="https://palette-k.github.io/2025/07/07/Redis%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/"/>
    <id>https://palette-k.github.io/2025/07/07/Redis%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9C%BA%E6%99%AF%E8%AE%BE%E8%AE%A1/</id>
    <published>2025-07-07T02:40:26.000Z</published>
    <updated>2025-08-28T03:32:18.661Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis-热升级"><a href="#Redis-热升级" class="headerlink" title="Redis 热升级"></a>Redis 热升级</h1><p>对于线上较大流量的业务，单个 Redis 实例的内存占用很容易达到数 G 的容量，对应的 aof 会占用数十 G 的空间。即便每天流量低峰时间，对 Redis 进行 rewriteaof，减少数据冗余，但由于业务数据多，写操作多，aof 文件仍然会达到 10G 以上。</p><p>此时，在 Redis 需要升级版本或修复 bug 时，如果直接重启变更，由于需要数据恢复，这个过程需要近 10 分钟的时间，时间过长，会严重影响系统的可用性。</p><p>首先构建一个 Redis 壳程序，将 redisServer 的所有属性（包括redisDb、client等）保存为全局变量。然后将 Redis 的处理逻辑代码全部封装到动态连接库 so 文件中。Redis 第一次启动，从磁盘加载恢复数据，在后续升级时，通过指令，壳程序重新加载 Redis 新的 so 文件，即可完成功能升级，毫秒级完成 Redis 的版本升级。而且整个过程中，所有 Client 连接仍然保留，在升级成功后，原有 Client 可以继续进行读写操作，整个过程对业务完全透明。</p><h1 id="Redis-功能扩展"><a href="#Redis-功能扩展" class="headerlink" title="Redis 功能扩展"></a>Redis 功能扩展</h1><p>在 Redis 使用中，也经常会遇到一些特殊业务场景，是当前 Redis 的数据结构无法很好满足的。此时可以对 Redis 进行定制化扩展。可以根据业务数据特点，扩展新的数据结构，甚至扩展新的 Redis 存储模型，来提升 Redis 的内存效率和处理性能。</p><p>在微博中，有个业务类型是关注列表。关注列表存储的是一个用户所有关注的用户 uid。关注列表可以用来验证关注关系，也可以用关注列表，进一步获取所有关注人的微博列表等。由于用户数量过于庞大，存储关注列表的 Redis 是作为一个缓存使用的，即不活跃的关注列表会很快被踢出 Redis。在再次需要这个用户的关注列表时，重新从 DB 加载，并写回 Redis。关注列表的元素全部 long，最初使用 set 存储，回种 set 时，使用 sadd 进行批量添加。线上发现，对于关注数比较多的关注列表，比如关注数有数千上万个用户，需要 sadd 上成千上万个 uid，即便分几次进行批量添加，每次也会消耗较多时间，数据回种效率较低，而且会导致 Redis 卡顿。另外，用 set 存关注列表，内存效率也比较低。</p><p>于是，我们对 Redis 扩展了 longset 数据结构。longset 本质上是一个 long 型的一维开放数组。可以采用 double-hash 进行寻址。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f8431237bd0f6b0a50fdcd1d1807a555e2786814.png" alt="image-20250709141345697"></p><p>从 DB 加载到用户的关注列表，准备写入 Redis 前。Client 首先根据关注的 uid 列表，构建成 long 数组的二进制格式，然后通过扩展的 lsset 指令写入 Redis。</p><p>longset 中的 long 数组，采用 double-hash 进行寻址，即对每个 long 值采用 2 个哈希函数计算，然后按 (h1 + n*h2)% 数组长度 的方式，确定 long 值的位置。n 从 0 开始计算，如果出现哈希冲突，即计算的哈希位置，已经有其他元素，则 n 加 1，继续向前推进计算，最大计算次数是数组的长度。</p><p>在向 longset 数据结构不断增加 long 值元素的过程中，当数组的填充率超过阀值，Redis 则返回 longset 过满的异常。此时 Client 会根据最新全量数据，构建一个容量加倍的一维 long 数组，再次 lsset 回 Redis 中。</p><h2 id="完全增量复制"><a href="#完全增量复制" class="headerlink" title="完全增量复制"></a>完全增量复制</h2><p>微博整合 Redis 的 rdb 和 aof 策略，构建了完全增量复制方案。</p><p>在完全增量方案中，aof 文件不再只有一个，而是按后缀 id 进行递增，如 aof.00001、aof.00002，当 aof 文件超过阀值，则创建下一个 id 加 1 的文件，从而滚动存储最新的写指令。在 bgsave 构建 rdb 时，rdb 文件除了记录当前的内存数据快照，还会记录 rdb 构建时间，对应 aof 文件的 id 及位置。这样 rdb 文件和其记录 aof 文件位置之后的写指令，就构成一份完整的最新数据记录。</p><p>主从复制时，master 通过独立的复制线程向 slave 同步数据。每个 slave 会创建一个复制线程。第一次复制是全量复制，之后的复制，不管 slave 断开复制连接有多久，只要 aof 文件没有被删除，都是增量复制。</p><p>第一次全量复制时，复制线程首先将 rdb 发给 slave，然后再将 rdb 记录的 aof 文件位置之后的所有数据，也发送给 slave，即可完成。整个过程不用重新构建 rdb。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/14de3f441fc9bb6f9c597c228c18c7e02b4fa8db.png" alt="image-20250709141402578"></p><p>后续同步时，slave 首先传递之前复制的 aof 文件的 id 及位置。master 的复制线程根据这个信息，读取对应 aof 文件位置之后的所有内容，发送给 slave，即可完成数据同步。</p><p>由于整个复制过程，master 在独立复制线程中进行，所以复制过程不影响用户的正常请求。为了减轻 master 的复制压力，全增量复制方案仍然支持 slave 嵌套，即可以在 slave 后继续挂载多个 slave，从而把复制压力分散到多个不同的 Redis 实例。</p><h1 id="如何为秒杀系统设计缓存体系"><a href="#如何为秒杀系统设计缓存体系" class="headerlink" title="如何为秒杀系统设计缓存体系"></a>如何为秒杀系统设计缓存体系</h1><p>在设计秒杀系统时，有两个设计原则。</p><p>首先，要尽力将请求拦截在系统上游，层层设阻拦截，过滤掉无效或超量的请求。因为访问量远远大于商品数量，所有的请求打到后端服务的最后一步，其实并没有必要，反而会严重拖慢真正能成交的请求，降低用户体验。</p><p>其次，要充分利用缓存，提升系统的性能和可用性。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/0247772e6c2f55ffc860328565ffef5bff57208f.png" alt="image-20250709141433518"></p><p>秒杀系统专为秒杀活动服务，售卖商品确定，因此可以在设计秒杀商品页面时，将商品信息提前设计为静态信息，将静态的商品信息以及常规的 CSS、JS、宣传图片等静态资源，一起独立存放到 CDN 节点，加速访问，且降低系统访问压力。</p><p>在访问前端也可以制定种种限制策略，比如活动没开始时，抢购按钮置灰，避免抢先访问，用户抢购一次后，也将按钮置灰，让用户排队等待，避免反复刷新。</p><p>用户所有的请求进入秒杀系统前，通过负载均衡策略均匀分发到不同 Web 服务器，避免节点过载。在 Web 服务器中，首先进行各种服务预处理，检查用户的访问权限，识别并发刷订单的行为。同时在真正服务前，也要进行服务前置检查，避免超售发生。如果发现售出数量已经达到秒杀数量，则直接返回结束。</p><p>秒杀系统在处理抢购业务逻辑时，除了对用户进行权限校验，还需要访问商品服务，对库存进行修改，访问订单服务进行订单创建，最后再进行支付、物流等后续服务。这些依赖服务，可以专门为秒杀业务设计排队策略，或者额外部署实例，对秒杀系统进行专门服务，避免影响其他常规业务系统。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/1366a88cadb61bd665fb9cffdb884430bed63509.png" alt="image-20250709141443825"></p><p>由于秒杀的参与者远大于商品数，为了提高抢购的概率，时常会出现一些利用脚本和僵尸账户并发频繁调用接口进行强刷的行为，秒杀系统需要构建访问记录缓存，记录访问 IP、用户的访问行为，发现异常访问，提前进行阻断及返回。同时还需要构建用户缓存，并针对历史数据分析，提前缓存僵尸强刷专业户，方便在秒杀期间对其进行策略限制。这些访问记录、用户数据，通过缓存进行存储，可以加速访问，另外，对用户数据还进行缓存预热，避免活动期间大量穿透。</p><p>在业务请求处理时，所有操作尽可能由缓存交互完成。由于秒杀商品较少，相关信息全部加载到内存，把缓存暂时当作存储用，并不会带来过大成本负担。</p><p>为秒杀商品构建商品信息缓存，并对全部目标商品进行预热加载。同时对秒杀商品构建独立的库存缓存，加速库存检测。这样通过秒杀商品列表缓存，进行快速商品信息查询，通过库存缓存，可以快速确定秒杀活动进程，方便高效成交或无可售商品后的快速检测及返回。在用户抢购到商品后，要进行库存事务变更，进行库存、订单、支付等相关的构建和修改，这些操作可以尽量由系统只与缓存组件交互完成初步处理。后续落地等操作，必须要入DB库的操作，可以先利用消息队列机，记录成交事件信息，然后再逐步分批执行，避免对 DB 造成过大压力。</p><p>总之，在秒杀系统中，除了常规的分拆访问内容和服务，最重要的是尽量将所有数据访问进行缓存化，尽量减少 DB 的访问，在大幅提升系统性能的同时，提升用户体验。</p><h1 id="如何为海量计数场景设计缓存体系"><a href="#如何为海量计数场景设计缓存体系" class="headerlink" title="如何为海量计数场景设计缓存体系"></a>如何为海量计数场景设计缓存体系</h1><h2 id="计数常规方案"><a href="#计数常规方案" class="headerlink" title="计数常规方案"></a>计数常规方案</h2><p>计数服务在互联网系统中非常常见，用户的关注粉丝数、帖子数、评论数等都需要进行计数存储。计数的存储格式也很简单，key 一般是用户 uid 或者帖子 id 加上后缀，value 一般是 8 字节的 long 型整数。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/302df249ad520edfdd0d51b42abe7f69b0bda7bc.png" alt="image-20250709141501087"></p><p>最常见的计数方案是采用缓存 + DB 的存储方案。当计数变更时，先变更计数 DB，计数加 1，然后再变更计数缓存，修改计数存储的 Memcached 或 Redis。这种方案比较通用且成熟，但在高并发访问场景，支持不够友好。在互联网社交系统中，有些业务的计数变更特别频繁，比如微博 feed 的阅读数，计数的变更次数和访问次数相当，每秒十万到百万级以上的更新量，如果用 DB 存储，会给 DB 带来巨大的压力，DB 就会成为整个计数服务的瓶颈所在。即便采用聚合延迟更新 DB 的方案，由于总量特别大，同时请求均衡分散在大量不同的业务端，巨大的写压力仍然是 DB 的不可承受之重。因此这种方案只适合中小规模的计数服务使用。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/d8fdb89f1386e9102e52a06292f559feea9eb23f.png" alt="image-20250709141514173"></p><p>在 Redis 问世并越来越成熟后，很多互联网系统会直接把计数全部存储在 Redis 中。通过 hash 分拆的方式，可以大幅提升计数服务在 Redis 集群的写性能，通过主从复制，在 master 后挂载多个从库，利用读写分离，可以大幅提升计数服务在 Redis 集群的读性能。而且 Redis 有持久化机制，不会丢数据，在很多大中型互联网场景，这都是一个比较适合的计数服务方案。</p><p>在互联网移动社交领域，由于用户基数巨大，每日发表大量状态数据，且相互之间有大量的交互动作，从而产生了海量计数和超高并发访问，如果直接用 Redis 进行存储，会带来巨大的成本和性能问题。</p><h2 id="海量计数场景"><a href="#海量计数场景" class="headerlink" title="海量计数场景"></a>海量计数场景</h2><p>以微博为例，系统内有大量的待计数对象。如从用户维度，日活跃用户 2 亿+，月活跃用户接近 5 亿。从 Feed 维度，微博历史 Feed 有数千亿条，而且每日新增数亿条的新 Feed。这些用户和 Feed 不但需要进行计数，而且需要进行多个计数。比如，用户维度，每个用户需要记录关注数、粉丝数、发表 Feed 数等。而从 Feed 维度，每条 Feed 需要记录转发数、评论数、赞、阅读等计数。</p><p>而且，在微博业务场景下，每次请求都会请求多个对象的多个计数。比如查看用户时，除了获取该用户的基本信息，还需要同时获取用户的关注数、粉丝数、发表 Feed 数。获取微博列表时，除了获取 Feed 内容，还需要同时获取 Feed 的转发数、评论数、赞数，以及阅读数。因此，微博计数服务的总访问量特别大，很容易达到百万级以上的 QPS。</p><p><strong>方案选择：</strong></p><p>因此，在海量计数高并发访问场景，如果采用缓存 + DB 的架构，首先 DB 在计数更新就会存在瓶颈，其次，单个请求一次请求数十个计数，一旦缓存 miss，穿透到 DB，DB 的读也会成为瓶颈。因为 DB 能支撑的 TPS 不过 3000~6000 之间，远远无法满足高并发计数访问场景的需要。</p><p>采用 Redis 全量存储方案，通过分片和主从复制，读写性能不会成为主要问题，但容量成本却会带来巨大开销。</p><p>因为，一方面 Redis 作为通用型存储来存储计数，<strong>内存存储效率低</strong>。以存储一个 key 为 long 型 id、value 为 4 字节的计数为例，Redis 至少需要 65 个字节左右，不同版本略有差异。但这个计数理论只需要占用 12 个字节即可。内存有效负荷只有 12⁄65&#x3D;18.5%。如果再考虑一个 long 型 id 需要存 4 个不同类型的 4 字节计数，内存有效负荷只有 (8+16)&#x2F;(65*4)&#x3D; 9.2%。</p><p>另一方面，Redis 所有数据均存在内存，单存储历史千亿级记录，单份数据拷贝需要 10T 以上，要考虑核心业务上 1 主 3 从，需要 40T 以上的内存，再考虑多 IDC 部署，<strong>轻松占用上百 T 内存</strong>。就按单机 100G 内存来算，计数服务就要占用上千台大内存服务器。存储成本太高。</p><h2 id="海量计数服务架构"><a href="#海量计数服务架构" class="headerlink" title="海量计数服务架构"></a>海量计数服务架构</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/0580bed1c59bb8eb3ad4c2035e37592012c8216c.png" alt="image-20250709141528777"></p><p>为了解决海量计数的存储及访问的问题，微博基于 Redis 定制开发了计数服务系统，该计数服务兼容 Redis 协议，将所有数据分别存储在内存和磁盘 2 个区域。首先，内存会预分配 N 块大小相同的 Table 空间，线上一般每个 Table 占用 1G 字节，最大分配 10 个左右的 Table 空间。首先使用 Table0，当存储填充率超过阀值，就使用 Table1，依次类推。每个 Table 中，key 是微博 id，value 是自定义的多个计数。</p><p>微博的 id 按时间递增，因此每个内存 Table 只用存储一定范围内的 id 即可。内存 Table 预先按设置分配为相同 size 大小的 key-value 槽空间。每插入一个新 key，就占用一个槽空间，当槽位填充率超过阀值，就滚动使用下一个 Table，当所有预分配的 Table 使用完毕，还可以根据配置，继续从内存分配更多新的 Table 空间。当内存占用达到阀值，就会把内存中 id 范围最小的 Table 落盘到 SSD 磁盘。落盘的 Table 文件称为 DDB。每个内存 Table 对应落盘为 1 个 DDB 文件。</p><p>计数服务会将落盘 DDB 文件的索引记录在内存，这样当查询需要从内存穿透到磁盘时，可以直接定位到磁盘文件，加快查询速度。</p><p>计数服务可以设置 Schema 策略，使一个 key 的 value 对应存储多个计数。每个计数占用空间根据 Schema 确定，可以精确到 bit。key 中的各个计数，设置了最大存储空间，所以只能支持有限范围内的计数。如果计数超过设置的阀值，则需要将这个 key 从 Table 中删除，转储到 aux dict 辅助词典中。</p><p>同时每个 Table 负责一定范围的 id，由于微博 id 随时间增长，而非逐一递增，Table 滚动是按照填充率达到阀值来进行的。当系统发生异常时，或者不同区域网络长时间断开重连后，在老数据修复期间，可能在之前的 Table 中插入较多的计数 key。如果旧 Table 插入数据量过大，超过容量限制，或者持续搜索存储位置而不得，查找次数超过阀值，则将新 key 插入到 extend dict 扩展词典中。</p><p>微博中的 feed 一般具有明显的冷热区分，并且越新的 feed 越热，访问量越大，越久远的 feed 越冷。新的热 key 存放内存 Table，老的冷 key 随所在的 Table 被置换到 DDB 文件。当查询 DDB 文件中的冷 key 时，会采用多线程异步并行查询，基本不影响业务的正常访问。同时，这些冷 key 从 DDB 中查询后，会被存放到 LRU 中，从而方便后续的再次访问。</p><p>计数服务的内存数据快照仍然采用前面讲的 RDB + 滚动 AOF 策略。RDB 记录构建时刻对应的 AOF 文件 id 及 pos 位置。全量复制时，master 会将磁盘中的 DDB 文件，以及内存数据快照对应的 RDB 和 AOF 全部传送给 slave。</p><p>在之后的所有复制就是全增量复制，slave 在断开连接，再次重连 master 时，汇报自己同步的 AOF 文件 id 及位置，master 将对应文件位置之后的内容全部发送给 slave，即可完成同步。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/02cf1e7531de2672ca7a37ed4776e0710bb09a9a.png" alt="image-20250709141539168"></p><p>计数服务中的内存 Table 是一个一维开放数据，每个 key-value 按照 Schema 策略占用相同的内存。每个 key-value 内部，key 和多个计数紧凑部署。首先 8 字节放置 long 型 key，然后按Schema 设置依次存放各个计数。</p><p>key 在插入及查询时，流程如下。</p><p>首先根据所有 Table 的 id 范围，确定 key 所在的内存 Table。</p><p>然后再根据 double-hash 算法计算 hash，用 2 个 hash 函数分别计算出 2 个 hash 值，采用公示 h1+N*h2 来定位查找。</p><p>在对计数插入或变更时，如果查询位置为空，则立即作为新值插入 key&#x2F;value，否则对比 key，如果 key 相同，则进行计数增减；如果 key 不同，则将 N 加 1，然后进入到下一个位置，继续进行前面的判断。如果查询的位置一直不为空，且 key 不同，则最多查询设置的阀值次数，如果仍然没查到，则不再进行查询。将该 key 记录到 extend dict 扩展词典中。</p><p>在对计数 key 查找时，如果查询的位置为空，说明 key 不存在，立即停止。如果 key 相同，返回计数，否则 N 加 1，继续向后查询，如果查询达到阀值次数，没有遇到空，且 key 不同，再查询 aux dict 辅助字典 和 extend dict 扩展字典，如果也没找到该 key，则说明该 key 不存在，即计数为 0。</p><h2 id="海量计数服务收益"><a href="#海量计数服务收益" class="headerlink" title="海量计数服务收益"></a>海量计数服务收益</h2><p>微博计数服务，多个计数按 Schema 进行紧凑存储，共享同一个 key，每个计数的 size 按 bit 设计大小，没有额外的指针开销，内存占用只有 Redis 的 10% 以下。同时，由于 key 的计数 size 固定，如果计数超过阀值，则独立存储 aux dict 辅助字典中。</p><p>同时由于一个 key 存储多个计数，同时这些计数一般都需要返回，这样一次查询即可同时获取多个计数，查询性能相比每个计数独立存储的方式提升 3~5 倍。</p><h1 id="如何为社交feed场景设计缓存体系"><a href="#如何为社交feed场景设计缓存体系" class="headerlink" title="如何为社交feed场景设计缓存体系"></a>如何为社交feed场景设计缓存体系</h1><h2 id="Feed-流场景分析"><a href="#Feed-流场景分析" class="headerlink" title="Feed 流场景分析"></a>Feed 流场景分析</h2><p><img src="https://i0.hdslb.com/bfs/openplatform/449049dfc24eacb62e14241de43667710b3173d6.png" alt="image-20250709141559577"></p><p>Feed 流是很多移动互联网系统的重要一环，如微博、微信朋友圈、QQ 好友动态、头条&#x2F;抖音信息流等。虽然这些产品形态各不相同，但业务处理逻辑却大体相同。用户日常的“刷刷刷”，就是在获取 Feed 流，这也是 Feed 流的一个最重要应用场景。用户刷新获取 Feed 流的过程，对于服务后端，就是一个获取用户感兴趣的 Feed，并对 Feed 进行过滤、动态组装的过程。</p><p>接下来，我将以微博为例，介绍用户在发出刷新 Feed 流的请求后，服务后端是如何进行处理的。</p><p>获取 Feed 流操作是一个重操作，后端数据处理存在 100 ~ 1000 倍以上的读放大。也就是说，前端用户发出一个接口请求，服务后端需要请求数百甚至数千条数据，然后进行组装处理并返回响应。因此，为了提升处理性能、快速响应用户，微博 Feed 平台重度依赖缓存，几乎所有的数据都从缓存获取。如用户的关注关系从 Redis 缓存中获取，用户发出的 Feed 或收到特殊 Feed 从 Memcached 中获取，用户及 Feed 的各种计数从计数服务中获取。</p><h2 id="Feed-流流程分析"><a href="#Feed-流流程分析" class="headerlink" title="Feed 流流程分析"></a>Feed 流流程分析</h2><p>Feed 流业务作为微博系统的核心业务，为了保障用户体验，SLA 要求较高，核心接口的可用性要达到 4 个 9，接口耗时要在 50<del>100ms 以内，后端数据请求平均耗时要在 3</del>5ms 以内，因此为了满足亿级庞大用户群的海量并发访问需求，需要对缓存体系进行良好架构且不断改进。</p><p>在 Feed 流业务中，核心业务数据的缓存命中率基本都在 99% 以上，这些缓存数据，由 Feed 系统进行多线程并发获取及组装，从而及时发送响应给用户。</p><p>Feed 流获取的处理流程如下。</p><p>首先，根据用户信息，获取用户的关注关系，一般会得到 300~2000 个关注用户的 UID。</p><p>然后，再获取用户自己的 Feed inbox 收件箱。收件箱主要存放其他用户发表的供部分特定用户可见的微博 ID 列表。</p><p>接下来，再获取所有关注列表用户的微博 ID 列表，即关注者发表的所有用户或者大部分用户可见的 Feed ID 列表。这些 Feed ID 列表都以 vector 数组的形式存储在缓存。由于一般用户的关注数会达到数百甚至数千，因此这一步需要获取数百或数千个 Feed vector。</p><p>然后，Feed 系统将 inbox 和关注用户的所有 Feed vector 进行合并，并排序、分页，即得到目标 Feed 的 ID 列表。</p><p>接下来，再根据 Feed ID 列表获取对应的 Feed 内容，如微博的文字、视频、发表时间、源微博 ID 等。</p><p>然后，再进一步获取所有微博的发表者 user 详细信息、源微博内容等信息，并进行内容组装。</p><p>之后，如果用户设置的过滤词，还要将这些 Feed 进行过滤筛选，剔除用户不感兴趣的 Feed。</p><p>接下来，再获取用户对这些 Feed 的收藏、赞等状态，并设置到对应微博中。</p><p>最后，获取这些 Feed 的转发数、评论数、赞数等，并进行计数组装。至此，Feed 流获取处理完毕，Feed 列表以 JSON 形式返回给前端，用户刷新微博首页成功完成。</p><h2 id="Feed-流缓存架构"><a href="#Feed-流缓存架构" class="headerlink" title="Feed 流缓存架构"></a>Feed 流缓存架构</h2><p>Feed 流处理中，缓存核心业务数据主要分为 6 大类。</p><p>第一类是用户的 inbox 收件箱，在用户发表仅供少量用户可见的 Feed 时，为了提升访问效率，这些 Feed ID 并不会进入公共可见的 outbox 发件箱，而会直接推送到目标客户的收件箱。</p><p>第二类是用户的 outbox 发件箱。用户发表的普通微博都进入 outbox，这些微博几乎所有人都可见，由粉丝在刷新 Feed 列表首页时，系统直接拉取组装。</p><p>第三类是 Social Graph 即用户的关注关系，如各种关注列表、粉丝列表。</p><p>第四类是 Feed Content 即 Feed 的内容，包括 Feed 的文字、视频、发表时间、源微博 ID 等。</p><p>第五类是 Existence 存在性判断缓存，用来判断用户是否阅读了某条 Feed，是否赞了某条 Feed 等。对于存在性判断，微博是采用自研的 phantom 系统，通过 bloomfilter 算法进行存储的。</p><p>第六类是 Counter 计数服务，用来存储诸如关注数、粉丝数，Feed 的转发、评论、赞、阅读等各种计数。</p><p>对于 Feed 的 inbox 收件箱、outbox 发件箱，Feed 系统通过 Memcached 进行缓存，以 feed id的一维数组格式进行存储。</p><p>对于关注列表，Feed 系统采用 Redis 进行缓存，存储格式为 longset。longset 在之前的课时介绍过，是微博扩展的一种数据结构，它是一个采用 double-hash 寻址的一维数组。当缓存 miss 后，业务 client 可以从 DB 加载，并直接构建 longset 的二进制格式数据作为 value写入Redis，Redis 收到后直接 restore 到内存，而不用逐条加入。这样，即便用户有成千上万个关注，也不会引发阻塞。</p><p>Feed content 即 Feed 内容，采用 Memcached 存储。由于 Feed 内容有众多的属性，且时常需要根据业务需要进行扩展，Feed 系统采用 Google 的 protocol bufers 的格式进行存放。protocol buffers 序列化后的所生成的二进制消息非常紧凑，二进制存储空间比 XML 小 3~10 倍，而序列化及反序列化的性能却高 10 倍以上，而且扩展及变更字段也很方便。微博的 Feed content 最初采用 XML 和 JSON 存储，在 2011 年之后逐渐全部改为 protocol buffers 存储。</p><p>对于存在性判断，微博 Feed 系统采用自研的 phantom 进行存储。数据存储采用 bloom filter 存储结构。实际上 phantom 本身就是一个分段存储的 bloomfilter 结构。bloomFilter 采用 bit 数组来表示一个集合，整个数组最初所有 bit 位都是 0，插入 key 时，采用 k 个相互独立的 hash 函数计算，将对应 hash 位置置 1。而检测某个 key 是否存在时，通过对 key 进行多次 hash，检查对应 hash 位置是否为 1 即可，如果有一个为 0，则可以确定该 key 肯定不存在，但如果全部为 1，大概率说明该 key 存在，但该 key 也有可能不存在，即存在一定的误判率，不过这个误判率很低，一般平均每条记录占用 1.2 字节时，误判率即可降低到 1%，1.8 字节，误判率可以降到千分之一。基本可以满足大多数业务场景的需要。</p><p>对于计数服务，微博就是用前面讲到的 CounterService。CounterService 采用 schema 策略，支持一个 key 对应多个计数，只用 5<del>10% 的空间，却提升 3</del>5 倍的读取性能。</p><p>对于 Feed 流中的 Redis 存储访问，业务的 Redis 部署基本都采用 1 主多从的方式。同时多个子业务按类型分为 cluster 集群，通过多租户 proxy 进行访问。对于一些数据量很小的业务，还可以共享 Redis 存储，进行混合读写。对于一些响应时间敏感的业务，基于性能考虑，也支持smart client 直接访问 Redis 集群。整个 Redis 集群，由 clusterManager 进行运维、slot 维护及迁移。配置中心记录集群相关的 proxy 部署及 Redis 配置及部署等。这个架构在之前的经典分布式缓存系统课程中有详细介绍，此处不再赘述。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis-热升级&quot;&gt;&lt;a href=&quot;#Redis-热升级&quot; class=&quot;headerlink&quot; title=&quot;Redis 热升级&quot;&gt;&lt;/a&gt;Redis 热升级&lt;/h1&gt;&lt;p&gt;对于线上较大流量的业务，单个 Redis 实例的内存占用很容易达到数 G 的容量，对</summary>
      
    
    
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
    <category term="缓存" scheme="https://palette-k.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Spring循环依赖及解决原理</title>
    <link href="https://palette-k.github.io/2025/06/19/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E7%90%86/"/>
    <id>https://palette-k.github.io/2025/06/19/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8E%9F%E7%90%86/</id>
    <published>2025-06-19T02:28:27.000Z</published>
    <updated>2025-08-28T03:37:48.211Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是循环依赖"><a href="#什么是循环依赖" class="headerlink" title="什么是循环依赖"></a>什么是循环依赖</h1><p>字面上理解就是A依赖B的同时，B也依赖了A。</p><p>体现在启动控制台就是以下的日志：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">┌─────┐</span><br><span class="line">|  asyncServiceImpl defined in file [D:\Download\GitLabProject\uhr\jr-uhr-provider\jr-uhr-attendance\target\classes\com\jr\uhr\gtd\service\impl\AsyncServiceImpl.class]</span><br><span class="line">↑     ↓</span><br><span class="line">|  gtdClassServiceImpl defined in file [D:\Download\GitLabProject\uhr\jr-uhr-provider\jr-uhr-attendance\target\classes\com\jr\uhr\gtd\service\impl\GtdClassServiceImpl.class]</span><br><span class="line">└─────┘</span><br></pre></td></tr></table></figure><p>体现在代码层次就是这个样子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了B</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> B b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="comment">// B中也注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>比较特殊的还有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自己依赖自己</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="什么情况下循环依赖可以被处理"><a href="#什么情况下循环依赖可以被处理" class="headerlink" title="什么情况下循环依赖可以被处理"></a>什么情况下循环依赖可以被处理</h1><p>在回答这个问题之前首先要明确一点，Spring解决循环依赖是有前置条件的</p><ol><li>出现循环依赖的Bean必须要是单例</li><li>依赖注入的方式不能全是构造器注入的方式</li></ol><p>其中第一点应该很好理解，第二点：不能全是构造器注入是什么意思呢？我们还是用代码说话</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line"><span class="comment">//@Autowired</span></span><br><span class="line"><span class="comment">//private B b;</span></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">A</span><span class="params">(B b)</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//@Autowired</span></span><br><span class="line"><span class="comment">//private A a;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">B</span><span class="params">(A a)</span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在上面的例子中，A中注入B的方式是通过构造器，B中注入A的方式也是通过构造器，这个时候循环依赖是无法被解决，如果你的项目中有两个这样相互依赖的Bean，在启动时就会报出以下错误：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Caused by: org.springframework.beans.factory.BeanCurrentlyInCreationException: Error creating bean with name <span class="string">&#x27;a&#x27;</span>: Requested bean is currently in creation: Is there an unresolvable circular reference?</span><br></pre></td></tr></table></figure><p>为了测试循环依赖的解决情况跟注入方式的关系，我们做如下四种情况的测试</p><table><thead><tr><th>依赖情况</th><th>依赖注入方式</th><th>循环依赖是否被解决</th></tr></thead><tbody><tr><td>AB相互依赖（循环依赖）</td><td>均采用setter方法注入</td><td>是</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>均采用构造器注入</td><td>否</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>A中注入B的方式为setter方法，B中注入A的方式为构造器</td><td>是</td></tr><tr><td>AB相互依赖（循环依赖）</td><td>B中注入A的方式为setter方法，A中注入B的方式为构造器</td><td>否</td></tr></tbody></table><h1 id="Spring是如何解决的循环依赖"><a href="#Spring是如何解决的循环依赖" class="headerlink" title="Spring是如何解决的循环依赖"></a>Spring是如何解决的循环依赖</h1><h2 id="简单的循环依赖（没有AOP）"><a href="#简单的循环依赖（没有AOP）" class="headerlink" title="简单的循环依赖（没有AOP）"></a>简单的循环依赖（没有AOP）</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="comment">// A中注入了B</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> B b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="comment">// B中也注入了A</span></span><br><span class="line"><span class="meta">@Autowired</span></span><br><span class="line"><span class="keyword">private</span> A a;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过上文我们已经知道了这种情况下的循环依赖是能够被解决的，那么具体的流程是什么呢？我们一步步分析</p><p>首先，我们要知道<strong>Spring在创建Bean的时候默认是按照自然排序来进行创建的，所以第一步Spring会去创建A</strong>。</p><p>与此同时，我们应该知道，Spring在创建Bean的过程中分为三步</p><ol><li>实例化，对应方法：<code>AbstractAutowireCapableBeanFactory</code>中的<code>createBeanInstance</code>方法</li><li>属性注入，对应方法：<code>AbstractAutowireCapableBeanFactory</code>的<code>populateBean</code>方法</li><li>初始化，对应方法：<code>AbstractAutowireCapableBeanFactory</code>的<code>initializeBean</code></li></ol><p>简单翻译下，就是：</p><ol><li>实例化，简单理解就是new了一个对象</li><li>属性注入，为实例化中new出来的对象填充属性</li><li>初始化，执行aware接口中的方法，初始化方法，完成<code>AOP</code>代理</li></ol><p>整个创建A这个Bean的流程图如下：</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjEzMzAxODY2OS5wbmc?x-oss-process=image/format,png" alt="image-20200706133018669"></p><p>从上图中我们可以看到，虽然在创建B时会提前给B注入了一个还未初始化的A对象，但是在创建A的流程中一直使用的是注入到B中的A对象的引用，之后会根据这个引用对A进行初始化，所以这是没有问题的。</p><h2 id="结合了AOP的循环依赖"><a href="#结合了AOP的循环依赖" class="headerlink" title="结合了AOP的循环依赖"></a>结合了AOP的循环依赖</h2><p>对A进行了<code>AOP</code>代理的话，那么此时<code>getEarlyBeanReference</code>将返回一个代理后的对象，而不是实例化阶段创建的对象，这样就意味着B中注入的A将是一个代理对象而不是A的实例化阶段创建后的对象。</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE2MTcwOTgyOS5wbmc?x-oss-process=image/format,png" alt="image-20200706161709829"></p><p>看到这个图你可能会产生下面这些疑问</p><ol><li>在给B注入的时候为什么要注入一个代理对象？</li></ol><p>答：当我们对A进行了<code>AOP</code>代理时，说明我们希望从容器中获取到的就是A代理后的对象而不是A本身，因此把A当作依赖进行注入时也要注入它的代理对象</p><ol start="2"><li>明明初始化的时候是A对象，那么Spring是在哪里将代理对象放入到容器中的呢？</li></ol><p>在完成初始化后，Spring又调用了一次<code>getSingleton</code>方法，这一次传入的参数又不一样了，false可以理解为禁用三级缓存，前面图中已经提到过了，在为B中注入A时已经将三级缓存中的工厂取出，并从工厂中获取到了一个对象放入到了二级缓存中，所以这里的这个<code>getSingleton</code>方法做的时间就是从二级缓存中获取到这个代理后的A对象。</p><ol start="3"><li>初始化的时候是对A对象本身进行初始化，而容器中以及注入到B中的都是代理对象，这样不会有问题吗？</li></ol><p>答：不会，这是因为不管是<code>cglib</code>代理还是<code>jdk</code>动态代理生成的代理类，内部都持有一个目标类的引用，当调用代理对象的方法时，实际会去调用目标对象的方法，A完成初始化相当于代理对象自身也完成了初始化</p><ol start="4"><li>三级缓存为什么要使用工厂而不是直接使用引用？换而言之，为什么需要这个三级缓存，直接通过二级缓存暴露一个引用不行吗？</li></ol><p>答：<strong>这个工厂的目的在于延迟对实例化阶段生成的对象的代理，只有真正发生循环依赖的时候，才去提前生成代理对象，否则只会创建一个工厂并将其放入到三级缓存中，但是不会去通过这个工厂去真正创建对象</strong></p><p>我们思考一种简单的情况，就以单独创建A为例，假设AB之间现在没有依赖关系，但是A被代理了，这个时候当A完成实例化后还是会进入下面这段代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A是单例的，mbd.isSingleton()条件满足</span></span><br><span class="line"><span class="comment">// allowCircularReferences：这个变量代表是否允许循环依赖，默认是开启的，条件也满足</span></span><br><span class="line"><span class="comment">// isSingletonCurrentlyInCreation：正在在创建A，也满足</span></span><br><span class="line"><span class="comment">// 所以earlySingletonExposure=true</span></span><br><span class="line"><span class="type">boolean</span> <span class="variable">earlySingletonExposure</span> <span class="operator">=</span> (mbd.isSingleton() &amp;&amp; <span class="built_in">this</span>.allowCircularReferences &amp;&amp;</span><br><span class="line">                                  isSingletonCurrentlyInCreation(beanName));</span><br><span class="line"><span class="comment">// 还是会进入到这段代码中</span></span><br><span class="line"><span class="keyword">if</span> (earlySingletonExposure) &#123;</span><br><span class="line"><span class="comment">// 还是会通过三级缓存提前暴露一个工厂对象</span></span><br><span class="line">    addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>看到了吧，即使没有循环依赖，也会将其添加到三级缓存中，而且是不得不添加到三级缓存中，因为到目前为止Spring也不能确定这个Bean有没有跟别的Bean出现循环依赖。</p><p>假设我们在这里直接使用二级缓存的话，那么意味着所有的Bean在这一步都要完成<code>AOP</code>代理。这样做有必要吗？</p><p>不仅没有必要，而且违背了Spring在结合<code>AOP</code>跟Bean的生命周期的设计！Spring结合<code>AOP</code>跟Bean的生命周期本身就是通过<code>AnnotationAwareAspectJAutoProxyCreator</code>这个后置处理器来完成的，在这个后置处理的<code>postProcessAfterInitialization</code>方法中对初始化后的Bean完成<code>AOP</code>代理。如果出现了循环依赖，那没有办法，只有给Bean先创建代理，但是没有出现循环依赖的情况下，设计之初就是让Bean在生命周期的最后一步完成代理而不是在实例化后就立马完成代理。</p><h2 id="三级缓存真的提高了效率了吗？"><a href="#三级缓存真的提高了效率了吗？" class="headerlink" title="三级缓存真的提高了效率了吗？"></a>三级缓存真的提高了效率了吗？</h2><p>现在我们已经知道了三级缓存的真正作用，但是这个答案可能还无法说服你，所以我们再最后总结分析一波，三级缓存真的提高了效率了吗？分为两点讨论：</p><ol><li>没有进行<code>AOP</code>的Bean间的循环依赖</li></ol><p>从上文分析可以看出，这种情况下三级缓存根本没用！所以不会存在什么提高了效率的说法</p><ol><li>进行了<code>AOP</code>的Bean间的循环依赖</li></ol><p>就以我们上的A、B为例，其中A被<code>AOP</code>代理，我们先分析下使用了三级缓存的情况下，A、B的创建流程</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE3MTUxNDMyNy5wbmc?x-oss-process=image/format,png" alt="image-20200706171514327"></p><p>假设不使用三级缓存，直接在二级缓存中</p><p><img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9naXRlZS5jb20vd3hfY2MzNDdiZTY5Ni9ibG9nSW1hZ2UvcmF3L21hc3Rlci9pbWFnZS0yMDIwMDcwNjE3MjUyMzI1OC5wbmc?x-oss-process=image/format,png" alt="image-20200706172523258"></p><p>上面两个流程的唯一区别在于为A对象创建代理的时机不同，在使用了三级缓存的情况下为A创建代理的时机是在B中需要注入A的时候，而不使用三级缓存的话在A实例化后就需要马上为A创建代理然后放入到二级缓存中去。对于整个A、B的创建过程而言，消耗的时间是一样的</p><p>综上，不管是哪种情况，三级缓存提高了效率这种说法都是错误的！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>面试官：”Spring是如何解决的循环依赖？“</p><p>答：Spring通过三级缓存解决了循环依赖，其中一级缓存为单例池（<code>singletonObjects</code>）,二级缓存为早期曝光对象<code>earlySingletonObjects</code>，三级缓存为早期曝光对象工厂（<code>singletonFactories</code>）。当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中，如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取，第一步，先获取到三级缓存中的工厂；第二步，调用对象工工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。至此，循环依赖结束！</p><p>面试官：”为什么要使用三级缓存呢？二级缓存能解决循环依赖吗？“</p><p>答：如果要使用二级缓存解决循环依赖，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过<code>AnnotationAwareAspectJAutoProxyCreator</code>这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;什么是循环依赖&quot;&gt;&lt;a href=&quot;#什么是循环依赖&quot; class=&quot;headerlink&quot; title=&quot;什么是循环依赖&quot;&gt;&lt;/a&gt;什么是循环依赖&lt;/h1&gt;&lt;p&gt;字面上理解就是A依赖B的同时，B也依赖了A。&lt;/p&gt;
&lt;p&gt;体现在启动控制台就是以下的日志：&lt;/p&gt;</summary>
      
    
    
    
    
    <category term="Spring" scheme="https://palette-k.github.io/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>销售提成计算引擎实现</title>
    <link href="https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0/"/>
    <id>https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E5%AE%9E%E7%8E%B0/</id>
    <published>2025-05-28T11:28:26.000Z</published>
    <updated>2025-07-09T06:08:24.600Z</updated>
    
    <content type="html"><![CDATA[<h1 id="销售提成计算引擎实现"><a href="#销售提成计算引擎实现" class="headerlink" title="销售提成计算引擎实现"></a>销售提成计算引擎实现</h1><h2 id="1-模块概述"><a href="#1-模块概述" class="headerlink" title="1. 模块概述"></a>1. 模块概述</h2><p>该模块是销售提成计算系统的具体实现层，基于模板方法模式设计，实现了不同业务线（BPO、HRO）的提成计算逻辑。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8c105790c8be2b324e1f4a08f74287ecd5ac54af.png" alt="image-20250709140808203"></p><h2 id="2-目录结构"><a href="#2-目录结构" class="headerlink" title="2. 目录结构"></a>2. 目录结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CopyInsertcalculation/engine/</span><br><span class="line">├── AbstractCalculationEngine.java    # 抽象计算引擎基类</span><br><span class="line">├── CalculationEngine.java           # 计算引擎接口</span><br><span class="line">├── BpoCalculationEngine.java        # BPO业务线计算引擎实现</span><br><span class="line">└── HroCalculationEngine.java        # HRO业务线计算引擎实现</span><br></pre></td></tr></table></figure><h2 id="3-核心组件说明"><a href="#3-核心组件说明" class="headerlink" title="3. 核心组件说明"></a>3. 核心组件说明</h2><h3 id="3-1-计算引擎接口"><a href="#3-1-计算引擎接口" class="headerlink" title="3.1 计算引擎接口"></a>3.1 计算引擎接口</h3><p><code>CalculationEngine</code></p><ul><li><p>定义了计算引擎的基本契约</p></li><li><p>核心方法：</p><ul><li><p><code>calculation(CalculationDto)</code>: 执行业务数据核算</p></li><li><p><code>supportedProductLine()</code>: 声明支持的产品线类型</p></li></ul></li></ul><h3 id="3-2-抽象计算引擎"><a href="#3-2-抽象计算引擎" class="headerlink" title="3.2 抽象计算引擎"></a>3.2 抽象计算引擎</h3><p><code>AbstractCalculationEngine</code></p><ul><li><p>实现了计算引擎的通用逻辑</p></li><li><p>核心功能：</p><ol><li><strong>计算流程控制</strong></li></ol><ul><li><code>calculation(CalculationDto)</code>: 总体计算流程控制<ul><li><code>processCalculation()</code>: 执行具体计算过程</li><li><code>validateCalculationDto()</code>: 验证计算参数</li></ul></li></ul><ol start="2"><li><strong>数据处理</strong><ul><li><code>getDetailData()</code>: 获取业务数据</li><li><code>getBasicSubjectValues()</code>: 获取基础科目值</li><li><code>processTableDataBatch()</code>: 处理单个表数据（in查询批量处理）</li><li><code>setDetailInfoBasicSubjectValues()</code>: 设置明细数据基础科目值</li></ul></li><li><strong>结果处理</strong><ul><li><code>processCalculationResults()</code>: 处理计算结果</li><li><code>writeCalculationDetail()</code>: 写入计算明细</li><li><code>handleCalculationSuccess()</code>: 处理计算成功</li><li><code>handleCalculationFailure()</code>: 处理计算失败</li><li><code>handleErrorResults()</code>: 处理错误结果</li></ul></li></ol></li></ul><h3 id="3-3-具体业务实现"><a href="#3-3-具体业务实现" class="headerlink" title="3.3 具体业务实现"></a>3.3 具体业务实现</h3><h4 id="3-3-1-BPO业务计算引擎"><a href="#3-3-1-BPO业务计算引擎" class="headerlink" title="3.3.1 BPO业务计算引擎"></a>3.3.1 BPO业务计算引擎</h4><p><code>BpoCalculationEngine</code></p><ul><li><p>特点：</p><ul><li><p>继承<code>AbstractCalculationEngine</code></p></li><li><p>实现BPO业务特有的数据获取和处理逻辑</p></li></ul></li><li><p>核心方法：</p><ul><li><p><code>getDetailData()</code>: 获取BPO业务数据</p></li><li><p><code>writeDetailInfo()</code>: 写入BPO计算结果</p></li><li><p><code>supportedProductLine()</code>: 返回BPO产品线标识</p></li></ul></li></ul><h4 id="3-3-2-HRO业务计算引擎"><a href="#3-3-2-HRO业务计算引擎" class="headerlink" title="3.3.2 HRO业务计算引擎"></a>3.3.2 HRO业务计算引擎</h4><p><code>HroCalculationEngine</code></p><ul><li><p>特点：</p><ul><li><p>继承<code>AbstractCalculationEngine</code></p></li><li><p>实现HRO业务特有的数据获取和处理逻辑</p></li></ul></li><li><p>核心方法：</p><ul><li><p><code>getDetailData()</code>: 获取HRO业务数据</p></li><li><p><code>writeDetailInfo()</code>: 写入HRO计算结果</p></li><li><p><code>supportedProductLine()</code>: 返回HRO产品线标识</p></li></ul></li></ul><h2 id="4-核心流程说明"><a href="#4-核心流程说明" class="headerlink" title="4. 核心流程说明"></a>4. 核心流程说明</h2><h3 id="4-1-计算流程"><a href="#4-1-计算流程" class="headerlink" title="4.1 计算流程"></a>4.1 计算流程</h3><ol><li><p>参数验证</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">validateCalculationDto(calculationDto)</span><br></pre></td></tr></table></figure></li><li><p>获取分布式锁</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">RLock</span> <span class="variable">lock</span> <span class="operator">=</span> redissonClient.getLock(RedisConstant.CALCULATION_LOCK_PREFIX + batch.getId());</span><br><span class="line"> <span class="keyword">if</span> (!lock.tryLock()) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BusinessException</span>(<span class="string">&quot;核算进行中，请稍后再试&quot;</span>);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></li><li><p>创建计算任务</p></li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">SysCalculationProcess</span> <span class="variable">process</span> <span class="operator">=</span> calculationProcessService</span><br><span class="line">                .saveProcess(batch.getId(), calculationDto.getProductLineCode());</span><br></pre></td></tr></table></figure><ol start="4"><li>用户登录信息存入上下文</li></ol><p>  因计算过程是异步的，且区分于定时任务调用、用户手动调用，需在核算开始前添加用户登录信息至上下文，核算结束后生成的错误文件明细数据是用户数据权限下的数据。</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 优先从 上下文 获取用户，如果没有再从 ServletUtils 获取</span></span><br><span class="line">      <span class="type">LoginUser</span> <span class="variable">currentUser</span> <span class="operator">=</span>  UserContext.getUser();</span><br><span class="line">      <span class="keyword">if</span> (currentUser == <span class="literal">null</span>) &#123;</span><br><span class="line">          currentUser = ServletUtils.getLoginUser();</span><br><span class="line">      &#125;</span><br><span class="line"> <span class="comment">// 使用装饰器包装任务</span></span><br><span class="line">      taskExecutor.execute(UserContextDecorator.decorate(() -&gt; &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">              processCalculation(calculationDto, batch, process, subjects);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (BusinessException e) &#123;</span><br><span class="line">              handleCalculationFailure(batch, process, e);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">              log.error(<span class="string">&quot;计算过程发生异常：&#123;&#125;&quot;</span>, e.getMessage(), e);</span><br><span class="line">              handleCalculationFailure(batch, process, e);</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">              lock.forceUnlock();</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;, currentUser));</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  用户装饰器类，这里使用了装饰器模式，不修改原有的代码结构的前提下，动态地在异步任务开始前设置用户上下文，异步任务结束后清理用户的上下文。</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">UserContextDecorator</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Runnable delegate;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> LoginUser user;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String taskId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">UserContextDecorator</span><span class="params">(Runnable delegate, LoginUser user)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.delegate = delegate;</span><br><span class="line">        <span class="built_in">this</span>.user = user;</span><br><span class="line">        <span class="comment">// 生成唯一任务ID</span></span><br><span class="line">        <span class="built_in">this</span>.taskId = UUID.randomUUID().toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">threadName</span> <span class="operator">=</span> Thread.currentThread().getName();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Task[&#123;&#125;] setting user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">            <span class="comment">// 前置处理：设置用户上下文</span></span><br><span class="line">            UserContext.setUser(user);</span><br><span class="line">              <span class="comment">// 执行原始任务</span></span><br><span class="line">            delegate.run();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;Task[&#123;&#125;] clearing user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">             <span class="comment">// 后置处理：清理用户上下文</span></span><br><span class="line">            UserContext.clear();</span><br><span class="line">            <span class="comment">// 额外验证确保清理成功</span></span><br><span class="line">            <span class="keyword">if</span> (UserContext.getUser() != <span class="literal">null</span>) &#123;</span><br><span class="line">                log.error(<span class="string">&quot;Task[&#123;&#125;] failed to clear user context in thread: &#123;&#125;&quot;</span>, taskId, threadName);</span><br><span class="line">                <span class="comment">// 再次尝试清理</span></span><br><span class="line">                UserContext.clear();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Runnable <span class="title function_">decorate</span><span class="params">(Runnable task, LoginUser user)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">UserContextDecorator</span>(task, user);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol start="5"><li>获取业务数据</li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">List&lt;DetailData&gt; details = getDetailData(calculationDto)</span><br></pre></td></tr></table></figure><ol start="6"><li><p>获取基础科目值</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Long, Map&lt;String, Object&gt;&gt; basicSubjectValues = getBasicSubjectValues(subjects, details)</span><br></pre></td></tr></table></figure></li><li><p>执行计算</p></li></ol>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 执行计算</span></span><br><span class="line"><span class="type">Calculator</span> <span class="variable">calculator</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Calculator</span>(subjects, details);</span><br><span class="line">List&lt;CalculationResult&gt; results = calculator.calculate();</span><br></pre></td></tr></table></figure><p>  为了提升每次核算的速度，将每条明细数据的核算过程并行处理</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 执行计算过程</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@return</span> 计算结果列表，每个明细一条结果记录</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">public</span> List&lt;CalculationResult&gt; <span class="title function_">calculate</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="comment">// 1. 预先验证所有公式</span></span><br><span class="line">      validateAllMethods();</span><br><span class="line">      <span class="comment">// 2. 使用并行流处理明细</span></span><br><span class="line">      <span class="keyword">return</span> details.parallelStream().map(<span class="built_in">this</span>::calculateDetail).collect(Collectors.toList());</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  每次计算都创建一次计算上下文，计算完成后将计算结果存进内存</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> CalculationResult <span class="title function_">calculateDetail</span><span class="params">(DetailData detail)</span> &#123;</span><br><span class="line">       DefaultContext&lt;String, Object&gt; context = createCalculationContext(detail);</span><br><span class="line">       <span class="type">CalculationResult</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CalculationResult</span>();</span><br><span class="line">       result.setDetailInfoId(detail.getDetailInfoId());</span><br><span class="line">       result.setIsCommissionPaidThisMonth(detail.getIsCommissionPaidThisMonth());</span><br><span class="line">  </span><br><span class="line">       <span class="keyword">for</span> (SysSubject subject : subjects) &#123;</span><br><span class="line">           <span class="type">String</span> <span class="variable">calculationMethod</span> <span class="operator">=</span> subject.getCalculationMethod();</span><br><span class="line">           <span class="keyword">if</span> (StringUtils.isBlank(calculationMethod)) &#123;</span><br><span class="line">               log.warn(<span class="string">&quot;科目计算的公式为空: &#123;&#125;&quot;</span>, subject.getSubjectName());</span><br><span class="line">               <span class="keyword">continue</span>;</span><br><span class="line">           &#125;</span><br><span class="line">  </span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               <span class="comment">// 使用缓存的验证结果</span></span><br><span class="line">               <span class="keyword">if</span> (!methodValidationCache.getOrDefault(calculationMethod, <span class="literal">false</span>)) &#123;</span><br><span class="line">                   <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">BusinessException</span>(String.format(<span class="string">&quot;科目[%s]的计算公式配置错误&quot;</span>, subject.getSubjectName()));</span><br><span class="line">               &#125;</span><br><span class="line">               <span class="type">Object</span> <span class="variable">computed</span> <span class="operator">=</span> calculateSubject(detail, subject, context);</span><br><span class="line">               saveCalculateResult(result, subject, computed);</span><br><span class="line">           &#125; <span class="keyword">catch</span> (BusinessException e) &#123;</span><br><span class="line">               <span class="keyword">throw</span> e;</span><br><span class="line">           &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">               handleCalculationError(detail, subject, result, e);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">  </span><br><span class="line">       <span class="keyword">return</span> result;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>  使用规则引擎进行计算</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 执行单个科目的计算</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> Object <span class="title function_">calculateSubject</span><span class="params">(DetailData detail, SysSubject subject,</span></span><br><span class="line"><span class="params">                                  DefaultContext&lt;String, Object&gt; context)</span> &#123;</span><br><span class="line">      <span class="type">String</span> <span class="variable">method</span> <span class="operator">=</span> subject.getCalculationMethod();</span><br><span class="line">      log.debug(<span class="string">&quot;计算明细表 detail ID: &#123;&#125;, 公式: &#123;&#125;&quot;</span>, detail.getDetailInfoId(), method);</span><br><span class="line">      <span class="type">Object</span> <span class="variable">computed</span> <span class="operator">=</span> QlExpressUtils.computer(method, context);</span><br><span class="line">  </span><br><span class="line">      <span class="comment">// 保留小数位</span></span><br><span class="line">      <span class="keyword">if</span> (subject.getDecimalPlaces() != <span class="literal">null</span> &amp;&amp; computed != <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="type">BigDecimal</span> <span class="variable">bigDecimal</span> <span class="operator">=</span> Convert.toBigDecimal(computed, BigDecimal.ZERO);</span><br><span class="line">          computed = bigDecimal.setScale(subject.getDecimalPlaces(), RoundingMode.HALF_UP);</span><br><span class="line">      &#125;</span><br><span class="line">  </span><br><span class="line">      context.put(subject.getSubjectCode(), computed);</span><br><span class="line">      log.debug(<span class="string">&quot;计算后的上下文: &#123;&#125;&quot;</span>, context);</span><br><span class="line">      <span class="keyword">return</span> computed;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>  使用懒加载模式，只在首次使用时初始化，避免了类加载时的初始化开销，保持了线程安全性</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> Object <span class="title function_">computer</span><span class="params">(String express, DefaultContext&lt;String, Object&gt; context)</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (StringUtils.isBlank(express) || Objects.isNull(context)) &#123;</span><br><span class="line">           <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">       &#125;</span><br><span class="line">       initializeIfNeeded();</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="comment">// 为每个计算创建独立的上下文</span></span><br><span class="line">           DefaultContext&lt;String, Object&gt; localContext = <span class="keyword">new</span> <span class="title class_">DefaultContext</span>&lt;&gt;();</span><br><span class="line">           localContext.putAll(context);</span><br><span class="line">           <span class="keyword">return</span> expressRunner.execute(express, localContext, <span class="literal">null</span>, <span class="literal">true</span>, <span class="literal">false</span>);</span><br><span class="line">       &#125;  <span class="keyword">catch</span> (QLBizException | QLException e) &#123;</span><br><span class="line">           <span class="type">Throwable</span> <span class="variable">cause</span> <span class="operator">=</span> e.getCause();</span><br><span class="line">           <span class="keyword">if</span> (cause != <span class="literal">null</span>) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(cause.getMessage());</span><br><span class="line">           &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e.getMessage());</span><br><span class="line">           &#125;</span><br><span class="line">       &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">           log.error(<span class="string">&quot;计算运算公式：&#123;&#125; 失败，参数为:&#123;&#125;&quot;</span>, express, JSONObject.toJSONString(context));</span><br><span class="line">           log.error(<span class="string">&quot;计算运算失败&quot;</span>, e);</span><br><span class="line">           <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e.getMessage());</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * 使用懒加载单例模式</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">initializeIfNeeded</span><span class="params">()</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (expressRunner == <span class="literal">null</span>) &#123;</span><br><span class="line">          <span class="keyword">synchronized</span> (LOCK) &#123;</span><br><span class="line">              <span class="keyword">if</span> (expressRunner == <span class="literal">null</span>) &#123;</span><br><span class="line">                  <span class="comment">// 优先使用Spring容器中的bean</span></span><br><span class="line">                  <span class="type">ExpressRunner</span> <span class="variable">runner</span> <span class="operator">=</span> SpringUtils.getBean(ExpressRunner.class);</span><br><span class="line">                  <span class="keyword">if</span> (runner == <span class="literal">null</span>) &#123;</span><br><span class="line">                      runner = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().expressRunner();</span><br><span class="line">                  &#125;</span><br><span class="line">                  </span><br><span class="line">                  Map&lt;String, String&gt; defineClass = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().selfDefineClass(runner);</span><br><span class="line">                  </span><br><span class="line">                  <span class="type">ExpressParse</span> <span class="variable">parse</span> <span class="operator">=</span> SpringUtils.getBean(ExpressParse.class);</span><br><span class="line">                  <span class="keyword">if</span> (parse == <span class="literal">null</span>) &#123;</span><br><span class="line">                      parse = <span class="keyword">new</span> <span class="title class_">QlExpressConfig</span>().expressParse(runner);</span><br><span class="line">                  &#125;</span><br><span class="line">                  </span><br><span class="line">                  <span class="comment">// 所有初始化完成后才赋值给静态变量</span></span><br><span class="line">                  expressRunner = runner;</span><br><span class="line">                  selfDefineClass = defineClass;</span><br><span class="line">                  expressParse = parse;</span><br><span class="line">              &#125;</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><ol start="8"><li>处理结果</li></ol><ul><li><p>将批次id写入提成明细</p></li><li><p>写入科目计算结果</p></li><li><p>写入销售提成金额</p></li><li><p>处理错误信息，生成错误文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 第一个事务：处理核心计算结果</span></span><br><span class="line">        transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">            writeDetailInfo(results, batch);</span><br><span class="line">            writeCalculationDetail(results, batch);</span><br><span class="line">            writeSaleCommissionDetail(results, batch);</span><br><span class="line">            handleErrorResults(results, process, calculationDto.getSalaryMonth());</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure></li><li><p>实时生成提成统计，并更改任务状态</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">         <span class="comment">// 第二个事务：处理统计数据</span></span><br><span class="line">         transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">             generateStatisticData(calculationDto);</span><br><span class="line">         &#125;);</span><br><span class="line">         <span class="comment">// 第三个事务：更新状态</span></span><br><span class="line">         transactionTemplate.executeWithoutResult(status -&gt; &#123;</span><br><span class="line">             handleCalculationSuccess(batch, process, subjects);</span><br><span class="line">         &#125;);</span><br><span class="line">     &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">         log.error(<span class="string">&quot;生成统计数据或更新状态失败&quot;</span>, e);</span><br><span class="line">         <span class="comment">// 更新为部分完成状态</span></span><br><span class="line">         handlePartialSuccess(batch, process, subjects, e);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure><h3 id="4-2-错误处理"><a href="#4-2-错误处理" class="headerlink" title="4.2 错误处理"></a>4.2 错误处理</h3><ul><li>计算失败处理  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">handleCalculationFailure(batch, process, exception)</span><br></pre></td></tr></table></figure></li><li>结果错误处理  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">handleErrorResults(results, process)</span><br></pre></td></tr></table></figure></li></ul><h2 id="5-扩展指南"><a href="#5-扩展指南" class="headerlink" title="5. 扩展指南"></a>5. 扩展指南</h2><h3 id="5-1-添加新的业务线"><a href="#5-1-添加新的业务线" class="headerlink" title="5.1 添加新的业务线"></a>5.1 添加新的业务线</h3><ol><li><p>创建新的业务线计算引擎类，继承<code>AbstractCalculationEngine</code></p></li><li><p>实现必要的抽象方法：</p><ul><li><p><code>getDetailData()</code></p></li><li><p><code>writeDetailInfo()</code></p></li><li><p><code>supportedProductLine()</code></p></li></ul></li><li><p>根据业务需求，可能需要重写其他方法</p></li></ol><h3 id="5-2-修改计算逻辑"><a href="#5-2-修改计算逻辑" class="headerlink" title="5.2 修改计算逻辑"></a>5.2 修改计算逻辑</h3><ol><li>核心计算逻辑在<code>processCalculation()</code>方法中</li><li>基础数据处理逻辑在<code>getBasicSubjectValues()</code>方法中</li><li>结果处理逻辑在<code>processCalculationResults()</code>方法中</li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;销售提成计算引擎实现&quot;&gt;&lt;a href=&quot;#销售提成计算引擎实现&quot; class=&quot;headerlink&quot; title=&quot;销售提成计算引擎实现&quot;&gt;&lt;/a&gt;销售提成计算引擎实现&lt;/h1&gt;&lt;h2 id=&quot;1-模块概述&quot;&gt;&lt;a href=&quot;#1-模块概述&quot; class=&quot;</summary>
      
    
    
    
    
    <category term="QlExpress" scheme="https://palette-k.github.io/tags/QlExpress/"/>
    
  </entry>
  
  <entry>
    <title>销售提成合并滚动明细逻辑</title>
    <link href="https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E5%90%88%E5%B9%B6%E6%BB%9A%E5%8A%A8%E6%98%8E%E7%BB%86%E9%80%BB%E8%BE%91/"/>
    <id>https://palette-k.github.io/2025/05/28/%E9%94%80%E5%94%AE%E6%8F%90%E6%88%90%E5%90%88%E5%B9%B6%E6%BB%9A%E5%8A%A8%E6%98%8E%E7%BB%86%E9%80%BB%E8%BE%91/</id>
    <published>2025-05-28T11:28:26.000Z</published>
    <updated>2025-07-09T06:09:21.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="销售提成合并滚动明细逻辑"><a href="#销售提成合并滚动明细逻辑" class="headerlink" title="销售提成合并滚动明细逻辑"></a>销售提成合并滚动明细逻辑</h1><h2 id="滚动明细"><a href="#滚动明细" class="headerlink" title="滚动明细"></a>滚动明细</h2><p>回款金额暂未发完的账单，会滚动到下一个工资月继续发放</p><p><img src="https://i0.hdslb.com/bfs/openplatform/06f807252c94f6304466fed3e58fdd3301fbd9e4.png" alt="image-20250709140851076"></p><h2 id="同步底表"><a href="#同步底表" class="headerlink" title="同步底表"></a>同步底表</h2><p>增量同步BI底表数据，系统自动给本次拉取的数据打上“工资月份”的标识，BPO(T+2),HRO(T+1)。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/2d9552d9da8647d5ce51de4070692878b2540d24.png" alt="image-20250709140905455"></p><h2 id="合并明细"><a href="#合并明细" class="headerlink" title="合并明细"></a>合并明细</h2><p>合并时注意需保留用户编辑后的数据，部分字段需延用（自动带出）上个账单月的数值。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/f43b2dc9cf0ae59d05e87d0fccf45dbf0230156f.png" alt="image-20250709140920033"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;销售提成合并滚动明细逻辑&quot;&gt;&lt;a href=&quot;#销售提成合并滚动明细逻辑&quot; class=&quot;headerlink&quot; title=&quot;销售提成合并滚动明细逻辑&quot;&gt;&lt;/a&gt;销售提成合并滚动明细逻辑&lt;/h1&gt;&lt;h2 id=&quot;滚动明细&quot;&gt;&lt;a href=&quot;#滚动明细&quot; cla</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>常用的缓存组件Redis是如何运行的</title>
    <link href="https://palette-k.github.io/2025/02/24/%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E7%BB%84%E4%BB%B6Redis%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E7%9A%84/"/>
    <id>https://palette-k.github.io/2025/02/24/%E5%B8%B8%E7%94%A8%E7%9A%84%E7%BC%93%E5%AD%98%E7%BB%84%E4%BB%B6Redis%E6%98%AF%E5%A6%82%E4%BD%95%E8%BF%90%E8%A1%8C%E7%9A%84/</id>
    <published>2025-02-24T02:17:00.000Z</published>
    <updated>2025-08-28T03:43:29.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h1><p>Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组件，它的所有数据结构都存在内存中，可以用作缓存、数据库和消息中间件。</p><p>Redis 是 Remote dictionary server 即远程字典服务的缩写，一个 Redis 实例可以有多个存储数据的字典，客户端可以通过 select 来选择字典即 DB 进行数据存储。</p><h1 id="Redis核心数据类型"><a href="#Redis核心数据类型" class="headerlink" title="Redis核心数据类型"></a>Redis核心数据类型</h1><p>同为 key-value 存储组件，Memcached 只能支持二进制字节块这一种数据类型。而 Redis 的数据类型却丰富的多，它具有 8 种核心数据类型，每种数据类型都有一系列操作指令对应。</p><p>首先，来看一下 Redis 的核心数据类型。Redis 有 8 种核心数据类型，分别是 ：</p><ul><li>string 字符串类型；</li><li>list 列表类型；</li><li>set 集合类型；</li><li>sorted set 有序集合类型；</li><li>hash 类型；</li><li>bitmap 位图类型；</li><li>geo 地理位置类型；</li><li>HyperLogLog 基数统计类型。</li></ul><h2 id="string-字符串"><a href="#string-字符串" class="headerlink" title="string 字符串"></a>string 字符串</h2><p>string 是 Redis 的最基本数据类型。可以把它理解为 Mc 中 key 对应的 value 类型。string 类型是二进制安全的，即 string 中可以包含任何数据。</p><p>Redis 中的普通 string 采用 raw encoding 即原始编码方式，该编码方式会动态扩容，并通过提前预分配冗余空间，来减少内存频繁分配的开销。</p><p>在字符串长度小于 1MB 时，按所需长度的 2 倍来分配，超过 1MB，则按照每次额外增加 1MB 的容量来预分配。</p><p>Redis 中的数字也存为 string 类型，但编码方式跟普通 string 不同，数字采用整型编码，字符串内容直接设为整数值的二进制字节序列。</p><p><strong>需要存储常规数据的场景</strong></p><ul><li>举例 ：缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。</li><li>相关命令 ： <code>SET</code>、<code>GET</code>、<code>MSET</code>、<code>INCR</code>、<code>DECR</code>。</li><li>项目相关：jwt + Redis 的 token 存储，在 Redis 上可实现登录过期失效即登出功能</li></ul><p><strong>需要计数的场景</strong></p><ul><li>举例 ：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。</li><li>相关命令 ：<code>SET</code>、<code>GET</code>、 <code>INCR</code>、<code>DECR</code> 。</li></ul><h2 id="List列表"><a href="#List列表" class="headerlink" title="List列表"></a>List列表</h2><p>Redis 的 list 列表，是一个快速双向链表，存储了一系列的 string 类型的字串值。list 中的元素按照插入顺序排列。插入元素的方式，可以通过 lpush 将一个或多个元素插入到列表的头部，也可以通过 rpush 将一个或多个元素插入到队列尾部，还可以通过 lset、linsert 将元素插入到指定位置或指定元素的前后。</p><p>feed timeline 存储时，由于 feed id 一般是递增的，可以直接存为 list，用户发表新 feed，就直接追加到队尾。另外消息队列、热门 feed 等业务场景，都可以使用 list 数据结构。</p><p><strong>信息流展示</strong></p><ul><li>举例 ：最新文章、最新动态。</li><li>相关命令 ： <code>LPUSH</code>、<code>LRANGE</code>。</li><li>项目相关：漫画项目中，对优惠活动场次的存储，key为起止时间，对应的活动中涉及到的产品idList为value</li></ul><h2 id="set-集合"><a href="#set-集合" class="headerlink" title="set 集合"></a>set 集合</h2><p>set 是 string 类型的无序集合，set 中的元素是唯一的，即 set 中不会出现重复的元素。Redis 中的集合一般是通过 dict 哈希表实现的，所以插入、删除，以及查询元素，可以根据元素 hash 值直接定位，时间复杂度为 O(1)。</p><p>set 集合的特点是查找、插入、删除特别高效，时间复杂度为 O(1)，所以在社交系统中，可以用于存储关注的好友列表，用来判断是否关注，还可以用来做好友推荐使用。另外，还可以利用 set 的唯一性，来对服务的来源业务、来源 IP 进行精确统计。</p><p><strong>需要存放的数据不能重复的场景</strong></p><ul><li>举例：网站 UV 统计（数据量巨大的场景还是 <code>HyperLogLog</code>更适合一些）、文章点赞、动态点赞等场景。</li><li>相关命令：<code>SCARD</code>（获取集合数量） 。</li></ul><p><strong>需要获取多个数据源交集、并集和差集的场景</strong></p><ul><li>举例 ：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集） 、订阅号推荐（差集+交集） 等场景。</li><li>相关命令：<code>SINTER</code>（交集）、<code>SINTERSTORE</code> （交集）、<code>SUNION</code> （并集）、<code>SUNIONSTORE</code>（并集）、<code>SDIFF</code>（差集）、<code>SDIFFSTORE</code> （差集）。</li></ul><h2 id="Sorted-Set（有序集合）"><a href="#Sorted-Set（有序集合）" class="headerlink" title="Sorted Set（有序集合）"></a>Sorted Set（有序集合）</h2><p>Redis 中的 sorted set 有序集合也称为 zset，有序集合同 set 集合类似，也是 string 类型元素的集合，且所有元素不允许重复。</p><p>但有序集合中，每个元素都会关联一个 double 类型的 score 分数值。有序集合通过这个 score 值进行由小到大的排序。有序集合中，元素不允许重复，但 score 分数值却允许重复。</p><p><strong>需要随机获取数据源中的元素根据某个权重进行排序的场景</strong></p><ul><li>举例 ：各种排行榜比如直播间送礼物的排行榜、朋友圈的微信步数排行榜、王者荣耀中的段位排行榜、话题热度排行榜等等。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><p><strong>需要存储的数据有优先级或者重要程度的场景</strong> 比如优先级任务队列。</p><ul><li>举例 ：优先级任务队列。</li><li>相关命令 ：<code>ZRANGE</code> (从小到大排序) 、 <code>ZREVRANGE</code> （从大到小排序）、<code>ZREVRANK</code> (指定元素排名)。</li></ul><h2 id="Hash（哈希）"><a href="#Hash（哈希）" class="headerlink" title="Hash（哈希）"></a>Hash（哈希）</h2><p>Redis 中的哈希实际是 field 和 value 的一个映射表。</p><p>hash 数据结构的特点是在单个 key 对应的哈希结构内部，可以记录多个键值对，即 field 和 value 对，value 可以是任何字符串。而且这些键值对查询和修改很高效。</p><p><strong>对象数据存储场景</strong></p><ul><li>举例 ：用户信息、商品信息、文章信息、购物车信息。</li><li>相关命令 ：<code>HSET</code> （设置单个字段的值）、<code>HMSET</code>（设置多个字段的值）、<code>HGET</code>（获取单个字段的值）、<code>HMGET</code>（获取多个字段的值）。</li><li>项目相关：存储产品的详细信息，key为固定字符串（即说明是优惠活动上架的商品信息），field为活动id-产品id，value为序列化后的对象（产品的数量名字起止时间等等，包括设置该产品的随机码（UUID），防恶意攻击）</li></ul><h2 id="Bitmap-位图"><a href="#Bitmap-位图" class="headerlink" title="Bitmap 位图"></a>Bitmap 位图</h2><p>Bitmap 存储的是连续的二进制数字（0 和 1），通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。</p><p>你可以将 Bitmap 看作是一个存储二进制数字（0 和 1）的数组，数组中每个元素的下标叫做 offset（偏移量）。</p><p><strong>需要保存状态信息（0&#x2F;1 即可表示）的场景</strong></p><ul><li>举例 ：用户签到情况、活跃用户情况、用户行为统计（比如是否点赞过某个视频）。</li><li>相关命令 ：<code>SETBIT</code>、<code>GETBIT</code>、<code>BITCOUNT</code>、<code>BITOP</code>。</li></ul><blockquote><p>使用 Bitmap 统计活跃用户怎么做？</p></blockquote><p>使用日期（精确到天）作为 key，然后用户 ID 为 offset，如果当日活跃过就设置为 1。</p><p>初始化数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; SETBIT 20210308 1 1</span><br><span class="line">(integer) 0</span><br><span class="line">&gt; SETBIT 20210308 2 1</span><br><span class="line">(integer) 0</span><br><span class="line">&gt; SETBIT 20210309 1 1</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure><p>统计 20210308~20210309 总活跃用户数:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; BITOP and desk1 20210308 20210309</span><br><span class="line">(integer) 1</span><br><span class="line">&gt; BITCOUNT desk1</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>统计 20210308~20210309 在线活跃用户数:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; BITOP or desk2 20210308 20210309</span><br><span class="line">(integer) 1</span><br><span class="line">&gt; BITCOUNT desk2</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><h2 id="hyperLogLog-基数统计"><a href="#hyperLogLog-基数统计" class="headerlink" title="hyperLogLog 基数统计"></a>hyperLogLog 基数统计</h2><p>Redis 提供的 HyperLogLog 占用空间非常非常小，只需要 12k 的空间就能存储接近<code>2^64</code>个不同元素。这是真的厉害，这就是数学的魅力么！并且，Redis 对 HyperLogLog 的存储结构做了优化，采用两种方式计数：</p><ul><li><strong>稀疏矩阵</strong> ：计数较少的时候，占用空间很小。</li><li><strong>稠密矩阵</strong> ：计数达到某个阈值的时候，占用 12k 的空间。</li></ul><p>基数计数概率算法为了节省内存并不会直接存储元数据，而是通过一定的概率统计方法预估基数值（集合中包含元素的个数）。因此， HyperLogLog 的计数结果并不是一个精确值，存在一定的误差（标准误差为 <code>0.81%</code> 。）。</p><p><strong>数量量巨大（百万、千万级别以上）的计数场景</strong></p><ul><li>举例 ：热门网站每日&#x2F;每周&#x2F;每月访问 ip 数统计、热门帖子 uv 统计、</li><li>相关命令 ：<code>PFADD</code>、<code>PFCOUNT</code> 。</li></ul><h2 id="Geospatial-index"><a href="#Geospatial-index" class="headerlink" title="Geospatial index"></a>Geospatial index</h2><p>Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。</p><p>通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。</p><p><strong>需要管理使用地理空间数据的场景</strong></p><ul><li>举例：附近的人。</li><li>相关命令: <code>GEOADD</code>、<code>GEORADIUS</code>、<code>GEORADIUSBYMEMBER</code></li></ul><h2 id="Redis使用规范小建议"><a href="#Redis使用规范小建议" class="headerlink" title="Redis使用规范小建议"></a>Redis使用规范小建议</h2><h3 id="键值对使用规范"><a href="#键值对使用规范" class="headerlink" title="键值对使用规范"></a>键值对使用规范</h3><p><strong>key命名规范</strong>：通过 key 的前缀区分不同的业务数据，可以使用相应的英文单词的首字母表示（ key 字符串的长度增加时，SDS 中的元数据也会占用更多内存空间）</p><p><strong>避免使用bigKey</strong>：Redis 是使用单线程读写数据，bigkey 的读写操作会阻塞线程。</p><ul><li>情况一：键值对的值大小本身就很大，例如 value 为 1MB 的 String 类型数据。为了避免 String 类型的 bigkey，在业务层，我们要尽量把 String 类型的数据大小控制在 10KB 以下。</li><li>情况二：键值对的值是集合类型，集合元素个数非常多，例如包含 100 万个元素的 Hash 集合类型数据。为了避免集合类型的 bigkey，我给你的设计规范建议是，<strong>尽量把集合类型的元素个数控制在 1 万以下</strong>。</li></ul><p><strong>使用高效序列化方法和压缩方法</strong>：Redis 中的字符串都是使用二进制安全的字节数组来保存的，所以，我们可以把业务数据序列化成二进制数据写入到 Redis 中。</p><p><strong>使用整数对象共享池</strong>：整数是常用的数据类型，Redis 内部维护了 0 到 9999 这 1 万个整数对象，并把这些整数作为一个共享池使用。</p><p>那什么时候不能用整数对象共享池呢？主要有两种情况。</p><p>第一种情况是，<strong>如果 Redis 中设置了 maxmemory，而且启用了 LRU 策略（allkeys-lru 或 volatile-lru 策略），那么，整数对象共享池就无法使用了</strong>。这是因为，LRU 策略需要统计每个键值对的使用时间，如果不同的键值对都共享使用一个整数对象，LRU 策略就无法进行统计了。</p><p>第二种情况是，如果集合类型数据采用 ziplist 编码，而集合元素是整数，这个时候，也不能使用共享池。因为 ziplist 使用了紧凑型内存结构，判断整数对象的共享情况效率低。</p><h3 id="数据保存规范"><a href="#数据保存规范" class="headerlink" title="数据保存规范"></a>数据保存规范</h3><ul><li>使用redis保存热数据</li><li>不同业务数据分实例存储</li><li>数据保存时设置过期时间</li><li>控制Redis实例的容量：设置在 2~6GB</li></ul><h3 id="命令使用规范"><a href="#命令使用规范" class="headerlink" title="命令使用规范"></a>命令使用规范</h3><ol><li>线上禁用部分命令：<ul><li><strong>KEYS</strong>，按照键值对的 key 内容进行匹配，返回符合匹配条件的键值对，该命令需要对 Redis 的全局哈希表进行全表扫描，严重阻塞 Redis 主线程；</li><li><strong>FLUSHALL</strong>，删除 Redis 实例上的所有数据，如果数据量很大，会严重阻塞 Redis 主线程；</li><li><strong>FLUSHDB</strong>，删除当前数据库中的数据，如果数据量很大，同样会阻塞 Redis 主线程。</li></ul></li></ol><p>对于 KEYS 命令来说，你可以用 SCAN 命令代替 KEYS 命令。</p><p>对于FLUSHALL、FLUSHDB命令来说，可以加上ASYNC选项，让这两个命令使用后台线程异步删除数据。</p><ol start="2"><li><p>慎用 MONITOR 命令</p><p>Redis 的 MONITOR 命令在执行后，会持续输出监测到的各个命令操作。如果线上命令的操作很多，输出缓冲区很快就会溢出了，这就会对 Redis 性能造成影响，甚至引起服务崩溃。</p></li><li><p>慎用全量操作命令</p><p> Hash 类型的 HGETALL、Set 类型的 SMEMBERS。这些操作会对 Hash 和 Set 类型的底层数据结构进行全量扫描，如果集合类型数据较多的话，就会阻塞 Redis 主线程。</p><p>如果想要获得集合类型的全量数据，我给你三个小建议。</p><ul><li>你可以使用 SSCAN、HSCAN 命令分批返回集合中的数据，减少对主线程的阻塞。</li><li>你可以化整为零，把一个大的 Hash 集合拆分成多个小的 Hash 集合。这个操作对应到业务层，就是对业务数据进行拆分，按照时间、地域、用户 ID 等属性把一个大集合的业务数据拆分成多个小集合数据。例如，当你统计用户的访问情况时，就可以按照天的粒度，把每天的数据作为一个 Hash 集合。</li><li>最后一个建议是，如果集合类型保存的是业务数据的多个属性，而每次查询时，也需要返回这些属性，那么，你可以使用 String 类型，将这些属性序列化后保存，每次直接返回 String 数据就行，不用再对集合类型做全量扫描了。</li></ul></li></ol><h1 id="Redis存储结构"><a href="#Redis存储结构" class="headerlink" title="Redis存储结构"></a>Redis存储结构</h1><p>Redis 中所有数据都保存在 DB 中，一个 Redis 默认最多支持 16 个 DB。Redis 中的每个 DB 都对应一个 redisDb 结构，即每个 Redis 实例，默认有 16 个 redisDb。用户访问时，默认使用的是 0 号 DB，可以通过 select $dbID 在不同 DB 之间切换。</p><p>redisDb 主要包括 2 个核心 dict 字典、3 个非核心 dict 字典、dbID 和其他辅助属性。2 个核心 dict 包括一个 dict 主字典和一个 expires 过期字典。主 dict 字典用来存储当前 DB 中的所有数据，它将 key 和各种数据类型的 value 关联起来，该 dict 也称 key space。过期字典用来存储过期时间 key，存的是 key 与过期时间的映射。日常的数据存储和访问基本都会访问到 redisDb 中的这两个 dict。</p><p>Redis 的所有内存数据结构都存在全局的 dict 字典中，dict 类似 Memcached 的 hashtable。Redis 的 dict 也有 2 个哈希表，插入新 key 时，一般用 0 号哈希表，随着 key 的插入或删除，当 0 号哈希表的 keys 数大于哈希表桶数，或 kyes 数小于哈希桶的 1⁄10 时，就对 hash 表进行扩缩。dict 中，哈希表解决冲突的方式，与 Memcached 相同，也是使用桶内单链表，来指向多个 hash 相同的 key&#x2F;value 数据。</p><h1 id="Redis淘汰key"><a href="#Redis淘汰key" class="headerlink" title="Redis淘汰key"></a>Redis淘汰key</h1><h2 id="淘汰原理"><a href="#淘汰原理" class="headerlink" title="淘汰原理"></a>淘汰原理</h2><p>当 key 过期后，或者 Redis 实际占用的内存超过阀值后，Redis 就会对 key 进行淘汰，删除过期的或者不活跃的 key，回收其内存，供新的 key 使用。Redis 的内存阀值是通过 maxmemory 设置的，而超过内存阀值后的淘汰策略，是通过 maxmemory-policy 设置的。</p><p>Redis 会在 2 种场景下对 key 进行淘汰，第一种是在定期执行 serverCron 时，检查淘汰 key；第二种是在执行命令时，检查淘汰 key。</p><ul><li><p>第一种场景，Redis 定期执行 serverCron 时，会对 DB 进行检测，清理过期 key。</p><p>清理流程如下。首先轮询每个 DB，检查其 expire dict，即带过期时间的过期 key 字典，从所有带过期时间的 key 中，随机选取 20 个样本 key，检查这些 key 是否过期，如果过期则清理删除。如果 20 个样本中，超过 5 个 key 都过期，即过期比例大于 25%，就继续从该 DB 的 expire dict 过期字典中，再随机取样 20 个 key 进行过期清理，持续循环，直到选择的 20 个样本 key 中，过期的 key 数小于等于 5，当前这个 DB 则清理完毕，然后继续轮询下一个 DB。</p><p>在执行 serverCron 时，如果在某个 DB 中，过期 dict 的填充率低于 1%，则放弃对该 DB 的取样检查，因为效率太低。如果 DB 的过期 dict 中，过期 key 太多，一直持续循环回收，会占用大量主线程时间，所以 Redis 还设置了一个过期时间。这个过期时间根据 serverCron 的执行频率来计算，5.0 版本及之前采用慢循环过期策略，默认是 25ms，如果回收超过 25ms 则停止，6.0 非稳定版本采用快循环策略，过期时间为 1ms。</p></li><li><p>第二种场景，Redis 在执行命令请求时。会检查当前内存占用是否超过 maxmemory 的数值，如果超过，则按照设置的淘汰策略，进行删除淘汰 key 操作。</p></li></ul><h2 id="淘汰方式"><a href="#淘汰方式" class="headerlink" title="淘汰方式"></a>淘汰方式</h2><p>Redis 中 key 的淘汰方式有两种，分别是同步删除淘汰和异步删除淘汰。</p><p><strong>异步删除淘汰：</strong>在 serverCron 定期清理过期 key 时，如果设置了延迟过期配置 lazyfree-lazy-expire，会检查 key 对应的 value 是否为多元素的复合类型，即是否是 list 列表、set 集合、zset 有序集合和 hash 中的一种，并且 value 的元素数大于 64，则在将 key 从 DB 中 expire dict 过期字典和主 dict 中删除后，value 存放到 BIO 任务队列，由 BIO 延迟删除线程异步回收；</p><p><strong>同步删除淘汰：</strong>否则，直接从 DB 的 expire dict 和主 dict 中删除，并回收 key、value 所占用的空间。</p><h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><p>Redis 提供了 8 种 maxmemory_policy 淘汰策略来应对内存超过阀值的情况。</p><p>第一种淘汰策略是 noeviction，它是 Redis 的默认策略。在内存超过阀值后，Redis 不做任何清理工作，然后对所有写操作返回错误，但对读请求正常处理。noeviction 适合数据量不大的业务场景，将关键数据存入 Redis 中，将 Redis 当作 DB 来使用。</p><p>第二种淘汰策略是 volatile-lru，它对带过期时间的 key 采用最近最少访问算法来淘汰。使用这种策略，Redis 会从 redisDb 的 expire dict 过期字典中，首先随机选择 N 个 key，计算 key 的空闲时间，然后插入 evictionPool 中，最后选择空闲时间最久的 key 进行淘汰。这种策略适合的业务场景是，需要淘汰的key带有过期时间，且有冷热区分，从而可以淘汰最久没有访问的key。</p><p>第三种策略是 volatile-lfu，它对带过期时间的 key 采用最近最不经常使用的算法来淘汰。使用这种策略时，Redis 会从 redisDb 中的 expire dict 过期字典中，首先随机选择 N 个 key，然后根据其 value 的 lru 值，计算 key 在一段时间内的使用频率相对值。对于 lfu，要选择使用频率最小的 key，为了沿用 evictionPool 的 idle 概念，Redis 在计算 lfu 的 Idle 时，采用 255 减去使用频率相对值，从而确保 Idle 最大的 key 是使用次数最小的 key，计算 N 个 key 的 Idle 值后，插入 evictionPool，最后选择 Idle 最大，即使用频率最小的 key，进行淘汰。这种策略也适合大多数 key 带过期时间且有冷热区分的业务场景。</p><p>第四种策略是 volatile-ttl，它是对带过期时间的 key 中选择最早要过期的 key 进行淘汰。使用这种策略时，Redis 也会从 redisDb 的 expire dict 过期字典中，首先随机选择 N 个 key，然后用最大无符号 long 值减去 key 的过期时间来作为 Idle 值，计算 N 个 key 的 Idle 值后，插入evictionPool，最后选择 Idle 最大，即最快就要过期的 key，进行淘汰。这种策略适合，需要淘汰的key带过期时间，且有按时间冷热区分的业务场景。</p><p>第五种策略是 volatile-random，它是对带过期时间的 key 中随机选择 key 进行淘汰。使用这种策略时，Redis 从 redisDb 的 expire dict 过期字典中，随机选择一个 key，然后进行淘汰。如果需要淘汰的key有过期时间，没有明显热点，主要被随机访问，那就适合选择这种淘汰策略。</p><p>第六种策略是 allkey-lru，它是对所有 key，而非仅仅带过期时间的 key，采用最近最久没有使用的算法来淘汰。这种策略与 volatile-lru 类似，都是从随机选择的 key 中，选择最长时间没有被访问的 key 进行淘汰。区别在于，volatile-lru 是从 redisDb 中的 expire dict 过期字典中选择 key，而 allkey-lru 是从所有的 key 中选择 key。这种策略适合，需要对所有 key 进行淘汰，且数据有冷热读写区分的业务场景。</p><p><img src="https://i0.hdslb.com/bfs/article/4e748a17cf32172b6cb126927350db7e171301454.png" alt="image-20250226170831894"></p><p>第七种策略是 allkeys-lfu，它也是针对所有 key 采用最近最不经常使用的算法来淘汰。这种策略与 volatile-lfu 类似，都是在随机选择的 key 中，选择访问频率最小的 key 进行淘汰。区别在于，volatile-flu从expire dict 过期字典中选择 key，而 allkeys-lfu 是从主 dict 中选择 key。这种策略适合的场景是，需要从所有的 key 中进行淘汰，但数据有冷热区分，且越热的数据访问频率越高。</p><p>最后一种策略是 allkeys-random，它是针对所有 key 进行随机算法进行淘汰。它也是从主 dict 中随机选择 key，然后进行删除回收。如果需要从所有的 key 中进行淘汰，并且 key 的访问没有明显热点，被随机访问，即可采用这种策略。</p><h1 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h1><p>Redis 的持久化是通过 RDB 和 AOF 文件进行的。</p><ul><li>RDB 只记录某个时间点的快照，可以通过设置指定时间内修改 keys 数的阀值，超过则自动构建 RDB 内容快照，不过线上运维，一般会选择在业务低峰期定期进行。RDB 存储的是构建时刻的数据快照，内存数据一旦落地，不会理会后续的变更。</li><li>AOF，记录是构建整个数据库内容的命令，它会随着新的写操作不断进行追加操作。由于不断追加，AOF 会记录数据大量的中间状态，AOF 文件会变得非常大，此时，可以通过 bgrewriteaof 指令，对 AOF 进行重写，只保留数据的最后内容，来大大缩减 AOF 的内容。</li></ul><h2 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h2><p>触发构建 RDB 的场景主要有以下四种。</p><ol><li>第一种场景是通过 save 或 bgsave 命令进行主动 RDB 快照构建。它是由调用方调用 save 或 bgsave 指令进行触发的。</li><li>第二种场景是利用配置 save m n 来进行自动快照生成。它是指在 m 秒中，如果插入或变更 n 个 key，则自动触发 bgsave。这个配置可以设置多个配置行，以便组合使用。由于峰值期间，Redis 的压力大，变更的 key 也比较多，如果再进行构建 RDB 的操作，会进一步增加机器负担，对调用方请求会有一定的影响，所以线上使用时需要谨慎。</li><li>第三种场景是主从复制，如果从库需要进行全量复制，此时主库也会进行 bgsave 生成一个 RDB 快照。</li><li>第四种场景是在运维执行 flushall 清空所有数据，或执行 shutdown 关闭服务时，也会触发 Redis 自动构建 RDB 快照。</li></ol><p>save 是在主进程中进行 RDB 持久化的，持久化期间 Redis 处于阻塞状态，不处理任何客户请求，所以一般使用较少。而 bgsave 是 fork 一个子进程，然后在子进程中构建 RDB 快照，构建快照的过程不直接影响用户的访问，但仍然会增加机器负载。线上 Redis 快照备份，一般会选择凌晨低峰时段，通过 bgsave 主动触发进行备份。</p><p>RDB 快照文件主要由 3 部分组成。</p><ol><li>第一部分是 RDB 头部，主要包括 RDB 的版本，以及 Redis 版本、创建日期、占用内存等辅助信息。</li><li>第二部分是各个 RedisDB 的数据。存储每个 RedisDB 时，会首先记录当前 RedisDB 的DBID，然后记录主 dict 和 expire dict 的记录数量，最后再轮询存储每条数据记录。存储数据记录时，如果数据有过期时间，首先记录过期时间。如果 Redis 的 maxmemory_policy 过期策略采用 LRU 或者 LFU，还会将 key 对应的 LRU、LFU 值进行落地，最后记录数据的类型、key，以及 value。</li><li>第三部部分是 RDB 的尾部。RDB 尾部，首先存储 Redis 中的 Lua 脚本等辅助信息。然后存储 EOF 标记，即值为 255 的字符。最后存 RDB 的 cksum。</li></ol><p>RDB 采用二进制方式存储内存数据，文件小，且启动时恢复速度快。但构建 RDB 时，一个快照文件只能存储，构建时刻的内存数据，无法记录之后的数据变更。构建 RDB 的过程，即便在子进程中进行，但仍然属于 CPU 密集型的操作，而且每次落地全量数据，耗时也比较长，不能随时进行，特别是不能在高峰期进行。由于 RDB 采用二进制存储，可读性差，而且由于格式固定，不同版本之间可能存在兼容性问题。</p><h2 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h2><p>Redis 的 AOF 持久化是以命令追加的方式进行数据落地的。通过打开 appendonly 配置，Redis 将每一个写指令追加到磁盘 AOF 文件，从而及时记录内存数据的最新状态。这样即便 Redis 被 crash 或异常关闭后，再次启动，也可以通过加载 AOF，来恢复最新的全量数据，基本不会丢失数据。</p><p>AOF 文件中存储的协议是写指令的 multibulk 格式，这是 Redis 的标准协议格式，所以不同的 Redis 版本均可解析并处理，兼容性很好。</p><p>但是，由于 Redis 会记录所有写指令操作到 AOF，大量的中间状态数据，甚至被删除的过期数据，都会存在 AOF 中，冗余度很大，而且每条指令还需通过加载和执行来进行数据恢复，耗时会比较大。</p><p>AOF 数据的落地流程如下。Redis 在处理完写指令后，首先将写指令写入 AOF 缓冲，然后通过 server_cron 定期将 AOF 缓冲写入文件缓冲。最后按照配置策略进行 fsync，将文件缓冲的数据真正同步写入磁盘。</p><p><img src="https://i0.hdslb.com/bfs/article/8432570784b531c74bc5418d935c0abc171301454.png" alt="image-20250303101943498"></p><p>Redis 通过 appendfsync 来设置三种不同的同步文件缓冲策略。</p><ol><li>第一种配置策略是 no，即 Redis 不主动使用 fsync 进行文件数据同步落地，而是由操作系统的 write 函数去确认同步时间，在 Linux 系统中大概每 30 秒会进行一次同步，如果 Redis 发生 crash，就会造成大量的数据丢失。</li><li>第二种配置策略是 always，即每次将 AOF 缓冲写入文件，都会调用 fsync 强制将内核数据写入文件，安全性最高，但性能上会比较低效，而且由于频繁的 IO 读写，磁盘的寿命会大大降低。</li><li>第三种配置策略是 everysec。即每秒通过 BIO 线程进行一次 fsync。这种策略在安全性、性能，以及磁盘寿命之间做较好的权衡，可以较好的满足线上业务需要。</li></ol><p>随着时间的推移，AOF 持续记录所有的写指令，AOF 会越来越大，而且会充斥大量的中间数据、过期数据，为了减少无效数据，提升恢复时间，可以定期对 AOF 进行 rewrite 操作。</p><p>AOF 的 rewrite 操作可以通过运维执行 bgrewiretaof 命令来进行，也可以通过配置重写策略进行，由 Redis 自动触发进行。当对 AOF 进行 rewrite 时，首先会 fork 一个子进程。子进程轮询所有 RedisDB 快照，将所有内存数据转为 cmd，并写入临时文件。在子进程 rewriteaof 时，主进程可以继续执行用户请求，执行完毕后将写指令写入旧的 AOF 文件和 rewrite 缓冲。子进程将 RedisDB 中数据落地完毕后，通知主进程。主进程从而将 AOF rewite 缓冲数据写入 AOF 临时文件，然后用新的 AOF 文件替换旧的 AOF 文件，最后通过 BIO 线程异步关闭旧的 AOF 文件。至此，AOF 的 rewrite 过程就全部完成了。</p><p>AOF 持久化的优势是可以记录全部的最新内存数据，最多也就是 1-2 秒的数据丢失。同时 AOF 通过 Redis 协议来追加记录数据，兼容性高，而且可以持续轻量级的保存最新数据。最后因为是直接通过 Redis 协议存储，可读性也比较好。</p><h2 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h2><p>Redis 在 4.0 版本之后，引入了混合持久化方式，而且在 5.0 版本后默认开启。前面讲到 RDB 加载速度快，但构建慢，缺少最新数据。AOF 持续追加最新写记录，可以包含所有数据，但冗余大，加载速度慢。混合模式一体化使用 RDB 和 AOF，综合 RDB 和 AOF 的好处。即可包含全量数据，加载速度也比较快。可以使用 aof-use-rdb-preamble 配置来明确打开混合持久化模式。</p><p>混合持久化也是通过 bgrewriteaof 来实现的。当启用混合存储后，进行 bgrewriteaof 时，主进程首先依然是 fork 一个子进程，子进程首先将内存数据以 RDB 的二进制格式写入 AOF 临时文件中。然后，再将落地期间缓冲的新增写指令，以命令的方式追加到临时文件。然后再通知主进程落地完毕。主进程将临时文件修改为 AOF 文件，并关闭旧的 AOF 文件。这样主体数据以 RDB 格式存储，新增指令以命令方式追加的混合存储方式进行持久化。后续执行的任务，以正常的命令方式追加到新的 AOF 文件即可。</p><p>混合持久化综合了 RDB 和 AOF 的优缺点，优势是包含全量数据，加载速度快。不足是头部的 RDB 格式兼容性和可读性较差。</p><p><img src="https://i0.hdslb.com/bfs/article/e866239a20926c53ef4056bc353957b2171301454.png" alt="image-20250226175656070"></p><p>为了提升系统的可扩展性，提升读操作的支撑能力，Redis 支持 master-slave 的复制功能。当 Redis 的 slave 部署并设置完毕后，slave 会和 master 建立连接，进行全量同步。</p><p>第一次建立连接，或者长时间断开连接后，缺失的指令超过 master 复制缓冲区的大小，都需要先进行一次全量同步。全量同步时，master 会启动一个子进程，将数据库快照保存到文件中，然后将这个快照文件发给 slave，同时将快照之后的写指令也同步给 slave。</p><p>全量同步完成后，如果 slave 短时间中断，然后重连复制，缺少的写指令长度小于 master 的复制缓冲大小，master 就会把 slave 缺失的内容全部发送给 slave，进行增量复制。</p><p>Redis 的 master 可以挂载多个 slave，同时 slave 还可以继续挂载 slave，通过这种方式，可以有效减轻 master 的压力，同时在 master 挂掉后，可以在 slave 通过 slaveof no one 指令，使当前 slave 停止与 master 的同步，转而成为新的 master。</p><h1 id="Redis高性能"><a href="#Redis高性能" class="headerlink" title="Redis高性能"></a>Redis高性能</h1><p>Redis 性能很高，单线程压测可以达到 10~11w 的 QPS。</p><p>Redis 一般被看作单进程&#x2F;单线程组件，因为 Redis 的网络 IO 和命令处理，都在核心进程中由单线程处理。Redis 基于 Epoll 事件模型开发，可以进行非阻塞网络 IO，同时由于单线程命令处理，整个处理过程不存在竞争，不需要加锁，没有上下文切换开销，所有数据操作都是在内存中操作，所以 Redis 的性能很高，单个实例即可以达到 10w 级的 QPS。核心线程除了负责网络 IO 及命令处理外，还负责写数据到缓冲，以方便将最新写操作同步到 AOF、slave。</p><ul><li>收到 bgrewriteaof 命令时，Redis 调用 fork，构建一个子进程，子进程往临时 AOF文件中，写入重建数据库状态的所有命令，当写入完毕，子进程则通知父进程，父进程把新增的写操作也追加到临时 AOF 文件，然后将临时文件替换老的 AOF 文件，并重命名。</li><li>收到 bgsave 命令时，Redis 构建子进程，子进程将内存中的所有数据通过快照做一次持久化落地，写入到 RDB 中。</li><li>当需要进行全量复制时，master 也会启动一个子进程，子进程将数据库快照保存到 RDB 文件，在写完 RDB 快照文件后，master 就会把 RDB 发给 slave，同时将后续新的写指令都同步给 slave。</li></ul><p><img src="https://i0.hdslb.com/bfs/article/0f0427bdab6125719ce8e29d27fef000171301454.png" alt="image-20250224103803951"></p><p>主进程中，除了主线程处理网络 IO 和命令操作外，还有 3 个辅助 BIO 线程。这 3 个 BIO 线程分别负责处理，文件关闭、AOF 缓冲数据刷新到磁盘，以及清理对象这三个任务队列。这是一个生产-消费模型，一般都是由主线程生产慢任务，放到处理队列中，BIO线程充当消费者来消费任务。</p><p>Redis 在启动时，会同时启动这三个 BIO 线程，然后 BIO 线程休眠等待任务。当需要执行相关类型的后台任务时，就会构建一个 bio_job 结构，记录任务参数，然后将 bio_job 追加到任务队列尾部。然后唤醒 BIO 线程，即可进行任务执行。</p><h2 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h2><p>Redis 6.0 的多线程处理流程如下图所示。主线程负责监听端口，注册连接读事件，当有新连接进入时，主线程accept新连接，创建client，并为新连接注册请求读事件。</p><p><img src="https://i0.hdslb.com/bfs/article/d5ce44917fa00607ba06aa02c3964deb171301454.png" alt="image-20250307101658118"></p><h1 id="Redis主从复制"><a href="#Redis主从复制" class="headerlink" title="Redis主从复制"></a>Redis主从复制</h1><h2 id="Redis复制原理"><a href="#Redis复制原理" class="headerlink" title="Redis复制原理"></a>Redis复制原理</h2><p>通过数据复制，Redis 的一个 master 可以挂载多个 slave，而 slave 下还可以挂载多个 slave，形成多层嵌套结构。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/32d1c9e07f517779764407af4bd2ffb006f66271.png" alt="image-20250709141026195"></p><p>master 在分发写请求时，同时会将写指令复制一份存入复制积压缓冲，这样当 slave 短时间断开重连时，只要 slave 的复制位置点仍然在复制积压缓冲，则可以从之前的复制位置点之后继续进行复制，提升复制效率。</p><h2 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h2><p>哨兵其实就是一个运行在特殊模式下的 Redis 进程，主从库实例运行的同时，它也在运行。哨兵主要负责的就是三个任务：监控、选主（选择主库）和通知。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/e94fdd5b2c39197abfaeeb8eda4bf8e05c1a2ce6.png" alt="image-20250709141146570"></p><p>但是，在监控和选主这两个任务中，哨兵需要做出两个决策：</p><ul><li>在监控任务中，哨兵需要判断主库是否处于下线状态；</li><li>在选主任务中，哨兵也要决定选择哪个从库实例作为主库。</li></ul><h3 id="主观下线和客观下线"><a href="#主观下线和客观下线" class="headerlink" title="主观下线和客观下线"></a>主观下线和客观下线</h3><p><strong>哨兵进程会使用 PING 命令检测它自己和主、从库的网络连接情况，用来判断实例的状态</strong>。如果哨兵发现<strong>从库</strong>对 PING 命令的响应超时了，那么，哨兵就会先把它标记为“主观下线”。</p><p><strong>而主库的下线，通常会采用哨兵集群（多实例组成的集群模式进行部署）判断</strong>。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/716bf87a3b237d7fd245471a3d8d05a7903d8f2f.png" alt="image-20250709141158788"></p><p>简单来说，“客观下线”的标准就是，当有 N 个哨兵实例时，最好要有 N&#x2F;2 + 1 个实例判断主库为“主观下线”，才能最终判定主库为“客观下线”。这样一来，就可以减少误判的概率，也能避免误判带来的无谓的主从库切换。（当然，有多少个实例做出“主观下线”的判断才可以，可以由 Redis 管理员自行设定）。</p><h3 id="选定新主库"><a href="#选定新主库" class="headerlink" title="选定新主库"></a>选定新主库</h3><p>筛选条件：判断从库之前的网络连接状态，检查从库当前的在线状态。</p><p>打分条件：</p><ul><li><strong>第一轮：优先级最高的从库得分高。</strong>用户可以通过 slave-priority 配置项，给不同的从库设置不同优先级。</li><li><strong>第二轮：和旧主库同步程度最接近的从库得分高。</strong>从库的复制位点离旧主库的复制进度最近。</li><li><strong>第三轮：ID 号小的从库得分高。</strong></li></ul><h4 id="脑裂"><a href="#脑裂" class="headerlink" title="脑裂"></a>脑裂</h4><p>脑裂发生的原因主要是原主库发生了假故障，我们来总结下假故障的两个原因。</p><ol><li>和主库部署在同一台服务器上的其他程序临时占用了大量资源（例如 CPU 资源），导致主库资源使用受限，短时间内无法响应心跳。其它程序不再使用资源时，主库又恢复正常。</li><li>主库自身遇到了阻塞的情况，例如，处理 bigkey 或是发生内存 swap（物理机器内存不足），短时间内无法响应心跳，等主库阻塞解除后，又恢复正常的请求处理了。</li></ol><p>Redis 已经提供了两个配置项来限制主库的请求处理，分别是 min-slaves-to-write 和 min-slaves-max-lag。</p><ul><li>min-slaves-to-write：这个配置项设置了主库能进行数据同步的最少从库数量；</li><li>min-slaves-max-lag：这个配置项设置了主从库间进行数据复制时，从库给主库发送 ACK 消息的最大延迟（以秒为单位）。</li></ul><p>有了这两个配置项后，我们就可以轻松地应对脑裂问题了。</p><p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h1 id="Redis集群管理"><a href="#Redis集群管理" class="headerlink" title="Redis集群管理"></a>Redis集群管理</h1><p>Redis 的集群管理有 3 种方式。</p><ul><li><p>client 分片访问，client 对 key 做 hash，然后按取模或一致性 hash，把 key 的读写分散到不同的 Redis 实例上。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/8ffa5dc03351ad6983d5f9c1dc23ef3304a75bf0.png" alt="image-20250709141214450"></p></li><li><p>proxy端分区，在 Redis 前加一个 proxy，把路由策略、后端 Redis 状态维护的工作都放到 proxy 中进行，client 直接访问 proxy，后端 Redis 变更，只需修改 proxy 配置即可。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b2d396db5857a6815dee9624d3545b47b169b311.png" alt="image-20250709141228028"></p></li><li><p>直接使用 Redis cluster。Redis 创建之初，使用方直接给 Redis 的节点分配 slot，后续访问时，对 key 做 hash 找到对应的 slot，然后访问 slot 所在的 Redis 实例。在需要扩容缩容时，可以在线通过 cluster setslot 指令，以及 migrate 指令，将 slot 下所有 key 迁移到目标节点，即可实现扩缩容的目的。</p></li></ul><p><img src="https://i0.hdslb.com/bfs/openplatform/28ed197a1da98de17944dd059088d8754800346c.png" alt="image-20250709141239383"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Redis简介&quot;&gt;&lt;a href=&quot;#Redis简介&quot; class=&quot;headerlink&quot; title=&quot;Redis简介&quot;&gt;&lt;/a&gt;Redis简介&lt;/h1&gt;&lt;p&gt;Redis 是一款基于 ANSI C 语言编写的，BSD 许可的，日志型 key-value 存储组</summary>
      
    
    
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>缓存的基本思想</title>
    <link href="https://palette-k.github.io/2025/02/17/%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/"/>
    <id>https://palette-k.github.io/2025/02/17/%E7%BC%93%E5%AD%98%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3/</id>
    <published>2025-02-17T10:00:02.000Z</published>
    <updated>2025-08-28T03:42:50.262Z</updated>
    
    <content type="html"><![CDATA[<h1 id="缓存的基本思想"><a href="#缓存的基本思想" class="headerlink" title="缓存的基本思想"></a>缓存的基本思想</h1><p>空间换时间。</p><p>缓存中的数据通常存储于内存中，因此访问速度非常快。为了避免内存中的数据在重启或者宕机之后丢失，很多缓存中间件会利用磁盘做持久化。</p><p>缓存相比较于我们常用的关系型数据库来说访问速度要快非常多，为了避免用户请求数据库中的数据速度过于缓慢，我们可以在数据库之上增加一层缓存。</p><p>除了能提高访问速度之外，缓存支持的并发量也要大。有了缓存后，数据库的压力也会随之变小。</p><h1 id="缓存的分类"><a href="#缓存的分类" class="headerlink" title="缓存的分类"></a>缓存的分类</h1><h2 id="本地缓存"><a href="#本地缓存" class="headerlink" title="本地缓存"></a>本地缓存</h2><p><img src="https://i0.hdslb.com/bfs/article/05ae15dcc71bb5e395ccd2aee0c5437c171301454.png" alt="Pasted image 20221215181540"><br><strong>本地缓存的方案</strong></p><ol><li>JDK 自带的 HashMap 和 ConcurrentHashMap</li></ol><ul><li>ConcurrentHashMap 是线程安全版本的 HashMap，大部分场景不会使用这两者做缓存，因为只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能。</li></ul><ol start="2"><li>Ehcache、Guava Cache、Spring Cache 比较常用的本地缓存框架</li></ol><ul><li>Ehcache 比其他两者更重量。Ehcache 可以嵌入到 Hibernate 和 MyBatis 作为多级缓存，并且可以将缓存的数据持久化到本地磁盘中</li><li>Guava Cache 和 Spring Cache 两者比较像。Guava 使用更多一点，提供了 API 方便使用，也提供了设置缓存有效时间等功能。</li><li>使用 Spring Cache 注解实现缓存，代码会看着干净优雅，但是很容易出现缓存穿透、内存溢出等问题。</li></ul><ol start="3"><li>Caffeine</li></ol><ul><li>一般建议替代 Guava</li></ul><p>本地缓存缺陷：</p><ul><li>当同一个相同服务部署到多台机器上时，各个服务之间的缓存无法共享，因为本地缓存在当前机器</li><li>如果当前系统服务所耗费的内存多，那么本地缓存可用的容量就很少</li></ul><h2 id="分布式缓存"><a href="#分布式缓存" class="headerlink" title="分布式缓存"></a>分布式缓存</h2><p><img src="https://i0.hdslb.com/bfs/article/2a4d9ea416e4a24215f7c89f422c7486171301454.png" alt="Pasted image 20221215181816"><br>使用分布式缓存后，缓存服务可以部署在一台单独的服务器上，即使同一个相同的服务部署在多台机器上，也是使用的同一份缓存。并且，单独的分布式缓存服务的性能、容量和提供的功能都更加强大。</p><h1 id="常见的缓存更新策略"><a href="#常见的缓存更新策略" class="headerlink" title="常见的缓存更新策略"></a>常见的缓存更新策略</h1><h2 id="Cache-Aside-Pattern-旁路缓存模式"><a href="#Cache-Aside-Pattern-旁路缓存模式" class="headerlink" title="Cache Aside Pattern 旁路缓存模式"></a>Cache Aside Pattern 旁路缓存模式</h2><p>Cache Aside Pattern 比较适合读请求比较多的场景。服务端需要同时维系数据库和缓存，以 db 的结果为准。</p><p>写：<br><img src="https://i0.hdslb.com/bfs/article/cd5c0c1a5a9957ea0012ca938d12a9b4171301454.png" alt="Pasted image 20221216124739"></p><blockquote><p>为什么要删除cache，而不是更新cache?</p></blockquote><p><strong>原因：</strong><br>1.对服务端资源造成浪费：删除cache更直接，因为cache中存放的一些数据需要通过服务端经过大量的计算才能得出，会消耗服务端的资源。如果频繁修改db，就会导致频繁更新cache，而cache中的数据可能没有被访问到。<br>2.产生数据不一致的情况：并发场景下，更新cache产生数据不一致的概率会更大。</p><blockquote><p><strong>可以先删除 cache 后更新 db 吗？</strong></p></blockquote><p>不行，会造成数据不一致的情况。</p><ol><li>请求1先删除 cache 中的 A 数据</li><li>请求2从 db 中读取数据</li><li>请求1再把 db 中的 A 数据更新</li><li>导致请求2读取到的 A 数据就是旧值</li></ol><blockquote><p><strong>在写数据过程中，先更新 db，后删除 cache 就没问题了吗？</strong></p></blockquote><p>不一定，有可能会产生数据不一致的问题。</p><ol><li>请求1从 db 读取数据 A</li><li>请求2更新 db 中的数据 A（此时缓存中没有数据A，不需要删除）</li><li>请求1将数据A写入cache</li><li>导致cache中存放的是旧值</li></ol><p>读：<br><img src="https://i0.hdslb.com/bfs/article/a41e75b82d5b209db3af29f1e7e2061e171301454.png" alt="Pasted image 20221216124806"></p><p><strong>Cache Aside Pattern 缺陷及解决方案</strong></p><p>缺陷1：首次请求数据一定不在cache中：可以将热点数据提前放入cache中</p><p>缺陷2：写操作比较频繁导致cache中的数据会被频繁地删除，这样会影响缓存命中率</p><ul><li><p>数据库和缓存数据强一致场景：更新db的时候同样更新cache，不过需要加一个锁&#x2F;分布式锁来保证更新cache的时候不存在线程安全问题</p></li><li><p>可以短暂允许数据库与缓存数据不一致的场景：更新db的时候同样更新cache,但是给缓存一个较短的过期时间，这样可以保证即使数据不一致，影响也比较小。</p></li></ul><h2 id="Read-Write-Through-读写穿透"><a href="#Read-Write-Through-读写穿透" class="headerlink" title="Read&#x2F;Write Through 读写穿透"></a>Read&#x2F;Write Through 读写穿透</h2><p>对于 Cache Aside 模式，业务应用需要同时维护 cache 和 DB 两个数据存储方，过于繁琐，于是就有了 Read&#x2F;Write Through 模式。</p><p>在这种模式下，业务应用只关注一个存储服务即可，业务方的读写 cache 和 DB 的操作，都由存储服务代理。存储服务收到业务应用的写请求时，会首先查 cache，如果数据在 cache 中不存在，则只更新 DB，如果数据在 cache 中存在，则先更新 cache，然后更新 DB。而存储服务收到读请求时，如果命中 cache 直接返回，否则先从 DB 加载，回种到 cache 后返回响应。</p><p>这种模式的特点是，存储服务封装了所有的数据处理细节，业务应用端代码只用关注业务逻辑本身，系统的隔离性更佳。另外，进行写操作时，如果 cache 中没有数据则不更新，有缓存数据才更新，内存效率更高。</p><p>微博 Feed 的 Outbox Vector（即用户最新微博列表）就采用这种模式。一些粉丝较少且不活跃的用户发表微博后，Vector 服务会首先查询 Vector Cache，如果 cache 中没有该用户的 Outbox 记录，则不写该用户的 cache 数据，直接更新 DB 后就返回，只有 cache 中存在才会通过 CAS 指令进行更新。</p><h2 id="Write-Behind-Pattern-异步缓存写入"><a href="#Write-Behind-Pattern-异步缓存写入" class="headerlink" title="Write Behind Pattern 异步缓存写入"></a>Write Behind Pattern 异步缓存写入</h2><p>只更新缓存，不直接更新 db，而是改为异步批量的方式更新 db</p><p>消息队列中消息的异步写入磁盘、Mysql 的 InnoDB Buffer Pool 机制都用到了这种策略</p><p>Write Pool Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、阅读量。</p><p>该模式的特点是，数据存储的写性能最高，非常适合一些变更特别频繁的业务，特别是可以合并写请求的业务，比如对一些计数业务，一条 Feed 被点赞 1万 次，如果更新 1万 次 DB 代价很大，而合并成一次请求直接加 1万，则是一个非常轻量的操作。</p><p>但这种模型有个显著的缺点，即数据的一致性变差，甚至在一些极端场景下可能会丢失数据。比如系统 Crash、机器宕机时，如果有数据还没保存到 DB，则会存在丢失的风险。所以这种读写模式适合变更频率特别高，但对一致性要求不太高的业务，这样写操作可以异步批量写入 DB，减小 DB 压力。</p><h1 id="缓存失效"><a href="#缓存失效" class="headerlink" title="缓存失效"></a>缓存失效</h1><h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>缓存里的数据存储基本上都是以 key 为索引进行存储和获取的。业务访问时，如果大量的 key 同时过期，很多缓存数据访问都会 miss，进而穿透到 DB，DB 的压力就会明显上升，由于 DB 的性能较差，只在缓存的 1%~2% 以下，这样请求的慢查率会明显上升。这就是缓存失效的问题。</p><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>导致缓存失效，特别是很多 key 一起失效的原因，跟我们日常写缓存的过期时间息息相关。</p><p>在某些场景，一大批数据会被系统主动或被动从 DB 批量加载，然后写入缓存。这些数据写入缓存时，由于使用相同的过期时间，在经历这个过期时间之后，这批数据就会一起到期，从而被缓存淘汰。此时，对这批数据的所有请求，都会出现缓存失效，从而都穿透到 DB，DB 由于查询量太大，就很容易压力大增，请求变慢。</p><h2 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h2><p>同一批火车票、飞机票，当可以售卖时，系统会一次性加载到缓存，如果缓存写入时，过期时间按照预先设置的过期值，那过期时间到期后，系统就会因缓存失效出现变慢的问题。</p><p>微博业务，会有后台离线系统，持续计算热门微博，每当计算结束，会将这批热门微博批量写入对应的缓存。</p><p>很多业务，在部署新 IDC 或新业务上线时，会进行缓存预热，也会一次性加载大批热数据。</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>设计缓存的过期时间时，使用公式：过期时间&#x3D;baes 时间+随机时间。</p><p>即相同业务数据写缓存时，在基础过期时间之上，再加一个随机的过期时间，让数据在未来一段时间内慢慢过期，避免瞬时全部过期，对 DB 造成过大压力。</p><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><h2 id="问题描述-1"><a href="#问题描述-1" class="headerlink" title="问题描述"></a>问题描述</h2><p>缓存穿透发生的概率很低，所以一般很难被发现。但是，一旦你发现了，而且量还不小，你可能立即就会经历一个忙碌的夜晚。</p><p>缓存穿透，则意味着有特殊访客在查询一个不存在的 key，导致每次查询都会穿透到 DB，如果这个特殊访客再控制一批肉鸡机器，持续访问你系统里不存在的 key，就会对 DB 产生很大的压力，从而影响正常服务。</p><h2 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h2><p>缓存穿透存在的原因，就是因为我们在系统设计时，更多考虑的是正常访问路径，对特殊访问路径、异常访问路径考虑相对欠缺。</p><p>缓存访问设计的正常路径，是先访问 cache，cache miss 后查 DB，DB 查询到结果后，回种缓存返回。这对于正常的 key 访问是没有问题的，但是如果用户访问的是一个不存在的 key，查 DB 返回空（即一个 NULL），那就不会把这个空写回cache。那以后不管查询多少次这个不存在的 key，都会 cache miss，都会查询 DB。整个系统就会退化成一个“前端+DB“的系统，由于 DB 的吞吐只在 cache 的 1%~2% 以下，如果有特殊访客，大量访问这些不存在的 key，就会导致系统的性能严重退化，影响正常用户的访问。</p><h2 id="业务场景-1"><a href="#业务场景-1" class="headerlink" title="业务场景"></a>业务场景</h2><p>缓存穿透的业务场景很多，比如通过不存在的 UID 访问用户，通过不存在的车次 ID 查看购票信息。用户输入错误，偶尔几个这种请求问题不大，但如果是大量这种请求，就会对系统影响非常大。</p><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><ul><li>第一种方案就是，查询这些不存在的数据时，第一次查 DB，虽然没查到结果返回 NULL，仍然记录这个 key 到缓存，只是这个 key 对应的 value 是一个特殊设置的值。</li><li>第二种方案是，构建一个 BloomFilter 缓存过滤器，记录全量数据，这样访问数据时，可以直接通过 BloomFilter 判断这个 key 是否存在，如果不存在直接返回即可，根本无需查缓存和 DB。</li></ul><p>不过这两种方案在设计时仍然有一些要注意的坑。</p><ul><li>对于方案一，如果特殊访客持续访问大量的不存在的 key，这些 key 即便只存一个简单的默认值，也会占用大量的缓存空间，导致正常 key 的命中率下降。所以进一步的改进措施是，对这些不存在的 key 只存较短的时间，让它们尽快过期；或者将这些不存在的 key 存在一个独立的公共缓存，从缓存查找时，先查正常的缓存组件，如果 miss，则查一下公共的非法 key 的缓存，如果后者命中，直接返回，否则穿透 DB，如果查出来是空，则回种到非法 key 缓存，否则回种到正常缓存。</li><li>对于方案二，BloomFilter 要缓存全量的 key，这就要求全量的 key 数量不大，10亿 条数据以内最佳，因为 10亿 条数据大概要占用 1.2GB 的内存。也可以用 BloomFilter 缓存非法 key，每次发现一个 key 是不存在的非法 key，就记录到 BloomFilter 中，这种记录方案，会导致 BloomFilter 存储的 key 持续高速增长，为了避免记录 key 太多而导致误判率增大，需要定期清零处理。</li></ul><h3 id="BloomFilter"><a href="#BloomFilter" class="headerlink" title="BloomFilter"></a>BloomFilter</h3><p>BloomFilter 是一个非常有意思的数据结构，不仅仅可以挡住非法 key 攻击，还可以低成本、高性能地对海量数据进行判断，比如一个系统有数亿用户和百亿级新闻 feed，就可以用 BloomFilter 来判断某个用户是否阅读某条新闻 feed。下面来对 BloomFilter 数据结构做一个分析，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/article/bc779ec51bf9095b1365e6bcde13d8dd171301454.png" alt="image-20250218114027598"></p><p>BloomFilter 的目的是检测一个元素是否存在于一个集合内。它的原理，是用 bit 数据组来表示一个集合，对一个 key 进行多次不同的 Hash 检测，如果所有 Hash 对应的 bit 位都是 1，则表明 key 非常大概率存在，平均单记录占用 1.2 字节即可达到 99%，<strong>只要有一次 Hash 对应的 bit 位是 0，就说明这个 key 肯定不存在于这个集合内。</strong></p><p><strong>BloomFilter 的算法：</strong></p><ul><li><p>首先分配一块内存空间做 bit 数组，数组的 bit 位初始值全部设为 0。</p></li><li><p>加入元素时，采用 k 个相互独立的 Hash 函数计算，然后将元素 Hash 映射的 K 个位置全部设置为 1。</p></li><li><p>检测 key 时，仍然用这 k 个 Hash 函数计算出 k 个位置，如果位置全部为 1，则表明 key 存在，否则不存在。</p></li></ul><p><strong>BloomFilter 的优势：</strong>全内存操作，性能很高。空间效率非常高，要达到 1% 的误判率，平均单条记录占用 1.2 字节即可。而且，平均单条记录每增加 0.6 字节，还可让误判率继续变为之前的 1&#x2F;10，即平均单条记录占用 1.8 字节，误判率可以达到 1&#x2F;1000；平均单条记录占用 2.4 字节，误判率可以到 1&#x2F;10000，以此类推。这里的误判率是指，BloomFilter 判断某个 key 存在，但它实际不存在的概率，因为它存的是 key 的 Hash 值，而非 key 的值，所以有概率存在这样的 key，它们内容不同，但多次 Hash 后的 Hash 值都相同。对于 BloomFilter 判断不存在的 key ，则是 100% 不存在的，反证法，如果这个 key 存在，那它每次 Hash 后对应的 Hash 值位置肯定是 1，而不会是 0。</p><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><h2 id="问题描述-2"><a href="#问题描述-2" class="headerlink" title="问题描述"></a>问题描述</h2><p>系统运行过程中，缓存雪崩是一个非常严重的问题。缓存雪崩是指部分缓存节点不可用，导致整个缓存体系甚至甚至服务系统不可用的情况。缓存雪崩按照缓存是否 rehash（即是否漂移）分两种情况：</p><ul><li>缓存不支持 rehash 导致的系统雪崩不可用</li><li>缓存支持 rehash 导致的缓存雪崩不可用</li></ul><h2 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h2><ul><li><p>缓存不进行 rehash 时产生的雪崩，一般是由于较多缓存节点不可用，大量 Cache 访问会失败，根据缓存读写模型，这些请求会进一步访问 DB，而且 DB 可承载的访问量要远比缓存小的多，请求量过大，就很容易造成 DB 过载，大量慢查询，最终阻塞甚至 Crash，从而导致服务异常。</p></li><li><p>缓存支持 rehash 时产生的雪崩，则大多跟流量洪峰有关，流量洪峰到达，引发部分缓存节点过载 Crash，然后因 rehash 扩散到其他缓存节点，最终整个缓存体系异常。</p><p>在缓存分布设计时，很多同学会选择<strong>一致性 Hash 分布方式</strong>，同时在部分节点异常时，<strong>采用 rehash 策略</strong>，即把异常节点请求平均分散到其他缓存节点。在一般情况下，一致性 Hash 分布+rehash 策略可以很好得运行，但在较大的流量洪峰到临之时，如果大流量 key 比较集中，正好在某 1～2 个缓存节点，很容易将这些缓存节点的内存、网卡过载，缓存节点异常 Crash，然后这些异常节点下线，这些大流量 key 请求又被 rehash 到其他缓存节点，进而导致其他缓存节点也被过载 Crash，缓存异常持续扩散，最终导致整个缓存体系异常，无法对外提供服务。</p></li></ul><h2 id="业务场景-2"><a href="#业务场景-2" class="headerlink" title="业务场景"></a>业务场景</h2><p>微博最初很多业务缓存采用一致性 Hash+rehash 策略，在突发洪水流量来临时，部分缓存节点过载 Crash 甚至宕机，然后这些异常节点的请求转到其他缓存节点，又导致其他缓存节点过载异常，最终整个缓存池过载。</p><p>机架断电，导致业务缓存多个节点宕机，大量请求直接打到 DB，也导致 DB 过载而阻塞，整个系统异常。最后缓存机器复电后，DB 重启，数据逐步加热后，系统才逐步恢复正常。</p><h2 id="解决方案-2"><a href="#解决方案-2" class="headerlink" title="解决方案"></a>解决方案</h2><p>预防缓存雪崩，这里给出 3 个解决方案。</p><ul><li><p>方案一，对业务 DB 的访问增加读写开关，当发现 DB 请求变慢、阻塞，慢请求超过阀值时，就会关闭读开关，部分或所有读 DB 的请求进行 failfast 立即返回，待 DB 恢复后再打开读开关，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/9c10f297f7fc8bd7f4656efdd0f228c1171301454.png" alt="image-20250218115208783"></p></li><li><p>方案二，对缓存增加多个副本，缓存异常或请求 miss 后，再读取其他缓存副本，而且多个缓存副本尽量部署在不同机架，从而确保在任何情况下，缓存系统都会正常对外提供服务。</p></li><li><p>方案三，对缓存体系进行实时监控，当请求访问的慢速比超过阀值时，及时报警，通过机器替换、服务替换进行及时恢复；也可以通过各种自动故障转移策略，自动关闭异常接口、停止边缘服务、停止部分非核心功能措施，确保在极端场景下，核心功能的正常运行。</p></li></ul><p>实际上，微博平台系统，这三种方案都采用了，通过三管齐下，规避缓存雪崩的发生。</p><h1 id="数据不一致"><a href="#数据不一致" class="headerlink" title="数据不一致"></a>数据不一致</h1><h2 id="问题描述-3"><a href="#问题描述-3" class="headerlink" title="问题描述"></a>问题描述</h2><p>七大缓存经典问题的第四个问题是数据不一致。同一份数据，可能会同时存在 DB 和缓存之中。那就有可能发生，DB 和缓存的数据不一致。如果缓存有多个副本，多个缓存副本里的数据也可能会发生不一致现象。</p><h2 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h2><p>不一致的问题大多跟缓存更新异常有关。比如更新 DB 后，写缓存失败，从而导致缓存中存的是老数据。另外，如果系统采用一致性 Hash 分布，同时采用 rehash 自动漂移策略，在节点多次上下线之后，也会产生脏数据。缓存有多个副本时，更新某个副本失败，也会导致这个副本的数据是老数据。</p><h2 id="业务场景-3"><a href="#业务场景-3" class="headerlink" title="业务场景"></a>业务场景</h2><p>导致数据不一致的场景也不少。如下图所示，在缓存机器的带宽被打满，或者机房网络出现波动时，缓存更新失败，新数据没有写入缓存，就会导致缓存和 DB 的数据不一致。缓存 rehash 时，某个缓存机器反复异常，多次上下线，更新请求多次 rehash。这样，一份数据存在多个节点，且每次 rehash 只更新某个节点，导致一些缓存节点产生脏数据。</p><p><img src="https://i0.hdslb.com/bfs/article/5f7ad3c1eca3c42e545bc6b67849fa42171301454.png" alt="image-20250220181055343"></p><h2 id="解决方案-3"><a href="#解决方案-3" class="headerlink" title="解决方案"></a>解决方案</h2><p>要尽量保证数据的一致性。这里也给出了 3 个方案，可以根据实际情况进行选择。</p><ul><li>第一个方案，cache 更新失败后，可以进行重试，如果重试失败，则将失败的 key 写入队列机服务，待缓存访问恢复后，将这些 key 从缓存删除。这些 key 在再次被查询时，重新从 DB 加载，从而保证数据的一致性。</li><li>第二个方案，缓存时间适当调短，让缓存数据及早过期后，然后从 DB 重新加载，确保数据的最终一致性。</li><li>第三个方案，不采用 rehash 漂移策略，而采用缓存分层策略，尽量避免脏数据产生。</li></ul><p><img src="https://i0.hdslb.com/bfs/article/91fc4102393e9273256f807ea4f3573f171301454.png" alt="image-20250220181337645"></p><h1 id="并发竞争"><a href="#并发竞争" class="headerlink" title="并发竞争"></a>并发竞争</h1><h2 id="问题描述-4"><a href="#问题描述-4" class="headerlink" title="问题描述"></a>问题描述</h2><p>第五个经典问题是数据并发竞争。互联网系统，线上流量较大，缓存访问中很容易出现数据并发竞争的现象。数据并发竞争，是指在高并发访问场景，一旦缓存访问没有找到数据，大量请求就会并发查询 DB，导致 DB 压力大增的现象。</p><p>数据并发竞争，主要是由于多个进程&#x2F;线程中，有大量并发请求获取相同的数据，而这个数据 key 因为正好过期、被剔除等各种原因在缓存中不存在，这些进程&#x2F;线程之间没有任何协调，然后一起并发查询 DB，请求那个相同的 key，最终导致 DB 压力大增，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/3fd4eaf59fa5b9436128c4f9a04adf0a171301454.png" alt="image-20250220181533138"></p><h2 id="业务场景-4"><a href="#业务场景-4" class="headerlink" title="业务场景"></a>业务场景</h2><p>数据并发竞争在大流量系统也比较常见，比如车票系统，如果某个火车车次缓存信息过期，但仍然有大量用户在查询该车次信息。又比如微博系统中，如果某条微博正好被缓存淘汰，但这条微博仍然有大量的转发、评论、赞。上述情况都会造成该车次信息、该条微博存在并发竞争读取的问题。</p><h2 id="解决方案-4"><a href="#解决方案-4" class="headerlink" title="解决方案"></a>解决方案</h2><p>要解决并发竞争，有 2 种方案。</p><ul><li><p>方案一是使用全局锁。如下图所示，即当缓存请求 miss 后，先尝试加全局锁，只有加全局锁成功的线程，才可以到 DB 去加载数据。其他进程&#x2F;线程在读取缓存数据 miss 时，如果发现这个 key 有全局锁，就进行等待，待之前的线程将数据从 DB 回种到缓存后，再从缓存获取。</p><p><img src="https://i0.hdslb.com/bfs/article/5ed2a325de08e7c3a060d9c69ee193df171301454.png" alt="image-20250220182352733"></p></li><li><p>方案二是，对缓存数据保持多个备份，即便其中一个备份中的数据过期或被剔除了，还可以访问其他备份，从而减少数据并发竞争的情况，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/2b594cbc54242d55dd8619e00442780c171301454.png" alt="image-20250220181834329"></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;缓存的基本思想&quot;&gt;&lt;a href=&quot;#缓存的基本思想&quot; class=&quot;headerlink&quot; title=&quot;缓存的基本思想&quot;&gt;&lt;/a&gt;缓存的基本思想&lt;/h1&gt;&lt;p&gt;空间换时间。&lt;/p&gt;
&lt;p&gt;缓存中的数据通常存储于内存中，因此访问速度非常快。为了避免内存中的数据在</summary>
      
    
    
    
    
    <category term="Redis" scheme="https://palette-k.github.io/tags/Redis/"/>
    
    <category term="缓存" scheme="https://palette-k.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>Java业务开发常见问题</title>
    <link href="https://palette-k.github.io/2025/02/07/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>https://palette-k.github.io/2025/02/07/Java%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</id>
    <published>2025-02-07T10:00:02.000Z</published>
    <updated>2025-07-16T06:05:57.566Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Spring-框架：IoC-和-AOP-是扩展的核心"><a href="#Spring-框架：IoC-和-AOP-是扩展的核心" class="headerlink" title="Spring 框架：IoC 和 AOP 是扩展的核心"></a>Spring 框架：IoC 和 AOP 是扩展的核心</h1><blockquote><p>当 Bean 产生循环依赖时，比如 BeanA 的构造方法依赖 BeanB 作为成员需要注入，BeanB 也依赖 BeanA，你觉得会出现什么问题呢？又有哪些解决方式呢？</p></blockquote><p>答：Bean 产生循环依赖，主要包括两种情况：一种是注入属性或字段涉及循环依赖，另一种是构造方法注入涉及循环依赖。接下来，我分别和你讲一讲。</p><p>第一种，注入属性或字段涉及循环依赖，比如 TestA 和 TestB 相互依赖：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestA</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestB testB;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestB</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestA testA;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>针对这个问题，Spring 内部通过三个 Map 的方式解决了这个问题，不会出错。基本原理是，因为循环依赖，所以实例的初始化无法一次到位，需要分步进行：</p><p>创建 A（仅仅实例化，不注入依赖）；</p><p>创建 B（仅仅实例化，不注入依赖）；</p><p>为 B 注入 A（此时 B 已健全）；</p><p>为 A 注入 B（此时 A 也健全）。</p><p>网上有很多相关的分析，我找了一篇比较详细的，可供你参考。</p><p>第二种，构造方法注入涉及循环依赖。遇到这种情况的话，程序无法启动，比如 TestC 和 TestD 的相互依赖：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestC</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestD testD;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestC</span><span class="params">(TestD testD)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testD = testD;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestD</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestC testC;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestD</span><span class="params">(TestC testC)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testC = testC;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种循环依赖的主要解决方式，有 2 种：</p><p>改为属性或字段注入；</p><p>使用 @Lazy 延迟注入。比如如下代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TestC</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Getter</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> TestD testD;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">TestC</span><span class="params">(<span class="meta">@Lazy</span> TestD testD)</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">this</span>.testD = testD;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其实，这种 @Lazy 方式注入的就不是实际的类型了，而是代理类，获取的时候通过代理去拿值（实例化）。所以，它可以解决循环依赖无法实例化的问题。</p><h1 id="数据库索引：索引并不是万能药"><a href="#数据库索引：索引并不是万能药" class="headerlink" title="数据库索引：索引并不是万能药"></a>数据库索引：索引并不是万能药</h1><blockquote><p>索引除了可以用于加速搜索外，还可以在排序时发挥作用，你能通过 EXPLAIN 来证明吗？你知道，针对排序在什么情况下，索引会失效吗？</p></blockquote><p>答：排序使用到索引，在执行计划中的体现就是 key 这一列。如果没有用到索引，会在 Extra 中看到 Using filesort，代表使用了内存或磁盘进行排序。而具体走内存还是磁盘，是由 sort_buffer_size 和排序数据大小决定的。</p><p>排序无法使用到索引的情况有：</p><ul><li><p>对于使用联合索引进行排序的场景，多个字段排序 ASC 和 DESC 混用；</p></li><li><p>a+b 作为联合索引，按照 a 范围查询后按照 b 排序；</p></li><li><p>排序列涉及到的多个字段不属于同一个联合索引；</p></li><li><p>排序列使用了表达式。</p></li></ul><h2 id="为什么联合索引无法优化排序"><a href="#为什么联合索引无法优化排序" class="headerlink" title="为什么联合索引无法优化排序"></a>为什么联合索引无法优化排序</h2><ul><li>联合索引 <code>(a, b)</code> 的设计是为了优化 <code>a</code> 列的查询和 <code>a</code> 列相同情况下的 <code>b</code> 列查询。</li><li>当 <code>a</code> 列是范围查询时，<code>b</code> 列的顺序在索引中被打乱，因此无法直接利用索引来优化 <code>b</code> 列的排序。</li></ul><p>如果需要对 <code>b</code> 列进行排序，同时又有 <code>a</code> 列的范围查询，可以考虑以下优化方法：</p><h3 id="方法-1：调整索引顺序"><a href="#方法-1：调整索引顺序" class="headerlink" title="方法 1：调整索引顺序"></a>方法 1：调整索引顺序</h3><ul><li>如果查询条件中 <code>b</code> 列的排序是必须的，可以尝试调整索引顺序为 <code>(b, a)</code>。</li><li>这样，MySQL 可以先按 <code>b</code> 列排序，然后再按 <code>a</code> 列过滤。但这种方法可能不适用于所有场景，具体取决于查询条件。</li></ul><h3 id="方法-2：覆盖索引"><a href="#方法-2：覆盖索引" class="headerlink" title="方法 2：覆盖索引"></a>方法 2：覆盖索引</h3><ul><li>如果查询只需要 <code>a</code> 和 <code>b</code> 列，可以创建一个覆盖索引 <code>(a, b)</code>，并确保查询只选择 <code>a</code> 和 <code>b</code> 列。</li><li>这样，MySQL 可以直接从索引中获取数据，而不需要回表查询，从而提高性能。</li></ul><h3 id="方法-3：拆分查询"><a href="#方法-3：拆分查询" class="headerlink" title="方法 3：拆分查询"></a>方法 3：拆分查询</h3><ul><li>如果数据量较大，可以将查询拆分为两步：<ol><li>先根据 <code>a</code> 列的范围条件查询出主键。</li><li>再根据主键查询数据，并对 <code>b</code> 列进行排序。</li></ol></li></ul><h1 id="数据源头：任何客户端的东西都不可信任"><a href="#数据源头：任何客户端的东西都不可信任" class="headerlink" title="数据源头：任何客户端的东西都不可信任"></a>数据源头：任何客户端的东西都不可信任</h1><blockquote><p>问题 1：在讲述用户标识不能从客户端获取这个要点的时候，我提到开发同学可能会因为用户信息未打通而通过前端来传用户 ID。那我们有什么好办法，来打通不同的系统甚至不同网站的用户标识吗？</p></blockquote><p>答：打通用户在不同系统之间的登录，大致有以下三种方案。</p><p>第一种，把用户身份放在统一的服务端，每一个系统都需要到这个服务端来做登录状态的确认，确认后在自己网站的 Cookie 中保存会话，这就是单点登录的做法。这种方案要求所有关联系统都对接一套中央认证服务器（中央保存用户会话），在未登录的时候跳转到中央认证服务器进行登录或登录状态确认。因此，这种方案适合一个公司内部的不同域名下的网站。</p><p>第二种，把用户身份信息直接放在 Token 中，在客户端任意传递，Token 由服务端进行校验（如果共享密钥话，甚至不需要同一个服务端进行校验），无需采用中央认证服务器，相对比较松耦合，典型的标准是 JWT。这种方案适合异构系统的跨系统用户认证打通，而且相比单点登录的方案，用户体验会更好一些。</p><p>第三种，如果需要打通不同公司系统的用户登录状态，那么一般都会采用 OAuth 2.0 的标准中的授权码模式，基本流程如下：</p><ul><li><p>第三方网站客户端转到授权服务器，上送 ClientID、重定向地址 RedirectUri 等信息。</p></li><li><p>用户在授权服务器进行登录并且进行授权批准（授权批准这步可以配置为自动完成）。</p></li><li><p>授权完成后，重定向回到之前客户端提供的重定向地址，附上授权码。</p></li><li><p>第三方网站服务端通过授权码 +ClientID+ClientSecret 去授权服务器换取 Token。这里的 Token 包含访问 Token 和刷新 Token，访问 Token 过期后用刷新 Token 去获得新的访问 Token。</p><p>因为我们不会对外暴露 ClientSecret，也不会对外暴露访问 Token，同时使用授权码换取 Token 的过程是服务端进行的，客户端拿到的只是一次性的授权码，所以这种模式比较安全。</p></li></ul><blockquote><p>问题 2：还有一类和客户端数据相关的漏洞非常重要，那就是 URL 地址中的数据。在把匿名用户重定向到登录页面的时候，我们一般会带上 redirectUrl，这样用户登录后可以快速返回之前的页面。黑客可能会伪造一个活动链接，由真实的网站 + 钓鱼的 redirectUrl 构成，发邮件诱导用户进行登录。用户登录时访问的其实是真的网站，所以不容易察觉到 redirectUrl 是钓鱼网站，登录后却来到了钓鱼网站，用户可能会不知不觉就把重要信息泄露了。这种安全问题，我们叫做开放重定向问题。你觉得，从代码层面应该怎么预防开放重定向问题呢？</p></blockquote><p>答：要从代码层面预防开放重定向问题，有以下三种做法可供参考：</p><p>第一种，固定重定向的目标 URL。</p><p>第二种，可采用编号方式指定重定向的目标 URL，也就是重定向的目标 URL 只能是在我们的白名单内的。</p><p>第三种，用合理充分的校验方式来校验跳转的目标地址，如果是非己方地址，就告知用户跳转有风险，小心钓鱼网站的威胁。</p><h1 id="安全兜底：涉及钱时，必须考虑防刷、限量和防重"><a href="#安全兜底：涉及钱时，必须考虑防刷、限量和防重" class="headerlink" title="安全兜底：涉及钱时，必须考虑防刷、限量和防重"></a>安全兜底：涉及钱时，必须考虑防刷、限量和防重</h1><blockquote><p>问题 1：防重、防刷都是事前手段，如果我们的系统正在被攻击或利用，你有什么办法及时发现问题吗？</p></blockquote><p>答：对于及时发现系统正在被攻击或利用，监控是较好的手段，关键点在于报警阈值怎么设置。我觉得可以对比昨天同时、上周同时的量，发现差异达到一定百分比报警，而且报警需要有升级机制。此外，有的时候大盘很大的话，活动给整个大盘带来的变化不明显，如果进行整体监控可能出了问题也无法及时发现，因此可以考虑对于活动做独立的监控报警。</p><blockquote><p>问题 2：任何三方资源的使用一般都会定期对账，如果在对账中发现我们系统记录的调用量低于对方系统记录的使用量，你觉得一般是什么问题引起的呢？</p></blockquote><p>答：我之前遇到的情况是，在事务内调用外部接口，调用超时后本地事务回滚本地就没有留下数据。更合适的做法是：</p><p>请求发出之前先记录请求数据提交事务，记录状态为未知。</p><p>发布调用外部接口的请求，如果可以拿到明确的结果，则更新数据库中记录的状态为成功或失败。如果出现超时或未知异常，不能假设第三方接口调用失败，需要通过查询接口查询明确的结果。</p><p>写一个定时任务补偿数据库中所有未知状态的记录，从第三方接口同步结果。</p><p>值得注意的是，对账的时候一定要对两边，不管哪方数据缺失都可能是因为程序逻辑有 bug，需要重视。此外，任何涉及第三方系统的交互，都建议在数据库中保持明细的请求 &#x2F; 响应报文，方便在出问题的时候定位 Bug 根因。</p><blockquote><p>问题3：开放平台资源的使用需要考虑防刷，该怎么限制短信接口被盗刷？</p></blockquote><p>第一种方式，只有固定的请求头才能发送验证码。</p><p>也就是说，我们通过请求头中网页或 App 客户端传给服务端的一些额外参数，来判断请求是不是 App 发起的。其实，这种方式“防君子不防小人”。</p><p>比如，判断是否存在浏览器或手机型号、设备分辨率请求头。对于那些使用爬虫来抓取短信接口地址的程序来说，往往只能抓取到 URL，而难以分析出请求发送短信还需要的额外请求头，可以看作第一道基本防御。</p><p>第二种方式，只有先到过注册页面才能发送验证码。</p><p>对于普通用户来说，不管是通过 App 注册还是 H5 页面注册，一定是先进入注册页面才能看到发送验证码按钮，再点击发送。我们可以在页面或界面打开时请求固定的前置接口，为这个设备开启允许发送验证码的窗口，之后的请求发送验证码才是有效请求。</p><p>这种方式可以防御直接绕开固定流程，通过接口直接调用的发送验证码请求，并不会干扰普通用户。</p><p>第三种方式，控制相同手机号的发送次数和发送频次。</p><p>除非是短信无法收到，否则用户不太会请求了验证码后不完成注册流程，再重新请求。因此，我们可以限制同一手机号每天的最大请求次数。验证码的到达需要时间，太短的发送间隔没有意义，所以我们还可以控制发送的最短间隔。比如，我们可以控制相同手机号一天只能发送 10 次验证码，最短发送间隔 1 分钟。</p><p>第四种方式，增加前置图形验证码。</p><p>短信轰炸平台一般会收集很多免费短信接口，一个接口只会给一个用户发一次短信，所以控制相同手机号发送次数和间隔的方式不够有效。这时，我们可以考虑对用户体验稍微有影响，但也是最有效的方式作为保底，即将弹出图形验证码作为前置。</p><p>除了图形验证码，我们还可以使用其他更友好的人机验证手段（比如滑动、点击验证码等），甚至是引入比较新潮的无感知验证码方案（比如，通过判断用户输入手机号的打字节奏，来判断是用户还是机器），来改善用户体验。</p><p>此外，我们也可以考虑在监测到异常的情况下再弹出人机检测。比如，短时间内大量相同远端 IP 发送验证码的时候，才会触发人机检测。</p><p>总之，我们要确保，只有正常用户经过正常的流程才能使用开放平台资源，并且资源的用量在业务需求合理范围内。此外，还需要考虑做好短信发送量的实时监控，遇到发送量激增要及时报警。</p><blockquote><p>钱的进出一定要和订单挂钩并且实现幂等</p></blockquote><p>涉及钱的进出，需要做好以下两点。</p><p>第一，任何资金操作都需要在平台侧生成业务属性的订单，可以是优惠券发放订单，可以是返现订单，也可以是借款订单，一定是先有订单再去做资金操作。同时，订单的产生需要有业务属性。业务属性是指，订单不是凭空产生的，否则就没有控制的意义。比如，返现发放订单必须关联到原先的商品订单产生；再比如，借款订单必须关联到同一个借款合同产生。</p><p>第二，一定要做好防重，也就是实现幂等处理，并且幂等处理必须是全链路的。这里的全链路是指，从前到后都需要有相同的业务订单号来贯穿，实现最终的支付防重。</p><p>对于支付操作，我们一定是调用三方支付公司的接口或银行接口进行处理的。一般而言，这些接口都会有商户订单号的概念，对于相同的商户订单号，无法进行重复的资金处理，所以三方公司的接口可以实现唯一订单号的幂等处理。</p><p>但是，业务系统在实现资金操作时容易犯的错是，没有自始至终地使用一个订单号作为商户订单号，透传给三方支付接口。出现这个问题的原因是，比较大的互联网公司一般会把支付独立一个部门。支付部门可能会针对支付做聚合操作，内部会维护一个支付订单号，然后使用支付订单号和三方支付接口交互。最终虽然商品订单是一个，但支付订单是多个，相同的商品订单因为产生多个支付订单导致多次支付。</p><p>如果说，支付出现了重复扣款，我们可以给用户进行退款操作，但给用户付款的操作一旦出现重复付款，就很难把钱追回来了，所以更要小心。</p><p>这，就是全链路的意义，从一开始就需要先有业务订单产生，然后使用相同的业务订单号一直贯穿到最后的资金通路，才能真正避免重复资金操作。</p><h1 id="如何正确保存和传输敏感数据？"><a href="#如何正确保存和传输敏感数据？" class="headerlink" title="如何正确保存和传输敏感数据？"></a>如何正确保存和传输敏感数据？</h1><blockquote><p>问题 1：虽然我们把用户名和密码脱敏加密保存在数据库中，但日志中可能还存在明文的敏感数据。你有什么思路在框架或中间件层面，对日志进行脱敏吗？</p></blockquote><p>答：如果我们希望在日志的源头进行脱敏，那么可以在日志框架层面做。比如对于 logback 日志框架，我们可以自定义 MessageConverter，通过正则表达式匹配敏感信息脱敏。</p><p>需要注意的是，这种方式有两个缺点。</p><p>第一，正则表达式匹配敏感信息的格式不一定精确，会出现误杀漏杀的现象。一般来说，这个问题不会很严重。要实现精确脱敏的话，就只能提供各种脱敏工具类，然后让业务应用在日志中记录敏感信息的时候，先手动调用工具类进行脱敏。</p><p>第二，如果数据量比较大的话，脱敏操作可能会增加业务应用的 CPU 和内存使用，甚至会导致应用不堪负荷出现不可用。考虑到目前大部分公司都引入了 ELK 来集中收集日志，并且一般而言都不允许上服务器直接看文件日志，因此我们可以考虑在日志收集中间件中（比如 logstash）写过滤器进行脱敏。这样可以把脱敏的消耗转义到 ELK 体系中，不过这种方式同样有第一点提到的字段不精确匹配导致的漏杀误杀的缺点。</p><blockquote><p>问题 2：你知道 HTTPS 双向认证的目的是什么吗？流程上又有什么区别呢？</p></blockquote><p>答：单向认证一般用于 Web 网站，浏览器只需要验证服务端的身份。对于移动端 App，如果我们希望有更高的安全性，可以引入 HTTPS 双向认证，也就是除了客户端验证服务端身份之外，服务端也验证客户端的身份。</p><p>单向认证和双向认证的流程区别，主要包括以下三个方面。</p><p>第一，不仅仅服务端需要有 CA 证书，客户端也需要有 CA 证书。</p><p>第二，双向认证的流程中，客户端校验服务端 CA 证书之后，客户端会把自己的 CA 证书发给服务端，然后服务端需要校验客户端 CA 证书的真实性。</p><p>第三，客户端给服务端的消息会使用自己的私钥签名，服务端可以使用客户端 CA 证书中的公钥验签。</p><p>这里还想补充一点，对于移动应用程序考虑到更强的安全性，我们一般也会把服务端的公钥配置在客户端中，这种方式的叫做 SSL Pinning。也就是说由客户端直接校验服务端证书的合法性，而不是通过证书信任链来校验。采用 SSL Pinning，由于客户端绑定了服务端公钥，因此我们无法通过在移动设备上信用根证书实现抓包。不过这种方式的缺点是需要小心服务端 CA 证书过期后续证书注意不要修改公钥。</p><h1 id="缓存设计：缓存可以锦上添花也可以落井下石"><a href="#缓存设计：缓存可以锦上添花也可以落井下石" class="headerlink" title="缓存设计：缓存可以锦上添花也可以落井下石"></a>缓存设计：缓存可以锦上添花也可以落井下石</h1><blockquote><p>问题 1：在聊到缓存并发问题时，我们说到热点 Key 回源会对数据库产生的压力问题，如果 Key 特别热的话，可能缓存系统也无法承受，毕竟所有的访问都集中打到了一台缓存服务器。如果我们使用 Redis 来做缓存，那可以把一个热点 Key 的缓存查询压力，分散到多个 Redis 节点上吗？</p></blockquote><p>答：Redis 4.0 以上如果开启了 LFU 算法作为 maxmemory-policy，那么可以使用–hotkeys 配合 redis-cli 命令行工具来探查热点 Key。此外，我们还可以通过 MONITOR 命令来收集 Redis 执行的所有命令，然后配合redis-faina 工具来分析热点 Key、热点前缀等信息。</p><p>对于重要节假日、线上促销活动、集中推送这些提前已知的事情，可以提前评估出可能的热 key 来。而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行实时分析，及时发现新发布的热点 key。而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。</p><p>找到热 key 后，就有很多解决办法了。首先可以将这些热 key 进行分散处理，比如一个热 key 名字叫 hotkey，可以被分散为 hotkey#1、hotkey#2、hotkey#3，……hotkey#n，这 n 个 key 分散存在多个缓存节点，然后 client 端请求时，随机访问其中某个后缀的 hotkey，这样就可以把热 key 的请求打散，避免一个缓存节点过载。</p><p><img src="https://i0.hdslb.com/bfs/article/148b232811c1452b7be86393dd006511171301454.png" alt="image-20250208160154244"></p><p>其次，也可以 key 的名字不变，对缓存提前进行多副本+多级结合的缓存架构设计。</p><p>再次，如果热 key 较多，还可以通过监控体系对缓存的 SLA 实时监控，通过快速扩容来减少热 key 的冲击。</p><p>最后，业务端还可以使用本地缓存，将这些热 key 记录在本地缓存，来减少对远程缓存的冲击。</p><p>当然，除了分散 Redis 压力之外，我们也可以考虑再做一层短时间的本地缓存，结合 Redis 的 Keyspace 通知功能，当 Redis 集群压力超过阈值时，熔断降级直接返回本地缓存或默认值。</p><blockquote><p>问题 2：大 Key 也是数据缓存容易出现的一个问题。如果一个 Key 的 Value 特别大，那么可能会对 Redis 产生巨大的性能影响，因为 Redis 是单线程模型，对大 Key 进行查询或删除等操作，可能会引起 Redis 阻塞甚至是高可用切换。你知道怎么查询 Redis 中的大 Key，以及如何在设计上实现大 Key 的拆分吗？</p></blockquote><p>答：Redis 的大 Key 可能会导致集群内存分布不均问题，并且大 Key 的操作可能也会产生阻塞。</p><p>关于查询 Redis 中的大 Key，我们可以使用 <code>redis-cli –bigkeys</code> 命令来实时探查大 Key。此外，我们还可以使用 redis-rdb-tools 工具来分析 Redis 的 RDB 快照，得到包含 Key 的字节数、元素个数、最大元素长度等信息的 CSV 文件。然后，我们可以把这个 CSV 文件导入 MySQL 中，写 SQL 去分析。</p><p>针对大 Key，我们可以考虑几方面的优化：</p><p>第一，是否有必要在 Redis 保存这么多数据。一般情况下，我们在缓存系统中保存面向呈现的数据，而不是原始数据；对于原始数据的计算，我们可以考虑其它文档型或搜索型的 NoSQL 数据库。</p><p>第二，考虑把具有二级结构的 Key（比如 List、Set、Hash）拆分成多个小 Key，来独立获取（或是用 MGET 获取）。将大 key 分拆为多个 key，尽量减少大 key 的存在。同时由于大 key 一旦穿透到 DB，加载耗时很大，所以可以对这些大 key 进行特殊照顾，比如设置较长的过期时间，比如缓存内部在淘汰 key 时，同等条件下，尽量不淘汰这些大 key。</p><p>第三，可以扩展新的数据结构，同时让 client 在这些大 key 写缓存之前，进行序列化构建，然后通过 restore 一次性写入。</p><p>此外值得一提的是，大 Key 的删除操作可能会产生较大性能问题。从 Redis 4.0 开始，我们可以使用 UNLINK 命令而不是 DEL 命令在后台删除大 Key；而对于 4.0 之前的版本，我们可以考虑使用游标删除大 Key 中的数据，而不是直接使用 DEL 命令，比如对于 Hash 使用 HSCAN+HDEL 结合管道功能来删除。</p><h1 id="异步处理好用，但非常容易用错"><a href="#异步处理好用，但非常容易用错" class="headerlink" title="异步处理好用，但非常容易用错"></a>异步处理好用，但非常容易用错</h1><blockquote><p>在用户注册后发送消息到 MQ，然后会员服务监听消息进行异步处理的场景下，有些时候我们会发现，虽然用户服务先保存数据再发送 MQ，但会员服务收到消息后去查询数据库，却发现数据库中还没有新用户的信息。你觉得，这可能是什么问题呢，又该如何解决呢？</p></blockquote><p>答：我先来分享下，我遇到这个问题的真实情况。</p><p>当时，我们是因为业务代码把保存数据和发 MQ 消息放在了一个事务中，收到消息的时候有可能事务还没有提交完成。为了解决这个问题，开发同学当时的处理方式是，收 MQ 消息的时候 Sleep 1 秒再去处理。这样虽然解决了问题，但却大大降低了消息处理的吞吐量。</p><p>更好的做法是先提交事务，完成后再发 MQ 消息。但是，这又引申出来一个问题：MQ 消息发送失败怎么办，如何确保发送消息和本地事务有整体事务性？</p><h2 id="方案-1：本地消息表（Local-Message-Table）"><a href="#方案-1：本地消息表（Local-Message-Table）" class="headerlink" title="方案 1：本地消息表（Local Message Table）"></a>方案 1：<strong>本地消息表（Local Message Table）</strong></h2><p>这是一种经典的分布式事务解决方案，核心思想是通过本地事务保证消息的可靠性。</p><p><strong>实现步骤：</strong></p><ol><li>在用户服务的数据库中创建一个本地消息表，用于存储待发送的 MQ 消息。</li><li>用户服务在保存用户数据的同时，将 MQ 消息写入本地消息表（同一个事务）。</li><li>事务提交后，通过一个后台任务（或定时任务）从本地消息表中读取消息，并发送到 MQ。</li><li>消息发送成功后，删除本地消息表中的记录。</li></ol><p><strong>优点：</strong></p><ul><li>保证了本地事务和消息发送的一致性。</li><li>即使消息发送失败，也可以通过后台任务重试。</li></ul><p><strong>缺点：</strong></p><ul><li>需要维护一个本地消息表，增加了数据库的复杂性。</li><li>需要实现后台任务来发送消息。</li></ul><h2 id="方案-2：事务消息（Transactional-Outbox）"><a href="#方案-2：事务消息（Transactional-Outbox）" class="headerlink" title="方案 2：事务消息（Transactional Outbox）"></a>方案 2：<strong>事务消息（Transactional Outbox）</strong></h2><p>这是一种基于消息队列的事务性解决方案，适用于支持事务消息的 MQ（如 RocketMQ、Kafka）。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据的同时，将 MQ 消息写入本地消息表（同一个事务）。</li><li>使用 MQ 的事务消息功能，将消息发送到 MQ。</li><li>如果消息发送成功，MQ 会通知用户服务删除本地消息表中的记录。</li><li>如果消息发送失败，MQ 会触发重试机制。</li></ol><p><strong>优点：</strong></p><ul><li>消息发送和本地事务具有强一致性。</li><li>不需要额外的后台任务。</li></ul><p><strong>缺点：</strong></p><ul><li>依赖 MQ 的事务消息功能，不是所有 MQ 都支持。</li><li>实现复杂度较高。</li></ul><h2 id="方案-3：消息队列的最终一致性"><a href="#方案-3：消息队列的最终一致性" class="headerlink" title="方案 3：消息队列的最终一致性"></a>方案 3：<strong>消息队列的最终一致性</strong></h2><p>这是一种基于消息队列的最终一致性解决方案，适用于对一致性要求不是特别高的场景。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据后，发送 MQ 消息。</li><li>如果消息发送失败，用户服务会记录日志，并通过定时任务重试发送消息。</li><li>会员服务监听到消息后，处理新用户的信息。如果查询不到新用户的信息，可以等待一段时间后重试。</li></ol><p><strong>优点：</strong></p><ul><li>实现简单，适用于大多数场景。</li><li>不需要依赖复杂的分布式事务机制。</li></ul><p><strong>缺点：</strong></p><ul><li>无法保证强一致性，只能保证最终一致性。</li><li>需要处理消息重复消费的问题（幂等性）。</li></ul><h2 id="方案-4：分布式事务框架（如-Seata）"><a href="#方案-4：分布式事务框架（如-Seata）" class="headerlink" title="方案 4：分布式事务框架（如 Seata）"></a>方案 4：<strong>分布式事务框架（如 Seata）</strong></h2><p>如果业务对一致性要求非常高，可以使用分布式事务框架（如 Seata）来保证本地事务和消息发送的一致性。</p><p><strong>实现步骤：</strong></p><ol><li>用户服务在保存用户数据后，发送 MQ 消息。</li><li>Seata 会协调用户服务和 MQ 的事务，确保两者同时提交或回滚。</li></ol><p><strong>优点：</strong></p><ul><li>保证了强一致性。</li><li>适用于复杂的分布式事务场景。</li></ul><p><strong>缺点：</strong></p><ul><li>实现复杂度高，性能开销较大。</li><li>需要引入额外的分布式事务框架。</li></ul><h2 id="推荐方案"><a href="#推荐方案" class="headerlink" title="推荐方案"></a>推荐方案</h2><p>根据你的场景和需求，推荐以下方案：</p><ol><li><strong>如果对一致性要求较高</strong>，可以选择 <strong>本地消息表</strong> 或 <strong>事务消息</strong>。</li><li><strong>如果对一致性要求较低</strong>，可以选择 <strong>消息队列的最终一致性</strong>，并通过重试机制和幂等性来保证数据的正确性。</li></ol><h1 id="数据服务系统架构"><a href="#数据服务系统架构" class="headerlink" title="数据服务系统架构"></a>数据服务系统架构</h1><p>我们设计了一个包含多个数据库系统的、能应对各种高并发场景的一套数据服务的系统架构，其中包含了同步写服务、异步写服务和查询服务三部分，分别实现主数据库写入、辅助数据库写入和查询路由。</p><p>我们按照服务来依次分析下这个架构。</p><p><img src="https://i0.hdslb.com/bfs/openplatform/b0001fb75ba9d4897dd4e4b5fc07356f2c555d23.png" alt="image-20250716115523752"></p><p>首先要明确的是，重要的业务主数据只能保存在 MySQL 这样的关系型数据库中，原因有三点：</p><ul><li><p>RDBMS 经过了几十年的验证，已经非常成熟；</p></li><li><p>RDBMS 的用户数量众多，Bug 修复快、版本稳定、可靠性很高；</p></li><li><p>RDBMS 强调 ACID，能确保数据完整。</p></li></ul><p>有两种类型的查询任务可以交给 MySQL 来做，性能会比较好，这也是 MySQL 擅长的地方：</p><ul><li><p>按照主键 ID 的查询。直接查询聚簇索引，其性能会很高。但是单表数据量超过亿级后，性能也会衰退，而且单个数据库无法承受超大的查询并发，因此我们可以把数据表进行 Sharding 操作，均匀拆分到多个数据库实例中保存。我们把这套数据库集群称作 Sharding 集群。</p></li><li><p>按照各种条件进行范围查询，查出主键 ID。对二级索引进行查询得到主键，只需要查询一棵 B+ 树，效率同样很高。但索引的值不宜过大，比如对 varchar(1000) 进行索引不太合适，而索引外键（一般是 int 或 bigint 类型）性能就会比较好。因此，我们可以在 MySQL 中建立一张“索引表”，除了保存主键外，主要是保存各种关联表的外键，以及尽可能少的 varchar 类型的字段。这张索引表的大部分列都可以建上二级索引，用于进行简单搜索，搜索的结果是主键的列表，而不是完整的数据。由于索引表字段轻量并且数量不多（一般控制在 10 个以内），所以即便索引表没有进行 Sharding 拆分，问题也不会很大。</p></li></ul><p>如图上蓝色线所示，写入两种 MySQL 数据表和发送 MQ 消息的这三步，我们用一个同步写服务完成了。我在“异步处理”中提到，所有异步流程都需要补偿，这里的异步流程同样需要。只不过为了简洁，我在这里省略了补偿流程。</p><p>然后，如图中绿色线所示，有一个异步写服务，监听 MQ 的消息，继续完成辅助数据的更新操作。这里我们选用了 ES 和 InfluxDB 这两种辅助数据库，因此整个异步写数据操作有三步：</p><p>MQ 消息不一定包含完整的数据，甚至可能只包含一个最新数据的主键 ID，我们需要根据 ID 从查询服务查询到完整的数据。</p><p>写入 InfluxDB 的数据一般可以按时间间隔进行简单聚合，定时写入 InfluxDB。因此，这里会进行简单的客户端聚合，然后写入 InfluxDB。</p><p>ES 不适合在各索引之间做连接（Join）操作，适合保存扁平化的数据。比如，我们可以把订单下的用户、商户、商品列表等信息，作为内嵌对象嵌入整个订单 JSON，然后把整个扁平化的 JSON 直接存入 ES。</p><p>对于数据写入操作，我们认为操作返回的时候同步数据一定是写入成功的，但是由于各种原因，异步数据写入无法确保立即成功，会有一定延迟，比如：</p><ul><li><p>异步消息丢失的情况，需要补偿处理；</p></li><li><p>写入 ES 的索引操作本身就会比较慢；</p></li><li><p>写入 InfluxDB 的数据需要客户端定时聚合。</p></li></ul><p>因此，对于查询服务，如图中红色线所示，我们需要根据一定的上下文条件（比如查询一致性要求、时效性要求、搜索的条件、需要返回的数据字段、搜索时间区间等）来把请求路由到合适的数据库，并且做一些聚合处理：</p><p>需要根据主键查询单条数据，可以从 MySQL Sharding 集群或 Redis 查询，如果对实时性要求不高也可以从 ES 查询。</p><p>按照多个条件搜索订单的场景，可以从 MySQL 索引表查询出主键列表，然后再根据主键从 MySQL Sharding 集群或 Redis 获取数据详情。</p><p>各种后台系统需要使用比较复杂的搜索条件，甚至全文搜索来查询订单数据，或是定时分析任务需要一次查询大量数据，这些场景对数据实时性要求都不高，可以到 ES 进行搜索。此外，MySQL 中的数据可以归档，我们可以在 ES 中保留更久的数据，而且查询历史数据一般并发不会很大，可以统一路由到 ES 查询。</p><p>监控系统或后台报表系统需要呈现业务监控图表或表格，可以把请求路由到 InfluxDB 查询。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Spring-框架：IoC-和-AOP-是扩展的核心&quot;&gt;&lt;a href=&quot;#Spring-框架：IoC-和-AOP-是扩展的核心&quot; class=&quot;headerlink&quot; title=&quot;Spring 框架：IoC 和 AOP 是扩展的核心&quot;&gt;&lt;/a&gt;Spring 框</summary>
      
    
    
    
    
    <category term="Java" scheme="https://palette-k.github.io/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Java程序从虚拟机迁移到Kubernetes的一些坑</title>
    <link href="https://palette-k.github.io/2025/02/07/Java%E7%A8%8B%E5%BA%8F%E4%BB%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB%E5%88%B0Kubernetes%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/"/>
    <id>https://palette-k.github.io/2025/02/07/Java%E7%A8%8B%E5%BA%8F%E4%BB%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%BF%81%E7%A7%BB%E5%88%B0Kubernetes%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9D%91/</id>
    <published>2025-02-07T02:48:02.000Z</published>
    <updated>2025-02-07T02:57:20.997Z</updated>
    
    <content type="html"><![CDATA[<p>在大多数的公司中，Kubernetes 集群由运维来搭建，而程序的发布一般也是由 CI&#x2F;CD 平台完成。从虚拟机到 Kubernetes 的整个迁移过程，基本不需要修改任何代码，可能只是重新发布一次而已。所以，我们 Java 开发人员可能对迁移这个事情本身感知不强烈，认为 Kubernetes 只是运维需要知道的事情。但是程序一旦部署到了 Kubernetes 集群中，在容器环境中运行，总是会出现各种各样之前没有的奇怪的问题。</p><h2 id="Pod-IP-不固定带来的坑"><a href="#Pod-IP-不固定带来的坑" class="headerlink" title="Pod IP 不固定带来的坑"></a>Pod IP 不固定带来的坑</h2><p>Pod 是 Kubernetes 中能够创建和部署应用的最小单元，我们可以通过 Pod IP 来访问到某一个应用实例，但需要注意的是，如果没有经过特殊配置，Pod IP 并不是固定不变的，会在 Pod 重启后会发生变化。</p><p>不过好在，通常我们的 Java 微服务都是没有状态的，我们并不需要通过 Pod IP 来访问到某一个特定的 Java 服务实例。通常来说，要访问到部署在 Kubernetes 中的微服务集群，有两种服务发现和访问的方式：</p><p>通过 Kubernetes 来实现。也就是通过 Service 进行内部服务的互访，通过 Ingress 从外部访问到服务集群。</p><p>通过微服务注册中心（比如 Eureka）来实现。也就是服务之间的互访通过客户端负载均衡后 + 直接访问 Pod IP 进行，外部访问到服务集群通过微服务网关转发请求。</p><p>使用这两种方式进行微服务的访问，我们都没有和 Pod IP 直接打交道，也不会把 Pod IP 记录持久化，所以一般不需要太关注 Pod IP 变动的问题。不过，在一些场景下，Pod IP 的变动会造成一些问题。</p><p>之前我就遇到过这样的情况：某任务调度中间件会记录被调度节点的 IP 到数据库，随后通过访问节点 IP 查看任务节点执行日志的时候，如果节点部署在 Kubernetes 中，那么节点重启后 Pod IP 就会变动。这样，之前记录在数据库中的老节点的 Pod IP 必然访问不到，那么就会发生无法查看任务日志的情况。</p><p>遇到这种情况，我们应该怎么做呢？这时候，可能就需要修改这个中间件，把任务执行日志也进行持久化，从而避免这种访问任务节点来查看日志的行为。</p><p>总之，我们需要意识到 Pod IP 不固定的问题，并且进行“避坑操作”：在迁移到 Kubernetes 集群之前，摸排一下是否会存在需要通过 IP 访问到老节点的情况，如果有的话需要进行改造。</p><h2 id="程序因为-OOM-被杀进程的坑"><a href="#程序因为-OOM-被杀进程的坑" class="headerlink" title="程序因为 OOM 被杀进程的坑"></a>程序因为 OOM 被杀进程的坑</h2><p>在 Kubernetes 集群中部署程序的时候，我们通常会为容器设置一定的内存限制（limit），容器不可以使用超出其资源 limit 属性所设置的资源量。如果容器内的 Java 程序使用了大量内存，可能会出现各种 OOM 的情况。</p><p>第一种情况，是 OS OOM Kill 问题。如果过量内存导致操作系统 Kernel 不稳定，操作系统可能就会杀死 Java 进程。这时候，你能在操作系统 &#x2F;var&#x2F;log&#x2F;messages 日志中找到类似 oom_kill_process 的关键字。</p><p>第二种情况，是我们最常遇到的 Java 程序的 OOM 问题。程序超出堆内存的限制申请内存，导致 Heap OOM，后续可能会因为健康检测没有通过被 Kubernetes 重启 Pod。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/2cf6d48915a0bce6834cf46edb462c04.png" alt="img"></p><p>在 Kubernetes 中部署 Java 程序时，这两种情况都很常见，表现出的症状也都是 OOM 关键字 + 重启。所以，当运维同学说程序因为 OOM 被杀死或重启的时候，我们一定要和运维同学一起去区分清楚，到底是哪一种情况，然后再对症处理。</p><p>对于情况 1，问题的原因往往不是 Java 堆内存不够，更可能是程序使用了太多的堆外内存，超过了内存限制。这个时候，调大 JVM 最大堆内存只会让问题更严重，因为堆内存是可以通过 GC 回收的。我们需要分析 Java 进程哪部分区域内存占用过大，是不是合理，以及是否可能存在内存泄露问题。Java 进程的内存占用除了堆之外，还包括</p><p>直接内存</p><p>元数据区</p><p>线程栈大小 Xss * 线程数</p><p>JIT 代码缓存</p><p>GC、编译器使用额外空间</p><p>……</p><p>我们可以使用 NMT 打印各部分区域大小，从而判断到底是哪部分内存区域占用了过多内存，或是可能有内存泄露问题：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -<span class="variable constant_">XX</span><span class="symbol">:NativeMemoryTracking=smmary/detail</span> -<span class="variable constant_">XX</span><span class="symbol">:+UnlockDiagnosticVMOptions</span> -<span class="variable constant_">XX</span><span class="symbol">:+PrintNMTStatistics</span></span><br></pre></td></tr></table></figure><p>如果你确认 OOM 是情况 2，那么我同样不建议直接调大堆内存的限制，防止之后再出现情况 1。我会更建议你把堆内存限制为容器内存限制的 50%~70%，预留出足够多的内存给堆外和 OS 核心。如果需要扩容堆内存的话，那么也需要同步扩容容器的内存 limit。此外，也需要通过 Heap Dump 等手段来排查为什么堆内存占用会这么大，排除潜在的内存泄露的可能性。</p><h2 id="内存和-CPU-资源配置不适配容器的坑"><a href="#内存和-CPU-资源配置不适配容器的坑" class="headerlink" title="内存和 CPU 资源配置不适配容器的坑"></a>内存和 CPU 资源配置不适配容器的坑</h2><p>刚刚我们提到了，堆内存扩容需要结合容器内存 limit 同步进行。其实，我们更希望的是，Java 程序的堆内存配置能随着容器的资源配置，实现自动扩容或缩容，而不是写死 Xmx 和 Xms。这样一来，运维同学可以更方便地针对整个集群进行扩容或缩容。</p><p>对于 JDK&gt;8u191 的版本，我们可以设置下面这些 JVM 参数，来让 JVM 自动根据容器内存限制来设置堆内存用量。比如，下面配置相当于把 Xmx 和 Xms 都设置为了容器内存 limit 的 50%：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable constant_">XX</span><span class="symbol">:MaxRAMPercentage=</span><span class="number">50.0</span> -<span class="variable constant_">XX</span><span class="symbol">:InitialRAMPercentage=</span><span class="number">50.0</span> -<span class="variable constant_">XX</span><span class="symbol">:MinRAMPercentage=</span><span class="number">50.0</span></span><br></pre></td></tr></table></figure><p>接下来，我们看看 CPU 资源配置不适配容器的坑，以及对应的解决方案。</p><p>对于 CPU 资源的使用，我们主要需要注意的是，代码中的各种组件甚至是 JVM 本身，会根据 CPU 数来配置并发数等重要参数指标，那么：</p><p>如果这个值因为 JVM 对容器的兼容性问题取到了 Kubernetes 工作节点的 CPU 数量，那么这个数量可能就不是 4 或 8，而是 128 以上，进而导致并发数过高。</p><p>对于 JDK&gt;8u191 的版本可能会对容器兼容性较好，但是其获取到的 Runtime.getRuntime().availableProcessors() 其实是 request 的值而不是 limit 的值（比如我们设置 request 为 2、limit 为 8、CICompilerCount 和 ParallelGCThreads 可能只是 2），那么可能并发数就会过低，进而影响 JVM 的 GC 或编译性能。</p><p>所以，我的建议是：</p><p>第一，通过 -XX:+PrintFlagsFinal 开关，来确认 ActiveProcessorCount 是不是符合我们的期望，并且确认 CICompilerCount、ParallelGCThreads 等重要参数配置是否合理。</p><p>第二，直接设置 CPU 的 request 和 limit 一致，或是对于 JDK&gt;8u191 的版本可以通过 -XX:ActiveProcessorCount&#x3D;xxx 直接把 ActiveProcessorCount 设置为容器的 CPU limit。</p><h2 id="Pod-重启以及重启后没有现场的坑"><a href="#Pod-重启以及重启后没有现场的坑" class="headerlink" title="Pod 重启以及重启后没有现场的坑"></a>Pod 重启以及重启后没有现场的坑</h2><p>除非宿主机有问题，否则虚拟机不太会自己重启或被重启，而 Kubernetes 中 Pod 的重启绝非小概率事件。在存活检测不通过、Pod 重新进行节点调度等情况下，Pod 都会进行重启。对于 Pod 的重启，我们需要关注两个问题。</p><p>第一个问题是，分析 Pod 为什么会重启。</p><p>其中，除了“程序因为 OOM 被杀进程的坑”这部分提到的 OOM 的问题之外，我们还需要关注存活检查不通过的情况。</p><p>Kubernetes 有 readinessProbe 和 livenessProbe 两个探针，前者用于检查应用是否已经启动完成，后者用于持续探活。一般而言，运维同学会配置这 2 个探针为一个健康检测的断点，如果健康检测访问一次需要消耗比较长的时间（比如涉及到存储或外部服务可用性检测），那么很可能可以通过 readinessProbe 的检查但不通过 livenessProbe 检查（毕竟我们通常会为 readinessProbe 设置比较长的超时时间，而对于 livenessProbe 则没有那么宽容）。此外，健康检测也可能会受到 Full GC 的干扰导致超时。所以，我们需要和运维同学一起确认 livenessProbe 的配置地址和超时时间设置是否合理，防止偶发的 livenessProbe 探活失败导致的 Pod 重启。</p><p>第二个问题是，要理解 Pod 和虚拟机不同。</p><p>虚拟机一般都是有状态的，即便部署在虚拟机内的 Java 程序重启了，我们始终能有现场。而对于 Pod 重启来说，则是新建一个 Pod，这就意味着老的 Pod 无法进入。因此，如果因为堆 OOM 问题导致重启，我们希望事后查看当时 OS 的一些日志或是在现场执行一些命令来分析问题，就不太可能了。</p><p>所以，我们需要想办法在 Pod 关闭之前尽可能保留现场，比如：</p><p>对于程序的应用日志、标准输出、GC 日志等可以直接挂载到持久卷，不要保存在容器内部。</p><p>对于程序的堆栈现场保留，可以配置 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath 在堆 OOM 的时候生成 Dump；还可以让 JVM 调用任一个 shell 脚本，通过脚本来保留线程栈等信息：</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-<span class="variable constant_">XX</span><span class="symbol">:OnOutOfMemoryError=saveinfo</span>.sh</span><br></pre></td></tr></table></figure><p>对于容器的现场保留，可以让运维配置 preStop 钩子，在 Pod 关闭之前把必要的信息上传到持久卷或云上。</p><h2 id="重点回顾"><a href="#重点回顾" class="headerlink" title="重点回顾"></a>重点回顾</h2><p>今天，我们探讨了 Java 应用部署到 Kubernetes 集群会遇到的 4 类问题。</p><p>第一类问题是，我们需要理解应用的 IP 会动态变化，因此要在设计上解除对 Pod IP 的强依赖，使用依赖服务发现来定位到应用。</p><p>第二类问题是，在出现 OOM 问题的时候，首先要区分 OOM 的原因来自 Java 进程层面还是容器层面。如果是容器层面的话，我们还需要进一步分析到底是哪个内存区域占用了过多内存，定位到问题后再根据容器资源设置合理的 JVM 参数或进行资源扩容。</p><p>第三类问题是，需要确保程序使用的内存和 CPU 资源匹配容器的资源限制，既要确保程序所“看”到的主机资源信息是容器本身的而不是物理机的，又要确保程序能尽可能随着容器扩容而扩容其资源限制。</p><p>第四类问题是，我们需要重点关注程序非发布期重启的问题，并且针对 Pod 的重启问题做好现场保留的准备工作，排除资源配置不合理、存活检查不通过等可能性，以避免因为程序频繁重启导致的偶发性能问题或可用性问题。</p><p>只有解决了这些隐患，才能让 Kubernetes 集群更好地发挥作用。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在大多数的公司中，Kubernetes 集群由运维来搭建，而程序的发布一般也是由 CI&amp;#x2F;CD 平台完成。从虚拟机到 Kubernetes 的整个迁移过程，基本不需要修改任何代码，可能只是重新发布一次而已。所以，我们 Java 开发人员可能对迁移这个事情本身感知不强</summary>
      
    
    
    
    
    <category term="Kubernetes" scheme="https://palette-k.github.io/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>漫谈RocketMQ消息发送</title>
    <link href="https://palette-k.github.io/2025/01/26/%E6%BC%AB%E8%B0%88RocketMQ%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81/"/>
    <id>https://palette-k.github.io/2025/01/26/%E6%BC%AB%E8%B0%88RocketMQ%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81/</id>
    <published>2025-01-26T10:09:22.000Z</published>
    <updated>2025-01-27T03:36:34.491Z</updated>
    
    <content type="html"><![CDATA[<h1 id="topic路由机制"><a href="#topic路由机制" class="headerlink" title="topic路由机制"></a>topic路由机制</h1><p>消息发送者向某一个topic发送消息时，需要查询topic的路由信息。初次发送时会根据topic的名称向NameServer集群查询topic的路由信息，然后将其缓存在本地内存中，并且每隔30s依次遍历缓存中的topic，向NameServer查询最新的路由信息。如果成功查询到路由信息，会将这些信息更新到本地缓存，实现topic路由信息的动态感知。</p><p>RocketMQ提供了自动创建主题的机制，消息发送者向一个不存在的主题发送消息时，向NameServer查询该主题的路由信息会先返回空，如果开启了自动创建主题机制，会使用一个默认的主题名再次从NameServer查询路由信息，然后消息发送者会使用默认主题的路由信息进行负载均衡，但不会直接使用默认路由信息为新主题创建对应的路由信息。</p><p><img src="https://i0.hdslb.com/bfs/article/7c203d765aa13dc7d121605b562f93e5171301454.png" alt="image-20250126182926724"></p><h2 id="生产环境中，为何不建议自动创建topic"><a href="#生产环境中，为何不建议自动创建topic" class="headerlink" title="生产环境中，为何不建议自动创建topic"></a>生产环境中，为何不建议自动创建topic</h2><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>因为生产环境一般是集群部署多台broker服务器，autoCreateTopicEnable设置为true，表示开启topic自动创建，但新创建的topic的路由信息只包含在其中一台broker服务器上。</p><p>期望回答：为了消息发送的高可用，希望新创建的topic在集群中的每台broker上创建对应的队列，避免broker的单节点故障。</p><p>在RocketMQ中，如果autoCreateTopicEnable设置为true，消息发送者向NameServer查询主题的路由消息返回空时，会尝试用一个系统默认的主题名称(MixAll.AUTO_CREATE_TOPIC_KEY_TOPIC)，此时消息发送者得到的路由信息为：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/Wkp2azia4QFv937FNO2g61wLud0L59P0dS9WndkJ2k15kWPEIyO9TA2hDEpfrf7micsVLukSFptGK84pqicjbs6Og/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>默认Topic在集群的每一台Broker上创建8个队列，那问题来了，为啥新创建的Topic只在一个Broker上创建4个队列呢？</p><p>Step1：在Broker启动流程中，会构建TopicConfigManager对象，其构造方法中首先会判断是否开启了允许自动创建主题，如果启用了自动创建主题，则向topicConfigTable中添加默认主题的路由信息。</p><p>BrokerConfig的defaultTopicQueueNum默认为8。两台Broker服务器都会运行上面的过程，故最终Nameserver中关于默认主题的路由信息中，会包含两个Broker分别各8个队列信息。</p><p>Step2：生产者寻找路由信息<br>生产者首先向NameServer查询路由信息，由于是一个不存在的主题，故此时返回的路由信息为空，RocketMQ会使用默认的主题再次寻找，由于开启了自动创建路由信息，NameServer会向生产者返回默认主题的路由信息。然后从返回的路由信息中选择一个队列（默认轮询）。消息发送者从Nameserver获取到默认的Topic的队列信息后，队列的个数会改变吗？答案是会的。</p><p>消息发送者在到默认路由信息时，其队列数量，会选择DefaultMQProducer#defaultTopicQueueNums与Nameserver返回的的队列数取最小值，<strong>DefaultMQProducer#defaultTopicQueueNums默认值为4，故自动创建的主题，其队列数量默认为4。</strong></p><p>Step3：发送消息</p><p>在消息发送时的请求报文中，设置默认topic名称，消息发送topic名称，使用的队列数量为DefaultMQProducer#defaultTopicQueueNums，即默认为4。</p><p>Step4：Broker端收到消息后的处理流程</p><p>在Broker端，首先会使用TopicConfigManager根据topic查询路由信息，如果Broker端不存在该主题的路由配置(路由信息),且Broker中存在默认主题的路由配置信息，则根据消息发送请求中的队列数量，在Broker创建新Topic的路由信息。这样Broker服务端就会存在主题的路由信息。</p><p>在Broker端的topic配置管理器中存在的路由信息，一会向Nameserver发送心跳包，汇报到Nameserver，另一方面会有一个定时任务，定时存储在broker端，具体路径为${ROCKET_HOME}&#x2F;store&#x2F;config&#x2F;topics.json中，这样在Broker关闭后再重启，并不会丢失路由信息。</p><h3 id="现象分析"><a href="#现象分析" class="headerlink" title="现象分析"></a>现象分析</h3><p>经过上面自动创建路由机制的创建流程，我们可以比较容易的分析得出如下结论：</p><p>因为开启了自动创建路由信息，消息发送者根据Topic去NameServer无法得到路由信息，但接下来根据默认Topic从NameServer是能拿到路由信息(在每个Broker中，存在8个队列)，因为两个Broker在启动时都会向NameServer汇报路由信息。此时消息发送者缓存的路由信息是2个Broker，每个Broker默认4个队列</p><p>消息发送者然后按照轮询机制，发送第一条消息选择(broker-a的messageQueue:0)，向Broker发送消息，Broker服务器在处理消息时，首先会查看自己的路由配置管理器(TopicConfigManager)中的路由信息，此时不存在对应的路由信息，然后尝试查询是否存在默认Topic的路由信息，如果存在，说明启用了autoCreateTopicEnable，则在TopicConfigManager中创建新Topic的路由信息，此时存在与Broker服务端的内存中，然后本次消息发送结束。此时，在NameServer中还不存在新创建的Topic的路由信息。</p><p>这里有三个关键点：</p><ol><li>启用autoCreateTopicEnable创建主题时，在Broker端创建主题的时机为，消息生产者往Broker端发送消息时才会创建。</li><li>然后Broker端会在一个心跳包周期内，将新创建的路由信息发送到NameServer，于此同时，Broker端还会有一个定时任务，定时将内存中的路由信息，持久化到Broker端的磁盘上。</li><li>消息发送者会每隔30s向NameServer更新路由信息，如果消息发送端一段时间内未发送消息，就不会有消息发送集群内的第二台Broker，那么NameServer中新创建的Topic的路由信息只会包含Broker-a，然后消息发送者会向NameServer拉取最新的路由信息，此时就会消息发送者原本缓存了2个broker的路由信息，将会变为一个Broker的路由信息，则该Topic的消息永远不会发送到另外一个Broker，就出现了上述现象。</li></ol><p>原因就分析到这里了，现在我们还可以的大胆假设，开启autoCreateTopicEnable机制，什么情况会在两个Broker上都创建队列，其实，我们只需要连续快速的发送9条消息，就有可能在2个Broker上都创建队列，验证代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"> 1public <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> MQClientException, InterruptedException &#123;</span><br><span class="line"> <span class="number">2</span>    <span class="type">DefaultMQProducer</span> <span class="variable">producer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultMQProducer</span>(<span class="string">&quot;please_rename_unique_group_name&quot;</span>);</span><br><span class="line"> <span class="number">3</span>    producer.setNamesrvAddr(<span class="string">&quot;127.0.0.1:9876&quot;</span>);</span><br><span class="line"> <span class="number">4</span>    producer.start();</span><br><span class="line"> <span class="number">5</span>    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">9</span>; i++) &#123;</span><br><span class="line"> <span class="number">6</span>        <span class="keyword">try</span> &#123;</span><br><span class="line"> <span class="number">7</span>            <span class="type">Message</span> <span class="variable">msg</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Message</span>(<span class="string">&quot;TopicTest10&quot;</span> ,<span class="string">&quot;TagA&quot;</span> , (<span class="string">&quot;Hello RocketMQ &quot;</span> + i).getBytes(RemotingHelper.DEFAULT_CHARSET));</span><br><span class="line"> <span class="number">8</span>            <span class="type">SendResult</span> <span class="variable">sendResult</span> <span class="operator">=</span> producer.send(msg);</span><br><span class="line"> <span class="number">9</span>            System.out.printf(<span class="string">&quot;%s%n&quot;</span>, sendResult);</span><br><span class="line"><span class="number">10</span>        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line"><span class="number">11</span>            e.printStackTrace();</span><br><span class="line"><span class="number">12</span>            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line"><span class="number">13</span>        &#125;</span><br><span class="line"><span class="number">14</span>    &#125;</span><br><span class="line"><span class="number">15</span>    producer.shutdown();</span><br><span class="line"><span class="number">16</span>&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;topic路由机制&quot;&gt;&lt;a href=&quot;#topic路由机制&quot; class=&quot;headerlink&quot; title=&quot;topic路由机制&quot;&gt;&lt;/a&gt;topic路由机制&lt;/h1&gt;&lt;p&gt;消息发送者向某一个topic发送消息时，需要查询topic的路由信息。初次发送时会根</summary>
      
    
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>线程安全小妙招</title>
    <link href="https://palette-k.github.io/2025/01/26/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%8F%E5%A6%99%E6%8B%9B/"/>
    <id>https://palette-k.github.io/2025/01/26/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E5%B0%8F%E5%A6%99%E6%8B%9B/</id>
    <published>2025-01-26T07:41:22.000Z</published>
    <updated>2025-01-26T07:58:22.768Z</updated>
    
    <content type="html"><![CDATA[<h1 id="TreadLocal的正确打开方式"><a href="#TreadLocal的正确打开方式" class="headerlink" title="TreadLocal的正确打开方式"></a>TreadLocal的正确打开方式</h1><p>我们知道，ThreadLocal 适用于变量在线程间隔离，而在方法或类间共享的场景。如果用户信息的获取比较昂贵（比如从数据库查询用户信息），那么在 ThreadLocal 中缓存数据是比较合适的做法。</p><p>但是如果错误地使用了ThreadLocal，可能会导致有时获取到的用户信息是别人的。为什么会出现用户信息错乱的 Bug 呢？</p><p>我们来复现一下这个场景。</p><p>使用 Spring Boot 创建一个 Web 应用程序，使用 ThreadLocal 存放一个 Integer 的值，来暂且代表需要在线程中保存的用户信息，这个值初始是 null。在业务逻辑中，我先从 ThreadLocal 获取一次值，然后把外部传入的参数设置到 ThreadLocal 中，来模拟从当前上下文获取到用户信息的逻辑，随后再获取一次值，最后输出两次获得的值和线程名称。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> ThreadLocal&lt;Integer&gt; currentUser = ThreadLocal.withInitial(() -&gt; <span class="literal">null</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">@GetMapping(&quot;wrong&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Map <span class="title function_">wrong</span><span class="params">(<span class="meta">@RequestParam(&quot;userId&quot;)</span> Integer userId)</span> &#123;</span><br><span class="line">    <span class="comment">//设置用户信息之前先查询一次ThreadLocal中的用户信息</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">before</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    <span class="comment">//设置用户信息到ThreadLocal</span></span><br><span class="line">    currentUser.set(userId);</span><br><span class="line">    <span class="comment">//设置用户信息之后再查询一次ThreadLocal中的用户信息</span></span><br><span class="line">    <span class="type">String</span> <span class="variable">after</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    <span class="comment">//汇总输出两次查询结果</span></span><br><span class="line">    <span class="type">Map</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">    result.put(<span class="string">&quot;before&quot;</span>, before);</span><br><span class="line">    result.put(<span class="string">&quot;after&quot;</span>, after);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>按理说，在设置用户信息之前第一次获取的值始终应该是 null，但我们要意识到，程序运行在 Tomcat 中，执行程序的线程是 Tomcat 的工作线程，而 Tomcat 的工作线程是基于线程池的。</p><p><strong>顾名思义，线程池会重用固定的几个线程，一旦线程重用，那么很可能首次从 ThreadLocal 获取的值是之前其他用户的请求遗留的值。这时，ThreadLocal 中的用户信息就是其他用户的信息。</strong></p><p>为了更快地重现这个问题，我在配置文件中设置一下 Tomcat 的参数，把工作线程池最大线程数设置为 1，这样始终是同一个线程在处理请求：</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">server.tomcat.max-threads</span>=<span class="string">1</span></span><br></pre></td></tr></table></figure><p>运行程序后先让用户 1 来请求接口，可以看到第一和第二次获取到用户 ID 分别是 null 和 1，符合预期：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/4b8f38415d03423132c7a3608ebe2430.png" alt="img"></p><p>随后用户 2 来请求接口，这次就出现了 Bug，第一和第二次获取到用户 ID 分别是 1 和 2，显然第一次获取到了用户 1 的信息，原因就是 Tomcat 的线程池重用了线程。从图中可以看到，两次请求的线程都是同一个线程：http-nio-8080-exec-1。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/a9ccd42716d807687b3acff9a0baf2db.png" alt="img"></p><p>这个例子告诉我们，在写业务代码时，首先要理解代码会跑在什么线程上：</p><ul><li>我们可能会抱怨学多线程没用，因为代码里没有开启使用多线程。但其实，可能只是我们没有意识到，在 Tomcat 这种 Web 服务器下跑的业务代码，本来就运行在一个多线程环境（否则接口也不可能支持这么高的并发），<strong>并不能认为没有显式开启多线程就不会有线程安全问题。</strong></li><li>因为线程的创建比较昂贵，所以 Web 服务器往往会使用线程池来处理请求，这就意味着线程会被重用。这时，<strong>使用类似 ThreadLocal 工具来存放一些数据时，需要特别注意在代码运行完后，显式地去清空设置的数据。</strong>如果在代码中使用了自定义的线程池，也同样会遇到这个问题。</li></ul><p>理解了这个知识点后，我们修正这段代码的方案是，在代码的 finally 代码块中，显式清除 ThreadLocal 中的数据。这样一来，新的请求过来即使使用了之前的线程也不会获取到错误的用户信息了。修正后的代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;right&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Map <span class="title function_">right</span><span class="params">(<span class="meta">@RequestParam(&quot;userId&quot;)</span> Integer userId)</span> &#123;</span><br><span class="line">    <span class="type">String</span> <span class="variable">before</span>  <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">    currentUser.set(userId);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">after</span> <span class="operator">=</span> Thread.currentThread().getName() + <span class="string">&quot;:&quot;</span> + currentUser.get();</span><br><span class="line">        <span class="type">Map</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashMap</span>();</span><br><span class="line">        result.put(<span class="string">&quot;before&quot;</span>, before);</span><br><span class="line">        result.put(<span class="string">&quot;after&quot;</span>, after);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">//在finally代码块中删除ThreadLocal中的数据，确保数据不串</span></span><br><span class="line">        currentUser.remove();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重新运行程序可以验证，再也不会出现第一次查询用户信息查询到之前用户请求的 Bug：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/Java%20%e4%b8%9a%e5%8a%a1%e5%bc%80%e5%8f%91%e5%b8%b8%e8%a7%81%e9%94%99%e8%af%af%20100%20%e4%be%8b/assets/0dfe40fca441b58d491fc799d120a7cc.png" alt="img"></p><p>其实如果使用<code>ThreadLocal</code> 后不及时调用 <code>remove()</code> 方法，可能还会引发内存泄漏问题。</p><p><code>ThreadLocal</code> 的实现依赖于每个线程内部的一个 <code>ThreadLocalMap</code>，<code>ThreadLocal</code> 对象作为键，存储的值作为值。<code>ThreadLocalMap</code> 中的键是对 <code>ThreadLocal</code> 对象的弱引用（<code>WeakReference</code>），而值是强引用。</p><p>当外部对 <code>ThreadLocal</code> 对象的强引用被释放后，由于 <code>ThreadLocalMap</code> 中的键是弱引用，在垃圾回收时，这个 <code>ThreadLocal</code> 实例会被回收，其对应的键会变为 <code>null</code>。但此时值仍然是强引用，只要线程一直存活，<code>ThreadLocalMap</code> 就不会被回收，这些 <code>null</code> 键对应的值就无法被访问到，却仍然占用着内存，从而造成内存泄漏。</p><h1 id="线程池的声明需手动进行"><a href="#线程池的声明需手动进行" class="headerlink" title="线程池的声明需手动进行"></a>线程池的声明需手动进行</h1><p>Java 中的 Executors 类定义了一些快捷的工具方法，来帮助我们快速创建线程池。《阿里巴巴 Java 开发手册》中提到，禁止使用这些方法来创建线程池，而应该手动 new ThreadPoolExecutor 来创建线程池。这一条规则的背后，是大量血淋淋的生产事故，最典型的就是 newFixedThreadPool 和 newCachedThreadPool，可能因为资源耗尽导致 OOM 问题。</p><p>首先，我们来看一下 newFixedThreadPool 为什么可能会出现 OOM 的问题。</p><p>我们写一段测试代码，来初始化一个单线程的 FixedThreadPool，循环 1 亿次向线程池提交任务，每个任务都会创建一个比较大的字符串然后休眠一小时：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@GetMapping(&quot;oom1&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">oom1</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">ThreadPoolExecutor</span> <span class="variable">threadPool</span> <span class="operator">=</span> (ThreadPoolExecutor) Executors.newFixedThreadPool(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印线程池的信息，稍后我会解释这段代码</span></span><br><span class="line">    printStats(threadPool); </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100000000</span>; i++) &#123;</span><br><span class="line"></span><br><span class="line">        threadPool.execute(() -&gt; &#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">payload</span> <span class="operator">=</span> IntStream.rangeClosed(<span class="number">1</span>, <span class="number">1000000</span>)</span><br><span class="line">                    .mapToObj(__ -&gt; <span class="string">&quot;a&quot;</span>)</span><br><span class="line">                    .collect(Collectors.joining(<span class="string">&quot;&quot;</span>)) + UUID.randomUUID().toString();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                TimeUnit.HOURS.sleep(<span class="number">1</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            log.info(payload);</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    threadPool.shutdown();</span><br><span class="line">    threadPool.awaitTermination(<span class="number">1</span>, TimeUnit.HOURS);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行程序后不久，日志中就出现了如下 OOM：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread <span class="string">&quot;http-nio-45678-ClientPoller&quot;</span> java.lang.OutOfMemoryError: GC overhead limit exceeded</span><br></pre></td></tr></table></figure><p>翻看 newFixedThreadPool 方法的源码不难发现，线程池的工作队列直接 new 了一个 LinkedBlockingQueue，而默认构造方法的 LinkedBlockingQueue 是一个 Integer.MAX_VALUE 长度的队列，可以认为是无界的：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title function_">newFixedThreadPool</span><span class="params">(<span class="type">int</span> nThreads)</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(nThreads, nThreads,</span><br><span class="line">                                  <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> <span class="title class_">LinkedBlockingQueue</span>&lt;Runnable&gt;());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LinkedBlockingQueue</span>&lt;E&gt; <span class="keyword">extends</span> <span class="title class_">AbstractQueue</span>&lt;E&gt;</span><br><span class="line">        <span class="keyword">implements</span> <span class="title class_">BlockingQueue</span>&lt;E&gt;, java.io.Serializable &#123;</span><br><span class="line"></span><br><span class="line">    ...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Creates a &#123;<span class="doctag">@code</span> LinkedBlockingQueue&#125; with a capacity of</span></span><br><span class="line"><span class="comment">     * &#123;<span class="doctag">@link</span> Integer#MAX_VALUE&#125;.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">LinkedBlockingQueue</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>(Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>虽然使用 newFixedThreadPool 可以把工作线程控制在固定的数量上，但任务队列是无界的。如果任务较多并且执行较慢的话，队列可能会快速积压，撑爆内存导致 OOM。</p><p>我们再把刚才的例子稍微改一下，改为使用 newCachedThreadPool 方法来获得线程池。程序运行不久后，同样看到了如下 OOM 异常：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[11:30:30.487] [http-nio-45678-exec-1] [ERROR] [.a.c.c.C.[.[.[/].[dispatcherServlet]:175 ] - Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: unable to create new native thread] with root cause</span><br><span class="line"></span><br><span class="line">java.lang.OutOfMemoryError: unable to create new native thread </span><br></pre></td></tr></table></figure><p>从日志中可以看到，这次 OOM 的原因是无法创建线程，翻看 newCachedThreadPool 的源码可以看到，这种线程池的最大线程数是 Integer.MAX_VALUE，可以认为是没有上限的，而其工作队列 SynchronousQueue 是一个没有存储空间的阻塞队列。这意味着，只要有请求到来，就必须找到一条工作线程来处理，如果当前没有空闲的线程就再创建一条新的。</p><p>由于我们的任务需要 1 小时才能执行完成，大量的任务进来后会创建大量的线程。我们知道线程是需要分配一定的内存空间作为线程栈的，比如 1MB，因此无限制创建线程必然会导致 OOM：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title function_">newCachedThreadPool</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">ThreadPoolExecutor</span>(<span class="number">0</span>, Integer.MAX_VALUE,</span><br><span class="line">                                  <span class="number">60L</span>, TimeUnit.SECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> <span class="title class_">SynchronousQueue</span>&lt;Runnable&gt;());</span><br></pre></td></tr></table></figure><p>其实，大部分 Java 开发同学知道这两种线程池的特性，只是抱有侥幸心理，觉得只是使用线程池做一些轻量级的任务，不可能造成队列积压或开启大量线程。</p><p>但，现实往往是残酷的。我之前就遇到过这么一个事故：用户注册后，我们调用一个外部服务去发送短信，发送短信接口正常时可以在 100 毫秒内响应，TPS 100 的注册量，CachedThreadPool 能稳定在占用 10 个左右线程的情况下满足需求。在某个时间点，外部短信服务不可用了，我们调用这个服务的超时又特别长，比如 1 分钟，1 分钟可能就进来了 6000 用户，产生 6000 个发送短信的任务，需要 6000 个线程，没多久就因为无法创建线程导致了 OOM，整个应用程序崩溃。</p><p>因此，我同样不建议使用 Executors 提供的两种快捷的线程池，原因如下：</p><p>我们需要根据自己的场景、并发情况来评估线程池的几个核心参数，包括核心线程数、最大线程数、线程回收策略、工作队列的类型，以及拒绝策略，确保线程池的工作行为符合需求，一般都需要设置有界的工作队列和可控的线程数。</p><p>任何时候，都应该为自定义线程池指定有意义的名称，以方便排查问题。当出现线程数量暴增、线程死锁、线程占用大量 CPU、线程执行出现异常等问题时，我们往往会抓取线程栈。此时，有意义的线程名称，就可以方便我们定位问题。</p><p>除了建议手动声明线程池以外，我还建议用一些监控手段来观察线程池的状态。线程池这个组件往往会表现得任劳任怨、默默无闻，除非是出现了拒绝策略，否则压力再大都不会抛出一个异常。如果我们能提前观察到线程池队列的积压，或者线程数量的快速膨胀，往往可以提早发现并解决问题。</p><h1 id="线程池核心参数设置"><a href="#线程池核心参数设置" class="headerlink" title="线程池核心参数设置"></a>线程池核心参数设置</h1><p>要根据任务的“轻重缓急”来指定线程池的核心参数，包括线程数、回收策略和任务队列：</p><p>对于执行比较慢、数量不大的 IO 任务，或许要考虑更多的线程数，而不需要太大的队列。</p><p>而对于吞吐量较大的计算型任务，线程数量不宜过多，可以是 CPU 核数或核数 *2（理由是，线程一定调度到某个 CPU 进行执行，如果任务本身是 CPU 绑定的任务，那么过多的线程只会增加线程切换的开销，并不能提升吞吐量），但可能需要较长的队列来做缓冲。</p><p>Java 8 的 parallel stream 功能，可以让我们很方便地并行处理集合中的元素，其背后是共享同一个 ForkJoinPool，默认并行度是 CPU 核数 -1。对于 CPU 绑定的任务来说，使用这样的配置比较合适，但如果集合操作涉及同步 IO 操作的话（比如数据库操作、外部服务调用等），建议自定义一个 ForkJoinPool（或普通线程池）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;TreadLocal的正确打开方式&quot;&gt;&lt;a href=&quot;#TreadLocal的正确打开方式&quot; class=&quot;headerlink&quot; title=&quot;TreadLocal的正确打开方式&quot;&gt;&lt;/a&gt;TreadLocal的正确打开方式&lt;/h1&gt;&lt;p&gt;我们知道，Threa</summary>
      
    
    
    
    
    <category term="并发" scheme="https://palette-k.github.io/tags/%E5%B9%B6%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ集群性能调优及运维</title>
    <link href="https://palette-k.github.io/2025/01/24/RocketMQ%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%8A%E8%BF%90%E7%BB%B4/"/>
    <id>https://palette-k.github.io/2025/01/24/RocketMQ%E9%9B%86%E7%BE%A4%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%8F%8A%E8%BF%90%E7%BB%B4/</id>
    <published>2025-01-24T07:58:52.000Z</published>
    <updated>2025-01-26T07:22:06.348Z</updated>
    
    <content type="html"><![CDATA[<h1 id="系统参数调优"><a href="#系统参数调优" class="headerlink" title="系统参数调优"></a>系统参数调优</h1><p>在解压 RocketMQ 安装包后，在 bin 目录中有个 os.sh 的文件，该文件由 RocketMQ 官方推荐系统参数配置。通常这些参数可以满足系统需求，也可以根据情况进行调整。</p><h2 id="最大文件数"><a href="#最大文件数" class="headerlink" title="最大文件数"></a>最大文件数</h2><p>设置用户的打开的最多文件数：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/security/limits.conf</span><br><span class="line"><span class="section"># End of file</span></span><br><span class="line">baseuser soft nofile 655360</span><br><span class="line">baseuser hard nofile 655360</span><br><span class="line"><span class="bullet">*</span> soft nofile 655360</span><br><span class="line"><span class="bullet">*</span> hard nofile 655360</span><br></pre></td></tr></table></figure><h2 id="系统参数设置"><a href="#系统参数设置" class="headerlink" title="系统参数设置"></a>系统参数设置</h2><p>系统参数的调整以官方给出的为主，下面对各个参数做个说明。设置时可以直接执行 <code>sh os.sh</code> 完成系统参数设定，也可以编辑 <code>vim /etc/sysctl.conf</code> 文件手动添加如下内容，添加后执行 <code>sysctl -p</code> 让其生效。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">vm.overcommit_memory</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">vm.drop_caches</span>=<span class="number">1</span></span><br><span class="line"><span class="attr">vm.zone_reclaim_mode</span>=<span class="number">0</span></span><br><span class="line"><span class="attr">vm.max_map_count</span>=<span class="number">655360</span></span><br><span class="line"><span class="attr">vm.dirty_background_ratio</span>=<span class="number">50</span></span><br><span class="line"><span class="attr">vm.dirty_ratio</span>=<span class="number">50</span></span><br><span class="line"><span class="attr">vm.dirty_writeback_centisecs</span>=<span class="number">360000</span></span><br><span class="line"><span class="attr">vm.page-cluster</span>=<span class="number">3</span></span><br><span class="line"><span class="attr">vm.swappiness</span>=<span class="number">1</span></span><br></pre></td></tr></table></figure><p>参数说明：</p><table><thead><tr><th align="left">参数</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">overcommit_memory</td><td align="left">是否允许内存的过量分配 overcommit_memory&#x3D;0 当用户申请内存的时候，内核会去检查是否有这么大的内存空间 overcommit_memory&#x3D;1 内核始终认为，有足够大的内存空间，直到它用完了为止 overcommit_memory&#x3D;2 内核禁止任何形式的过量分配内存</td></tr><tr><td align="left">drop_caches</td><td align="left">写入的时候，内核会清空缓存，腾出内存来，相当于 sync drop_caches&#x3D;1 会清空页缓存，就是文件 drop_caches&#x3D;2 会清空 inode 和目录树 drop_caches&#x3D;3 都清空</td></tr><tr><td align="left">zone_reclaim_mode</td><td align="left">zone_reclaim_mode&#x3D;0 系统会倾向于从其他节点分配内存 zone_reclaim_mode&#x3D;1 系统会倾向于从本地节点回收 Cache 内存</td></tr><tr><td align="left">max_map_count</td><td align="left">定义了一个进程能拥有的最多的内存区域，默认为 65536</td></tr><tr><td align="left">dirty_background_ratio&#x2F;dirty_ratio</td><td align="left">当 dirty cache 到了多少的时候，就启动 pdflush 进程，将 dirty cache 写回磁盘 当有 dirty_background_bytes&#x2F;dirty_bytes 存在的时候，dirty_background_ratio&#x2F;dirty_ratio 是被自动计算的</td></tr><tr><td align="left">dirty_writeback_centisecs</td><td align="left">pdflush 每隔多久，自动运行一次（单位是百分之一秒）</td></tr><tr><td align="left">page-cluster</td><td align="left">每次 swap in 或者 swap out 操作多少内存页为 2 的指数 page-cluster&#x3D;0 表示 1 页 page-cluster&#x3D;1 表示 2 页 page-cluster&#x3D;2 表示 4 页 page-cluster&#x3D;3 表示 8 页</td></tr><tr><td align="left">swappiness</td><td align="left">swappiness&#x3D;0 仅在内存不足的情况下，当剩余空闲内存低于 vm.min_free_kbytes limit 时，使用交换空间 swappiness&#x3D;1 内核版本 3.5 及以上、Red Hat 内核版本 2.6.32-303 及以上，进行最少量的交换，而不禁用交换 swappiness&#x3D;10 当系统存在足够内存时，推荐设置为该值以提高性能 swappiness&#x3D;60 默认值 swappiness&#x3D;100 内核将积极的使用交换空间</td></tr></tbody></table><h2 id="集群参数调优"><a href="#集群参数调优" class="headerlink" title="集群参数调优"></a>集群参数调优</h2><h3 id="调优建议"><a href="#调优建议" class="headerlink" title="调优建议"></a>调优建议</h3><p>对 Broker 的几个属性可能影响到集群性能的稳定性，下面进行特别说明。</p><p><strong>1. 开启异步刷盘</strong></p><p>除了一些支付类场景、或者 TPS 较低的场景（例如：TPS 在 2000 以下）生产环境建议开启异步刷盘，提高集群吞吐。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">flushDiskType</span>=ASYNC_FLUSH</span><br></pre></td></tr></table></figure><p><strong>2. 开启 Slave 读权限</strong></p><p>消息占用物理内存的大小通过 accessMessageInMemoryMaxRatio 来配置默认为 40%；如果消费的消息不在内存中，开启 slaveReadEnable 时会从 slave 节点读取；提高 Master 内存利用率。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">slaveReadEnable</span>=<span class="literal">true</span></span><br></pre></td></tr></table></figure><p><strong>3. 消费一次拉取消息数量</strong></p><p>消费时一次拉取的数量由 broker 和 consumer 客户端共同决定，默认为 32 条。Broker 端参数由 maxTransferCountOnMessageInMemory 设置。consumer 端由 pullBatchSize 设置。Broker 端建议设置大一些，例如 1000，给 consumer 端留有较大的调整空间。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">maxTransferCountOnMessageInMemory</span>=<span class="number">1000</span></span><br></pre></td></tr></table></figure><p><strong>4. 发送队列等待时间</strong></p><p>消息发送到 Broker 端，在队列的等待时间由参数 waitTimeMillsInSendQueue 设置，默认为 200ms。建议设置大一些，例如：1000ms~5000ms。设置过短，发送客户端会引起超时。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">waitTimeMillsInSendQueue</span>=<span class="number">1000</span></span><br></pre></td></tr></table></figure><p><strong>5. 主从异步复制</strong></p><p>为提高集群性能，在生成环境建议设置为主从异步复制，经过压力测试主从同步复制性能过低。</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">brokerRole</span>=ASYNC_MASTER</span><br></pre></td></tr></table></figure><p><strong>6. 提高集群稳定性</strong></p><p>为了提高集群稳定性，对下面三个参数进行特别说明，在后面踩坑案例中也会提到。</p><p>关闭堆外内存：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">transientStorePoolEnable</span>=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>关闭文件预热：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">warmMapedFileEnable</span>=<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>开启堆内传输：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">transferMsgByHeap</span>=<span class="literal">true</span></span><br></pre></td></tr></table></figure><h1 id="集群平滑运维"><a href="#集群平滑运维" class="headerlink" title="集群平滑运维"></a>集群平滑运维</h1><h2 id="优雅摘除节点"><a href="#优雅摘除节点" class="headerlink" title="优雅摘除节点"></a>优雅摘除节点</h2><h3 id="案例背景"><a href="#案例背景" class="headerlink" title="案例背景"></a>案例背景</h3><p>自建机房 4 主 4 从、异步刷盘、主从异步复制。有一天运维同学遗失其中一个 Master 节点所有账户的密码，该节点在集群中运行正常，然不能登陆该节点机器终究存在安全隐患，所以决定摘除该节点。</p><p>如何平滑地摘除该节点呢？</p><p>直接关机，有部分未同步到从节点的数据会丢失，显然不可行。线上安全的指导思路“先摘除流量”，当没有流量流入流出时，对节点的操作是安全的。</p><h3 id="流量摘除"><a href="#流量摘除" class="headerlink" title="流量摘除"></a>流量摘除</h3><p><strong>1. 摘除写入流量</strong></p><p>我们可以通过关闭 Broker 的写入权限，来摘除该节点的写入流量。RocketMQ 的 broker 节点有 3 种权限设置，brokerPermission&#x3D;2 表示只写权限，brokerPermission&#x3D;4 表示只读权限，brokerPermission&#x3D;6 表示读写权限。通过 updateBrokerConfig 命令将 Broker 设置为只读权限，执行完之后原该 Broker 的写入流量会分配到集群中的其他节点，所以摘除前需要评估集群节点的负载情况。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -<span class="selector-tag">b</span> x<span class="selector-class">.x</span><span class="selector-class">.x</span><span class="selector-class">.x</span>:<span class="number">10911</span> -n x.x.x.x:<span class="number">9876</span> -k brokerPermission -v <span class="number">4</span></span><br><span class="line">Java <span class="built_in">HotSpot</span>(TM) <span class="number">64</span>-Bit Server VM warning: ignoring option PermSize=<span class="number">128</span>m; support was removed in <span class="number">8.0</span></span><br><span class="line">Java HotSpot(TM) <span class="number">64</span>-Bit Server VM warning: ignoring option MaxPermSize=<span class="number">128</span>m; support was removed in <span class="number">8.0</span></span><br><span class="line">update broker config success, x<span class="selector-class">.x</span><span class="selector-class">.x</span><span class="selector-class">.x</span>:<span class="number">10911</span></span><br></pre></td></tr></table></figure><p>将 Broker 设置为只读权限后，观察该节点的流量变化，直到写入流量（InTPS）掉为 0 表示写入流量已摘除。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">bin/mqadmin</span> <span class="string">clusterList</span> <span class="string">-n</span> <span class="string">x.x.x.x:9876</span></span><br><span class="line"><span class="string">Java</span> <span class="string">HotSpot(TM)</span> <span class="attr">64-Bit Server VM warning:</span> <span class="string">ignoring</span> <span class="string">option</span> <span class="string">PermSize=128m;</span> <span class="string">support</span> <span class="string">was</span> <span class="string">removed</span> <span class="string">in</span> <span class="number">8.0</span></span><br><span class="line"><span class="string">Java</span> <span class="string">HotSpot(TM)</span> <span class="attr">64-Bit Server VM warning:</span> <span class="string">ignoring</span> <span class="string">option</span> <span class="string">MaxPermSize=128m;</span> <span class="string">support</span> <span class="string">was</span> <span class="string">removed</span> <span class="string">in</span> <span class="number">8.0</span></span><br><span class="line"><span class="comment">#Cluster Name #Broker Name #BID #Addr #Version #InTPS(LOAD) #OutTPS(LOAD) #PCWait(ms) #Hour #SPACE</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-a</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2492.95</span><span class="string">(0,0ms)</span> <span class="number">2269.27</span><span class="string">(1,0ms)</span> <span class="number">0</span> <span class="number">137.57</span> <span class="number">0.1861</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-a</span> <span class="number">1</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2485.45</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.26</span> <span class="number">0.3055</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-b</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">26.47</span><span class="string">(0,0ms)</span> <span class="number">26.08</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.24</span> <span class="number">0.1610</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-b</span> <span class="number">1</span> <span class="string">x.x.x.x:10915</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">20.47</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.22</span> <span class="number">0.3055</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-c</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2061.09</span><span class="string">(0,0ms)</span> <span class="number">1967.30</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.28</span> <span class="number">0.2031</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-c</span> <span class="number">1</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2048.20</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.51</span> <span class="number">0.2789</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-d</span> <span class="number">0</span> <span class="string">x.x.x.x:10911</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2017.40</span><span class="string">(0,0ms)</span> <span class="number">1788.32</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">125.22</span> <span class="number">0.1261</span></span><br><span class="line"><span class="string">ClusterA</span> <span class="string">broker-d</span> <span class="number">1</span> <span class="string">x.x.x.x:10915</span> <span class="string">V4_7_0_SNAPSHOT</span> <span class="number">2026.50</span><span class="string">(0,0ms)</span> <span class="number">0.00</span><span class="string">(0,0ms)</span> <span class="number">0</span> <span class="number">137.61</span> <span class="number">0.2789</span></span><br></pre></td></tr></table></figure><p><strong>2. 摘除读出流量</strong></p><p>当摘除 Broker 写入流量后，读出消费流量也会逐步降低。可以通过 clusterList 命令中 OutTPS 观察读出流量变化。除此之外，也可以通过 brokerConsumeStats 观察 broker 的积压（Diff）情况，当积压为 0 时，表示消费全部完成。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-id">#Topic</span>             <span class="selector-id">#Group</span>                <span class="selector-id">#Broker</span> <span class="selector-tag">Name</span>    <span class="selector-id">#QID</span>  <span class="selector-id">#Broker</span> <span class="selector-tag">Offset</span>   <span class="selector-id">#Consumer</span> <span class="selector-tag">Offset</span>  <span class="selector-id">#Diff</span>     <span class="selector-id">#LastTime</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">0</span>     <span class="number">2171742</span>           <span class="number">2171742</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">38</span>:<span class="number">09</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">1</span>     <span class="number">2171756</span>           <span class="number">2171756</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">38</span>:<span class="number">50</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">2</span>     <span class="number">2171740</span>           <span class="number">2171740</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">42</span>:<span class="number">58</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">3</span>     <span class="number">2171759</span>           <span class="number">2171759</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">40</span>:<span class="number">44</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">4</span>     <span class="number">2171743</span>           <span class="number">2171743</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">32</span>:<span class="number">48</span></span><br><span class="line"><span class="selector-tag">test_melon_topic</span>   <span class="selector-tag">test_melon_consumer</span>     <span class="selector-tag">broker-b</span>        <span class="number">5</span>     <span class="number">2171740</span>           <span class="number">2171740</span>          <span class="number">0</span>       <span class="number">2020</span><span class="selector-tag">-08-13</span> <span class="number">23</span>:<span class="number">35</span>:<span class="number">58</span></span><br></pre></td></tr></table></figure><p><strong>3. 节点下线</strong></p><p>在观察到该 Broker 的所有积压为 0 时，通常该节点可以摘除了。考虑到可能消息回溯到之前某个时间点重新消费，可以过了日志保存日期再下线该节点。如果日志存储为 3 天，那 3 天后再移除该节点。</p><h2 id="平滑扩所容"><a href="#平滑扩所容" class="headerlink" title="平滑扩所容"></a>平滑扩所容</h2><h3 id="案例背景-1"><a href="#案例背景-1" class="headerlink" title="案例背景"></a>案例背景</h3><p>需要将线上的集群操作系统从 CentOS 6 全部换成 CenOS 7，具体现象和原因在踩坑记中介绍。集群部署架构为 4 主 4 从，见下图，broker-a 为主节点，broker-a-s 是 broker-a 的从节点。</p><p><img src="https://i0.hdslb.com/bfs/article/bf648a1fc83c047875f4bbeba7498e9e171301454.png" alt="image-20250126151748499"></p><p>那需要思考的是如何做到平滑替换？指导思想为“先扩容再缩容”。</p><h3 id="集群扩容"><a href="#集群扩容" class="headerlink" title="集群扩容"></a>集群扩容</h3><p>申请 8 台相同配置的机器，机器操作系统为 CenOS 7。分别组建主从结构加入到原来的集群中，此时集群中架构为 8 主 8 从，如下图：</p><p><img src="https://i0.hdslb.com/bfs/article/aa7cf927ecf92bc1ed29e0eaddf9ccb1171301454.png" alt="image-20250126151837253"></p><p>broker-a、broker-b、broker-c、broker-d 及其从节点为 CentOS 6。broker-a1、broker-b1、broker-c1、broker-d1 及其从节点为 CentOS 7。8 主均有流量流入流出，至此我们完成了集群的平滑扩容操作。</p><h3 id="集群缩容"><a href="#集群缩容" class="headerlink" title="集群缩容"></a>集群缩容</h3><p>按照第二部分“优雅摘除节点”操作，分别摘除 broker-a、broker-b、broker-c、broker-d 及其从节点的流量。为了安全，可以在过了日志保存时间（例如：3 天）后再下线。集群中剩下操作系统为 CentOS 7 的 4 主 4 从的架构，如图。至此，完成集群的平滑缩容操作。</p><p><img src="https://i0.hdslb.com/bfs/article/4528f6a51d45c9c2c1b13343fcbd72db171301454.png" alt="image-20250126151854858"></p><h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>在扩容中，我们将新申请的 8 台 CentOS 7 节点，命名为 broker-a1、broker-b1、broker-c1、broker-d1 的形式，而不是 broker-e、broker-f、broker-g、broker-h。下面看下这么命名的原因，客户端消费默认采用平均分配算法，假设有四个消费节点。</p><p><strong>第一种形式</strong></p><p>扩容后排序如下，即新加入的节点 broker-e 会排在原集群的最后。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broker-<span class="selector-tag">a</span>,broker-<span class="selector-tag">b</span>,broker-c,broker-d,broker-e,broker-f,broker-g,broker-h</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/article/c0e99ad51ef0b08e43d3874f1f6f9c41171301454.png" alt="image-20250126152106693"></p><p>注：当缩容摘除 broker-a、broker-b、broker-c、broker-d 的流量时，会发现 consumer-01、consumer-02 没有不能分到 Broker 节点，造成流量偏移，存在剩余的一半节点无法承载流量压力的隐患。</p><p><strong>第二种形式</strong></p><p>扩容后的排序如下，即新加入的主节点 broker-a1 紧跟着原来的主节点 broker-a。</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">broker-<span class="selector-tag">a</span>,broker-a1,broker-<span class="selector-tag">b</span>,broker-b1,broker-c,broker-c1,broker-d,broker-d1</span><br></pre></td></tr></table></figure><p><img src="https://i0.hdslb.com/bfs/article/d2b69fedbeca46dbf4c0a16ac8e919c7171301454.png" alt="image-20250126152157127"></p><p>注：当缩容摘除 broker-a、broker-b、broker-c、broker-d 的流量时，各个 consumer 均分配到了新加入的 Broker 节点，没有流量偏移的情况。</p><h2 id="集群节点进程神秘消失"><a href="#集群节点进程神秘消失" class="headerlink" title="集群节点进程神秘消失"></a>集群节点进程神秘消失</h2><h3 id="现象描述"><a href="#现象描述" class="headerlink" title="现象描述"></a>现象描述</h3><p>接到告警和运维反馈，一个 RocketMQ 的节点不见了。此类现象在以前从未发生过，消失肯定有原因，开始查找日志，从集群的 broker.log、stats.log、storeerror.log、store.log、watermark.log 到系统的 message 日志没发现错误日志。集群流量出入在正常水位、CPU 使用率、CPU Load、磁盘 IO、内存、带宽等无明显变化。</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>继续查原因，最终通过 history 查看了历史运维操作。发现运维同学在启动 Broker 时没有在后台启动，而是在当前 session 中直接启动了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh bin/mqbroker -c conf/broker-a.conf</span><br></pre></td></tr></table></figure><p>问题即出现在此命令，当 session 过期时 Broker 节点也就退出了。</p><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p>标准化运维操作，对运维的每次操作进行评审，将标准化的操作实现自动化运维就更好了。</p><p>正确启动 Broker 方式：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">nohup</span> sh bin/mqbroker -c conf/broker-a.conf &amp;</span><br></pre></td></tr></table></figure><h2 id="Master-节点-CPU-莫名飙高"><a href="#Master-节点-CPU-莫名飙高" class="headerlink" title="Master 节点 CPU 莫名飙高"></a>Master 节点 CPU 莫名飙高</h2><h3 id="现象描述-1"><a href="#现象描述-1" class="headerlink" title="现象描述"></a>现象描述</h3><p>RocketMQ 主节点 CPU 频繁飙高后回落，业务发送超时严重，由于两个从节点部署在同一个机器上，从节点还出现了直接挂掉的情况。</p><p>主节点 CPU 毛刺截图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910105626655.png" alt="img"></p><p>从节点 CPU 毛刺截图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910105701883.png" alt="img"></p><p>说明：中间缺失部分为掉线，没有采集到的情况。</p><p><strong>系统错误日志一</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020-03-16T17:56:07.505715+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&lt;IRQ&gt;</span>  [<span class="string">&lt;ffffffff81143c31&gt;</span>] <span class="string">?</span> <span class="string">__alloc_pages_nodemask+0x7e1/0x960</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505717+08:00</span> <span class="attr">VECS0xxxx kernel: java:</span> <span class="string">page</span> <span class="string">allocation</span> <span class="string">failure.</span> <span class="string">order:0,</span> <span class="string">mode:0x20</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505719+08:00</span> <span class="attr">VECS0xxxx kernel: Pid:</span> <span class="number">12845</span><span class="string">,</span> <span class="attr">comm:</span> <span class="string">java</span> <span class="string">Not</span> <span class="string">tainted</span> <span class="number">2.6</span><span class="number">.32</span><span class="number">-754.17</span><span class="number">.1</span><span class="string">.el6.x86_64</span> <span class="comment">#1</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505721+08:00</span> <span class="attr">VECS0xxxx kernel: Call Trace:</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505724+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&lt;IRQ&gt;</span>  [<span class="string">&lt;ffffffff81143c31&gt;</span>] <span class="string">?</span> <span class="string">__alloc_pages_nodemask+0x7e1/0x960</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505726+08:00</span> <span class="attr">VECS0xxxx kernel:</span> [<span class="string">&lt;ffffffff8148e700&gt;</span>] <span class="string">?</span> <span class="string">dev_queue_xmit+0xd0/0x360</span></span><br><span class="line"><span class="number">2020-03-16T17:56:07.505729+08:00</span> <span class="attr">VECS0xxxx kernel:</span> [<span class="string">&lt;ffffffff814cb3e2&gt;</span>] <span class="string">?</span> <span class="string">ip_finish_output+0x192/0x380</span></span><br></pre></td></tr></table></figure><p><strong>系统错误日志二</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">30</span> <span class="number">2020-03-27T10:35:28.769900+08:00</span> <span class="attr">VECSxxxx kernel: INFO:</span> <span class="string">task</span> <span class="string">AliYunDunUpdate:29054</span> <span class="string">blocked</span> <span class="string">for</span> <span class="string">more</span> <span class="string">than</span> <span class="number">120</span> <span class="string">seconds.</span></span><br><span class="line"><span class="number">31</span> <span class="number">2020-03-27T10:35:28.769932+08:00</span> <span class="attr">VECSxxxx kernel:</span>      <span class="string">Not</span> <span class="string">tainted</span> <span class="number">2.6</span><span class="number">.32</span><span class="number">-754.17</span><span class="number">.1</span><span class="string">.el6.x86_64</span> <span class="comment">#1</span></span><br><span class="line"><span class="number">32</span> <span class="number">2020-03-27T10:35:28.771650+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">&quot;echo 0 &gt; /proc/sys/kernel/hung_task_timeout_secs&quot;</span> <span class="string">disables</span> <span class="string">this</span> <span class="string">message.</span></span><br><span class="line"><span class="number">33</span> <span class="number">2020-03-27T10:35:28.774631+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">AliYunDunUpda</span> <span class="string">D</span> <span class="string">ffffffff815592fb</span>     <span class="number">0</span> <span class="number">29054</span>      <span class="number">1</span> <span class="number">0x10000080</span></span><br><span class="line"><span class="number">34</span> <span class="number">2020-03-27T10:35:28.777500+08:00</span> <span class="attr">VECS0xxxx kernel:</span> <span class="string">ffff8803ef75baa0</span> <span class="number">0000000000000082</span> <span class="string">ffff8803ef75ba68</span> <span class="string">ffff8803ef75ba64</span></span><br></pre></td></tr></table></figure><p>说明：系统日志显示错误“page allocation failure”和“blocked for more than 120 second”错误，日志目录 &#x2F;var&#x2F;log&#x2F;messages。</p><p><strong>GC 日志</strong></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020-03-16T17:49:13.785</span><span class="string">+0800:</span> <span class="attr">13484510.599: Total time for which application threads were stopped:</span> <span class="number">0.0072354</span> <span class="string">seconds,</span> <span class="attr">Stopping threads took:</span> <span class="number">0.0001536</span> <span class="string">seconds</span></span><br><span class="line"><span class="number">2020-03-16T18:01:23.149</span><span class="string">+0800:</span> <span class="attr">13485239.963:</span> [<span class="string">GC</span> <span class="string">pause</span> <span class="string">(G1</span> <span class="string">Evacuation</span> <span class="string">Pause)</span> <span class="string">(young)</span> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">start</span> <span class="string">choosing</span> <span class="string">CSet</span>, <span class="attr">_pending_cards:</span> <span class="number">7738</span>, <span class="attr">predicted base time:</span> <span class="number">5.74</span> <span class="string">ms</span>, <span class="attr">remaining time:</span> <span class="number">194.26</span> <span class="string">ms</span>, <span class="attr">target pause time:</span> <span class="number">200.00</span> <span class="string">ms</span>]</span><br><span class="line"> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">add</span> <span class="string">young</span> <span class="string">regions</span> <span class="string">to</span> <span class="string">CSet</span>, <span class="attr">eden:</span> <span class="number">255</span> <span class="string">regions</span>, <span class="attr">survivors:</span> <span class="number">1</span> <span class="string">regions</span>, <span class="attr">predicted young region time:</span> <span class="number">0.52</span> <span class="string">ms</span>]</span><br><span class="line"> <span class="attr">13485239.965:</span> [<span class="string">G1Ergonomics</span> <span class="string">(CSet</span> <span class="string">Construction)</span> <span class="string">finish</span> <span class="string">choosing</span> <span class="string">CSet</span>, <span class="attr">eden:</span> <span class="number">255</span> <span class="string">regions</span>, <span class="attr">survivors:</span> <span class="number">1</span> <span class="string">regions</span>, <span class="attr">old:</span> <span class="number">0</span> <span class="string">regions</span>, <span class="attr">predicted pause time:</span> <span class="number">6.26</span> <span class="string">ms</span>, <span class="attr">target pause time:</span> <span class="number">200.00</span> <span class="string">ms</span>]</span><br><span class="line">, <span class="number">0.0090963</span> <span class="string">secs</span>]</span><br><span class="line">   [<span class="attr">Parallel Time:</span> <span class="number">2.3</span> <span class="string">ms</span>, <span class="attr">GC Workers:</span> <span class="number">23</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Start</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">13485239965.1</span>, <span class="attr">Avg:</span> <span class="number">13485239965.4</span>, <span class="attr">Max:</span> <span class="number">13485239965.7</span>, <span class="attr">Diff:</span> <span class="number">0.6</span>]</span><br><span class="line">      [<span class="string">Ext</span> <span class="string">Root</span> <span class="string">Scanning</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.3</span>, <span class="attr">Max:</span> <span class="number">0.6</span>, <span class="attr">Diff:</span> <span class="number">0.6</span>, <span class="attr">Sum:</span> <span class="number">8.0</span>]</span><br><span class="line">      [<span class="string">Update</span> <span class="string">RS</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.1</span>, <span class="attr">Avg:</span> <span class="number">0.3</span>, <span class="attr">Max:</span> <span class="number">0.6</span>, <span class="attr">Diff:</span> <span class="number">0.5</span>, <span class="attr">Sum:</span> <span class="number">7.8</span>]</span><br><span class="line">         [<span class="attr">Processed Buffers: Min:</span> <span class="number">2</span>, <span class="attr">Avg:</span> <span class="number">5.7</span>, <span class="attr">Max:</span> <span class="number">11</span>, <span class="attr">Diff:</span> <span class="number">9</span>, <span class="attr">Sum:</span> <span class="number">131</span>]</span><br><span class="line">      [<span class="string">Scan</span> <span class="string">RS</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.1</span>, <span class="attr">Diff:</span> <span class="number">0.1</span>, <span class="attr">Sum:</span> <span class="number">0.8</span>]</span><br><span class="line">      [<span class="string">Code</span> <span class="string">Root</span> <span class="string">Scanning</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.0</span>, <span class="attr">Diff:</span> <span class="number">0.0</span>, <span class="attr">Sum:</span> <span class="number">0.3</span>]</span><br><span class="line">      [<span class="string">Object</span> <span class="string">Copy</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.2</span>, <span class="attr">Avg:</span> <span class="number">0.5</span>, <span class="attr">Max:</span> <span class="number">0.7</span>, <span class="attr">Diff:</span> <span class="number">0.4</span>, <span class="attr">Sum:</span> <span class="number">11.7</span>]</span><br><span class="line">      [<span class="string">Termination</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.0</span>, <span class="attr">Max:</span> <span class="number">0.0</span>, <span class="attr">Diff:</span> <span class="number">0.0</span>, <span class="attr">Sum:</span> <span class="number">0.3</span>]</span><br><span class="line">         [<span class="attr">Termination Attempts: Min:</span> <span class="number">1</span>, <span class="attr">Avg:</span> <span class="number">1.0</span>, <span class="attr">Max:</span> <span class="number">1</span>, <span class="attr">Diff:</span> <span class="number">0</span>, <span class="attr">Sum:</span> <span class="number">23</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Other</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">0.0</span>, <span class="attr">Avg:</span> <span class="number">0.2</span>, <span class="attr">Max:</span> <span class="number">0.3</span>, <span class="attr">Diff:</span> <span class="number">0.3</span>, <span class="attr">Sum:</span> <span class="number">3.6</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">Total</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">1.0</span>, <span class="attr">Avg:</span> <span class="number">1.4</span>, <span class="attr">Max:</span> <span class="number">1.9</span>, <span class="attr">Diff:</span> <span class="number">0.8</span>, <span class="attr">Sum:</span> <span class="number">32.6</span>]</span><br><span class="line">      [<span class="string">GC</span> <span class="string">Worker</span> <span class="string">End</span> <span class="string">(ms):</span> <span class="attr">Min:</span> <span class="number">13485239966.7</span>, <span class="attr">Avg:</span> <span class="number">13485239966.9</span>, <span class="attr">Max:</span> <span class="number">13485239967.0</span>, <span class="attr">Diff:</span> <span class="number">0.3</span>]</span><br><span class="line">   [<span class="attr">Code Root Fixup:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Code Root Purge:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Clear CT:</span> <span class="number">0.9</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Other:</span> <span class="number">5.9</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Choose CSet:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Ref Proc:</span> <span class="number">1.9</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Ref Enq:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Redirty Cards:</span> <span class="number">1.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Humongous Register:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Humongous Reclaim:</span> <span class="number">0.0</span> <span class="string">ms</span>]</span><br><span class="line">      [<span class="attr">Free CSet:</span> <span class="number">0.2</span> <span class="string">ms</span>]</span><br><span class="line">   [<span class="attr">Eden:</span> <span class="number">4080.</span><span class="string">0M(4080.0M)-&gt;0.0B(4080.0M)</span> <span class="attr">Survivors:</span> <span class="number">16.</span><span class="string">0M-&gt;16.0M</span> <span class="attr">Heap:</span> <span class="number">4176.</span><span class="string">5M(8192.0M)-&gt;96.5M(8192.0M)</span>]</span><br><span class="line"> [<span class="attr">Times:</span> <span class="string">user=0.05</span> <span class="string">sys=0.00</span>, <span class="string">real=0.01</span> <span class="string">secs</span>]</span><br></pre></td></tr></table></figure><p>说明：GC 日志正常。</p><p><strong>Broker 错误日志</strong></p><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-<span class="number">03</span>-<span class="number">16</span> <span class="number">17</span>:<span class="number">55</span>:<span class="number">15</span> ERROR BrokerControllerScheduledThread1 - SyncTopicConfig <span class="built_in">Exception</span>, x.x.x.x:<span class="number">10911</span> </span><br><span class="line">org.apache.rocketmq.remoting.exception.RemotingTimeoutException: wait response on the channel &lt;x.x.x.x:<span class="number">10909</span>&gt; timeout, <span class="number">3000</span>(ms)</span><br><span class="line">        at org.apache.rocketmq.remoting.netty.NettyRemotingAbstract.<span class="title function_ invoke__">invokeSyncImpl</span>(NettyRemotingAbstract.<span class="attr">java</span>:<span class="number">427</span>) ~[rocketmq-remoting-<span class="number">4.5</span>.<span class="number">2</span>.jar:<span class="number">4.5</span>.<span class="number">2</span>]</span><br><span class="line">        at org.apache.rocketmq.remoting.netty.NettyRemotingClient.<span class="title function_ invoke__">invokeSync</span>(NettyRemotingClient.<span class="attr">java</span>:<span class="number">375</span>) ~[rocketmq-remoting-<span class="number">4.5</span>.<span class="number">2</span>.jar:<span class="number">4.5</span>.<span class="number">2</span>]</span><br></pre></td></tr></table></figure><p>说明：通过查看 RocketMQ 的集群和 GC 日志，只能说明但是网络不可用，造成主从同步问题；并未发现 Broker 自身出问题了。</p><h3 id="原因分析-1"><a href="#原因分析-1" class="headerlink" title="原因分析"></a>原因分析</h3><p>系统使用 CentOS 6，内核版本为 2.6。通过摸排并未发现 broker 和 GC 本身的问题，却发现了系统 message 日志有频繁的“page allocation failure”和“blocked for more than 120 second”错误。所以将目光聚焦在系统层面，通过尝试系统参数设置，例如：min_free_kbytes 和 zone_reclaim_mode，然而并不能消除 CPU 毛刺问题。通过与社区朋友的会诊讨论，内核版本 2.6 操作系统内存回收存在 Bug。我们决定更换集群的操作系统。</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>将集群的 CentOS 6 升级到 CentOS 7，内核版本也从 2.6 升级到了 3.10，升级后 CPU 毛刺问题不在乎出现。升级方式采取的方式先扩容后缩容，先把 CentOS 7 的节点加入集群后，再将 CentOS 6 的节点移除，详见前面实战部分“RocketMQ 集群平滑运维”。</p><figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">Linux</span> <span class="selector-tag">version</span> <span class="number">3.10</span><span class="selector-class">.0-1062</span><span class="selector-class">.4</span><span class="selector-class">.1</span><span class="selector-class">.el7</span><span class="selector-class">.x86_64</span> (mockbuild<span class="variable">@kbuilder</span>.bsys.centos.org) (gcc version <span class="number">4.8</span>.<span class="number">5</span> <span class="number">20150623</span> (Red Hat <span class="number">4.8</span>.<span class="number">5</span>-<span class="number">39</span>) (GCC) ) <span class="selector-id">#1</span> <span class="selector-tag">SMP</span> <span class="selector-tag">Fri</span> <span class="selector-tag">Oct</span> <span class="number">18</span> <span class="number">17</span>:<span class="number">15</span>:<span class="number">30</span> <span class="selector-tag">UTC</span> <span class="number">2019</span></span><br></pre></td></tr></table></figure><h2 id="集群频繁抖动发送超时"><a href="#集群频繁抖动发送超时" class="headerlink" title="集群频繁抖动发送超时"></a>集群频繁抖动发送超时</h2><h3 id="现象描述-2"><a href="#现象描述-2" class="headerlink" title="现象描述"></a>现象描述</h3><p>监控和业务同学反馈发送超时，而且频繁出现。具体现象如下图。</p><h3 id="预热现象"><a href="#预热现象" class="headerlink" title="预热现象"></a>预热现象</h3><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095246617.jpg" alt="img"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095328878.jpg" alt="img"></p><p>说明：上图分别为开启预热时（<code>warmMapedFileEnable=true</code>）集群的发送 RT 监控、Broker 开启预热设置时的日志。</p><p><strong>存传输现象</strong></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095358560.jpg" alt="CPU 抖动"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095449761.jpg" alt="img"></p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200910095559121.jpg" alt="img"></p><p>说明：上图分别为开启堆外内存传输（<code>transferMsgByHeap=fals</code>e）时的 CPU 抖动截图、系统内存分配不足截图、Broker 日志截图。</p><h3 id="原因分析-2"><a href="#原因分析-2" class="headerlink" title="原因分析"></a>原因分析</h3><p>上面展现的两种显现均会导致集群 CPU 抖动、客户端发送超时，对业务造成影响。</p><p>预热设置：在预热文件时会填充 1 个 G 的假值 0 作为占位符，提前分配物理内存，防止消息写入时发生缺页异常。然而往往伴随着磁盘写入耗时过长、CPU 小幅抖动、业务具体表现为发送耗时过长，超时错误增多。关闭预热配置从集群 TPS 摸高情况来看并未有明显的差异，但是从稳定性角度关闭却很有必要。</p><p>堆外内存：transferMsgByHeap 设置为 false 时，通过堆外内存传输数据，相比堆内存传输减少了数据拷贝、零字节拷贝、效率更高。但是可能造成堆外内存分配不够，触发系统内存回收和落盘操作，设置为 true 时运行更加平稳。</p><h3 id="解决办法-1"><a href="#解决办法-1" class="headerlink" title="解决办法"></a>解决办法</h3><p>预热 warmMapedFileEnable 默认为 false，保持默认即可。如果开启了，可以通过热更新关闭。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -b x.x.x.x:10911 -n x.x.x.x:9876 -k warmMapedFileEnable -v <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>内存传输参数 transferMsgByHeap 默认为 true（即：通过堆内内存传输）保持默认即可。如果关闭了，可以通过热更新开启。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/mqadmin updateBrokerConfig -b x.x.x.x:10911 -n x.x.x.x:9876 -k transferMsgByHeap -v <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="用了此属性消费性能下降一半"><a href="#用了此属性消费性能下降一半" class="headerlink" title="用了此属性消费性能下降一半"></a>用了此属性消费性能下降一半</h2><h3 id="现象描述-3"><a href="#现象描述-3" class="headerlink" title="现象描述"></a>现象描述</h3><p>配置均采用 8C16G，RocketMQ 的消费线程 20 个，通过测试消费性能在 1.5 万 tps 左右。通过 tcpdump 显示在消费的机器存在频繁的域名解析过程；10.x.x.185 向 DNS 服务器 100.x.x.136.domain 和 10.x.x.138.domain 请求解析。而 10.x.x.185 这台机器又是消息发送者的机器 IP，测试的发送和消费分别部署在两台机器上。</p><p>问题：消费时为何会有消息发送方的 IP 呢？而且该 IP 还不断进行域名解析。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200911100907927.jpg" alt="img"></p><h3 id="原因分析-3"><a href="#原因分析-3" class="headerlink" title="原因分析"></a>原因分析</h3><p>通过 dump 线程堆栈，如下图：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200911101209514.jpg" alt="img"></p><p>代码定位：在消费时有通过 MessageExt.bornHost.getBornHostNameString 获取消费这信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MessageExt</span> <span class="keyword">extends</span> <span class="title class_">Message</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">serialVersionUID</span> <span class="operator">=</span> <span class="number">5720810158625748049L</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> queueId;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> storeSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> queueOffset;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> sysFlag;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> bornTimestamp;</span><br><span class="line">    <span class="keyword">private</span> SocketAddress bornHost;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> storeTimestamp;</span><br><span class="line">    <span class="keyword">private</span> SocketAddress storeHost;</span><br><span class="line">    <span class="keyword">private</span> String msgId;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> commitLogOffset;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> bodyCRC;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> reconsumeTimes;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> preparedTransactionOffset;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用 GetBornHostNameString 获取 HostName 时会根据 IP 反查 DNS 服务器：</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">InetSocketAddress inetSocketAddress = (InetSocketAddress)<span class="keyword">this</span>.bornHost;</span><br><span class="line"><span class="keyword">return</span> inetSocketAddress.getAddress().getHostName();</span><br></pre></td></tr></table></figure><h3 id="解决办法-2"><a href="#解决办法-2" class="headerlink" title="解决办法"></a>解决办法</h3><p>消费的时候不要使用 MessageExt.bornHost.getBornHostNameString 即可，去掉该属性，配置 8C16G 的机器消费性能在 3 万 TPS，提升了 1 倍。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;系统参数调优&quot;&gt;&lt;a href=&quot;#系统参数调优&quot; class=&quot;headerlink&quot; title=&quot;系统参数调优&quot;&gt;&lt;/a&gt;系统参数调优&lt;/h1&gt;&lt;p&gt;在解压 RocketMQ 安装包后，在 bin 目录中有个 os.sh 的文件，该文件由 RocketMQ </summary>
      
    
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>RocketMQ消息消费原理及实战</title>
    <link href="https://palette-k.github.io/2025/01/24/RocketMQ%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E6%88%98/"/>
    <id>https://palette-k.github.io/2025/01/24/RocketMQ%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E6%88%98/</id>
    <published>2025-01-24T02:45:52.000Z</published>
    <updated>2025-06-05T03:14:12.143Z</updated>
    
    <content type="html"><![CDATA[<h1 id="DefaultMQPushConsumer-核心参数与工作原理"><a href="#DefaultMQPushConsumer-核心参数与工作原理" class="headerlink" title="DefaultMQPushConsumer 核心参数与工作原理"></a>DefaultMQPushConsumer 核心参数与工作原理</h1><h2 id="Push模型消息拉取机制"><a href="#Push模型消息拉取机制" class="headerlink" title="Push模型消息拉取机制"></a>Push模型消息拉取机制</h2><p><img src="https://i0.hdslb.com/bfs/article/34094d07a066ff7e6475acf99c7d5e6e171301454.png" alt="image-20250126143819864"></p><p>其核心关键点如下：</p><ol><li>经过队列负载机制后，会分配给当前消费者一些队列，注意一个消费组可以订阅多个主题，正如上面 pullRequestQueue 中所示，topic_test、topic_test1 这两个主题都分配了一个队列。</li><li>轮流从 pullRequestQueue 中取出一个 PullRequest 对象，根据该对象中的拉取偏移量向 Broker 发起拉取请求，默认拉取 32 条，可通过上文中提到的 pullBatchSize 参数进行改变，该方法不仅会返回消息列表，还会返更改 PullRequest 对象中的下一次拉取的偏移量。</li><li>接收到 Broker 返回的消息后，会首先放入 ProccessQueue（处理队列），该队列的内部结构为 TreeMap，key 存放的是消息在消息消费队列（consumequeue）中的偏移量，而 value 为具体的消息对象。</li><li>然后将拉取到的消息提交到消费组内部的线程池，并立即返回，并将 PullRequest 对象放入到 pullRequestQueue 中，然后取出下一个 PullRequest 对象继续重复消息拉取的流程，从这里可以看出，消息拉取与消息消费是不同的线程。</li><li>消息消费组线程池处理完一条消息后，会将消息从 ProccessQueue 中，然后会向 Broker 汇报消息消费进度，以便下次重启时能从上一次消费的位置开始消费。</li></ol><h3 id="消息消费进度提交"><a href="#消息消费进度提交" class="headerlink" title="消息消费进度提交"></a>消息消费进度提交</h3><p>通过上面的介绍，想必读者应该对消息消费进度有了一个比较直观的认识，接下来我们再来介绍一下 RocketMQ PUSH 模式的消息消费进度提交机制。</p><p>通过上文的消息消费拉取模型可以看出，消息消费组线程池在处理完一条消息后，会将消息从 ProccessQueue 中移除，并向 Broker 汇报消息消费进度，那请大家思考一下下面这个问题：</p><p><img src="https://i0.hdslb.com/bfs/article/82c160432118244a2ece7530177c739c171301454.png" alt="image-20250126143838943"></p><p>例如现在处理队列中有 5 条消息，并且是线程池并发消费，那如果消息偏移量为 3 的消息（3:msg3）先于偏移量为 0、1、2 的消息处理完，那向 Broker 如何汇报消息消费进度呢？</p><p>有读者朋友说，消息 msg3 处理完，当然是向 Broker 汇报 msg3 的偏移量作为消息消费进度呀。但细心思考一下，发现如果提交 msg3 的偏移量为消息消费进度，那汇报完毕后如果消费者发生内存溢出等问题导致 JVM 异常退出，msg1 的消息还未处理，然后重启消费者，由于消息消费进度文件中存储的是 msg3 的消息偏移量，会继续从 msg3 开始消费，会造成<strong>消息丢失</strong>。显然这种方式并不可取。</p><p>RocketMQ 采取的方式是处理完 msg3 之后，会将 msg3 从消息处理队列中移除，但在向 Broker 汇报消息消费进度时是<strong>取 ProceeQueue 中最小的偏移量为消息消费进度</strong>，即汇报的消息消费进度是 0。</p><p><img src="https://i0.hdslb.com/bfs/article/dba0487f9bf6e1bf234d2f3ce58b14df171301454.png" alt="image-20250126143931458"></p><p>即如果处理队列如上图所示，那提交的消息进度为 2。但这种方案也并非完美，有可能会造成消息重复消费，例如如果发生内存溢出等异常情况，消费者重新启动，会继续从消息偏移量为 2 的消息开始消费，msg3 就会被消费多次，故<strong>RocketMQ 不保证消息重复消费</strong>。</p><p>消息消费进度具体的提交流程如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/article/00a14766630dc1a91146c33fbe28460b171301454.png" alt="image-20250126144455180"></p><p>从这里也可以看成，为了减少消费者与 Broker 的网络交互，提高性能，提交消息消费进度时会首先存入到本地缓存表中，然后定时上报到 Broker，同样 Broker 也会首先存储本地缓存表，然后定时刷写到磁盘。</p><h2 id="Push模型参数注意事项"><a href="#Push模型参数注意事项" class="headerlink" title="Push模型参数注意事项"></a>Push模型参数注意事项</h2><h3 id="ConsumeFromWhere-注意事项"><a href="#ConsumeFromWhere-注意事项" class="headerlink" title="ConsumeFromWhere 注意事项"></a>ConsumeFromWhere 注意事项</h3><p>下面首先先看一段 RokcetMQ PUSH 模式消费者的常见使用方式：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815222732166.png" alt="1"></p><p>构建需要通过 setConsumeFromWhere(…) 指定从哪消费，正如上篇提到的，RocketMQ 支持从最新消息、最早消息、指定时间戳这三种方式进行消费。大家可以思考一下，如果一个消费者启动运行了一段时间，由于版本发布等原因需要先停掉消费者，代码更新后，再启动消费者时消费者还能使用上面这三种策略，从新的一条消息消费吗？如果是这样，在发版期间新发送的消息将全部丢失，这显然是不可接受的，要从上一次开始消费的时候消费，才能保证消息不丢失。</p><p><strong>故 ConsumeFromWhere 这个参数的含义是，初次启动从何处开始消费。更准确的表述是，如果查询不到消息消费进度时，从什么地方开始消费</strong>。</p><p>所以在实际使用过程中，如果对于一个设置为 CONSUME_FROM_FIRST_OFFSET 的运行良久的消费者，当前版本的业务逻辑进行了重大重构，而且业务希望是从最新的消息开始消费，想通过如下代码来实现其业务意图，则显然是不成功的。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">consumer<span class="selector-class">.setConsumeFromWhere</span>(ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET);</span><br></pre></td></tr></table></figure><p>上面做法是错误的，要达到业务目标，需要使用 RocketMQ 提供的重置位点，其命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh ./mqadmin resetOffsetByTime -n 127.0.0.1:9876  -g CID_CONSUMER_TEST -t TopicTest -s now</span><br></pre></td></tr></table></figure><p>其中参数说明如下：</p><ul><li>-n：NameServer 地址</li><li>-g：消费组名称</li><li>-t：主题名称</li><li>-s：时间戳，可选值为 now、时间戳（毫秒）、yyyy-MM-dd#HH:mm:ss:SSS</li></ul><p>当然也可以通过 RocketMQ-Console 重置位点，操作如下图所示：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815222739573.png" alt="2"></p><h3 id="消费组线程数设置注意事项"><a href="#消费组线程数设置注意事项" class="headerlink" title="消费组线程数设置注意事项"></a>消费组线程数设置注意事项</h3><p>在 RocketMQ 中，每一个消费组都会启动一个线程池用来实现消费端在消费组的隔离，RocketMQ 也提供了 consumeThreadMin、consumeThreadMax 两个参数来设置线程池中的线程个数，但是由于线程池内部持有的队列为一个无界队列，导致 consumeThreadMax 大于 consumeThreadMin，线程个数最大也只能 consumeThreadMin 个线程数量，故在实践中，往往会将这两个值设置为相同，避免给大家带来一种误解，在消息端消息很多的情况，会创建更多的线程来提高消息的处理速率。</p><p>小技巧：RocketMQ 中的消费组线程的名称会以 ConsumeMessageThread_ 开头，例如下图。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815222942104.png" alt="9"></p><h3 id="批量消费注意事项"><a href="#批量消费注意事项" class="headerlink" title="批量消费注意事项"></a>批量消费注意事项</h3><p>RocketMQ 支持消息批量消费，在消费端与批量消费相关的两个参数分别为：</p><ul><li><strong>pullBatchSize</strong>：消息客户端一次向 Broker 发送拉取消息每批返回最大的消息条数，默认为 32。</li><li><strong>consumeMessageBatchMaxSize</strong>：提交到消息消费监听器中的消息条数，默认为 1。</li></ul><h4 id="consumeMessageBatchMaxSize"><a href="#consumeMessageBatchMaxSize" class="headerlink" title="consumeMessageBatchMaxSize"></a><strong>consumeMessageBatchMaxSize</strong></h4><p>默认情况下一次消息会拉取 32 条消息，但业务监听器收到的消息默认一条，为了更直观对其了解，现给出如下示例代码：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815222950456.png" alt="10"></p><p>如果将 consumeMessageBatchMaxSize 设置 10，其运行效果如下图所示：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815222958233.png" alt="11"></p><p>可以看到该参数生效了，consumeMessageBatchMaxSize 这个参数非常适合批处理，例如结合数据库的批处理，能显著提高性能。</p><h4 id="pullBatchSize"><a href="#pullBatchSize" class="headerlink" title="pullBatchSize"></a><strong>pullBatchSize</strong></h4><p>大家发现了一个问题，如果单条消息的处理时间较快，通过增加消费组线程个数无法显著提高消息的消费 TPS，并且通过 jstack 命令，看到几乎所有的线程都处于等待处理任务，其截图类似如下：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815223006940.png" alt="12"></p><p>此种情况说明线程都“无所事事”，应该增大其工作量，自然而然地需要增大每一批次消息拉取的数量。故尝试每一次消息拉取 100 条，每批消费 50 条。即通过如下代码进行设置：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">consumer<span class="selector-class">.setPullBatchSize</span>(<span class="number">100</span>);</span><br><span class="line">consumer<span class="selector-class">.setConsumeMessageBatchMaxSize</span>(<span class="number">200</span>);</span><br></pre></td></tr></table></figure><p>这里设置 consumeMessageBatchMaxSize 的值大于 pullBatchSize 的主要目的，就是验证每一次拉取的消息，因为如果 consumeMessageBatchMaxSize 大于 pullBatchSize，那每次批处理的消息条数等于 pullBatchSize，如果 consumeMessageBatchMaxSize 小于 pullBatchSize，会在客户端分页，然后尽最大可能一次传入 consumeMessageBatchMaxSize 条消息。</p><p>为了确保有足够的消息，在消息拉取之前，我建议先使用生产者压入大量消息。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815223014316.png" alt="13"></p><p>发现每批拉取的条数最多不会超过 32，显然服务端有足够的消息够拉取。</p><p>这是因为 Broker 端对消息拉取也提供了保护机制，同样有参数可以控制一次拉取最多返回消息的条数，其参数主要如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxTransferCountOnMessageInMemory</span><br></pre></td></tr></table></figure><p>如果此次消息拉取能全部命中，内存允许一次消息拉取的最大条数，默认值为 32 条。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxTransferBytesOnMessageInMemory</span><br></pre></td></tr></table></figure><p>如果此次消息拉取能全部命中，内存允许一次消息拉取的最大消息大小，默认为 256K。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxTransferCountOnMessageInDisk</span><br></pre></td></tr></table></figure><p>如果此次消息无法命中，内存需要从磁盘读取消息，则每一次拉取允许的最大条数，默认为 8。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> maxTransferBytesOnMessageInDisk</span><br></pre></td></tr></table></figure><p>如果此次消息无法命中，内存需要从磁盘读取消息，则每一次拉取允许的消息总大小，默认为 64K。</p><p>故如果需要一次拉取 100 条消息，还需要修改 broker 端相关的配置信息，通常建议修只修改命中内存相关的，如果要从磁盘拉取，为了包含 Broker，maxTransferCountOnMessageInDisk、maxTransferBytesOnMessageInDisk 保持默认值。</p><p>如果使用场景是大数据领域，建议的配置如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">maxTransferCountOnMessageInMemory</span>=<span class="number">5000</span></span><br><span class="line"><span class="attr">maxTransferBytesOnMessageInMemory</span> = <span class="number">5000</span> * <span class="number">1024</span></span><br></pre></td></tr></table></figure><p>如果是业务类场景，建议配置如下：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">maxTransferCountOnMessageInMemory</span>=<span class="number">2000</span></span><br><span class="line"><span class="attr">maxTransferBytesOnMessageInMemory</span> = <span class="number">2000</span> * <span class="number">1024</span></span><br></pre></td></tr></table></figure><p>修改 Broker 相关配置后，再运行上面的程序，其返回结果如下：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200815223025190.png" alt="14"></p><h3 id="订阅关系不一致导致消息丢失"><a href="#订阅关系不一致导致消息丢失" class="headerlink" title="订阅关系不一致导致消息丢失"></a>订阅关系不一致导致消息丢失</h3><p>在 RocketMQ 中，一个消费组能订阅多个主题，也能订阅多个 Tag，多个 Tag 用 <code>||</code> 分割，但同一个消费组中的所有消费者的订阅关系必须一致，不能一个订阅 TAGA，另外一个消费者却订阅 TAGB</p><p>一条消息的 Tag 为 TAGA，并且消费组 dw_tag_test 其中一个消费者有订阅 TAGA，那为什么还会显示 CONSUMED_BUT_FILTERED，这个状态代表的含义是，该条消息不符合消息过滤规则被过滤了，其原理图如下所示：</p><p><img src="https://i0.hdslb.com/bfs/article/c70b4316cb1046213a2aad1790d2bd75171301454.png" alt="image-20250126150301779"></p><p>其本质原因是，一个队列同一时间只会分配给一个消费者，这样队列上不符合的消息消费会被过滤，并且消息消费进度会向前移动，这样就会造成消息丢失。</p><h1 id="DefaultLitePullConsumer-核心参数与实战"><a href="#DefaultLitePullConsumer-核心参数与实战" class="headerlink" title="DefaultLitePullConsumer 核心参数与实战"></a>DefaultLitePullConsumer 核心参数与实战</h1><p>DefaultMQPullConsumer（PULL 模式）的 API 太底层，使用起来及其不方便，RocketMQ 官方设计者也注意到这个问题，为此在 RocketMQ 4.6.0 版本中引入了 PULL 模式的另外一个实现类 DefaultLitePullConsumer，即从 4.6.0 版本后，DefaultMQPullConsumer 已经被标记为废弃，故接下来将重点介绍 DefaultLitePullConsumer，并探究如何在实际中运用它解决相关问题。</p><h2 id="Lite-Pull-与-PUSH-模式之对比"><a href="#Lite-Pull-与-PUSH-模式之对比" class="headerlink" title="Lite Pull 与 PUSH 模式之对比"></a>Lite Pull 与 PUSH 模式之对比</h2><p>从上面的示例可以看出 Lite PULL 相关的 API 比 4.6.0 之前的 DefaultMQPullConsumer 的使用上要简便不少，从编程风格上已非常接近了 PUSH 模式，其底层的实现原理是否也一致呢？显然不是的，请听我我慢慢道来。</p><p>不知大家是否注意到，Lite PULL 模式下只是通过 poll() 方法拉取一批消息，然后提交给应用程序处理，<strong>采取自动提交模式下位点的提交与消费结果并没有直接挂钩，即消息如果处理失败，其消费位点还是继续向前继续推进，缺乏消息的重试机制。</strong>为了论证笔者的观点，这里给出 DefaultLitePullConsumer 的 poll() 方法执行流程图，请大家重点关注位点提交所处的位置。</p><p><img src="https://i0.hdslb.com/bfs/article/3534cd914ea4286dc343cd52a9267d9f171301454.png" alt="image-20250126151333790"></p><p><strong>Lite Pull 模式的自动提交位点，一个非常重要的特征是 poll() 方法一返回，这批消息就默认是消费成功了</strong>，一旦没有处理好，就会造成消息丢失，那有没有方法解决上述这个问题呢，<strong>seek 方法就闪亮登场了</strong>，在业务方法处理过程中，如果处理失败，可以通过 seek 方法重置消费位点，即在捕获到消息业务处理后，需要根据返回的第一条消息中（MessageExt）信息构建一个 MessageQueue 对象以及需要重置的位点。</p><p>Lite Pull 模式的消费者相比 PUSH 模式的另外一个不同点是 Lite Pull 模式没有消息消费重试机制，PUSH 模式在并发消费模式下默认提供了 16 次重试，并且每一次重试的间隔不一致，极大的简化了编程模型。在这方面 Lite Pull 模型还是会稍显复杂。</p><p>Lite Pull 模式针对 PUSH 模式一个非常大亮点是消息拉取线程是以消息消费组为维度的，而且一个消费者默认会创建 20 个拉取任务，在消息拉取效率方面比 PUSH 模型具有无可比拟的优势，特别适合大数据领域的批处理任务，即每隔多久运行一次的拉取任务。</p><h3 id="消息位点"><a href="#消息位点" class="headerlink" title="消息位点"></a>消息位点</h3><p>消息是按到达服务端的先后顺序存储在指定主题的多个队列中，每条消息在队列中都有一个唯一的Long类型坐标，这个坐标被定义为消息位点。</p><p>队列中最早一条消息的位点为最小消息位点（MinOffset）；最新一条消息的位点为最大消息位点（MaxOffset）。虽然消息队列逻辑上是无限存储，但由于服务端物理节点的存储空间有限，云消息队列 RocketMQ 版会滚动删除队列中存储最早的消息。因此，消息的最小消费位点和最大消费位点会一直递增变化。</p><h3 id="消费位点"><a href="#消费位点" class="headerlink" title="消费位点"></a>消费位点</h3><p>每个主题的队列都可以被多个消费者分组订阅。若某条消息被某个消费者消费后直接被删除，则其他订阅了该主题的消费者将无法消费该消息。</p><p>因此，云消息队列 RocketMQ 版通过消费位点管理消息的消费进度。每条消息被某个消费者消费完成后不会立即在队列中删除，云消息队列 RocketMQ 版会<strong>基于每个消费者分组维护一份消费记录</strong>，该记录指定消费者分组消费某一个队列时，消费过的最新一条消息的位点，即消费位点。</p><p>当消费者客户端离线，又再次重新上线时，会严格按照服务端保存的消费进度继续处理消息。如果服务端保存的历史位点信息已过期被删除，此时消费位点向前移动至服务端存储的最小位点。</p><p>因此，不同应用需要设置不同的消费者组，每个应用都能独立地接收和处理该 Topic 下的所有消息，互不干扰。而且消息队列会为每个消费者组独立记录其在 Topic 中的消费位点（offset）。这意味着每个消费者组都可以从自己上次消费的位置继续消费，互不影响。</p><h3 id="长轮询实现原理"><a href="#长轮询实现原理" class="headerlink" title="长轮询实现原理"></a>长轮询实现原理</h3><p>PULL 模式通常适合大数据领域的批处理操作，对消息的实时性要求不高，更加看重的是消息的拉取效率，即一次消息需要拉取尽可能多的消息，这样方便一次性对大量数据进行处理，提高数据的处理效率，特别是希望一次消息拉取再不济也要拉取点消息，不要出现太多无效的拉取请求（没有返回消息的拉取请求）。</p><p>首先大家来看一下如下这个场景：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200817190929584.png" alt="5"></p><p>即 Broker 端没有新消息时，Broker 端采取何种措施呢？我想基本有如下两种策略进行选择：</p><ul><li>Broker 端没有新消息，立即返回，拉取结果中不包含任何消息。</li><li>当前拉取请求在 Broker 端挂起，在 Broker 端挂起，并且轮询 Broker 端是否有新消息，即轮询机制。</li></ul><p>上面说的第二种方式，有一个“高大上”的名字——<strong>轮询</strong>，根据轮询的方式又可以分为<strong>长轮询、短轮询</strong>。</p><ul><li><strong>短轮询</strong>：第一次未拉取到消息后等待一个时间间隔后再试，默认为 1s，可以在 Broker 的配置文件中设置 shortPollingTimeMills 改变默认值，即轮询一次，<strong>注意：只轮询一次</strong>。</li><li><strong>长轮询</strong>：可以由 PULL 客户端设置在 Broker 端挂起的超时时间，默认为 20s，然后在 Broker 端没有拉取到消息后默认每隔 5s 一次轮询，并且在 Broker 端获取到新消息后，会唤醒拉取线程，结束轮询，尝试一次消息拉取，然后返回一批消息到客户端，长轮询的时序图如下所示：</li></ul><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200817190938839.png" alt="6"></p><p>从这里可以看出，长轮询比短轮询，轮询等待的时间长，短轮询只轮询一次，并且默认等待时间为 1s，而长轮询默认一次阻塞 5s，但支持被唤醒。</p><p>在 broker 端与长轮询相关的参数如下：</p><ul><li>longPollingEnable：是否开启长轮询，默认为 true。</li><li>shortPollingTimeMills：短轮询等待的时间，默认为 1000，表示 1s。</li></ul><h2 id="结合实际场景顺序消费、消息过滤实战"><a href="#结合实际场景顺序消费、消息过滤实战" class="headerlink" title="结合实际场景顺序消费、消息过滤实战"></a>结合实际场景顺序消费、消息过滤实战</h2><h3 id="顺序消费"><a href="#顺序消费" class="headerlink" title="顺序消费"></a>顺序消费</h3><h4 id="业务场景描述"><a href="#业务场景描述" class="headerlink" title="业务场景描述"></a><strong>业务场景描述</strong></h4><p>现在开发一个银行类项目，对用户的每一笔余额变更都需要发送短信通知到用户。如果用户同时在电商平台下单，转账两个渠道在同一时间进行了余额变更，此时用户收到的短信必须顺序的，例如先网上购物，消费了 128，余额 1000，再转账给朋友 200，剩余余额 800，如果这两条短信的发送顺序颠倒，给用户会带来很大的困扰，故在该场景下必须保证顺序。这里所谓的顺序，是针对同一个账号的，不同的账号无需保证顺序性，例如用户 A 的余额发送变更，用户 B 的余额发生变更，这两条短信的发送其实相互不干扰的，故不同账号之间无需保证顺序。</p><h4 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a><strong>代码实现</strong></h4><p>本篇代码主要采用截图的方式展示其关键代码，并对其进行一些简单的解读。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200823180055930.png" alt="1"></p><p>首先这里的主业务是操作账户的余额，然后是余额变更后需要发短信通知给用户，但由于发送短信与账户转载是两个相对独立但又紧密的操作，故这里可以引入消息中间件来解耦这两个操作。但由于发送短信业务，其顺序一定要与扣款的顺序保证一致，故需要使用顺序消费。</p><p>由于 RocketMQ 只提供了消息队列的局部有序，故如果要实现某一类消息的顺序执行，就必须将这类消息发送到同一个队列，故这里在消息发送时使用了 MessageQueueSelector，并且使用用户账户进行队列负载，这样同一个账户的消息就会账号余额变更的顺序到达队列，然后队列中的消息就能被顺序消费。</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/2020082318010499.png" alt="2"></p><p>顺序消费的事件监听器为 MessageListenerOrderly，表示顺序消费。</p><p>顺序消费在使用上比较简单，那 RocketMQ 顺序消费是如何实现的？队列重新负载时还能保持顺序消费吗？顺序消费会重复消费吗？</p><h4 id="RocketMQ-顺序消费原理简述"><a href="#RocketMQ-顺序消费原理简述" class="headerlink" title="RocketMQ 顺序消费原理简述"></a><strong>RocketMQ 顺序消费原理简述</strong></h4><p>在 RocketMQ 中，PUSH 模式的消息拉取模型如下图所示：</p><p><img src="https://i0.hdslb.com/bfs/article/34094d07a066ff7e6475acf99c7d5e6e171301454.png" alt="image-20250126143819864"></p><p>上述流程在前面的章节中已做了详述，这里不再累述，这里想重点突出线程池。</p><p>RocketMQ 消息消费端按照消费组进行的线程隔离，即每一个消费组都会创建已线程池，由一个线程池负责分配的所有队列中的消息。</p><p><strong>所以要保证消费端对单队列中的消息顺序处理，故多线程处理，需要按照消息消费队列进行加锁。</strong>故顺序消费在消费端的并发度并不取决消费端线程池的大小，而是取决于分给给消费者的队列数量，故如果一个 Topic 是用在顺序消费场景中，建议消费者的队列数设置增多，可以适当为非顺序消费的 2~3 倍，这样有利于提高消费端的并发度，方便横向扩容。</p><p>消费端的横向扩容或 Broker 端队列个数的变更都会触发消息消费队列的重新负载，在并发消息时在队列负载的时候一个消费队列有可能被多个消费者同时消息，但顺序消费时并不会出现这种情况，因为顺序消息不仅仅在消费消息时会锁定消息消费队列，在分配到消息队列时，<strong>能从该队列拉取消息还需要在 Broker 端申请该消费队列的锁</strong>，即同一个时间只有一个消费者能拉取该队列中的消息，确保顺序消费的语义。</p><p>从前面的文章中也介绍到并发消费模式在消费失败是有重试机制，默认重试 16 次，而且重试时是先将消息发送到 Broker，然后再次拉取到消息，这种机制就会丧失其消费的顺序性，故如果是顺序消费模式，消息重试时在消费端不停的重试，重试次数为 Integer.MAX_VALUE，<strong>即如果一条消息如果一直不能消费成功，其消息消费进度就会一直无法向前推进，即会造成消息积压现象。</strong></p><blockquote><p>温馨提示：顺序消息时一定要捕捉异常，必须能区分是系统异常还是业务异常，更加准确的要能区分哪些异常是通过重试能恢复的，哪些是通过重试无法恢复的。无法恢复的一定要尽量在发送到 MQ 之前就要拦截，并且需要提高告警功能。</p></blockquote><h3 id="消息过滤实战"><a href="#消息过滤实战" class="headerlink" title="消息过滤实战"></a>消息过滤实战</h3><h4 id="业务场景描述-1"><a href="#业务场景描述-1" class="headerlink" title="业务场景描述"></a><strong>业务场景描述</strong></h4><p>例如公司采用的是微服务架构，分为如下几个子系统，基础数据、订单模块、商家模块，各个模块的数据库都是独立的。微服务带来的架构伸缩性不容质疑，但数据库的相互独立，对于基础数据的 join 操作就不那么方便了，即在订单模块需要使用基础数据，还需要通过 Dubbo 服务的方式去请求接口，为了避免接口的调用，基础数据的数据量又不是特别多的情况，项目组更倾向于将基础数据的数据同步到各个业务模块的数据库，然后基础数据发生变化及时通知订单模块，这样与基础数据的表 join 操作就可以在本库完成。</p><h4 id="技术方案"><a href="#技术方案" class="headerlink" title="技术方案"></a><strong>技术方案</strong></h4><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200823180123686.png" alt="4"></p><p>上述方案的关键思路：</p><ol><li>基础数据一旦数据发生变化，就向 MQ 的 base_data_topic 发送一条消息。</li><li>下游系统例如订单模块、商家模块订阅 base_data_topic 完成数据的同步。</li></ol><p>问题，如果订单模块出现一些不可预知的错误，导致数据同步出现异常，并且发现的时候，存储在 MQ 中的消息已经被删除，此时需要上游（基础数据）重推数据，这个时候，如果基础数据重推的消息直接发送到 base_data_topic，那该 Topic 的所有消费者都会消费到，这显然是不合适的。怎么解决呢？</p><p>通常有两种办法：</p><ul><li>为各个子模块创建另外一个主题，例如 retry_ods_base_data_topic，这样需要向哪个子系统就向哪个 Topic 发送。</li><li>引入 Tag 机制。</li></ul><p>本节主要来介绍一下 Tag 的思路。</p><p>首先，正常情况下，基础模块将数据变更发送到 base_data_topic，并且消息的 Tag 为 all。然后为每一个子系统定义一个单独的重推 Tag，例如 ods、shop。</p><p>消费端同时订阅 all 和各自的重推 Tag，完美解决问题。</p><h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a><strong>代码实现</strong></h4><p>在消息发送时需要按照需求指定消息的 Tag，其示例代码如下：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200823180130930.png" alt="5"></p><p>然后在消息消费时订阅时，更加各自的模块订阅各自关注的 Tag，其示例代码如下：</p><p><img src="https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/RocketMQ%20%e5%ae%9e%e6%88%98%e4%b8%8e%e8%bf%9b%e9%98%b6%ef%bc%88%e5%ae%8c%ef%bc%89/assets/20200823180139407.png" alt="6"></p><p>在消息订阅时一个消费组可以订阅多个 Tag，多个 Tag 使用双竖线分隔。</p><h4 id="Topic-与-Tag-之争"><a href="#Topic-与-Tag-之争" class="headerlink" title="Topic 与 Tag 之争"></a><strong>Topic 与 Tag 之争</strong></h4><p>用 Tag 对同一个主题进行区分会引来一个“副作用”，就是在重置消息消费位点时该消费组需要“处理”的是所有标签的数据，虽然在 Broker 端、消息消费端最终会过滤，不符合 Tag 的消息并不会执行业务逻辑，但在消息拉取时还是需要将消息读取到 PageCache 中并进行过滤，会有一定的性能损耗，但这个不是什么大问题。</p><p>在数据推送这个场景，除了使用 Tag 机制来区分重推数据外，也可以为重推的数据再申请一个额外的主题，即通过主题来区分不同的数据，这种方案倒不说不可以，但这个在运维管理层面需要申请众多的 Topic，而这类 Topic 存储的其实是一类数据，使用不同的 Topic 存储同类数据，会显得较为松散。当然如果是不同的业务场景，就建议使用 Topic 来隔离。</p><h4 id="消息过滤常见问题"><a href="#消息过滤常见问题" class="headerlink" title="消息过滤常见问题"></a>消息过滤常见问题</h4><ol><li>多个消费者订阅同一个Topic下的不同Tag，出现消息丢失情况。</li></ol><p>可能原因：若多个消费者是通过同一个消费者分组（Group ID）订阅的指定Topic，则所有消费者的过滤条件即订阅的Tag要一致，否则会出现订阅关系不一致，导致部分消息丢失。</p><ol start="2"><li>消费者在线无消费消息，但Group有堆积。</li></ol><p>采用SQL&#x2F;TAG消费过滤的方式，未被过滤条件命中的消息会计算为消息堆积，堆积量的计算如下所示。</p><p><img src="https://help-static-aliyun-doc.aliyuncs.com/assets/img/zh-CN/0584115371/CAEQTxiBgMDLjcy2jBkiIDhkM2MyMGRmNTI1MDQ1ODNhMTYzZGJiYTRhYTkxNTIw4618633_20240826151619.705.svg" alt="image"></p><ul><li>SQL消费方式：堆积量 &#x3D; 已就绪的消息量 + 处理中的消息量 - 未被SQL命中的消息数量。</li><li>TAG消费方式：堆积量 &#x3D;（已就绪的消息量 + 处理中的消息量）* TAG标签消息百分比。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;DefaultMQPushConsumer-核心参数与工作原理&quot;&gt;&lt;a href=&quot;#DefaultMQPushConsumer-核心参数与工作原理&quot; class=&quot;headerlink&quot; title=&quot;DefaultMQPushConsumer 核心参数与工作原</summary>
      
    
    
    
    
    <category term="RocketMQ" scheme="https://palette-k.github.io/tags/RocketMQ/"/>
    
  </entry>
  
  <entry>
    <title>JVM调优实战——解决内存占用高问题</title>
    <link href="https://palette-k.github.io/2025/01/23/JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%AB%98%E9%97%AE%E9%A2%98/"/>
    <id>https://palette-k.github.io/2025/01/23/JVM%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98%E2%80%94%E2%80%94%E8%A7%A3%E5%86%B3%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%AB%98%E9%97%AE%E9%A2%98/</id>
    <published>2025-01-23T10:04:54.000Z</published>
    <updated>2025-08-28T03:44:05.670Z</updated>
    
    <content type="html"><![CDATA[<h1 id="JVM启动后一段时间内内存占用飙升"><a href="#JVM启动后一段时间内内存占用飙升" class="headerlink" title="JVM启动后一段时间内内存占用飙升"></a>JVM启动后一段时间内内存占用飙升</h1><p>如下，是我们一服务重启后运行快2天的内存占用情况，可以发现内存一直从45%涨到了62%，8G的容器，上涨内存大小为1.36G！</p><p><img src="https://img2023.cnblogs.com/blog/2792815/202308/2792815-20230826194514366-332827220.png" alt="image_2023-08-26_20230826181426"></p><p>但我们这个服务其实没有内存泄露问题，因为JVM为堆申请的内存是虚拟内存，如4.8G，但在启动后JVM一开始可能实际只使用了3G内存，导致Linux实际只分配了3G。</p><p>然后在gc时，由于会复制存活对象到堆的空闲部分，如果正好复制到了以前未使用过的区域，就又会触发Linux进行内存分配，故一段时间内内存占用会越来越多，直到堆的所有区域都被touch到。</p><p><img src="https://img2023.cnblogs.com/blog/2792815/202308/2792815-20230826194514377-1068982994.png" alt="image_2023-08-26_20230826181452"></p><p>而通过添加JVM参数<code>-XX:+AlwaysPreTouch</code>，可以让JVM为堆申请虚拟内存后，立即把堆全部touch一遍，使得堆区域全都被分配物理内存，而由于Java进程主要活动在堆内，故后续内存就不会有很大变化了，我们另一服务添加了此参数，内存表现如下：</p><p><img src="https://img2023.cnblogs.com/blog/2792815/202308/2792815-20230826194514283-503639924.png" alt="image_2023-08-26_20230826181512"></p><p>可以看到，内存上涨幅度不到2%，无此参数可以提高内存利用度，加此参数则会使应用运行得更稳定。</p><p>如我们之前一服务一周内会有1到2次GC耗时超过2s，当我添加此参数后，再未出现过此情况。这是因为当无此参数时，若GC访问到了未读写区域，会触发Linux分配内存，大多数情况下此过程很快，但有极少数情况下会较慢，在GC日志中则表现为sys耗时较高。</p><p><img src="https://img2023.cnblogs.com/blog/2792815/202308/2792815-20230826194514361-1454953680.png" alt="image_2023-08-26_20230826191255"></p><h1 id="长连接Netty服务内存泄漏"><a href="#长连接Netty服务内存泄漏" class="headerlink" title="长连接Netty服务内存泄漏"></a>长连接Netty服务内存泄漏</h1><p>为了本地复现<code>Netty</code>泄漏，定位详细的内存泄漏代码，我们需要做这几步：</p><p>1、配置足够小的本地JVM内存，以便快速模拟堆外内存泄漏。</p><p>如图，我们设置PermSize&#x3D;30M, MaxPermSize&#x3D;43M</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/7bad239a7e433f3d67d758743cb2b37f.png" alt="img"></p><p>2、模拟足够多的长连接请求，我们使用Postman定时批量发请求，以达到服务的堆外内存泄漏。</p><p>启动项目，通过<code>JProfiler</code> JVM监控工具，我们观察到内存缓慢的增长，最终触发了本地<code>Netty</code>的堆外内存泄漏，本地复现成功：</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/9b8c75f6d2fbcf2d7572c62794535111.png" alt="img"></p><p>3、开启<code>Netty</code>的高级内存泄漏检测级别，JVM参数如下：</p><p>-Dio.netty.leakDetectionLevel&#x3D;advanced</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/5fa81cb6e671a918d3c85c004b7b79ac.png" alt="img"></p><p>再启动项目，模拟请求，达到本地应用JVM内存泄漏，Netty输出如下具体日志信息，可以看到，具体的日志信息比之前的信息更加完善：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2020</span>-09-<span class="number">24</span> <span class="number">20</span>:<span class="number">11</span>:<span class="number">59.078</span> [nioEventLoopGroup-<span class="number">3</span>-<span class="number">1</span>] INFO  io.netty.handler.logging.LoggingHandler [<span class="number">101</span>] - [id: <span class="number">0x2a5e5026</span>, L:/<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">8883</span>] READ: [id: <span class="number">0x926e140c</span>, L:/<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">8883</span> - R:/<span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">58920</span>]</span><br><span class="line"><span class="number">2020</span>-09-<span class="number">24</span> <span class="number">20</span>:<span class="number">11</span>:<span class="number">59.078</span> [nioEventLoopGroup-<span class="number">3</span>-<span class="number">1</span>] INFO  io.netty.handler.logging.LoggingHandler [<span class="number">101</span>] - [id: <span class="number">0x2a5e5026</span>, L:/<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">0</span>:<span class="number">8883</span>] READ COMPLETE</span><br><span class="line"><span class="number">2020</span>-09-<span class="number">24</span> <span class="number">20</span>:<span class="number">11</span>:<span class="number">59.079</span> [nioEventLoopGroup-<span class="number">2</span>-<span class="number">8</span>] ERROR io.netty.util.ResourceLeakDetector [<span class="number">171</span>] - LEAK: ByteBuf.release() was not called before it<span class="string">&#x27;s garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.</span></span><br><span class="line"><span class="string">WARNING: 1 leak records were discarded because the leak record count is limited to 4. Use system property io.netty.leakDetection.maxRecords to increase the limit.</span></span><br><span class="line"><span class="string">Recent access records: 5</span></span><br><span class="line"><span class="string">#5:</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.readBytes(AdvancedLeakAwareCompositeByteBuf.java:476)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.readBytes(AdvancedLeakAwareCompositeByteBuf.java:36)</span></span><br><span class="line"><span class="string">  com.jd.jr.keeplive.front.service.nettyServer.handler.LongRotationServerHandler.getClientMassageInfo(LongRotationServerHandler.java:169)</span></span><br><span class="line"><span class="string">  com.jd.jr.keeplive.front.service.nettyServer.handler.LongRotationServerHandler.handleHttpFrame(LongRotationServerHandler.java:121)</span></span><br><span class="line"><span class="string">  com.jd.jr.keeplive.front.service.nettyServer.handler.LongRotationServerHandler.channelRead(LongRotationServerHandler.java:80)</span></span><br><span class="line"><span class="string">  io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)</span></span><br><span class="line"><span class="string">  io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)</span></span><br><span class="line"><span class="string">  io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)</span></span><br><span class="line"><span class="string">  io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)</span></span><br><span class="line"><span class="string">  ......</span></span><br><span class="line"><span class="string">#4:</span></span><br><span class="line"><span class="string">  Hint: &#x27;</span>LongRotationServerHandler#<span class="number">0</span><span class="string">&#x27; will handle the message from this point.</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:1028)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:36)</span></span><br><span class="line"><span class="string">  io.netty.handler.codec.http.HttpObjectAggregator$AggregatedFullHttpMessage.touch(HttpObjectAggregator.java:359)</span></span><br><span class="line"><span class="string">  ......</span></span><br><span class="line"><span class="string">#3:</span></span><br><span class="line"><span class="string">  Hint: &#x27;</span>HttpServerExpectContinueHandler#<span class="number">0</span><span class="string">&#x27; will handle the message from this point.</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:1028)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:36)</span></span><br><span class="line"><span class="string">  io.netty.handler.codec.http.HttpObjectAggregator$AggregatedFullHttpMessage.touch(HttpObjectAggregator.java:359)</span></span><br><span class="line"><span class="string">  ......</span></span><br><span class="line"><span class="string">#2:</span></span><br><span class="line"><span class="string">  Hint: &#x27;</span>HttpHeartbeatHandler#<span class="number">0</span><span class="string">&#x27; will handle the message from this point.</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:1028)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:36)</span></span><br><span class="line"><span class="string">  io.netty.handler.codec.http.HttpObjectAggregator$AggregatedFullHttpMessage.touch(HttpObjectAggregator.java:359)</span></span><br><span class="line"><span class="string">  ......</span></span><br><span class="line"><span class="string">#1:</span></span><br><span class="line"><span class="string">  Hint: &#x27;</span>IdleStateHandler#<span class="number">0</span><span class="string">&#x27; will handle the message from this point.</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:1028)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AdvancedLeakAwareCompositeByteBuf.touch(AdvancedLeakAwareCompositeByteBuf.java:36)</span></span><br><span class="line"><span class="string">  io.netty.handler.codec.http.HttpObjectAggregator$AggregatedFullHttpMessage.touch(HttpObjectAggregator.java:359)</span></span><br><span class="line"><span class="string">  ......</span></span><br><span class="line"><span class="string">Created at:</span></span><br><span class="line"><span class="string">  io.netty.util.ResourceLeakDetector.track(ResourceLeakDetector.java:237)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AbstractByteBufAllocator.compositeDirectBuffer(AbstractByteBufAllocator.java:217)</span></span><br><span class="line"><span class="string">  io.netty.buffer.AbstractByteBufAllocator.compositeBuffer(AbstractByteBufAllocator.java:195)</span></span><br><span class="line"><span class="string">  io.netty.handler.codec.MessageAggregator.decode(MessageAggregator.java:255)</span></span><br><span class="line"><span class="string">  ......</span></span><br></pre></td></tr></table></figure><p>开启高级的泄漏检测级别后，通过上面异常日志，我们可以看到内存泄漏的具体地方：com.jd.jr.keeplive.front.service.nettyServer.handler.LongRotationServerHandler.getClientMassageInfo(LongRotationServerHandler.java:169)</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/3725d1c2e97fadf24a1bdbd49d84fdda.png" alt="img"></p><p> <strong>如何回收泄漏的ByteBuf</strong></p><p>其实<code>Netty</code>官方也针对这个问题做了专门的讨论，一般的经验法则是，最后访问引用计数对象的一方负责销毁该引用计数对象，具体来说：</p><ul><li>如果一个[发送]组件将一个引用计数的对象传递给另一个[接收]组件，则发送组件通常不需要销毁它，而是由接收组件进行销毁。</li><li>如果一个组件使用了一个引用计数的对象，并且知道没有其他对象将再访问它（即，不会将引用传递给另一个组件），则该组件应该销毁它。</li></ul><p>总结起来主要三个方式： </p><p><strong>方式一：</strong></p><p>手动释放，哪里使用了，使用完就手动释放。</p><p><strong>方式二：</strong></p><p>升级ChannelHandler为SimpleChannelHandler，在SimpleChannelHandler中，Netty对收到的所有消息都调用了ReferenceCountUtil.release(msg)。</p><p><strong>方式三：</strong></p><p>如果处理过程中不确定ByteBuf是否应该被释放，那交给Netty的ReferenceCountUtil.release(msg)来释放，这个方法会判断上下文是否可以释放。</p><p>考虑到长连接前置应用使用的是<code>ChannelHandler</code>，如果升级<code>SimpleChannelHandler</code>对现有API接口变动比较大，同时如果手动释放，不确定是否应该释放风险也大，因此使用方式三，如下：</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/470281787e5db005b7cadef8bdc813d0.png" alt="img">****</p><p>问题修复后，线上服务正常，内存使用率也没有再出现因泄漏而增长，从线上我们增加的日志中看出，<code>FullHttpRequest</code>中<code>ByteBuf</code>内存释放成功。 从此长连接前置内存泄漏的问题彻底解决。</p><p><img src="https://developer.qcloudimg.com/http-save/yehe-1623505/c311b2ed479bc27b9b2e185ce3ae486c.png" alt="img"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>美团的这篇技术文章共 2w+ 字，详细介绍了 GC 基础，总结了 CMS GC 的一些常见问题分析与解决办法，出现线上问题时可以参考下思路：<a href="https://tech.meituan.com/2020/11/12/java-9-cms-gc.html">https://tech.meituan.com/2020/11/12/java-9-cms-gc.html</a></p><p>阿里也有一篇关于JVM内存问题排查的3W字长文，可以结合一起参考：<a href="https://mp.weixin.qq.com/s/zshcVuQreAB8YHwjBL0EmA">https://mp.weixin.qq.com/s/zshcVuQreAB8YHwjBL0EmA</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;JVM启动后一段时间内内存占用飙升&quot;&gt;&lt;a href=&quot;#JVM启动后一段时间内内存占用飙升&quot; class=&quot;headerlink&quot; title=&quot;JVM启动后一段时间内内存占用飙升&quot;&gt;&lt;/a&gt;JVM启动后一段时间内内存占用飙升&lt;/h1&gt;&lt;p&gt;如下，是我们一服务重</summary>
      
    
    
    
    
    <category term="netty" scheme="https://palette-k.github.io/tags/netty/"/>
    
    <category term="JVM" scheme="https://palette-k.github.io/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>MAT排查案例——BeanCopy的正确使用方式</title>
    <link href="https://palette-k.github.io/2025/01/23/MAT%E6%8E%92%E6%9F%A5%E6%A1%88%E4%BE%8B%E2%80%94%E2%80%94BeanCopy%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"/>
    <id>https://palette-k.github.io/2025/01/23/MAT%E6%8E%92%E6%9F%A5%E6%A1%88%E4%BE%8B%E2%80%94%E2%80%94BeanCopy%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/</id>
    <published>2025-01-23T01:51:54.000Z</published>
    <updated>2025-08-28T03:44:22.379Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-问题背景"><a href="#1-问题背景" class="headerlink" title="1 问题背景"></a>1 问题背景</h1><p>线上环境和测试环境均发现过应用卡死，频繁Full GC，原因是因为Metaspace空间（JVM参数为-XX:MaxMetaspaceSize为256m）不足导致OOM，一段时间后服务自动重启，重启后服务正常。因为有配置OOM dump文件生成记录，所以获取到了当时OOM dump文件。</p><p>项目频繁发生<code>metaspace</code>溢出，基于相关知识毫不犹豫的想到以下几点</p><ul><li>项目中使用过多反射</li><li>项目中使用过多的动态代理技术</li><li>项目中使用过多的<code>lambda</code></li></ul><h1 id="2-问题分析"><a href="#2-问题分析" class="headerlink" title="2 问题分析"></a>2 问题分析</h1><h2 id="2-1-OOM-dump文件分析"><a href="#2-1-OOM-dump文件分析" class="headerlink" title="2.1 OOM dump文件分析"></a>2.1 OOM dump文件分析</h2><p>从MAT Leak Suspects分析来看：</p><ul><li>不存在占用内存大的对象。</li><li>整体看下来无明显异常情况。</li></ul><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0ff23793b6b744a2948a22c985c55731~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=957&h=812&s=45433&e=png&b=fdf9f8" alt="MAT Leak Suspects分析"></p><h2 id="2-2-结合资料分析"><a href="#2-2-结合资料分析" class="headerlink" title="2.2 结合资料分析"></a>2.2 结合资料分析</h2><p><strong>Metaspace空间使用</strong></p><ul><li>Metaspace 空间通过 mmap 来从操作系统申请内存，申请的内存会分成一个一个 Metachunk，以 Metachunk 为单位将内存分配给类加载器，每个 Metachunk 对应唯一一个类加载器，一个类加载器可以有多个 Metachunk。</li><li>通过监控可以发现，Metaspace空间使用率为：87%。可能的原因是给类加载器分配的chunk使用率太低，也就是<strong>创建了很多类加载器，而每个类加载器又加载了很少的类。</strong></li></ul><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2edcd1c1f2344050bb11cf30e8699771~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=746&h=265&s=32337&e=png&b=171a1e" alt="Metaspace空间使用情况"></p><p><strong>类加载器情况</strong></p><ul><li>通过arthas查看类加载器使用情况，命令：classloader</li><li>对应用程序执行情况如下，发现DelegatingClassLoader类加载器数量比较多。</li></ul><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a773dee6f152401196e5d9a5bd159579~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=752&h=273&s=18991&e=png&b=000000" alt="类加载器情况"></p><p><strong>DelegatingClassLoader分析</strong></p><p>对dump文件进行分析</p><ul><li>发现dump文件中有较多的DelegatingClassLoader，且持有GeneratedMethodAccessorXXXX，该类是反射用于加载生成的Method类时，使用的加载器。</li></ul><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ab745d110924442698ba7c04945d43c3~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1015&h=408&s=50413&e=png&b=fdfcfc" alt="DelegatingClassLoader分析"></p><ul><li>通过MAT工具查看GeneratedMethodAccessorXXXX对象（List objects with <strong>incoming</strong> refenrece），发现大部分都是业务DTO字段的set方法。</li></ul><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b5653ef71184e049a788baf92408e9d~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=1341&h=169&s=22889&e=png&b=fefdfd" alt="业务字段"></p><h2 id="2-3-关于beanCopy"><a href="#2-3-关于beanCopy" class="headerlink" title="2.3 关于beanCopy"></a>2.3 关于beanCopy</h2><p>运行期间最有可能引起问题的地方无疑是我们大量的使用了<code>beanCopy</code>那么检查项目发现各种方式的<code>beanCopy</code>都有，有<code>apache</code>的<code>BeanUtils</code>，有<code>spring</code>的<code>BeanUtils</code>，有<code>cglib</code>的<code>BeanCopy</code>。并且我们的很多实体都有上百个字段。</p><h3 id="2-3-1-性能测试"><a href="#2-3-1-性能测试" class="headerlink" title="2.3.1 性能测试"></a>2.3.1 性能测试</h3><p>当我们开启阿里代码扫描插件时，如果你使用了 Apache BeanUtils.copyProperties 进行属性拷贝，它会给你一个<strong>非常严重的警告</strong>。因为，<strong>Apache BeanUtils性能较差，可以使用 Spring BeanUtils 或者 Cglib BeanCopier 来代替</strong>。</p><p>执行以下代码，测试这三种beanCopy方法的性能</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">testCglibBeanCopier</span><span class="params">(OriginObject origin, <span class="type">int</span> len)</span> &#123;</span><br><span class="line">        <span class="type">Stopwatch</span> <span class="variable">stopwatch</span> <span class="operator">=</span> Stopwatch.createStarted();</span><br><span class="line">        System.out.println();</span><br><span class="line">        System.out.println(<span class="string">&quot;================cglib BeanCopier执行&quot;</span> + len + <span class="string">&quot;次================&quot;</span>);</span><br><span class="line">        <span class="type">DestinationObject</span> <span class="variable">destination3</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DestinationObject</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            <span class="type">BeanCopier</span> <span class="variable">copier</span> <span class="operator">=</span> BeanCopier.create(OriginObject.class, DestinationObject.class, <span class="literal">false</span>);</span><br><span class="line">            copier.copy(origin, destination3, <span class="literal">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        stopwatch.stop();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;testCglibBeanCopier 耗时: &quot;</span> + stopwatch.elapsed(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">testApacheBeanUtils</span><span class="params">(OriginObject origin, <span class="type">int</span> len)</span></span><br><span class="line">            <span class="keyword">throws</span> IllegalAccessException, InvocationTargetException &#123;</span><br><span class="line">        <span class="type">Stopwatch</span> <span class="variable">stopwatch</span> <span class="operator">=</span> Stopwatch.createStarted();</span><br><span class="line">        System.out.println();</span><br><span class="line">        System.out.println(<span class="string">&quot;================apache BeanUtils执行&quot;</span> + len + <span class="string">&quot;次================&quot;</span>);</span><br><span class="line">        <span class="type">DestinationObject</span> <span class="variable">destination2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DestinationObject</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            BeanUtils.copyProperties(destination2, origin);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stopwatch.stop();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;testApacheBeanUtils 耗时: &quot;</span> + stopwatch.elapsed(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">testSpringFramework</span><span class="params">(OriginObject origin, <span class="type">int</span> len)</span> &#123;</span><br><span class="line">        <span class="type">Stopwatch</span> <span class="variable">stopwatch</span> <span class="operator">=</span> Stopwatch.createStarted();</span><br><span class="line">        System.out.println(<span class="string">&quot;================springframework执行&quot;</span> + len + <span class="string">&quot;次================&quot;</span>);</span><br><span class="line">        <span class="type">DestinationObject</span> <span class="variable">destination</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DestinationObject</span>();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            org.springframework.beans.BeanUtils.copyProperties(origin, destination);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stopwatch.stop();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;testSpringFramework 耗时: &quot;</span> + stopwatch.elapsed(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">testApacheBeanUtilsPropertyUtils</span><span class="params">(OriginObject origin, <span class="type">int</span> len)</span></span><br><span class="line">            <span class="keyword">throws</span> IllegalAccessException, InvocationTargetException, NoSuchMethodException &#123;</span><br><span class="line">        <span class="type">Stopwatch</span> <span class="variable">stopwatch</span> <span class="operator">=</span> Stopwatch.createStarted();</span><br><span class="line">        System.out.println();</span><br><span class="line">        System.out.println(<span class="string">&quot;================apache BeanUtils PropertyUtils执行&quot;</span> + len + <span class="string">&quot;次================&quot;</span>);</span><br><span class="line">        <span class="type">DestinationObject</span> <span class="variable">destination2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DestinationObject</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++) &#123;</span><br><span class="line">            PropertyUtils.copyProperties(destination2, origin);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        stopwatch.stop();</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">&quot;testApacheBeanUtilsPropertyUtils 耗时: &quot;</span> + stopwatch.elapsed(TimeUnit.MILLISECONDS));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>分别执行1000、10000、100000、1000000次耗时数(毫秒):</p><table><thead><tr><th><strong>工具名称</strong></th><th><strong>执行1000次耗时</strong></th><th>10000次</th><th><strong>100000次</strong></th><th><strong>1000000次</strong></th></tr></thead><tbody><tr><td>Apache BeanUtils</td><td>390ms</td><td>854ms</td><td>1763ms</td><td>8408ms</td></tr><tr><td>Apache PropertyUtils</td><td>26ms</td><td>221ms</td><td>352ms</td><td>2663ms</td></tr><tr><td>spring BeanUtils</td><td>39ms</td><td>315ms</td><td>373ms</td><td>949ms</td></tr><tr><td>Cglib BeanCopier</td><td>64ms</td><td>144ms</td><td>171ms</td><td>309ms</td></tr></tbody></table><p>结论:</p><ol><li>Apache BeanUtils主要集中了各种丰富的功能(日志、转换、解析等等),导致性能变差，不建议使用。</li><li>Apache PropertyUtils100000次以内性能还能接受,到百万级别性能就比较差了,可酌情考虑。</li><li>spring BeanUtils和BeanCopier性能较好,如果对性能有特别要求,可使用BeanCopier,不然spring BeanUtils也是可取的。</li></ol><h3 id="2-3-2-metaspace分析"><a href="#2-3-2-metaspace分析" class="headerlink" title="2.3.2 metaspace分析"></a>2.3.2 metaspace分析</h3><p>研究完了性能，确实如阿里代码扫描插件所说，使用 Spring BeanUtils 或者 Cglib BeanCopier 是最稳妥的。但是本次的metaspace溢出，又暴露出了另一个问题：项目中 beanCopy 的使用导致 classLoader 的数量骤增。</p><p>先测试下<code>spring</code>的<code>BeanUtils</code>：</p><p>使用<code>jcmd</code> 命令查看下<code>metaspace</code>的使用情况发现前<code>15</code>次调用情况如下<code>jcmd 23328 VM.classloader_stats</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Total = 3                                                     1276   7915520   7636416</span><br><span class="line">ChunkSz: Total size of all allocated metaspace chunks</span><br><span class="line">BlockSz: Total size of all allocated metaspace blocks (each chunk has several blocks)</span><br></pre></td></tr></table></figure><p>而在<code>15</code>次之后的情况如下<code>jcmd 23328 VM.classloader_stats</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Total = 1035                                                  2321  14387200  10678952</span><br><span class="line">ChunkSz: Total size of all allocated metaspace chunks</span><br><span class="line">BlockSz: Total size of all allocated metaspace blocks (each chunk has several blocks)</span><br></pre></td></tr></table></figure><p>可以看到在<code>15</code>次前<code>classloader</code>一直是<code>3</code>个，而<code>15</code>次之后增长到了<code>1035</code>个往后稳定在<code>1035</code>个</p><p>那么我们在同样的条件下测试下<code>spring</code>提供的另一个基于<code>cglib</code>的<code>BeanCopy</code>结果如下:</p><p>前<code>15</code>次调用</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Total = 3                                                      805   6180864   5358144</span><br><span class="line">ChunkSz: Total size of all allocated metaspace chunks</span><br><span class="line">BlockSz: Total size of all allocated metaspace blocks (each chunk has several blocks)</span><br></pre></td></tr></table></figure><p><code>15</code>次后调用</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Total = 4                                                      820   6187008   5439976</span><br><span class="line">ChunkSz: Total size of all allocated metaspace chunks</span><br><span class="line">BlockSz: Total size of all allocated metaspace blocks (each chunk has several blocks)</span><br></pre></td></tr></table></figure><p>我们发现<code>cglib</code>的<code>beanCopy</code>仅仅增加了一个<code>classloader</code>，并且对<code>metaspace</code>的使用增加幅度非常小。</p><p>意味着项目中如果大量使用了反射方式的<code>beancopy</code>就会创建大量的<code>DelegatingClassLoader</code>，那么这里为什么是15次之后才出现呢？我们顺着<a href="https://so.csdn.net/so/search?q=BeanUtils&spm=1001.2101.3001.7020">BeanUtils</a>.copyProperties方法点进去，在使用反射调用<code>method.Invoke()</code>的时候，当你的使用次数超过<code>15</code>次就会为每一个<code>method</code>生成一个<code>class</code>。就会导致<code>metaspace</code>极速膨胀。</p><p>而在<code>cglib</code>方式下则是以类为单位，所以同样也走到了相关的代码，但是它只生成了一个<code>DelegatingClassLoader</code>，所以它的<code>metaspace</code>内存占用比反射来的小很多。</p><h1 id="3-结论"><a href="#3-结论" class="headerlink" title="3 结论"></a>3 结论</h1><p>此处我们已经很明确这个问题出在项目中大量使用的反射的<code>beancopy</code>导致<code>metaspace</code>溢出，理论上来说这种情况可以通过调整-XX:MaxMetaspaceSize为512m解决问题，但是更好的解决方案是尽量使用<code>cglib</code>方式的<code>beancopy</code>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-问题背景&quot;&gt;&lt;a href=&quot;#1-问题背景&quot; class=&quot;headerlink&quot; title=&quot;1 问题背景&quot;&gt;&lt;/a&gt;1 问题背景&lt;/h1&gt;&lt;p&gt;线上环境和测试环境均发现过应用卡死，频繁Full GC，原因是因为Metaspace空间（JVM参数为-XX</summary>
      
    
    
    
    
    <category term="JVM" scheme="https://palette-k.github.io/tags/JVM/"/>
    
    <category term="MAT" scheme="https://palette-k.github.io/tags/MAT/"/>
    
  </entry>
  
  <entry>
    <title>JVM内存分析工具MAT的使用方式</title>
    <link href="https://palette-k.github.io/2025/01/16/JVM%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7MAT%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/"/>
    <id>https://palette-k.github.io/2025/01/16/JVM%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7MAT%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F/</id>
    <published>2025-01-16T05:53:54.000Z</published>
    <updated>2025-08-28T03:44:38.927Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MAT工具简介"><a href="#MAT工具简介" class="headerlink" title="MAT工具简介"></a>MAT工具简介</h1><p>MAT（全名：Memory Analyzer Tool），是一款快速便捷且功能强大丰富的 JVM 堆内存离线分析工具。其通过展现 JVM 异常时所记录的运行时堆转储快照（Heap dump）状态（正常运行时也可以做堆转储分析），帮助定位内存泄漏问题或优化大内存消耗逻辑。</p><p>一般来说，线上出现GC问题会有异常告警，此时应该做的是下线一个节点，导出dump文件保留事故现场，然后对线上服务做回滚&#x2F;灰度处理，或者调整堆内存大小，或者重启服务器&#x2F;手动触发FullGC快速回收内存，先保证服务正常运行，然后再用1天的时间对dump文件进行分析，排查出异常问题并进行修复。</p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><h3 id="Heap-Dump"><a href="#Heap-Dump" class="headerlink" title="Heap Dump"></a>Heap Dump</h3><p>Heap Dump 是 Java 进程堆内存在一个时间点的快照，其主要结构包含：</p><ul><li>所有对象的实例信息：对象所属类名、基础类型和引用类型的属性等</li><li>所有类信息：类加载器、类名、继承关系、静态属性</li><li>GC Root：GC Root 代表通过可达性分析来判定 JVM 对象是否存活的起始集合。JVM 采用追踪式垃圾回收（Tracing GC）模式，<strong>从所有 GC Roots 出发通过引用关系可以关联的对象</strong>就是存活的（且不可回收），其余的不可达的对象（Unreachable object：如果无法从 GC Root 找到一条引用路径能到达某对象，则该对象为Unreachable object）可以回收。</li><li>线程栈及局部变量：快照生成时刻的所有线程的线程栈帧，以及每个线程栈的局部变量</li></ul><h3 id="Shallow-Heap"><a href="#Shallow-Heap" class="headerlink" title="Shallow Heap"></a>Shallow Heap</h3><p>Shallow Heap 代表一个<strong>对象结构自身</strong>所占用的内存大小，不包括其属性引用对象所占的内存。</p><h3 id="Retained-Heap"><a href="#Retained-Heap" class="headerlink" title="Retained Heap"></a>Retained Heap</h3><p>Retained Heap 是一个对象被 GC 回收后，可释放的内存大小。如果一个对象A同时被两个对象B和C引用，那么B回收后不能释放掉A，因为A也被C引用了。</p><h3 id="Dominator-tree"><a href="#Dominator-tree" class="headerlink" title="Dominator tree"></a>Dominator tree</h3><p>如果所有指向对象 Y 的路径都经过对象 X，则 X 支配（dominate） Y</p><h3 id="QQL"><a href="#QQL" class="headerlink" title="QQL"></a>QQL</h3><p>OQL 是类似于 SQL 的 MAT 专用统一查询语言，可以根据复杂的查询条件对 dump 文件中的类或者对象等数据进行查询筛选。</p><h3 id="references"><a href="#references" class="headerlink" title="references"></a>references</h3><p>outgoing references、incoming references 可以直击对象间依赖关系，MAT 也提供了链式快速操作。</p><ul><li>outgoing references：对象引用的外部对象（注意不包含对象的基本类型属性。基本属性内容可在 inspector 查看）。</li><li>incoming references：直接引用了当前对象的对象，每个对象的 incoming references 可能有 0 到多个。</li></ul><h1 id="MAT功能概述"><a href="#MAT功能概述" class="headerlink" title="MAT功能概述"></a>MAT功能概述</h1><p>熟练掌握 MAT 是 Java 高手的必备能力，但实践时大家往往需面对众多功能，可以根据这个脑图去寻找一些使用MAT的切入点，分析出异常点。</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8bb5e21bfb5a4a4d855e5e0ee80206d7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>菜单-各功能的使用入口</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/822515f03c704e61ae8967048a36b4b3~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><h2 id="1-内存分布详解及实战"><a href="#1-内存分布详解及实战" class="headerlink" title="1 内存分布详解及实战"></a>1 内存分布详解及实战</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><strong>功能：</strong>展现堆内存大小、对象数量、class 数量、class loader 数量、GC Root 数量、环境变量、线程概况等全局统计信息。</p><p><strong>使用入口</strong>：MAT 主界面 → Heap Dump Overview。</p><p><strong>举例</strong>：下面是对象数量、class loader 数量、GC Root 数量，可以看出 class loader 存在异常。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cdfda3beda914ae288b96f261d0e58ca~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p><strong>使用入口</strong>：MAT 主界面 → Java Basics -&gt;  Thread Overview and stack。</p><p>下图是线程概况，可以查看每个线程名、线程的 Retained Heap、daemon 属性等。</p><p><img src="https://i0.hdslb.com/bfs/article/60d0bc0af37234d6bfadce5af151e50e171301454.png" alt="image-20250116142503899"></p><p><strong>使用场景</strong> 全局概览呈现全局统计信息，重点查看整体是否有异常数据，所以有效信息有限，下面几种场景有一定帮助：</p><ul><li>方法区溢出时（Java 8后不使用方法区，对应堆溢出），查看 class 数量异常多，可以考虑是否为动态代理类异常载入过多或类被反复重复加载。</li><li>方法区溢出时，查看 class loader 数量过多，可以考虑是否为自定义 class loader 被异常循环使用。</li><li>GC Root 过多，可以查看 GC Root 分布，理论上这种情况极少会遇到，笔者只在 JNI 使用一个存在 BUG 的库时遇到过。</li><li>线程数过多，一般是频繁创建线程但无法执行结束，从概览可以了解异常表象，具体原因可以参考本文线程分析部分内容，此处不展开。</li></ul><h3 id="Dominator-tree-1"><a href="#Dominator-tree-1" class="headerlink" title="Dominator tree"></a>Dominator tree</h3><p><em>使用频率top 1，是高效分析 Dump 必看的功能</em></p><p><strong>功能</strong></p><ul><li>展现对象的支配关系图，并给出对象支配内存的大小（支配内存等同于 Retained Heap，即其被 GC 回收可释放的内存大小）</li><li>支持排序、支持按 package、class loader、super class、class 聚类统计</li></ul><p><strong>使用入口</strong>：全局支配树： MAT 主界面 → Dominator tree。</p><p><strong>举例：</strong> 下图中查看 Dominator tree</p><p><img src="https://i0.hdslb.com/bfs/article/f2517439a70d3c760d94697717f279f9171301454.png" alt="image-20250116142731886"></p><p>有些情况下可能看不太出来支配起点对象的 Reatained Heap 占用很大内存，这时可以按 class、package、class loader做聚合，进而定位目标。</p><p><img src="https://i0.hdslb.com/bfs/article/3263fc79d9be243a86d76e2aa51c08c0171301454.png" alt="image-20250116142918095"></p><p>可以定位到String对象支配内存较多，然后结合代码进一步分析具体原因。</p><p><img src="https://i0.hdslb.com/bfs/article/d4955f9a8d6ec4b684188d7f94027556171301454.png" alt="image-20250116143212144"></p><p>在一些操作后定位到异常持有 Retained Heap 对象后（如从代码看对象应该被回收），可以获取对象的直接支配者，操作方式如下。</p><p><img src="https://i0.hdslb.com/bfs/article/2439777d8f5871a529422f5e2818ffe3171301454.png" alt="image-20250116143524870"></p><h3 id="Histogram-直方图"><a href="#Histogram-直方图" class="headerlink" title="Histogram 直方图"></a>Histogram 直方图</h3><p><em>使用概率 Top 2</em></p><p><strong>功能</strong></p><ul><li>罗列每个类实例的数量、类实例累计内存占比，包括自身内存占用量（Shallow Heap）及支配对象的内存占用量（Retain Heap）。</li><li>支持按对象数量、Retained Heap、Shallow Heap（默认排序）等指标排序；支持按正则过滤；支持按 package、class loader、super class、class 聚类统计，</li></ul><p><strong>使用入口</strong>：MAT 主界面 → Histogram；注意 Histogram 默认不展现 Retained Heap，可以使用计算器图标计算，如下图所示。</p><p><img src="https://i0.hdslb.com/bfs/article/d9802f9a77d226c351fefcf3138bdbf0171301454.png" alt="image-20250116144018648"></p><p>使用技巧</p><ul><li><p>Integer，String 和 Object[] 一般不直接导致内存问题。为更好的组织视图，可以通过 class loader 或 package 分组进一步聚焦，如下图。</p><p><img src="https://i0.hdslb.com/bfs/article/61bcd368a76d272a9aa68cd335481a20171301454.png" alt="image-20250116144148218"></p></li><li><p>可以在 Histogram 的某个类继续使用 outgoing reference 查看对象分布，进而定位哪些对象是大头</p><p><img src="https://i0.hdslb.com/bfs/article/dc1bde161a10e1bd7e03fa100c23c294171301454.png" alt="image-20250116144429449"></p></li></ul><p>List objects找到大对象后，可以点击Path To GC Roots或incoming reference，查看大数组的引用路径。</p><h3 id="Leak-Suspects"><a href="#Leak-Suspects" class="headerlink" title="Leak Suspects"></a>Leak Suspects</h3><p><strong>功能</strong>：具备自动检测内存泄漏功能，罗列可能存在内存泄漏的问题点。</p><p><strong>使用入口</strong>：一般当存在明显的内存泄漏时，分析完Dump文件后就会展现，也可以如下图在 MAT 主页 → Leak Suspects。</p><p><strong>使用场景</strong>：需要查看引用链条上占用内存较多的可疑对象。这个功能可解决一些基础问题，但复杂的问题往往帮助有限。</p><p><img src="https://i0.hdslb.com/bfs/article/3d3661a118e2908ac681243b6c9d7386171301454.png" alt="image-20250116144654696"></p><p>点击Keywords中的“Details”，获取实例到GC Root的最短路径、dominator路径的详细信息</p><p><img src="https://i0.hdslb.com/bfs/article/3ff950b85e0d87dd149507e2da5f0c86171301454.png" alt="image-20250116144804972"></p><p><img src="https://i0.hdslb.com/bfs/article/519d151488ec3dd0b22144a4b0772cc6171301454.png" alt="image-20250116144819555"></p><h3 id="Top-Consumers"><a href="#Top-Consumers" class="headerlink" title="Top Consumers"></a>Top Consumers</h3><p><strong>功能</strong>：最大对象报告，可以展现哪些类、哪些 class loader、哪些 package 占用最高比例的内存，其功能 Histogram 及 Dominator tree 也都支持。</p><p><strong>使用场景</strong>：应用程序发生内存泄漏时，查看哪些泄漏的对象通常在 Dump 快照中会占很大的比重。因此，对简单的问题具有较高的价值。</p><h3 id="综合案例一"><a href="#综合案例一" class="headerlink" title="综合案例一"></a>综合案例一</h3><p>首先进入 Dominator tree，可以看出是 SameContentWrapperContainerProxy 对象与 main 线程两者持有99%内存不能释放导致 OOM。</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9fe24e47a05042b7b61a103e3c7dbf4b~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8d953a502fdf40c6ad95a5a992ec33fb~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>先来看方向一，在 Heap Dump Overview 中可以快速定位到 Number of class loaders 数达50万以上，这种基本属于异常情况，如下图所示。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bc64b31b8e484ca88e02590b42f82c74~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>使用 Class Loader Explorer 分析工具，此时会展现类加载详情，可以看到有524061个 class loader。我们的案例中仅有ClassLoaderOOMOps 这样的自定义类加载器，所以很快可以定位到问题。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bf60312fd4894df98ccd7573a1c0c5c6~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9309e3ecfa4e48dc8b98ab2f1e4e08d6~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>如果类加载器较多，不能确定是哪个引发问题，则可以将所有的 class loader对象按类做聚类，如下图所示。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3dad1e14bad84ced8f906bf162dad4c5~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>Histogram 会根据 class 聚合，并展现对象数量级其 Shallow Heap 及 Retained Heap（如Retained Heap项目为空，可以点击下图中计算机的图标并计算 Retained Heap），可以看到 ClassLoaderOOMOps 有524044个对象，其 Retain Heap 占据了370M以上（上述代码是100M左右）。</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/09f7a1ecbe1d495cb144c16f676f9888~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>使用 incoming references，可以找到创建的代码位置。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b8128a34a4fb42a7a28d4f7c69313e12~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p>再来看方向二，同样在占据319M内存的 Obejct 数组采用 incoming references 查看引用路径，也很容易定位到具体代码位置。并且从下图中我们看出，Dominator tree 的起点并不一定是 GC根，且通过 Dominator tree 可能无法获取到最开始的创建路径，但 incoming references 是可以的。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/64fac354fd204b3f93c43d48a25c0646~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><h2 id="2-对象间依赖详解及实战"><a href="#2-对象间依赖详解及实战" class="headerlink" title="2 对象间依赖详解及实战"></a>2 对象间依赖详解及实战</h2><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><p><em><strong>注：笔者使用频率 Top2</strong></em></p><p><strong>功能</strong>：在对象引用图中查看某个特定对象的所有引用关系（提供对象对其他对象或基本类型的引用关系，以及被外部其他对象的引用关系）。通过任一对象的直接引用及间接引用详情（主要是属性值及内存占用），提供完善的依赖链路详情。</p><p><strong>使用入口</strong>：目标域右键 → List objects → with outgoing references&#x2F;with incoming references.</p><p><strong>使用场景</strong></p><ul><li>outgoing reference：查看对象所引用的对象，并支持链式传递操作。如查看一个大对象持有哪些内容，当一个复杂对象的 Retained Heap 较大时，通过 outgoing reference 可以查看由哪个属性引发。下图中 A 支配 F，且 F 占据大量内存，但优化时 F 的直接支配对象 A 无法修改。可通过 outgoing reference 看关系链上 D、B、E、C，并结合业务逻辑优化中间环节，这依托 dominator tree 是做不到的。</li><li>incoming reference：查看对象被哪些对象引用，并支持链式传递操作。如查看一个大对象都被哪些对象引用，下图中 K 占内存大，所以 J 的 Retained Heap 较大，目标是从 GC Roots 摘除 J 引用，但在 Dominator tree 上 J 是树根，无法获取其被引用路径，可通过 incoming reference 查看关系链上的 H、X、Y ，并结合业务逻辑将 J 从 GC Root 链摘除。 <img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bde68d299620415cb34f5d6cbbeeeae7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li></ul><h3 id="Thread-overview"><a href="#Thread-overview" class="headerlink" title="Thread overview"></a>Thread overview</h3><p><strong>功能</strong>：展现转储 dump 文件时线程执行栈、线程栈引用的对象等详细状态，也提供各线程的 Retained Heap 等关联内存信息。</p><p><strong>使用入口</strong>：MAT 主页 → Thread overview</p><p><strong>使用场景</strong></p><ul><li>查看不同线程持有的内存占比，定位高内存消耗线程（开发技巧：不要直接使用 Thread 或 Executor 默认线程名避免全部混合在一起，使用线程尽量自命名方便识别，如下图中 ThreadAndListHolder-thread 是自定义线程名，可以很容易定位到具体代码）</li><li>查看线程的执行栈及变量，结合业务代码了解线程阻塞在什么地方，以及无法继续运行释放内存，如下图中 ThreadAndListHolder-thread 阻塞在 sleep 方法。 <img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cfcded48fb234e0682bdc6d872f03717~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li></ul><h3 id="Path-To-GC-Roots"><a href="#Path-To-GC-Roots" class="headerlink" title="Path To GC Roots"></a>Path To GC Roots</h3><p><strong>功能</strong>：提供任一对象到 GC Root 的路径详情。</p><p><strong>使用入口</strong>：目标域右键 → Path To GC Roots</p><p><strong>使用场景</strong>：有时你确信已经处理了大的对象集合但依然无法回收，该功能能快速定位异常对象不能被 GC 回收的原因，直击异常对象到 GC Root 的引用路径。比 incoming reference 的优势是屏蔽掉很多不需关注的引用关系，比 Dominator tree 的优势是可以得到更全面的信息。</p><p><em>小技巧：在排查内存泄漏时，建议选择 exclude all phantom&#x2F;weak&#x2F;soft etc.references 排除虚引用&#x2F;弱引用&#x2F;软引用等的引用链，因为被虚引用&#x2F;弱引用&#x2F;软引用的对象可以直接被 GC 给回收，聚焦在对象否还存在 Strong 引用链即可。</em></p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3919a0973e6f4ac0b4fe3460e24fec75~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><h3 id="class-loader-分析"><a href="#class-loader-分析" class="headerlink" title="class loader 分析"></a>class loader 分析</h3><p><strong>功能</strong></p><ul><li>查看堆中所有 class loader 的使用情况（入口：MAT 主页菜单蓝色桶图标 → Java Basics → Class Loader Explorer）。</li><li>查看堆中被不同class loader 重复加载的类（入口：MAT 主页菜单蓝色桶图标 → Java Basics → Duplicated Classes）。</li></ul><p><strong>使用场景</strong></p><ul><li>当从 Heap dump overview 了解到系统中 class loader 过多，导致占用内存异常时进入更细致的分析定位根因时使用。</li><li>解决 NoClassDefFoundError 问题或检测 jar 包是否被重复加载</li></ul><p>具体使用方法在 2.6 及 3.5 两节的案例中有介绍。</p><h3 id="综合案例二"><a href="#综合案例二" class="headerlink" title="综合案例二"></a>综合案例二</h3><p><strong>使用工具项</strong>：class loader（重复类检测）、inspector、正则检索。</p><p><strong>异常现象</strong> ：运行时报 NoClassDefFoundError，在 classpath 中有两个不同版本的同名类。</p><p><strong>分析过程</strong></p><ol><li><p>进入 MAT 已加载的重复类检测功能，方式如下图。 <img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60fbe324fe9d416c90c2e659b4f971c7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p></li><li><p>可以看到所有重复的类，以及相关的类加载器，如下图。 <img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/2cdae3fc7b614c01a8047e3c024b4680~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p></li><li><p>根据类名，在<code>&lt;Regex&gt;</code>框中输入类名可以过滤无效信息。</p></li><li><p>选中目标类，通过Inspector视图，可以看到被加载的类具体是在哪个jar包里。（本例中重复的类是被 URLClassloader 加载的，右键点击 “_context” 属性，最后点击 “Go Into”，在弹出的窗口中的属性 “_war” 值是被加载类的具体包位置）</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db89543ca6b544cf8e36252aa08a60be~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"> <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3be497af48b4c5b9ea96b2ae2a9c967~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p></li></ol><h2 id="3-对象状态详解及实战"><a href="#3-对象状态详解及实战" class="headerlink" title="3 对象状态详解及实战"></a>3 对象状态详解及实战</h2><h3 id="inspector"><a href="#inspector" class="headerlink" title="inspector"></a>inspector</h3><p><strong>功能</strong>：MAT 通过 inspector 面板展现对象的详情信息，如静态属性值及实例属性值、内存地址、类继承关系、package、class loader、GC Roots 等详情数据。</p><p><strong>使用场景</strong></p><ul><li>当内存使用量与业务逻辑有较强关联的场景，通过 inspector 可以通过查看对象具体属性值。比如：社交场景中某个用户对象的好友列表异常，其 List 长度达到几亿，通过  inspector 面板获取到异常用户 ID，进而从业务视角继续排查属于哪个用户，本例可能有系统账号，与所有用户是好友。</li><li>集合等类型的使用会较多，如查看 ArrayList 的 size 属性也就了解其大小。</li></ul><p><strong>举例</strong>：下图中左边的 Inspector 窗口展现了地址 0x125754cf8 的 ArrayList 实例详情，包括 modCount 等并不会在 outgoing references 展现的基本属性。 <img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b5067f8c3bc94397ad829ae9ee882b34~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><h3 id="集合状态"><a href="#集合状态" class="headerlink" title="集合状态"></a>集合状态</h3><p><strong>功能</strong>：帮助更直观的了解系统的内存使用情况，查找浪费的内存空间。</p><p><strong>使用入口</strong>：MAT 主页 → Java Collections → 填充率&#x2F;Hash冲突等功能。</p><p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/409f4fd84bef43dfabdd9f6337615917~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></p><p><strong>使用场景</strong></p><ul><li>通过对 ArrayList 或数组等集合类对象按填充率聚类，定位稀疏或空集合类对象造成的内存浪费。</li><li>通过 HashMap 冲突率判定 hash 策略是否合理。</li></ul><p>具体使用方法在 4.3 节案例详细介绍。</p><h3 id="综合案例三"><a href="#综合案例三" class="headerlink" title="综合案例三"></a>综合案例三</h3><p><strong>使用工具项</strong>：Dominator tree、Histogram、集合 ratio。</p><p><strong>异常现象</strong> ：程序 OOM，且 Dominator tree 无大对象，通过 Histogram 了解到多个 ArrayList 占据大量内存，期望通过减少 ArrayList 优化程序。</p><p><strong>分析过程</strong></p><ol><li>使用 Dominator tree 查看并无高占比起点。 <img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2f44f9216f94b08bc3bdf7107d5a737~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li><li>使用 Histogram 定位到 ListHolder 及 ArrayList 占比过高，经过业务分析很多 List 填充率很低浪费内存。 <img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/de3c98f88cf14561ae1117e2f8e55cd2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li><li>查看 ArrayList 的填充率，MAT 首页 → Java Collections → Collection Fill Ratio。 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/44000e6e5c2946e18ed1703d68aec244~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li><li>查看类型填写 java.util.ArrayList。 <img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ad7db951d8254ebaa9c85f07e799f887~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li><li>从结果可以看出绝大部分 ArrayList 初始申请长度过大。 <img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fe6c558fd665443c874d41c920a64018~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp" alt="img"></li></ol>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;MAT工具简介&quot;&gt;&lt;a href=&quot;#MAT工具简介&quot; class=&quot;headerlink&quot; title=&quot;MAT工具简介&quot;&gt;&lt;/a&gt;MAT工具简介&lt;/h1&gt;&lt;p&gt;MAT（全名：Memory Analyzer Tool），是一款快速便捷且功能强大丰富的 JVM 堆</summary>
      
    
    
    
    
    <category term="JVM" scheme="https://palette-k.github.io/tags/JVM/"/>
    
    <category term="MAT" scheme="https://palette-k.github.io/tags/MAT/"/>
    
  </entry>
  
</feed>
